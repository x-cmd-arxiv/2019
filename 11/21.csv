"1911.08993","Maximilian Engel","Maximilian Engel and Christian Kuehn","A Random Dynamical Systems Perspective on Isochronicity for Stochastic
  Oscillations",,,"10.1007/s00220-021-04077-z",,"math.DS math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For an attracting periodic orbit (limit cycle) of a deterministic dynamical
system, one defines the isochron for each point of the orbit as the
cross-section with fixed return time under the flow. Equivalently, isochrons
can be characterized as stable manifolds foliating neighborhoods of the limit
cycle or as level sets of an isochron map. In recent years, there has been a
lively discussion in the mathematical physics community on how to define
isochrons for stochastic oscillations, i.e. limit cycles or heteroclinic cycles
exposed to stochastic noise. The main discussion has concerned an approach
finding stochastic isochrons as sections of equal expected return times versus
the idea of considering eigenfunctions of the backward Kolmogorov operator. We
discuss the problem in the framework of random dynamical systems and introduce
a new rigorous definition of stochastic isochrons as random stable manifolds
for random periodic solutions with noise-dependent period. This allows us to
establish a random version of isochron maps whose level sets coincide with the
random stable manifolds. Finally, we discuss links between the random dynamical
systems interpretation and the equal expected return time approach via averaged
quantities.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:06:43 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 11:08:29 GMT""}]","2021-08-24"
"1911.08995","Okan K\""op\""ukl\""u","Yinglong Feng, Shuncheng Wu, Okan K\""op\""ukl\""u, Xueyang Kang,
  Federico Tombari","Unsupervised Monocular Depth Prediction for Indoor Continuous Video
  Streams",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies unsupervised monocular depth prediction problem. Most of
existing unsupervised depth prediction algorithms are developed for outdoor
scenarios, while the depth prediction work in the indoor environment is still
very scarce to our knowledge. Therefore, this work focuses on narrowing the gap
by firstly evaluating existing approaches in the indoor environments and then
improving the state-of-the-art design of architecture. Unlike typical outdoor
training dataset, such as KITTI with motion constraints, data for indoor
environment contains more arbitrary camera movement and short baseline between
two consecutive images, which deteriorates the network training for the pose
estimation. To address this issue, we propose two methods: Firstly, we propose
a novel reconstruction loss function to constraint pose estimation, resulting
in accuracy improvement of the predicted disparity map; secondly, we use an
ensemble learning with a flipping strategy along with a median filter, directly
taking operation on the output disparity map. We evaluate our approaches on the
TUM RGB-D and self-collected datasets. The results have shown that both
approaches outperform the previous state-of-the-art unsupervised learning
approaches.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:08:10 GMT""}]","2019-11-21"
"1911.08996","Elizabeth Heron","Carlos Pinto, Michael Gill, Schizophrenia Working Group of the
  Psychiatric Genomics Consortium, Elizabeth A. Heron","Can artificial neural networks supplant the polygene risk score for risk
  prediction of complex disorders given very large sample sizes?",,,,,"q-bio.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Genome-wide association studies (GWAS) provide a means of examining the
common genetic variation underlying a range of traits and disorders. In
addition, it is hoped that GWAS may provide a means of differentiating affected
from unaffected individuals. This has potential applications in the area of
risk prediction. Current attempts to address this problem focus on using the
polygene risk score (PRS) to predict case-control status on the basis of GWAS
data. However this approach has so far had limited success for complex traits
such as schizophrenia (SZ). This is essentially a classification problem.
Artificial neural networks (ANNs) have been shown in recent years to be highly
effective in such applications. Here we apply an ANN to the problem of
distinguishing SZ patients from unaffected controls. We compare the
effectiveness of the ANN with the PRS in classifying individuals by
case-control status based only on genetic data from a GWAS. We use the
schizophrenia dataset from the Psychiatric Genomics Consortium (PGC) for this
study. Our analysis indicates that the ANN is more sensitive to sample size
than the PRS. As larger and larger sample sizes become available, we suggest
that ANNs are a promising alternative to the PRS for classification and risk
prediction for complex genetic disorders.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:08:27 GMT""}]","2019-11-21"
"1911.08997","Nikolay Kozyrev","Nikolay Kozyrev","Partial breaking of arbitrary amount of d=3 supersymmetry","12 pages, no figures","Phys. Rev. D 102, 026011 (2020)","10.1103/PhysRevD.102.026011",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Among the solutions of string theory and supergravity which preserve some
fraction of supersymmetry, the best known are those that leave one half of the
supersymmetry unbroken, and there is a large number of field theory models with
this pattern of supersymmetry breaking. However, a lot of brane configurations
exist which preserve only $1/4$, $1/8$ or more exotic fractions of
supersymmetry, and field theory side of these systems remains largely
unexplored. To find whether the formalism of nonlinear realizations is useful
in construction of models of this type, we consider the systems of some $N_0$
scalar and vector $N=1$, $d=3$ Goldstone supermultiplets. We find that it is
possible to construct an $SO(N_0)$ invariant theory of $N_0$ scalar multiplets
with $N_0$ broken supersymmetries. For $N_0=3$ or $N_0\geq 5$ its action is not
of Nambu-Goto type and its structure remains universal for arbitrary $N_0$. The
cases of $N_0=1,2$ correspond to the membranes in $D=4$ and $D=5$,
respectively, while for $N_0=4$ some arbitrariness in the action remains, and
with proper choice of parameters, it is possible to obtain the action of the
membrane in $D=7$ in the bosonic limit. It is also shown that the $SO(N_0)$
invariant action of $N_0$ vector multiplets with $1/N_0$ pattern of
supersymmetry breaking does not exist for arbitrary $N_0$.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:09:41 GMT""}]","2020-07-15"
"1911.08998","Takumi Bessho","Takumi Bessho, Kohei Kawabata, Masatoshi Sato","Topological Classificaton of Non-Hermitian Gapless Phases: Exceptional
  Points and Bulk Fermi Arcs","6 pages, 1 figure, 3 tables, submitted to the Proceedings of SCES
  2019",,"10.7566/JPSCP.30.011098",,"cond-mat.mes-hall math-ph math.MP physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We provide classification of gapless phases in non-Hermitian systems
according to two types of complex-energy gaps: point gap and line gap. We show
that exceptional points, at which not only eigenenergies but also eigenstates
coalesce, are characterized by gap closing of point gaps with nontrivial
topological charges. Moreover, we find that bulk Fermi arcs accompanying
exceptional points are robust because of topological charges for real line
gaps. On the basis of the classification, some examples are also discussed.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:14:30 GMT""}]","2020-04-22"
"1911.08999","Marco Ornigotti Prof. Dr.","Arttu Nieminen, Andrea marini, and Marco Ornigotti","Goos-H\""anchen and Imbert-Fedorov Shifts for Epsilon-Near-Zero Materials",,,"10.1088/2040-8986/ab6ae7",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the reflection of a Gaussian beam impinging upon the surface
of an epsilon-near-zero (ENZ) medium. In particular, we discuss the occurrence
of Goos-H\""anchen and Imbert-Fedorov shifts. Our calculations reveal that
spatial shifts are significantly enhanced owing to the ENZ nature of the
medium, and that their value and angular position can be tuned by tuning the
plasma frequency of the medium.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:17:27 GMT""}]","2020-02-19"
"1911.09000","Guolin Qin","Daomin Cao, Guolin Qin","Liouville type theorems for fractional and higher-order fractional
  H\'enon-Lane-Emden systems",,"Discrete and Continuous Dynamical Systems, 41 (5), 2269-2283
  (2021)","10.3934/dcds.2020361",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we first establish decay estimates for the fractional and
higher-order fractional H\'enon-Lane-Emden systems by using a nonlocal average
and integral estimates, which deduce a result of non-existence. Next, we apply
the method of scaling spheres introduced in \cite{DQ2} to derive a Liouville
type theorem. We also construct an interesting example on super
$\frac{\alpha}{2}$-harmonic functions (Proposition 1.2).
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:17:42 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 11:22:05 GMT""},{""version"":""v3"",""created"":""Sun, 15 Dec 2019 13:38:59 GMT""},{""version"":""v4"",""created"":""Sun, 5 Jan 2020 12:46:07 GMT""},{""version"":""v5"",""created"":""Sat, 12 Sep 2020 09:25:46 GMT""}]","2021-06-09"
"1911.09005","Thomas Gilbert","Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz","Hard Choices in Artificial Intelligence: Addressing Normative
  Uncertainty through Sociotechnical Commitments","To be presented at the AI for Social Good workshop at NeurIPS 2019",,,,"cs.AI cs.CY cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As AI systems become prevalent in high stakes domains such as surveillance
and healthcare, researchers now examine how to design and implement them in a
safe manner. However, the potential harms caused by systems to stakeholders in
complex social contexts and how to address these remains unclear. In this
paper, we explain the inherent normative uncertainty in debates about the
safety of AI systems. We then address this as a problem of vagueness by
examining its place in the design, training, and deployment stages of AI system
development. We adopt Ruth Chang's theory of intuitive comparability to
illustrate the dilemmas that manifest at each stage. We then discuss how
stakeholders can navigate these dilemmas by incorporating distinct forms of
dissent into the development pipeline, drawing on Elizabeth Anderson's work on
the epistemic powers of democratic institutions. We outline a framework of
sociotechnical commitments to formal, substantive and discursive challenges
that address normative uncertainty across stakeholders, and propose the
cultivation of related virtues by those responsible for development.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:21:12 GMT""}]","2019-11-21"
"1911.09006","Gilles Kratzer","Gilles Kratzer, Fraser Iain Lewis, Arianna Comin, Marta Pittavino,
  Reinhard Furrer","Additive Bayesian Network Modelling with the R Package abn","37 pages, 14 figures and 2 tables",,,,"stat.ML cs.LG stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The R package abn is designed to fit additive Bayesian models to
observational datasets. It contains routines to score Bayesian networks based
on Bayesian or information theoretic formulations of generalized linear models.
It is equipped with exact search and greedy search algorithms to select the
best network. It supports a possible blend of continuous, discrete and count
data and input of prior knowledge at a structural level. The Bayesian
implementation supports random effects to control for one-layer clustering. In
this paper, we give an overview of the methodology and illustrate the package's
functionalities using a veterinary dataset about respiratory diseases in
commercial swine production.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:22:22 GMT""}]","2019-11-21"
"1911.09007","Abdulkadir Celikkanat","Abdulkadir \c{C}elikkanat and Fragkiskos D. Malliaros","Exponential Family Graph Embeddings","Accepted to the The Thirty-Fourth AAAI Conference on Artificial
  Intelligence (AAAI-20), New York City, New York, 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Representing networks in a low dimensional latent space is a crucial task
with many interesting applications in graph learning problems, such as link
prediction and node classification. A widely applied network representation
learning paradigm is based on the combination of random walks for sampling
context nodes and the traditional \textit{Skip-Gram} model to capture
center-context node relationships. In this paper, we emphasize on exponential
family distributions to capture rich interaction patterns between nodes in
random walk sequences. We introduce the generic \textit{exponential family
graph embedding} model, that generalizes random walk-based network
representation learning techniques to exponential family conditional
distributions. We study three particular instances of this model, analyzing
their properties and showing their relationship to existing unsupervised
learning models. Our experimental evaluation on real-world datasets
demonstrates that the proposed techniques outperform well-known baseline
methods in two downstream machine learning tasks.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:23:09 GMT""}]","2019-11-21"
"1911.09008","Harry Clifford MSci DPhil","Geoffroy Dubourg-Felonneau, Yasmeen Kussad, Dominic Kirkham, John W
  Cassidy, Nirmesh Patel, Harry W Clifford","Learning Embeddings from Cancer Mutation Sets for Classification Tasks","Sets & Partitions Workshop at NeurIPS 2019",,,,"cs.LG eess.IV q-bio.GN stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analysis of somatic mutation profiles from cancer patients is essential in
the development of cancer research. However, the low frequency of most
mutations and the varying rates of mutations across patients makes the data
extremely challenging to statistically analyze as well as difficult to use in
classification problems, for clustering, visualization or for learning useful
information. Thus, the creation of low dimensional representations of somatic
mutation profiles that hold useful information about the DNA of cancer cells
will facilitate the use of such data in applications that will progress
precision medicine. In this paper, we talk about the open problem of learning
from somatic mutations, and present Flatsomatic: a solution that utilizes
variational autoencoders (VAEs) to create latent representations of somatic
profiles. The work done in this paper shows great potential for this method,
with the VAE embeddings performing better than PCA for a clustering task, and
performing equally well to the raw high dimensional data for a classification
task. We believe the methods presented herein can be of great value in future
research and in bringing data-driven models into precision oncology.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:23:30 GMT""}]","2019-11-21"
"1911.09009","Hiroyuki Yamase","Hiroyuki Yamase and Tomoaki Agatsuma","Suppression of superconductivity by spin fluctuations in iron-based
  superconductors","13 pages, 5 figures","Phys. Rev. B 102, 060504 (2020)","10.1103/PhysRevB.102.060504",,"cond-mat.supr-con cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the superconducting instability mediated by spin fluctuations in the
Eliashberg theory for a minimal two-band model of iron-based superconductors.
While antiferromagnetic spin fluctuations can drive superconductivity (SC) as
is well established, we find that spin fluctuations necessarily contain a
contribution to suppress SC even though SC can eventually occur at lower
temperatures. This self-restraint effect stems from a general feature of the
spin-fluctuation mechanism, namely the repulsive pairing interaction, which
leads to phase frustration of the pairing gap and consequently the suppression
of SC.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:24:10 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2020 03:08:15 GMT""},{""version"":""v3"",""created"":""Thu, 27 Aug 2020 22:30:29 GMT""}]","2020-09-02"
"1911.09010","Neelanjan Bhowmik","Ganesh Samarth C.A., Neelanjan Bhowmik, Toby P. Breckon","Experimental Exploration of Compact Convolutional Neural Network
  Architectures for Non-temporal Real-time Fire Detection",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we explore different Convolutional Neural Network (CNN)
architectures and their variants for non-temporal binary fire detection and
localization in video or still imagery. We consider the performance of
experimentally defined, reduced complexity deep CNN architectures for this task
and evaluate the effects of different optimization and normalization techniques
applied to different CNN architectures (spanning the Inception, ResNet and
EfficientNet architectural concepts). Contrary to contemporary trends in the
field, our work illustrates a maximum overall accuracy of 0.96 for full frame
binary fire detection and 0.94 for superpixel localization using an
experimentally defined reduced CNN architecture based on the concept of
InceptionV4. We notably achieve a lower false positive rate of 0.06 compared to
prior work in the field presenting an efficient, robust and real-time solution
for fire region detection.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:27:10 GMT""}]","2019-11-21"
"1911.09011","Soma Yokoi","Soma Yokoi and Issei Sato","Bayesian interpretation of SGD as Ito process",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The current interpretation of stochastic gradient descent (SGD) as a
stochastic process lacks generality in that its numerical scheme restricts
continuous-time dynamics as well as the loss function and the distribution of
gradient noise. We introduce a simplified scheme with milder conditions that
flexibly interprets SGD as a discrete-time approximation of an Ito process. The
scheme also works as a common foundation of SGD and stochastic gradient
Langevin dynamics (SGLD), providing insights into their asymptotic properties.
We investigate the convergence of SGD with biased gradient in terms of the
equilibrium mode and the overestimation problem of the second moment of SGLD.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:29:45 GMT""}]","2019-11-21"
"1911.09012","Paul McNicholas","Michael P.B. Gallaugher and Paul D. McNicholas","Parsimonious Mixtures of Matrix Variate Bilinear Factor Analyzers",,,,,"stat.ME stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the years, data have become increasingly higher dimensional, which has
prompted an increased need for dimension reduction techniques. This is perhaps
especially true for clustering (unsupervised classification) as well as
semi-supervised and supervised classification. Many methods have been proposed
in the literature for two-way (multivariate) data and quite recently methods
have been presented for three-way (matrix variate) data. One such such method
is the mixtures of matrix variate bilinear factor analyzers (MMVBFA) model.
Herein, we propose of total of 64 parsimonious MMVBFA models. Simulated and
real data are used for illustration.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:30:31 GMT""}]","2019-11-21"
"1911.09014","James F. Peters Ph.D.","James F. Peters","Ribbon Complexes & their Approximate Descriptive Proximities. Ribbon &
  Vortex Nerves, Betti Numbers and Planar Divisions","14 pages, 5 figures, dedicated to E. Betti and S.A. Naimpally","Bulletin of the Allahabad Mathematical Society vol. 35, no. 1,
  2020, 31-53",,,"math.GT math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article introduces planar ribbons, Vergili ribbon complexes and ribbon
nerves in Alexandroff-Hopf-Whitehead CW (Closure finite Weak) topological
spaces. A {\em planar ribbon} (briefly, {ribbon}) in a CW space is the closure
of a pair of nesting, non-concentric filled cycles that includes the boundary
but does not include the interior of the inner cycle. Each planar ribbon has
its own distinctive shape determined by its outer and inner boundaries and the
interior within its boundaries. A Vergili ribbon complex (briefly, ribbon
complex) in a CW space is a non-void collection of countable planar ribbons. A
ribbon nerve is a nonvoid collection of planar ribbons (members of a ribbon
complex) that have nonempty intersection. A planar CW space is a non-void
collection of cells (vertexes, edges and filled triangles) that may or may not
be attached to other and which satisfy Alexandroff-Hopf-Whitehead containment
and intersection conditions. In the context of CW spaces, planar ribbons,
ribbon complexes and ribbon nerves are characterized by Betti numbers derived
from standard Betti numbers $\mathcal{B}_0$ (cell count), $\mathcal{B}_1$
(cycle count) and $\mathcal{B}_2$ (hole count), namely, $\mathcal{B}_{rb}$ and
$\mathcal{B}_{rbNrv}$ introduced in this paper. Results are given for
collections of ribbons and ribbon nerves in planar CW spaces equipped with an
approximate descriptive proximity, division of the plane into three bounded
regions by a ribbon and Brouwer fixed points on ribbons. In addition, the
homotopy types of ribbons and ribbon nerves are introduced.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:33:29 GMT""},{""version"":""v2"",""created"":""Thu, 21 Nov 2019 13:05:34 GMT""},{""version"":""v3"",""created"":""Mon, 25 Nov 2019 14:10:14 GMT""},{""version"":""v4"",""created"":""Sun, 8 Dec 2019 18:24:06 GMT""},{""version"":""v5"",""created"":""Mon, 16 Dec 2019 13:51:30 GMT""},{""version"":""v6"",""created"":""Mon, 27 Apr 2020 11:47:41 GMT""}]","2021-01-05"
"1911.09015","Peter Baddoo","Peter J. Baddoo and Lorna J. Ayton","Acoustic scattering by cascades with complex boundary conditions:
  compliance, porosity and impedance","40 pages",,"10.1017/jfm.2020.417",,"physics.flu-dyn math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a solution for the scattered field caused by an incident wave
interacting with an infinite cascade of blades with complex boundary
conditions. This extends previous studies by allowing the blades to be
compliant, porous or satisfying a generalised impedance condition. Beginning
with the convected wave equation, we employ Fourier transforms to obtain an
integral equation amenable to the Wiener--Hopf method. This Wiener--Hopf system
is solved using a method that avoids the factorisation of matrix functions. The
Fourier transform is inverted to obtain an expression for the acoustic
potential function that is valid throughout the entire domain. We observe that
the principal effect of complex boundary conditions is to perturb the zeros of
the Wiener--Hopf kernel, which correspond to the duct modes in the inter-blade
region. We focus efforts on understanding the role of porosity, and present a
range of results on sound transmission and generation. The behaviour of the
duct modes is discussed in detail in order to explain the physical mechanisms
behind the associated noise reductions. In particular, we show that cut-on duct
modes do not exist for arbitrary porosity coefficients. Conversely, the
acoustic modes are unchanged by modifications to the boundary conditions.
Consequently, we observe that even modest values of porosity can result in
reductions in the sound power level of $5$ dB for the first mode and $20$ dB
for the second mode. The solution is essentially analytic (the only numerical
requirements are matrix inversion and root finding) and is therefore extremely
rapid to compute.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:34:26 GMT""}]","2020-08-26"
"1911.09016","Suela Isaj","Suela Isaj, Torben Bach Pedersen, Esteban Zim\'anyi","Multi-Source Spatial Entity Linkage",,,"10.1109/TKDE.2020.2990491",,"cs.DB","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Besides the traditional cartographic data sources, spatial information can
also be derived from location-based sources. However, even though different
location-based sources refer to the same physical world, each one has only
partial coverage of the spatial entities, describe them with different
attributes, and sometimes provide contradicting information. Hence, we
introduce the spatial entity linkage problem, which finds which pairs of
spatial entities belong to the same physical spatial entity. Our proposed
solution (QuadSky) starts with a time-efficient spatial blocking technique
(QuadFlex), compares pairwise the spatial entities in the same block, ranks the
pairs using Pareto optimality with the SkyRank algorithm, and finally,
classifies the pairs with our novel SkyEx-* family of algorithms that yield
0.85 precision and 0.85 recall for a manually labeled dataset of 1,500 pairs
and 0.87 precision and 0.6 recall for a semi-manually labeled dataset of
777,452 pairs. Moreover, we provide a theoretical guarantee and formalize the
SkyEx-FES algorithm that explores only 27% of the skylines without any loss in
F-measure. Furthermore, our fully unsupervised algorithm SkyEx-D approximates
the optimal result with an F-measure loss of just 0.01. Finally, QuadSky
provides the best trade-off between precision and recall, and the best
F-measure compared to the existing baselines and clustering techniques, and
approximates the results of supervised learning solutions.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:38:05 GMT""},{""version"":""v2"",""created"":""Wed, 29 Apr 2020 12:38:11 GMT""}]","2020-04-30"
"1911.09017","Quanshi Zhang","Hao Zhang, Jiayi Chen, Haotian Xue, Quanshi Zhang","Towards a Unified Evaluation of Explanation Methods without Ground Truth",,,,,"cs.LG cs.AI cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a set of criteria to evaluate the objectiveness of
explanation methods of neural networks, which is crucial for the development of
explainable AI, but it also presents significant challenges. The core challenge
is that people usually cannot obtain ground-truth explanations of the neural
network. To this end, we design four metrics to evaluate explanation results
without ground-truth explanations. Our metrics can be broadly applied to nine
benchmark methods of interpreting neural networks, which provides new insights
of explanation methods.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:44:48 GMT""}]","2019-11-21"
"1911.09018","Carlos Eduardo Cancino-Chac\'on","Laura Bishop, Carlos Cancino-Chac\'on, Werner Goebl","Moving to Communicate, Moving to Interact: Patterns of Body Motion in
  Musical Duo Performance","32 pages, 10 figures. This version is a final preprint of the paper
  prepared by the authors. Please cite as Bishop, L., Cancino-Chac\'on, C., and
  Goebl, W. (2019). Moving to communicate, moving to interact: Patterns of body
  motion in musical duo performance. Music Perception, 37, 1-25","Music Perception 37 (2019) 1-25","10.1525/mp.2019.37.1.1",,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Skilled ensemble musicians coordinate with high precision, even when
improvising or interpreting loosely-defined notation. Successful coordination
is supported primarily through shared attention to the musical output; however,
musicians also interact visually, particularly when the musical timing is
irregular. This study investigated the performance conditions that encourage
visual signalling and interaction between ensemble members. Piano and clarinet
duos rehearsed a new piece as their body motion was recorded. Analyses of head
movement showed that performers communicated gesturally following held notes.
Gesture patterns became more consistent as duos rehearsed, though consistency
dropped again during a final performance given under no-visual-contact
conditions. Movements were smoother and interperformer coordination was
stronger during irregularly-timed passages than elsewhere in the piece,
suggesting heightened visual interaction. Performers moved more after
rehearsing than before, and more when they could see each other than when
visual contact was occluded. Periods of temporal instability and increased
familiarity with the music and co-performer seem to encourage visual
interaction, while specific communicative gestures are integrated into
performance routines through rehearsal. We propose that visual interaction may
support successful ensemble performance by affirming coordination throughout
periods of temporal instability and serving as a social motivator to promote
creative risk-taking.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:46:23 GMT""}]","2019-11-21"
"1911.09019","Marina Iliopoulou","Anthony Carbery, Marina Iliopoulou","Joints formed by lines and a $k$-plane, and a discrete estimate of
  Kakeya type","45 pages, 4 figures. Published in Discrete Analysis",,"10.19086/da.18361",,"math.CO math.CA","http://creativecommons.org/licenses/by/4.0/","  Let $\mathcal{L}$ be a family of lines and let $\mathcal{P}$ be a family of
$k$-planes in $\mathbb{F}^n$ where $\mathbb{F}$ is a field. In our first result
we show that the number of joints formed by a $k$-plane in $\mathcal{P}$
together with $(n-k)$ lines in $\mathcal{L}$ is
$O_n(|\mathcal{L}||\mathcal{P}|^{1/(n-k)}$). This is the first sharp result for
joints involving higher-dimensional affine subspaces, and it holds in the
setting of arbitrary fields $\mathbb{F}$. In contrast, for our second result,
we work in the three-dimensional Euclidean space $\mathbb{R}^3$, and we
establish the Kakeya-type estimate \begin{equation*}\sum_{x \in J}
\left(\sum_{\ell \in \mathcal{L}} \chi_\ell(x)\right)^{3/2} \lesssim
|\mathcal{L}|^{3/2}\end{equation*} where $J$ is the set of joints formed by
$\mathcal{L}$; such an estimate fails in the setting of arbitrary fields. This
result strengthens the known estimates for joints, including those counting
multiplicities. Additionally, our techniques yield significant structural
information on quasi-extremisers for this inequality.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:46:24 GMT""},{""version"":""v2"",""created"":""Sun, 27 Dec 2020 12:39:41 GMT""}]","2020-12-29"
"1911.09021","Yadira Valdivieso Diaz","Sibylle Schroll, Hipolito Treffinger and Yadira Valdivieso","On band modules and $\tau$-tilting finiteness","To appear in Mathematische Zeitschrift. Substantial re-write:
  introduced tau-tilting version of the Brauer-Thrall conjectures for finite
  dimensional algebras and proof of the conjectures for special biserial
  algebras; removed Proposition 3.1 which contained a mistake; new proof of the
  criterion of tau-tilting finiteness for special biserial algebras",,,,"math.RT math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, motivated by a $\tau$-tilting version of the Brauer-Thrall
Conjectures, we study general properties of band modules and their
endomorphisms in the module category of a finite dimensional algebra. As an
application we describe properties of torsion classes containing band modules.
Furthermore, we show that a special biserial algebra is $\tau$-tilting finite
if and only if no band module is a brick. We also recover a criterion for the
$\tau$-tilting finiteness of Brauer graph algebras in terms of the Brauer
graph.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:48:47 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 10:22:24 GMT""},{""version"":""v3"",""created"":""Tue, 28 Apr 2020 12:04:24 GMT""},{""version"":""v4"",""created"":""Sat, 19 Dec 2020 04:04:17 GMT""}]","2020-12-22"
"1911.09024","Leonard Hardiman","Leonard Hardiman","Extending the trace of a pivotal monoidal functor","35 pages, many figures, to appear in Comm. Math. Phys","Communications in Mathematical Physics, 381(3), 1055-1090 (2021)","10.1007/s00220-020-03909-8",,"math.QA math-ph math.MP","http://creativecommons.org/licenses/by/4.0/","  We consider a pivotal monoidal functor whose domain is a modular tensor
category (MTC). We show that the trace of such a functor naturally extends to a
representation of the corresponding tube category. As irreducible
representations of the tube category are indexed by pairs of simple objects in
the underlying MTC, the simple multiplicities of this representation form a
candidate modular invariant matrix. In general, this matrix will not be modular
invariant, however it will always commute with the T-matrix. Furthermore, under
certain additional conditions on the original functor, it is shown that the
corresponding representation of the tube category is a haploid, symmetric,
commutative Frobenius algebra. Such algebras are known to be connected to
modular invariants, in particular a result of Kong and Runkel implies that the
matrix of simple multiplicities commutes with the S-matrix if and only if the
dimension of the algebra is equal to the dimension of the underlying MTC.
Finally, we apply these techniques to certain pivotal monoidal functors arising
from module categories over the Temperley-Lieb category and the associated MTC.
This provides a novel explanation of the A-D-E pattern appearing in the
classification of $ A_1^{(1)} $ modular invariants.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:49:56 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 18:26:48 GMT""},{""version"":""v3"",""created"":""Thu, 12 Nov 2020 23:46:26 GMT""}]","2021-02-23"
"1911.09029","Aritra Basu","Aritra Basu, Andrew Fletcher, S. A. Mao, Blakesley Burkhart, Rainer
  Beck, Dominic Schnitzeler","An In-depth Investigation of Faraday Depth Spectrum Using Synthetic
  Observations of Turbulent MHD Simulations","30 article-style pages, 11 figures, Accepted to be published in the
  special issue of MDPI Galaxies on ""New Perspectives on Galactic Magnetism""",,,,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a detailed analysis of the Faraday depth (FD)
spectrum and its clean components obtained through the application of the
commonly used technique of Faraday rotation measure synthesis to analyze
spectro-polarimetric data. In order to directly compare the Faraday depth
spectrum with physical properties of a magneto-ionic medium, we generated
synthetic broad-bandwidth spectro-polarimetric observations from
magnetohydrodynamic (MHD) simulations of a transonic, isothermal, compressible
turbulent medium. We find that correlated magnetic field structures give rise
to a combination of spiky, localized peaks at certain FD values, and broad
structures in the FD spectrum. Although the majority of these spiky FD
structures appear narrow, giving an impression of a Faraday thin medium, we
show that they arise from strong synchrotron emissivity at that FD. Strong
emissivity at a FD can arise because of both strong spatially-local polarized
synchrotron emissivity at a FD or accumulation of weaker emissions along the
distance through a medium that have Faraday depths within half the width of the
rotation measure spread function. Such a complex Faraday depth spectrum is a
natural consequence of MHD turbulence when the lines of sight pass through a
few turbulent cells. This therefore complicates the convention of attributing
narrow FD peaks to presence of a Faraday rotating medium along the line of
sight. Our work shows that it is difficult to extract the FD along a line of
sight from the Faraday depth spectrum using standard methods for a turbulent
medium in which synchrotron emission and Faraday rotation occur simultaneously.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:57:08 GMT""}]","2019-11-21"
"1911.09030","Cong Xie","Cong Xie, Oluwasanmi Koyejo, Indranil Gupta, Haibin Lin","Local AdaAlter: Communication-Efficient Stochastic Gradient Descent with
  Adaptive Learning Rates",,,,,"cs.LG cs.DC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When scaling distributed training, the communication overhead is often the
bottleneck. In this paper, we propose a novel SGD variant with reduced
communication and adaptive learning rates. We prove the convergence of the
proposed algorithm for smooth but non-convex problems. Empirical results show
that the proposed algorithm significantly reduces the communication overhead,
which, in turn, reduces the training time by up to 30% for the 1B word dataset.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:58:40 GMT""},{""version"":""v2"",""created"":""Sat, 5 Dec 2020 00:26:57 GMT""}]","2020-12-08"
"1911.09031","Antonio J. Di Scala","Antonio J. Di Scala, Carlos E. Olmos, Francisco Vittone","Cones and Cartan geometry",,,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the extended principal bundle of a Cartan geometry of type
$(A(m,\mathbb{R}),GL(m,\mathbb{R}))$, endowed with its extended connection
$\hat\omega$, is isomorphic to the principal $A(m,\mathbb{R})$-bundle of affine
frames endowed with the affine connection as defined in classical
Kobayashi-Nomizu volume I.
  Then we classify the local holonomy groups of the Cartan geometry canonically
associated to a Riemannian manifold. It follows that if the holonomy group of
the Cartan geometry canonically associated to a Riemannian manifold is compact
then the Riemannian manifold is locally a product of cones.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:01:25 GMT""},{""version"":""v2"",""created"":""Mon, 14 Dec 2020 12:59:40 GMT""},{""version"":""v3"",""created"":""Tue, 15 Dec 2020 08:28:45 GMT""}]","2020-12-16"
"1911.09032","Christian Schilling","Thomas A. Henzinger and Anna Lukina and Christian Schilling","Outside the Box: Abstraction-Based Monitoring of Neural Networks","accepted at ECAI 2020","ECAI 2020","10.3233/FAIA200375",,"cs.LG cs.AI cs.LO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural networks have demonstrated unmatched performance in a range of
classification tasks. Despite numerous efforts of the research community,
novelty detection remains one of the significant limitations of neural
networks. The ability to identify previously unseen inputs as novel is crucial
for our understanding of the decisions made by neural networks. At runtime,
inputs not falling into any of the categories learned during training cannot be
classified correctly by the neural network. Existing approaches treat the
neural network as a black box and try to detect novel inputs based on the
confidence of the output predictions. However, neural networks are not trained
to reduce their confidence for novel inputs, which limits the effectiveness of
these approaches. We propose a framework to monitor a neural network by
observing the hidden layers. We employ a common abstraction from program
analysis - boxes - to identify novel behaviors in the monitored layers, i.e.,
inputs that cause behaviors outside the box. For each neuron, the boxes range
over the values seen in training. The framework is efficient and flexible to
achieve a desired trade-off between raising false warnings and detecting novel
inputs. We illustrate the performance and the robustness to variability in the
unknown classes on popular image-classification benchmarks.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:03:21 GMT""},{""version"":""v2"",""created"":""Fri, 29 Nov 2019 10:32:30 GMT""},{""version"":""v3"",""created"":""Wed, 19 Feb 2020 15:46:18 GMT""}]","2022-05-03"
"1911.09033","Eric Crawford","Eric Crawford, Joelle Pineau","Exploiting Spatial Invariance for Scalable Unsupervised Object Tracking","Accepted at AAAI 2020. Code: https://github.com/e2crawfo/silot.
  Visualizations: https://sites.google.com/view/silot",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to detect and track objects in the visual world is a crucial
skill for any intelligent agent, as it is a necessary precursor to any
object-level reasoning process. Moreover, it is important that agents learn to
track objects without supervision (i.e. without access to annotated training
videos) since this will allow agents to begin operating in new environments
with minimal human assistance. The task of learning to discover and track
objects in videos, which we call \textit{unsupervised object tracking}, has
grown in prominence in recent years; however, most architectures that address
it still struggle to deal with large scenes containing many objects. In the
current work, we propose an architecture that scales well to the large-scene,
many-object setting by employing spatially invariant computations (convolutions
and spatial attention) and representations (a spatially local object
specification scheme). In a series of experiments, we demonstrate a number of
attractive features of our architecture; most notably, that it outperforms
competing methods at tracking objects in cluttered scenes with many objects,
and that it can generalize well to videos that are larger and/or contain more
objects than videos encountered during training.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:03:51 GMT""}]","2019-11-21"
"1911.09034","Amirul Islam","Amirul Islam, Leila Musavian, and Nikolaos Thomos","Rate Maximization in Vehicular uRLLC with Optical Camera Communications","This paper is updated and has been fully modified starting from the
  system model and solution schemes",,,,"cs.NI cs.PF eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Optical camera communication (OCC) has emerged as a key enabling technology
for the seamless operation of future autonomous vehicles. By leveraging the
supreme performance of OCC, we can meet the stringent requirements of
ultra-reliable and low-latency communication (uRLLC) in vehicular OCC. In this
paper, we introduce a rate optimization approach in vehicular OCC through
optimal power allocation while respecting uRLLC requirements. We first
formulate a discrete-rate optimization problem as a mixed-integer programming
(MIP) subject to average transmit power and uRLLC constraints for a given set
of modulation schemes. To reduce the complexity in solving the MIP problem, we
convert the discrete-rate problem into a continuous-rate optimization scheme.
Then, we present an algorithm based on Lagrangian relaxation and Bisection
method to solve the optimization problem. Considering the proposed algorithm,
we drive the rate optimization and power allocation scheme for both
discrete-rate and continuous-rate optimization schemes while satisfying uRLLC
constraints. We first analyze the performance of the proposed system model
through simulations. We then investigate the impact of proposed power
allocation and rate optimization schemes on average rate and latency for
different target bit error rates. The results show that increasing the transmit
power allocation improves the average rate and latency performance.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:04:23 GMT""},{""version"":""v2"",""created"":""Tue, 22 Sep 2020 08:30:49 GMT""},{""version"":""v3"",""created"":""Fri, 13 May 2022 16:46:58 GMT""}]","2022-05-16"
"1911.09035","Fiona Macfarlane","Fiona R Macfarlane, Mark AJ Chaplain, Raluca Eftimie","Quantitative predictive modelling approaches to understanding rheumatoid
  arthritis: A brief review",,,"10.3390/cells9010074",,"q-bio.QM q-bio.TO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Rheumatoid arthritis is a chronic autoimmune disease that is a major public
health challenge. The disease is characterised by inflammation of synovial
joints and cartilage erosion, which leads to chronic pain, poor life quality
and, in some cases, premature mortality. Understanding the biological
mechanisms behind the progression of the disease, as well as developing new
methods for quantitative predictions of disease progression in the
presence/absence of various therapies is important for the success of
therapeutic approaches. The aim of this study is to review various quantitative
predictive modelling approaches for understanding rheumatoid arthritis. To this
end, we start by discussing briefly the biology of this disease and some
current treatment approaches, as well as emphasising some of the open problems
in the field. Then we review various mathematical mechanistic models derived to
address some of these open problems. We discuss models that investigate the
biological mechanisms behind the progression of the disease, as well as
pharmacokinetic and pharmacodynamic models for various drug therapies.
Furthermore, we highlight models aimed at optimising the costs of the
treatments while taking into consideration the evolution of the disease and
potential complications.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:04:28 GMT""},{""version"":""v2"",""created"":""Thu, 12 Dec 2019 15:57:39 GMT""},{""version"":""v3"",""created"":""Thu, 19 Dec 2019 12:49:40 GMT""},{""version"":""v4"",""created"":""Mon, 6 Jan 2020 10:01:22 GMT""}]","2020-01-07"
"1911.09036","Xiaolin Zeng","Yinshan Chang, Dang-Zheng Liu, Xiaolin Zeng","On $H^{2|2}$ Isomorphism theorems and reinforced loop soup","16 pages",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that supersymmetric (susy) hyperbolic isomorphism theorems that
relate Vertex Reinforced Jump Processes and $H^{2|2}$ field, introduced in [2]
and [3], are annealed version of isomorphism theorems relating Markov processes
and Gaussian free field, with the help of a Bayes formula that relates susy
hyperbolic field to susy free field. On the other hand, we also prove a
BFS-Dynkin's isomorphism theorem for reinforced loop soup. Moreover, we provide
yet another proof of BFS-Dynkin's isomorphism for VRJP a la Feynman-Kac.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:04:38 GMT""},{""version"":""v2"",""created"":""Tue, 21 Apr 2020 14:32:49 GMT""}]","2020-04-22"
"1911.09037","Digesh Raut","Sudip Jana, Nobuchika Okada, and Digesh Raut","Displaced Vertex and Disappearing Track Signatures in type-III Seesaw","24 pages, 13 Figures (includes updated and new figures), Sec. 3
  revised and new discussion added, typos corrected",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate a prospect of probing the type-III seesaw neutrino mass
generation mechanism at various collider experiments by searching for a
disappearing track and a displaced vertex signature originating from the decay
of $SU(2)_L$ triplet fermion ($\Sigma$). Since $\Sigma$ is primarily produced
at colliders through the electroweak gauge interactions, its production rate is
uniquely determined by its mass. We find that a $\Sigma$ particle with a mass
of a few hundred GeV produces a disappearing track signature from the decay of
its charged component, which can be searched at the HL-LHC. Furthermore, we
show that if the lightest observed neutrino has a mass of around $10^{-9}$ eV,
the neutral component of ${\Sigma}$ can be discovered at the proposed MATHUSLA
detector. We also show that the charged component of ${\Sigma}$ with a mass of
a few hundred GeV can be observed at the LHeC and FCC-he as a displaced vertex
signature.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:07:42 GMT""},{""version"":""v2"",""created"":""Wed, 1 Apr 2020 17:28:52 GMT""},{""version"":""v3"",""created"":""Wed, 3 Jun 2020 12:25:47 GMT""},{""version"":""v4"",""created"":""Mon, 8 Mar 2021 15:08:14 GMT""}]","2021-03-09"
"1911.09038","Craig Lage","Craig Lage, Andrew K. Bradshaw, J. Anthony Tyson","Poisson_CCD: A dedicated simulator for modeling CCDs","37 pages, 27 figures","Journal of Applied Physics, V130, N16, 2021","10.1063/5.0058894",,"astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A dedicated simulator, Poisson_CCD, has been constructed which models
astronomical CCDs by solving Poisson's equation numerically and simulating
charge transport within the CCD. The potentials and free carrier densities
within the CCD are self-consistently solved for, giving realistic results for
the charge distribution within the CCD storage wells. The simulator has been
used to model the CCDs which are being used to construct the LSST digital
camera. The simulator output has been validated by comparing its predictions
with several different types of CCD measurements, including astrometric shifts,
brighter-fatter induced pixel-pixel covariances, saturation effects, and
diffusion spreading. The code is open source and freely available.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:08:14 GMT""},{""version"":""v2"",""created"":""Tue, 1 Jun 2021 20:19:14 GMT""}]","2021-11-10"
"1911.09039","EPTCS","Niel de Beaudrap (Department of Computer Science, University of
  Oxford), Xiaoning Bian (Department of Mathematics and Statistics, Dalhousie
  University), Quanlong Wang (Department of Computer Science, University of
  Oxford, Cambridge Quantum Computing Ltd.)","Techniques to Reduce $\pi/4$-Parity-Phase Circuits, Motivated by the ZX
  Calculus","In Proceedings QPL 2019, arXiv:2004.14750","EPTCS 318, 2020, pp. 131-149","10.4204/EPTCS.318.9",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To approximate arbitrary unitary transformations on one or more qubits, one
must perform transformations which are outside of the Clifford group. The gate
most commonly considered for this purpose is the T = diag(1, exp(i \pi/4))
gate. As T gates are computationally expensive to perform fault-tolerantly in
the most promising error-correction technologies, minimising the ""T-count"" (the
number of T gates) required to realise a given unitary in a Clifford+T circuit
is of great interest. We describe techniques to find circuits with reduced
T-count in unitary circuits, which develop on the ideas of Heyfron and Campbell
[arXiv:1712.01557] with the help of the ZX calculus. Following
[arXiv:1712.01557], we reduce the problem to that of minimising the T count of
a CNOT+T circuit. The ZX calculus motivates a further reduction to simplifying
a product of commuting ""\pi/4-parity-phase"" operations: diagonal unitary
transformations which induce a relative phase of exp(i \pi/4) depending on the
outcome of a parity computation on the standard basis (which motivated
Kissinger and van de Wetering [1903.10477] to introduce ""phase gadgets""). For a
number of standard benchmark circuits, we show that these techniques -- in some
cases supplemented by the TODD subroutine of Heyfron and Campbell
[arXiv:1712.01557] -- yield T-counts comparable to or better than the best
previously known results.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:10:45 GMT""},{""version"":""v2"",""created"":""Fri, 1 May 2020 04:11:39 GMT""}]","2020-05-04"
"1911.09040","Quanshi Zhang","Wen Shen, Binbin Zhang, Shikun Huang, Zhihua Wei, Quanshi Zhang","3D-Rotation-Equivariant Quaternion Neural Networks",,,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a set of rules to revise various neural networks for 3D
point cloud processing to rotation-equivariant quaternion neural networks
(REQNNs). We find that when a neural network uses quaternion features under
certain conditions, the network feature naturally has the rotation-equivariance
property. Rotation equivariance means that applying a specific rotation
transformation to the input point cloud is equivalent to applying the same
rotation transformation to all intermediate-layer quaternion features. Besides,
the REQNN also ensures that the intermediate-layer features are invariant to
the permutation of input points. Compared with the original neural network, the
REQNN exhibits higher rotation robustness.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:10:52 GMT""},{""version"":""v2"",""created"":""Sun, 11 Oct 2020 08:24:30 GMT""}]","2020-10-13"
"1911.09041","Laura Koesten","Laura Koesten, Kathleen Gregory, Paul Groth, Elena Simperl","Talking datasets: Understanding data sensemaking behaviours","26 pages, 7 figures, 6 tables",,"10.1016/j.ijhcs.2020.102562",,"cs.HC cs.DL","http://creativecommons.org/licenses/by/4.0/","  The sharing and reuse of data are seen as critical to solving the most
complex problems of today. Despite this potential, relatively little is known
about a key step in data reuse: people's behaviours involved in data-centric
sensemaking. We aim to address this gap by presenting a mixed-methods study
combining in-depth interviews, a think-aloud task and a screen recording
analysis with 31 researchers as they summarised and interacted with both
familiar and unfamiliar data. We use our findings to identify and detail common
activity patterns and necessary data attributes across three clusters of
sensemaking activities: inspecting data, engaging with content, and placing
data within broader contexts. We conclude by proposing design recommendations
for tools and documentation practices which can be used to facilitate
sensemaking and subsequent data reuse.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:14:18 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jan 2020 17:17:03 GMT""},{""version"":""v3"",""created"":""Sat, 18 Jul 2020 16:36:18 GMT""}]","2022-11-10"
"1911.09042","Yongfei Liu","Yongfei Liu, Bo Wan, Xiaodan Zhu, Xuming He","Learning Cross-modal Context Graph for Visual Grounding","AAAI-2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Visual grounding is a ubiquitous building block in many vision-language tasks
and yet remains challenging due to large variations in visual and linguistic
features of grounding entities, strong context effect and the resulting
semantic ambiguities. Prior works typically focus on learning representations
of individual phrases with limited context information. To address their
limitations, this paper proposes a language-guided graph representation to
capture the global context of grounding entities and their relations, and
develop a cross-modal graph matching strategy for the multiple-phrase visual
grounding task. In particular, we introduce a modular graph neural network to
compute context-aware representations of phrases and object proposals
respectively via message propagation, followed by a graph-based matching module
to generate globally consistent localization of grounding phrases. We train the
entire graph neural network jointly in a two-stage strategy and evaluate it on
the Flickr30K Entities benchmark. Extensive experiments show that our method
outperforms the prior state of the arts by a sizable margin, evidencing the
efficacy of our grounding framework. Code is available at
""https://github.com/youngfly11/LCMCG-PyTorch"".
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:16:04 GMT""},{""version"":""v2"",""created"":""Sat, 23 Nov 2019 07:56:23 GMT""}]","2019-11-26"
"1911.09043","Kirill Atapin","Alexander Vinokurov, Kirill Atapin and Yulia Solovyeva","Optical Counterpart to the Ultraluminous X-Ray Source in the UGC6456
  Galaxy","5 pages, 3 figure, 1 table. Published in The Astrophysical Journal
  Letters","ApJL, 893, L28 (2020)","10.3847/2041-8213/ab8642",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the identification of the optical counterpart to the transient
ultraluminuos X-ray source in the blue dwarf galaxy UGC6456 (VII Zw 403). The
source is highly variable in both the X-ray (more 100 times, 0.3-10 keV) and
optical (more 3 times, V band) ranges. The peak X-ray luminosity of UGC6456 ULX
exceeds $10^{40}$ erg/s; the absolute magnitude when the source is optically
bright is M$_V = -8.24\pm0.11$, which makes this source one of the brightest
ULXs in the optical range. We found a correlation between the optical and X-ray
fluxes (with a coefficient of $0.9\pm 0.3$), which may indicate that the
optical emission is produced by re-processing of the X-rays in outer parts of
the optically-thick wind coming from the supercritical accretion disk. Optical
spectra of UGC6456 ULX show broad and variable hydrogen and helium emission
lines, which also confirms the presence of the strong wind.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:17:15 GMT""},{""version"":""v2"",""created"":""Mon, 12 Oct 2020 17:42:00 GMT""}]","2020-10-13"
"1911.09044","Daniil Galaktionov","Nieves R. Brisaboa, Antonio Fari\~na, Daniil Galaktionov, Tirso V.
  Rodeiro, M. Andrea Rodr\'iguez","New structures to solve aggregated queries for trips over public
  transportation networks","This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941","Proc. of the 25th International Symposium on String Processing and
  Information Retrieval (SPIRE), Lima, Peru, October 9-11th, pp 85-101 (2018)","10.1007/978-3-030-00479-8_8",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Representing the trajectories of mobile objects is a hot topic from the
widespread use of smartphones and other GPS devices. However, few works have
focused on representing trips over public transportation networks (buses,
subway, and trains) where a user's trips can be seen as a sequence of stages
performed within a vehicle shared with many other users. In this context,
representing vehicle journeys reduces the redundancy because all the passengers
inside a vehicle share the same arrival time for each stop. In addition, each
vehicle journey follows exactly the sequence of stops corresponding to its
line, which makes it unnecessary to represent that sequence for each journey.
  To solve data management for transportation systems, we designed a conceptual
model that gave us a better insight into this data domain and allowed us the
definition of relevant terms and the detection of redundancy sources among
those data. Then, we designed two compact representations focused on users'
trips (TTCTR) and on vehicle trips (AcumM), respectively. Each approach owns
some strengths and is able to answer some queries efficiently.
  We include experimental results over synthetic trips generated from accurate
schedules obtained from a real network description (from the bus transportation
system of Madrid) to show the space/time trade-off of both approaches. We
considered a wide range of different queries about the use of the
transportation network such as counting-based or aggregate queries regarding
the load of any line of the network at different times.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:18:11 GMT""}]","2019-11-21"
"1911.09045","Saeed Khaki","Saeed Khaki, Lizhi Wang and Sotirios V. Archontoulis","A CNN-RNN Framework for Crop Yield Prediction","26 Pages, 14 Figures","Frontiers in Plant Science, 2019","10.3389/fpls.2019.01750",,"cs.LG q-bio.QM stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Crop yield prediction is extremely challenging due to its dependence on
multiple factors such as crop genotype, environmental factors, management
practices, and their interactions. This paper presents a deep learning
framework using convolutional neural networks (CNN) and recurrent neural
networks (RNN) for crop yield prediction based on environmental data and
management practices. The proposed CNN-RNN model, along with other popular
methods such as random forest (RF), deep fully-connected neural networks
(DFNN), and LASSO, was used to forecast corn and soybean yield across the
entire Corn Belt (including 13 states) in the United States for years 2016,
2017, and 2018 using historical data. The new model achieved a
root-mean-square-error (RMSE) 9% and 8% of their respective average yields,
substantially outperforming all other methods that were tested. The CNN-RNN
have three salient features that make it a potentially useful method for other
crop yield prediction studies. (1) The CNN-RNN model was designed to capture
the time dependencies of environmental factors and the genetic improvement of
seeds over time without having their genotype information. (2) The model
demonstrated the capability to generalize the yield prediction to untested
environments without significant drop in the prediction accuracy. (3) Coupled
with the backpropagation method, the model could reveal the extent to which
weather conditions, accuracy of weather predictions, soil conditions, and
management practices were able to explain the variation in the crop yields.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:18:48 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jan 2020 19:10:32 GMT""}]","2020-01-28"
"1911.09046","Xiangfeng Wang","Junjie Wang, Xiangfeng Wang, Bo Jin, Junchi Yan, Wenjie Zhang,
  Hongyuan Zha","Heterogeneous Graph-based Knowledge Transfer for Generalized Zero-shot
  Learning",,,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalized zero-shot learning (GZSL) tackles the problem of learning to
classify instances involving both seen classes and unseen ones. The key issue
is how to effectively transfer the model learned from seen classes to unseen
classes. Existing works in GZSL usually assume that some prior information
about unseen classes are available. However, such an assumption is unrealistic
when new unseen classes appear dynamically. To this end, we propose a novel
heterogeneous graph-based knowledge transfer method (HGKT) for GZSL, agnostic
to unseen classes and instances, by leveraging graph neural network.
Specifically, a structured heterogeneous graph is constructed with high-level
representative nodes for seen classes, which are chosen through Wasserstein
barycenter in order to simultaneously capture inter-class and intra-class
relationship. The aggregation and embedding functions can be learned through
graph neural network, which can be used to compute the embeddings of unseen
classes by transferring the knowledge from their neighbors. Extensive
experiments on public benchmark datasets show that our method achieves
state-of-the-art results.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:20:05 GMT""}]","2019-11-21"
"1911.09047","Christopher Culver","Chris Culver, Maxim Mai, Ruair\'i Brett, Andrei Alexandru, Michael
  D\""oring","Three pion spectrum in the $I=3$ channel from lattice QCD",,"Phys. Rev. D 101, 114507 (2020)","10.1103/PhysRevD.101.114507",,"hep-lat nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three-body states are critical to the dynamics of many hadronic resonances.
We show that lattice QCD calculations have reached a stage where these states
can be accurately resolved. We perform a calculation over a wide range of
parameters and find all states below inelastic threshold agree with predictions
from a state-of-the-art phenomenological formalism. This also illustrates the
reliability of the formalism used to connect lattice QCD results to infinite
volume physics. Our calculation is performed using three positively charged
pions, with different lattice geometries and quark masses.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:20:09 GMT""},{""version"":""v2"",""created"":""Fri, 21 Aug 2020 19:24:07 GMT""},{""version"":""v3"",""created"":""Wed, 23 Sep 2020 15:10:02 GMT""}]","2020-09-24"
"1911.09048","James Schmidt","James Schmidt","Morphisms of Networks of Hybrid Open Systems",,,,,"math.DS math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This thesis (defended 10/07/2019) develops a theory of networks of hybrid
open systems and morphisms. It builds upon a framework of networks of
continuous-time open systems as product and interconnection. We work out
categorical notions for hybrid systems, deterministic hybrid systems, hybrid
open systems, networks of hybrid open systems, and morphisms of networks of
hybrid open systems.
  We also develop categorical notions for abstract systems, abstract open
systems, networks of abstract open systems, and morphisms of networks of
abstract open systems. We show that a collection of relations holding among
pairs of systems induces a relation between interconnected systems. We use this
result for abstract systems to prove a corresponding result for networks of
hybrid systems.
  This result translates as saying that our procedure for building networks
preserves morphisms of open systems: a collection of morphisms of (sub)systems
is sent to a morphism of networked systems. We thus both justify our formalism
and concretize the intuition that a network is a collection of systems pieced
together in a certain way.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:20:41 GMT""},{""version"":""v2"",""created"":""Thu, 26 Dec 2019 15:15:12 GMT""}]","2019-12-30"
"1911.09049","Russell Bowater","Russell J. Bowater","Sharp hypotheses and bispatial inference","Corrected, rewritten and extended. *Final version*",,,,"stat.OT stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A fundamental class of inferential problems are those characterised by there
having been a substantial degree of pre-data (or prior) belief that the value
of a model parameter was equal or lay close to a specified value, which may,
for example, be the value that indicates the absence of an effect. Standard
ways of tackling problems of this type, including the Bayesian method, are
often highly inadequate in practice. To address this issue, an inferential
framework called bispatial inference is put forward, which can be viewed as
both a generalisation and radical reinterpretation of existing approaches to
inference that are based on P values. It is shown that to obtain an appropriate
post-data density function for a given parameter, it is often convenient to
combine a special type of bispatial inference, which is constructed around
one-sided P values, with a previously outlined form of fiducial inference.
Finally, by using what are called post-data opinion curves, this
bispatial-fiducial theory is naturally extended to deal with the general
scenario in which any number of parameters may be unknown. The application of
the theory is illustrated in various examples, which are especially relevant to
the analysis of clinical trial data.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:24:29 GMT""},{""version"":""v2"",""created"":""Mon, 25 Jan 2021 18:28:26 GMT""}]","2021-01-26"
"1911.09050","Alexandros Kehagias","A. Kehagias and A. Riotto","A Note on the Swampland Distance Conjecture","6 pages, new revised version and title changed",,"10.1002/prop.201900099",,"hep-th astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the Swampland Distance Conjecture in the framework of black hole
thermodynamics. In particular, we consider black holes in de Sitter space and
we show that the Swampland Distance Conjecture is a consequence of the fact
that apparent horizons are always inside cosmic event horizons whenever they
exist in the case of fast-roll inflation. In addition, we show that the
Bekenstein and the Hubble entropy bounds for the entropy in a region of
spacetime lead similarly to the same conjecture.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:25:06 GMT""},{""version"":""v2"",""created"":""Wed, 27 Nov 2019 08:45:08 GMT""}]","2020-02-19"
"1911.09051","Cosimo Flavi","Cosimo Flavi","On the Fr\""olicher spectral sequence of the Iwasawa manifold and its
  small deformations",,,,,"math.DG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine the successive pages of the Fr\""olicher spectral sequence of the
Iwasawa manifold and some of its small deformations, providing new examples and
counterexamples on its properties, including the behaviour under small
deformations.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:26:38 GMT""}]","2019-11-21"
"1911.09053","Quanshi Zhang","Wen Shen, Zhihua Wei, Shikun Huang, Binbin Zhang, Panyue Chen, Ping
  Zhao, Quanshi Zhang","Verifiability and Predictability: Interpreting Utilities of Network
  Architectures for Point Cloud Processing",,,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we diagnose deep neural networks for 3D point cloud processing
to explore utilities of different intermediate-layer network architectures. We
propose a number of hypotheses on the effects of specific intermediate-layer
network architectures on the representation capacity of DNNs. In order to prove
the hypotheses, we design five metrics to diagnose various types of DNNs from
the following perspectives, information discarding, information concentration,
rotation robustness, adversarial robustness, and neighborhood inconsistency. We
conduct comparative studies based on such metrics to verify the hypotheses. We
further use the verified hypotheses to revise intermediate-layer architectures
of existing DNNs and improve their utilities. Experiments demonstrate the
effectiveness of our method.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:33:19 GMT""},{""version"":""v2"",""created"":""Sun, 11 Oct 2020 09:00:39 GMT""},{""version"":""v3"",""created"":""Thu, 1 Apr 2021 03:54:03 GMT""}]","2021-04-02"
"1911.09054","Linwei Zheng","Umar Ozgunalp, Rui Fan, Shanshan Cheng, Yuxiang Sun, Weixun Zuo,
  Yilong Zhu, Bohuan Xue, Linwei Zheng, Qing Liang, Ming Liu","Robust Lane Marking Detection Algorithm Using Drivable Area Segmentation
  and Extended SLT","4 pages, 3 figures, 2019 IEEE International Conference on Robotics
  and Biomimetics",,,,"cs.RO cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a robust lane detection algorithm is proposed, where the
vertical road profile of the road is estimated using dynamic programming from
the v-disparity map and, based on the estimated profile, the road area is
segmented. Since the lane markings are on the road area and any feature point
above the ground will be a noise source for the lane detection, a mask is
created for the road area to remove some of the noise for lane detection. The
estimated mask is multiplied by the lane feature map in a bird's eye view
(BEV). The lane feature points are extracted by using an extended version of
symmetrical local threshold (SLT), which not only considers dark light dark
transition (DLD) of the lane markings, like (SLT), but also considers
parallelism on the lane marking borders. The segmentation then uses only the
feature points that are on the road area. A maximum of two linear lane markings
are detected using an efficient 1D Hough transform. Then, the detected linear
lane markings are used to create a region of interest (ROI) for parabolic lane
detection. Finally, based on the estimated region of interest, parabolic lane
models are fitted using robust fitting. Due to the robust lane feature
extraction and road area segmentation, the proposed algorithm robustly detects
lane markings and achieves lane marking detection with an accuracy of 91% when
tested on a sequence from the KITTI dataset.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:34:31 GMT""}]","2019-11-21"
"1911.09055","Halleh Balch","Jason Horng, Halleh B. Balch, Allister F. McGuire, Hsin-Zon Tsai,
  Patrick R. Forrester, Michael F. Crommie, Bianxiao Cui, Feng Wang","Imaging electric field dynamics with graphene optoelectronics","9 pages, 5 figures, supplement can be found at 10.1038/ncomms13704","Nat Commun 7, 13704 (2016)","10.1038/ncomms13704",,"cond-mat.mes-hall physics.ins-det physics.optics","http://creativecommons.org/licenses/by/4.0/","  The use of electric fields for signalling and control in liquids is
widespread, spanning bioelectric activity in cells to electrical manipulation
of microstructures in lab-on-a-chip devices. However, an appropriate tool to
resolve the spatio-temporal distribution of electric fields over a large
dynamic range has yet to be developed. Here we present a label-free method to
image local electric fields in real time and under ambient conditions. Our
technique combines the unique gate-variable optical transitions of graphene
with a critically coupled planar waveguide platform that enables highly
sensitive detection of local electric fields with a voltage sensitivity of a
few microvolts, a spatial resolution of tens of micrometres and a frequency
response over tens of kilohertz. Our imaging platform enables parallel
detection of electric fields over a large field of view and can be tailored to
broad applications spanning lab-on-a-chip device engineering to analysis of
bioelectric phenomena.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:36:06 GMT""}]","2019-11-21"
"1911.09056","Giorgio Galanti","Giorgio Galanti, Fabrizio Tavecchio, Marco Landoni","Fundamental physics with blazar spectra: a critical appraisal","10 pages, 7 figures, revised version submitted to MNRAS",,"10.1093/mnras/stz3411",,"astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Very-high-energy (VHE) BL Lac spectra extending above $10 \, \rm TeV$ provide
a unique opportunity for testing physics beyond the standard model of
elementary particle and alternative blazar emission models. We consider the
hadron beam, the photon to axion-like particle (ALP) conversion, and the
Lorentz invariance violation (LIV) scenarios by analyzing their consequences
and induced modifications to BL Lac spectra. In particular, we consider how
different processes can provide similar spectral features (e.g. hard tails) and
we discuss the ways they can be disentangled. We use HEGRA data of a high state
of Markarian 501 and the HESS spectrum of the extreme BL Lac (EHBL) 1ES
0229+200. In addition, we consider two hypothetical EHBLs similar to 1ES
0229+200 located at redshifts $z=0.3$ and $z=0.5$. We observe that both the
hadron beam and the photon-ALP oscillations predict a hard tail extending to
energies larger than those possible in the standard scenario. Photon-ALP
interaction predicts a peak in the spectra of distant BL Lacs at about $20-30
\, \rm TeV$, while LIV produces a strong peak in all BL Lac spectra around
$\sim 100 \, \rm TeV$. The peculiar feature of the photon-ALP conversion model
is the production of oscillations in the spectral energy distribution, so that
its detection/absence can be exploited to distinguish among the considered
models. The above mentioned features coming from the three models may be
detected by the upcoming Cherenkov Telescope Array (CTA). Thus, future
observations of BL Lac spectra could eventually shed light about new physics
and alternative blazar emission models, driving fundamental research towards a
specific direction.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:41:19 GMT""}]","2020-01-08"
"1911.09057","Lucas Gren","Lucas Gren, Alfredo Goldman and Christian Jacobsson","The perceived effects of group developmental psychology training on
  agile software development teams",,"IEEE Software, 2019","10.1109/MS.2019.2955675",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Research has shown that the maturity of small workgroups from a psychological
perspective is intimately connected to team agility. We, therefore, tested if
agile team members appreciated group development psychology training. Our
results show that the participating teams seem to have a very positive view of
group development training and state that they now have a new way of thinking
about teamwork and new tools to deal with team-related problems. We, therefore,
see huge potential in training agile teams in group development psychology
since the positive effects might span over the entire software development
organization.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:41:57 GMT""}]","2019-11-26"
"1911.09058","Omid Poursaeed","Omid Poursaeed, Tianxing Jiang, Yordanos Goshu, Harry Yang, Serge
  Belongie, Ser-Nam Lim","Fine-grained Synthesis of Unrestricted Adversarial Examples",,,,,"cs.CV cs.CR cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a novel approach for generating unrestricted adversarial examples
by manipulating fine-grained aspects of image generation. Unlike existing
unrestricted attacks that typically hand-craft geometric transformations, we
learn stylistic and stochastic modifications leveraging state-of-the-art
generative models. This allows us to manipulate an image in a controlled,
fine-grained manner without being bounded by a norm threshold. Our approach can
be used for targeted and non-targeted unrestricted attacks on classification,
semantic segmentation and object detection models. Our attacks can bypass
certified defenses, yet our adversarial images look indistinguishable from
natural images as verified by human evaluation. Moreover, we demonstrate that
adversarial training with our examples improves performance of the model on
clean images without requiring any modifications to the architecture. We
perform experiments on LSUN, CelebA-HQ and COCO-Stuff as high resolution
datasets to validate efficacy of our proposed approach.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:42:12 GMT""},{""version"":""v2"",""created"":""Thu, 22 Oct 2020 16:53:26 GMT""}]","2020-10-23"
"1911.09059","Sergei F Soprunov","Sergei Soprunov","There is no maximal decidable expansion of the $\langle \mathbb{N} ,\{ <
  \} \rangle$ structure","found an error in the proof of statement 2, page 3",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We are going to prove that if the theory of a structure $\mathcal M=\langle
\mathbb{N}, \Sigma \rangle$ is decidable and the standard order $<$ on natural
numbers $\mathbb{N}$ is definable in $\mathcal M$, then there is a nontrivial
decidable expansion of $\mathcal M$
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:43:52 GMT""},{""version"":""v2"",""created"":""Tue, 24 Dec 2019 07:39:06 GMT""},{""version"":""v3"",""created"":""Tue, 29 Nov 2022 11:00:16 GMT""}]","2022-11-30"
"1911.09060","Antonino Del Popolo","J. A. S. Lima (Departamento de Astronomia, Universidade de Sao Paulo),
  A. Del Popolo (Catania University), A. R. Plastino (CeBio y Departamento de
  Ciencias Basicas, Universidad Nacional del Noroeste de la Provincia de Buenos
  Aires, UNNOBA)","Thermodynamic Equilibrium in General Relativity","7 pages, 2 figures, PRD accepted","PRD 2009, volume 100, 104042;
  https://journals.aps.org/prd/abstract/10.1103/PhysRevD.100.104042","10.1103/PhysRevD.100.104042",,"gr-qc astro-ph.GA cond-mat.stat-mech physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The thermodynamic equilibrium condition for a static self-gravitating fluid
in the Einstein theory is defined by the Tolman-Ehrenfest temperature law,
$T{\sqrt {g_{00}(x^{i})}} = constant$, according to which the proper
temperature depends explicitly on the position within the medium through the
metric coefficient $g_{00}(x^{i})$. By assuming the validity of
Tolman-Ehrenfest ""pocket temperature"", Klein also proved a similar relation for
the chemical potential, namely, $\mu {\sqrt {g_{00}(x^{i})}} = constant$. In
this letter we prove that a more general relation uniting both quantities holds
regardless of the equation of state satisfied by the medium, and that the
original Tolman-Ehrenfest law form is valid only if the chemical potential
vanishes identically. In the general case of equilibrium, the temperature and
the chemical potential are intertwined in such a way that only a definite
(position dependent) relation uniting both quantities is obeyed. As an
illustration of these results, the temperature expressions for an isothermal
gas (finite spherical distribution) and a neutron star are also determined.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:44:36 GMT""},{""version"":""v2"",""created"":""Sat, 23 Nov 2019 17:53:43 GMT""}]","2020-09-02"
"1911.09061","Azim Ahmadzadeh","Azim Ahmadzadeh, Maxwell Hostetter, Berkay Aydin, Manolis K.
  Georgoulis, Dustin J. Kempton, Sushant S. Mahajan, and Rafal A. Angryk","Challenges with Extreme Class-Imbalance and Temporal Coherence: A Study
  on Solar Flare Data","9 pages, 9 figures, and 1 table, accepted in IEEE BigData 2019",,,,"cs.LG astro-ph.SR stat.ML","http://creativecommons.org/licenses/by/4.0/","  In analyses of rare-events, regardless of the domain of application,
class-imbalance issue is intrinsic. Although the challenges are known to data
experts, their explicit impact on the analytic and the decisions made based on
the findings are often overlooked. This is in particular prevalent in
interdisciplinary research where the theoretical aspects are sometimes
overshadowed by the challenges of the application. To show-case these
undesirable impacts, we conduct a series of experiments on a recently created
benchmark data, named Space Weather ANalytics for Solar Flares (SWAN-SF). This
is a multivariate time series dataset of magnetic parameters of active regions.
As a remedy for the imbalance issue, we study the impact of data manipulation
(undersampling and oversampling) and model manipulation (using class weights).
Furthermore, we bring to focus the auto-correlation of time series that is
inherited from the use of sliding window for monitoring flares' history.
Temporal coherence, as we call this phenomenon, invalidates the randomness
assumption, thus impacting all sampling practices including different
cross-validation techniques. We illustrate how failing to notice this concept
could give an artificial boost in the forecast performance and result in
misleading findings. Throughout this study we utilized Support Vector Machine
as a classifier, and True Skill Statistics as a verification metric for
comparison of experiments. We conclude our work by specifying the correct
practice in each case, and we hope that this study could benefit researchers in
other domains where time series of rare events are of interest.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:46:38 GMT""}]","2019-11-21"
"1911.09062","David Luong","David Luong, Sreeraman Rajan, Bhashyam Balaji","Quantum Two-Mode Squeezing Radar and Noise Radar: Correlation
  Coefficients for Target Detection","7 pages, 5 figures; submitted to IEEE Sensors Journal",,"10.1109/JSEN.2020.2971851",,"quant-ph eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum two-mode squeezing (QTMS) radars and noise radars detect targets by
correlating the received signal with an internally stored recording. A
covariance matrix can be calculated between the two which, in theory, is a
function of a single correlation coefficient. This coefficient can be used to
decide whether a target is present or absent. We can estimate the correlation
coefficient by minimizing the Frobenius norm between the sample covariance
matrix and the theoretically expected form of the matrix. Using simulated data,
we show that the estimates follow a Rice distribution whose parameters are
simple functions of the underlying, ""true"" correlation coefficient as well as
the number of integrated samples. We obtain an explicit expression for the
receiver operating characteristic curve that results when the correlation
coefficient is used for target detection. This is an important first step
toward performance prediction for QTMS radars.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:49:50 GMT""}]","2020-05-06"
"1911.09063","Yizhe Zhu","Zhixin Zhou, Yizhe Zhu","Sparse random tensors: Concentration, regularization and applications","24 pages","Electron. J. Statist. 15(1): 2483-2516 (2021)","10.1214/21-EJS1838",,"math.PR math.CO math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a non-asymptotic concentration inequality for the spectral norm of
sparse inhomogeneous random tensors with Bernoulli entries. For an order-$k$
inhomogeneous random tensor $T$ with sparsity $p_{\max}\geq \frac{c\log n}{n
}$, we show that $\|T-\mathbb E T\|=O(\sqrt{n p_{\max}}\log^{k-2}(n))$ with
high probability. The optimality of this bound up to polylog factors is
provided by an information theoretic lower bound. By tensor unfolding, we
extend the range of sparsity to $p_{\max}\geq \frac{c\log n}{n^{m}}$ with
$1\leq m\leq k-1$ and obtain concentration inequalities for different sparsity
regimes. We also provide a simple way to regularize $T$ such that
$O(\sqrt{n^{m}p_{\max}})$ concentration still holds down to sparsity
$p_{\max}\geq \frac{c}{n^{m}}$ with $k/2\leq m\leq k-1$. We present our
concentration and regularization results with two applications: (i) a
randomized construction of hypergraphs of bounded degrees with good expander
mixing properties, (ii) concentration of sparsified tensors under uniform
sampling.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:50:55 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 04:05:31 GMT""},{""version"":""v3"",""created"":""Mon, 2 Dec 2019 05:11:32 GMT""},{""version"":""v4"",""created"":""Mon, 23 Dec 2019 03:16:02 GMT""},{""version"":""v5"",""created"":""Tue, 23 Mar 2021 19:43:11 GMT""},{""version"":""v6"",""created"":""Sun, 28 Mar 2021 05:23:01 GMT""},{""version"":""v7"",""created"":""Tue, 4 May 2021 05:20:31 GMT""}]","2021-05-05"
"1911.09064","Lucas Gren","Lucas Gren, Alfredo Goldman and Christian Jacobsson","Agile Ways of Working: A Team Maturity Perspective",,"Journal of Software: Evolution and Process, 2019","10.1002/smr.2244",,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With the agile approach to managing software development projects comes an
increased dependability on well functioning teams, since many of the practices
are built on teamwork. The objective of this study was to investigate if, and
how, team development from a group psychological perspective is related to some
work practices of agile teams. Data were collected from 34 agile teams (200
individuals) from six software development organizations and one university in
both Brazil and Sweden using the Group Development Questionnaire (Scale IV) and
the Perceptive Agile Measurement (PAM). The result indicates a strong
correlation between levels of group maturity and the two agile practices
\emph{iterative development} and \emph{retrospectives}. We, therefore, conclude
that agile teams at different group development stages adopt parts of team
agility differently, thus confirming previous studies but with more data and by
investigating concrete and applied agile practices. We thereby add evidence to
the hypothesis that an agile implementation and management of agile projects
need to be adapted to the group maturity levels of the agile teams.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:56:21 GMT""}]","2019-11-26"
"1911.09065","Marcin Wrochna","Alex Brandts, Marcin Wrochna, Stanislav \v{Z}ivn\'y","The complexity of promise SAT on non-Boolean domains","Full version of an ICALP 2020 paper","ACM Transactions on Computation Theory 13(4) Article No. 26 (2021)","10.1145/3470867",,"cs.DM cs.CC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  While 3-SAT is NP-hard, 2-SAT is solvable in polynomial time. Austrin,
Guruswami, and H\r{a}stad roved a result known as ""$(2+\varepsilon)$-SAT is
NP-hard"" [FOCS'14/SICOMP'17]. They showed that the problem of distinguishing
k-CNF formulas that are g-satisfiable (i.e. some assignment satisfies at least
g literals in every clause) from those that are not even 1-satisfiable is
NP-hard if $\frac{g}{k} < \frac{1}{2}$ and is in P otherwise. We study a
generalisation of SAT on arbitrary finite domains, with clauses that are
disjunctions of unary constraints, and establish analogous behaviour. Thus we
give a dichotomy for a natural fragment of promise constraint satisfaction
problems (PCSPs) on arbitrary finite domains.
  The hardness side is proved using the algebraic approach, via a new general
NP-hardness criterion on polymorphisms of the problem, based on a gap version
of the Layered Label Cover problem. We show that previously used criteria are
insufficient -- the problem hence gives an interesting benchmark of algebraic
techniques for proving hardness of approximation problems such as PCSPs.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:57:38 GMT""},{""version"":""v2"",""created"":""Sun, 3 May 2020 11:36:59 GMT""},{""version"":""v3"",""created"":""Tue, 6 Apr 2021 18:40:00 GMT""}]","2021-09-10"
"1911.09066","Simon Boudet","Flavio Bombacigno, Simon Boudet and Giovanni Montani","Generalized Ashtekar variables for Palatini f(R) models","27 pages, comments are welcome",,"10.1016/j.nuclphysb.2020.115281",,"gr-qc hep-th","http://creativecommons.org/licenses/by/4.0/","  We consider special classes of Palatini f(R) theories, featured by additional
Loop Quantum Gravity inspired terms, with the aim of identifying a set of
modified Ashtekar canonical variables, which still preserve the SU(2) gauge
structure of the standard theory. In particular, we allow for affine connection
to be endowed with torsion, which turns out to depend on the additional scalar
degree affecting Palatini f(R) gravity, and in this respect we successfully
construct a novel Gauss constraint. We analyze the role of the additional
scalar field, outlining as it acquires a dynamical character by virtue of a non
vanishing Immirzi parameter, and we describe some possible effects on the area
operator stemming from such a revised theoretical framework. Finally, we
compare our results with earlier studies in literature, discussing differences
between metric and Palatini approaches. It is worth noting how the Hamiltonian
turns out to be different in the two cases. The results can be reconciled when
the analysis is performed in the Einstein frame.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:59:01 GMT""},{""version"":""v2"",""created"":""Mon, 2 Mar 2020 10:22:43 GMT""},{""version"":""v3"",""created"":""Wed, 27 May 2020 13:01:09 GMT""},{""version"":""v4"",""created"":""Mon, 12 Oct 2020 16:57:57 GMT""},{""version"":""v5"",""created"":""Thu, 17 Dec 2020 13:08:57 GMT""}]","2020-12-22"
"1911.09067","Bruno Sudret","X. Zhu and B. Sudret","Replication-based emulation of the response distribution of stochastic
  simulators using generalized lambda distributions",,,,"RSUQ-2019-008","stat.CO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to limited computational power, performing uncertainty quantification
analyses with complex computational models can be a challenging task. This is
exacerbated in the context of stochastic simulators, the response of which to a
given set of input parameters, rather than being a deterministic value, is a
random variable with unknown probability density function (PDF). Of interest in
this paper is the construction of a surrogate that can accurately predict this
response PDF for any input parameters. We suggest using a flexible distribution
family -- the generalized lambda distribution -- to approximate the response
PDF. The associated distribution parameters are cast as functions of input
parameters and represented by sparse polynomial chaos expansions. To build such
a surrogate model, we propose an approach based on a local inference of the
response PDF at each point of the experimental design based on replicated model
evaluations. Two versions of this framework are proposed and compared on
analytical examples and case studies.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:03:13 GMT""}]","2019-11-21"
"1911.09068","Denise Resende","Erick Schultz S. A. Caetano, Denise Fonseca Resende, Samir Angelo
  Milani Martins, Erivelton Geraldo Nepomuceno and Leonardo Bonato Felix","Modelagem de Sistemas Audiom\'etricos Usando T\'ecnicas de
  Computa\c{c}\~ao Flex\'ivel","16 pages, in Portuguese, 9 figures, To appear in the proceedings of
  II Latin American Workshop on Computational Neuroscience, S\~ao Jo\~ao
  del-Rei, MG - Brazil - September, 18-20, 2019",,,,"eess.SY cs.SY","http://creativecommons.org/licenses/by/4.0/","  In systems identification, the studied phenomena are accompanied by
uncertainties, whether arising from measurement data or computational
calculations. Interval data provides a valuable way to represent available
information on complex problems where uncertainty, inaccuracy, or variability
must be taken into account. The present work aims to determine interval
parameters for a model considering data measurement uncertainties using the MQ
estimator and neural networks. The main objective of this work is to apply this
technique in audiometric systems, particularly in the automatic detection of
auditory responses taking into consideration the flexible computing concepts
that offer solutions tolerant to subjectivity, inaccuracy or uncertainty. It
was possible to obtain a model with interval parameters that allow an infinite
set of parameters to be evaluated as a limited range. The model was validated
using two methods, one with prediction of 2 steps ahead, using the MQ estimator
and extended to another representation as neural networks 5 steps delay. It has
been shown that interval parameters generate interval results that contain most
validation data improving system reliability.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:03:26 GMT""}]","2019-11-21"
"1911.09069","Nicola Apollonio","Nicola Apollonio and Lorenzo Balzotti","A New Characterization of Path Graphs",,,,,"cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Path graphs are intersection graphs of paths in a tree.~In this paper we give
a ""6\ good characterization"" of path graphs, namely, we prove that path graph
membership is in $NP\cap CoNP$ without resorting to existing polynomial time
algorithms. The characterization is given in terms of the collection of the
\emph{attachedness graphs} of a graph, a novel device to deal with the
connected components of a graph after the removal of clique separators. On the
one hand, the characterization refines and simplifies the characterization of
path graphs due to Monma and Wei [C.L.~Monma,~and~V.K.~Wei, Intersection
{G}raphs of {P}aths in a {T}ree, J. Combin. Theory Ser. B, 41:2 (1986)
141--181], which we build on, by reducing a constrained vertex coloring problem
defined on the \emph{attachedness graphs} to a vertex 2-coloring problem on the
same graphs. On the other hand, the characterization allows us to exhibit two
exhaustive lists of obstructions to path graph membership in the form of
minimal forbidden induced/partial 2-edge colored subgraphs in each of the
\emph{attachedness graphs}.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:08:36 GMT""},{""version"":""v2"",""created"":""Fri, 17 Sep 2021 09:40:34 GMT""}]","2021-09-20"
"1911.09070","Mingxing Tan","Mingxing Tan, Ruoming Pang, Quoc V. Le","EfficientDet: Scalable and Efficient Object Detection","CVPR 2020","Proceedings of the IEEE Conference on Computer Vision and Pattern
  Recognition (2020)",,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model efficiency has become increasingly important in computer vision. In
this paper, we systematically study neural network architecture design choices
for object detection and propose several key optimizations to improve
efficiency. First, we propose a weighted bi-directional feature pyramid network
(BiFPN), which allows easy and fast multiscale feature fusion; Second, we
propose a compound scaling method that uniformly scales the resolution, depth,
and width for all backbone, feature network, and box/class prediction networks
at the same time. Based on these optimizations and better backbones, we have
developed a new family of object detectors, called EfficientDet, which
consistently achieve much better efficiency than prior art across a wide
spectrum of resource constraints. In particular, with single model and
single-scale, our EfficientDet-D7 achieves state-of-the-art 55.1 AP on COCO
test-dev with 77M parameters and 410B FLOPs, being 4x - 9x smaller and using
13x - 42x fewer FLOPs than previous detectors. Code is available at
https://github.com/google/automl/tree/master/efficientdet.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:16:09 GMT""},{""version"":""v2"",""created"":""Sun, 15 Mar 2020 22:55:42 GMT""},{""version"":""v3"",""created"":""Tue, 31 Mar 2020 18:47:08 GMT""},{""version"":""v4"",""created"":""Fri, 3 Apr 2020 20:34:21 GMT""},{""version"":""v5"",""created"":""Sun, 24 May 2020 07:12:44 GMT""},{""version"":""v6"",""created"":""Sun, 14 Jun 2020 18:28:53 GMT""},{""version"":""v7"",""created"":""Mon, 27 Jul 2020 15:55:16 GMT""}]","2020-07-28"
"1911.09071","Katherine Hermann","Katherine L. Hermann, Ting Chen, and Simon Kornblith","The Origins and Prevalence of Texture Bias in Convolutional Neural
  Networks","NeurIPS'2020",,,,"cs.CV cs.LG q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent work has indicated that, unlike humans, ImageNet-trained CNNs tend to
classify images by texture rather than by shape. How pervasive is this bias,
and where does it come from? We find that, when trained on datasets of images
with conflicting shape and texture, CNNs learn to classify by shape at least as
easily as by texture. What factors, then, produce the texture bias in CNNs
trained on ImageNet? Different unsupervised training objectives and different
architectures have small but significant and largely independent effects on the
level of texture bias. However, all objectives and architectures still lead to
models that make texture-based classification decisions a majority of the time,
even if shape information is decodable from their hidden representations. The
effect of data augmentation is much larger. By taking less aggressive random
crops at training time and applying simple, naturalistic augmentation (color
distortion, noise, and blur), we train models that classify ambiguous images by
shape a majority of the time, and outperform baselines on out-of-distribution
test sets. Our results indicate that apparent differences in the way humans and
ImageNet-trained CNNs process images may arise not primarily from differences
in their internal workings, but from differences in the data that they see.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:16:38 GMT""},{""version"":""v2"",""created"":""Mon, 29 Jun 2020 20:48:56 GMT""},{""version"":""v3"",""created"":""Tue, 3 Nov 2020 22:51:23 GMT""}]","2020-11-05"
"1911.09072","Philippe Gimenez","Philippe Gimenez and Hema Srinivasan","Gluing semigroups -- when and how",,,,,"math.AC math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given two semigroups $\langle A\rangle$ and $\langle B\rangle$ in ${\mathbb
N}^n$, we wonder when they can be glued, i.e., when there exists a semigroup
$\langle C\rangle$ in ${\mathbb N}^n$ such that the defining ideals of the
corresponding semigroup rings satisfy that $I_C=I_A+I_B+\langle\rho\rangle$ for
some binomial $\rho$. If $n\geq 2$ and $k[A]$ and $k[B]$ are Cohen-Macaulay, we
prove that in order to glue them, one of the two semigroups must be degenerate.
Then we study the two most degenerate cases: when one of the semigroups is
generated by one single element (simple split) and the case where it is
generated by at least two elements and all the elements of the semigroup lie on
a line. In both cases we characterize the semigroups that can be glued and say
how to glue them. Further, in these cases, we conclude that the glued $\langle
C\rangle$ is Cohen-Macaulay if and only if both $\langle A\rangle$ and $\langle
B\rangle$ are also Cohen-Macaulay. As an application, we characterize precisely
the Cohen-Macaulay semigroups that can be glued when $n=2$.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:16:55 GMT""}]","2019-11-21"
"1911.09073","Nathalie Palanque-Delabrouille","Nathalie Palanque-Delabrouille, Christophe Y\`eche, Nils Sch\""oneberg,
  Julien Lesgourgues, Michael Walther, Sol\`ene Chabanier, Eric Armengaud","Hints, neutrino bounds and WDM constraints from SDSS DR14 Lyman-$\alpha$
  and Planck full-survey data","accepted for publication in JCAP","JCAP 04 (2020) 038","10.1088/1475-7516/2020/04/038",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Ly-$\alpha$ forest 1D flux power spectrum is a powerful probe of several
cosmological parameters. Assuming a $\Lambda$CDM cosmology including massive
neutrinos, we find that the latest SDSS DR14 BOSS and eBOSS Ly-$\alpha$ forest
data is in very good agreement with current weak lensing constraints on
$(\Omega_m, \sigma_8)$ and has the same small level of tension with Planck. We
did not identify a systematic effect in the data analysis that could explain
this small tension, but we show that it can be reduced in extended cosmological
models where the spectral index is not the same on the very different times and
scales probed by CMB and Ly-$\alpha$ data. A particular case is that of a
$\Lambda$CDM model including a running of the spectral index on top of massive
neutrinos. With combined Ly-$\alpha$ and Planck data, we find a slight
(3$\sigma$) preference for negative running, $\alpha_s= -0.010 \pm 0.004$ (68%
CL). Neutrino mass bounds are found to be robust against different assumptions.
In the $\Lambda$CDM model with running, we find $\sum m_\nu <0.11$ eV at the
95% confidence level for combined Ly-$\alpha$ and Planck (temperature and
polarisation) data, or $\sum m_\nu < 0.09$ eV when adding CMB lensing and BAO
data. We further provide strong and nearly model-independent bounds on the mass
of thermal warm dark matter. For a conservative configuration consisting of
SDSS data restricted to $z<4.5$ combined with XQ-100 \lya data, we find $m_X >
5.3\;\mathrm{keV}$ (95\%CL).
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:17:57 GMT""},{""version"":""v2"",""created"":""Thu, 21 Nov 2019 10:07:47 GMT""},{""version"":""v3"",""created"":""Mon, 6 Apr 2020 16:20:03 GMT""}]","2020-04-28"
"1911.09074","Yu Liu","Yu Liu, Xuhui Jia, Mingxing Tan, Raviteja Vemulapalli, Yukun Zhu,
  Bradley Green, Xiaogang Wang","Search to Distill: Pearls are Everywhere but not the Eyes","Accepted as an oral representation to CVPR 2020",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Standard Knowledge Distillation (KD) approaches distill the knowledge of a
cumbersome teacher model into the parameters of a student model with a
pre-defined architecture. However, the knowledge of a neural network, which is
represented by the network's output distribution conditioned on its input,
depends not only on its parameters but also on its architecture. Hence, a more
generalized approach for KD is to distill the teacher's knowledge into both the
parameters and architecture of the student. To achieve this, we present a new
Architecture-aware Knowledge Distillation (AKD) approach that finds student
models (pearls for the teacher) that are best for distilling the given teacher
model. In particular, we leverage Neural Architecture Search (NAS), equipped
with our KD-guided reward, to search for the best student architectures for a
given teacher. Experimental results show our proposed AKD consistently
outperforms the conventional NAS plus KD approach, and achieves
state-of-the-art results on the ImageNet classification task under various
latency settings. Furthermore, the best AKD student architecture for the
ImageNet classification task also transfers well to other tasks such as million
level face recognition and ensemble learning.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:19:25 GMT""},{""version"":""v2"",""created"":""Tue, 17 Mar 2020 03:48:49 GMT""}]","2020-03-18"
"1911.09075","Wenxiang Jiao","Wenxiang Jiao, Michael R. Lyu, Irwin King","Real-Time Emotion Recognition via Attention Gated Hierarchical Memory
  Network","AAAI 2020, 8 pages, 5 figures",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Real-time emotion recognition (RTER) in conversations is significant for
developing emotionally intelligent chatting machines. Without the future
context in RTER, it becomes critical to build the memory bank carefully for
capturing historical context and summarize the memories appropriately to
retrieve relevant information. We propose an Attention Gated Hierarchical
Memory Network (AGHMN) to address the problems of prior work: (1) Commonly used
convolutional neural networks (CNNs) for utterance feature extraction are less
compatible in the memory modules; (2) Unidirectional gated recurrent units
(GRUs) only allow each historical utterance to have context before it,
preventing information propagation in the opposite direction; (3) The Soft
Attention for summarizing loses the positional and ordering information of
memories, regardless of how the memory bank is built. Particularly, we propose
a Hierarchical Memory Network (HMN) with a bidirectional GRU (BiGRU) as the
utterance reader and a BiGRU fusion layer for the interaction between
historical utterances. For memory summarizing, we propose an Attention GRU
(AGRU) where we utilize the attention weights to update the internal state of
GRU. We further promote the AGRU to a bidirectional variant (BiAGRU) to balance
the contextual information from recent memories and that from distant memories.
We conduct experiments on two emotion conversation datasets with extensive
analysis, demonstrating the efficacy of our AGHMN models.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:27:22 GMT""}]","2019-11-21"
"1911.09076","Joni Ter\""av\""ainen","Kaisa Matom\""aki, Joni Ter\""av\""ainen","On the M\""obius function in all short intervals","18 pages; referee comments incorporated",,"10.4171/JEMS/1205",,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that, for the M\""obius function $\mu(n)$, we have $$ \sum_{x < n\leq
x+x^{\theta}}\mu(n)=o(x^{\theta}) $$ for any $\theta>0.55$. This improves on a
result of Ramachandra from 1976, which is valid for $\theta>7/12$.
Ramachandra's result corresponded to Huxley's $7/12$ exponent for the prime
number theorem in short intervals. The main new idea leading to the improvement
is using Ramar\'e's identity to extract a small prime factor from the $n$-sum.
The proof method also allows us to improve on an estimate of Zhan for the
exponential sum of the M\""obius function as well as some results on
multiplicative functions and almost primes in short intervals.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:28:04 GMT""},{""version"":""v2"",""created"":""Wed, 2 Dec 2020 00:38:24 GMT""}]","2022-06-08"
"1911.09077","Alberto Ordonez Pereira","Alberto Ord\'o\~nez, Gonzalo Navarro and Nieves R. Brisaboa","Grammar Compressed Sequences with Rank/Select Support","This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941","Journal of Discrete Algorithms 43, pp. 54-71 (2017)","10.1016/j.jda.2016.10.001",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequence representations supporting not only direct access to their symbols,
but also rank/select operations, are a fundamental building block in many
compressed data structures. Several recent applications need to represent
highly repetitive sequences, and classical statistical compression proves
ineffective. We introduce, instead, grammar-based representations for
repetitive sequences, which use up to 6% of the space needed by statistically
compressed representations, and support direct access and rank/select
operations within tens of microseconds. We demonstrate the impact of our
structures in text indexing applications.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:29:30 GMT""},{""version"":""v2"",""created"":""Thu, 21 Nov 2019 21:32:34 GMT""}]","2019-11-25"
"1911.09078","Franco Vargas Pallete","D\'idac Mart\'inez-Granado and Franco Vargas Pallete","Comparing hyperbolic and extremal lengths for shortest curves","18 pages, 7 figures. Comments welcome",,,,"math.GT math.DG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  We give a linear upper bound for the extremal length in terms of the
hyperbolic length for curves of a shortest pair of pants decomposition. As a
consequence, we obtain results on the asymptotics of the maximum of the
extremal length systole in moduli space for large genus. We also obtain upper
bounds for the extremal length of shortest pair of pants decompositions and for
the renormalized volume of 3-manifolds.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:29:54 GMT""}]","2019-11-21"
"1911.09079","Federico Fuentes","Federico Fuentes, David Goluskin and Sergei Chernyshenko","Global stability of fluid flows despite transient growth of energy","6 pages + 4-page supplement, 3 figures","Phys. Rev. Lett. 128, 204502 (2022)","10.1103/PhysRevLett.128.204502",,"physics.flu-dyn math.DS math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Verifying nonlinear stability of a laminar fluid flow against all
perturbations is a central challenge in fluid dynamics. Past results rely on
monotonic decrease of a perturbation energy or a similar quadratic generalized
energy. None show stability for the many flows that seem to be stable despite
these energies growing transiently. Here a broadly applicable method to verify
global stability of such flows is presented. It uses polynomial optimization
computations to construct non-quadratic Lyapunov functions that decrease
monotonically. The method is used to verify global stability of 2D plane
Couette flow at Reynolds numbers above the energy stability threshold found by
Orr in 1907. This is the first global stability result for any flow that
surpasses the energy method.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:29:57 GMT""},{""version"":""v2"",""created"":""Thu, 3 Mar 2022 18:22:01 GMT""}]","2022-05-26"
"1911.09083","Gabriele Vajente","Gabriele Vajente, Yiwen Huang, Maximiliano Isi, Jenne C. Driggers,
  Jeffrey S. Kissel, Marek J. Szczepanczyk, Salvatore Vitale","Machine-learning non-stationary noise out of gravitational wave
  detectors",,"Phys. Rev. D 101, 042003 (2020)","10.1103/PhysRevD.101.042003",,"gr-qc astro-ph.IM cs.LG physics.data-an physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Signal extraction out of background noise is a common challenge in high
precision physics experiments, where the measurement output is often a
continuous data stream. To improve the signal to noise ratio of the detection,
witness sensors are often used to independently measure background noises and
subtract them from the main signal. If the noise coupling is linear and
stationary, optimal techniques already exist and are routinely implemented in
many experiments. However, when the noise coupling is non-stationary, linear
techniques often fail or are sub-optimal. Inspired by the properties of the
background noise in gravitational wave detectors, this work develops a novel
algorithm to efficiently characterize and remove non-stationary noise
couplings, provided there exist witnesses of the noise source and of the
modulation. In this work, the algorithm is described in its most general
formulation, and its efficiency is demonstrated with examples from the data of
the Advanced LIGO gravitational wave observatory, where we could obtain an
improvement of the detector gravitational wave reach without introducing any
bias on the source parameter estimation.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:41:24 GMT""},{""version"":""v2"",""created"":""Fri, 10 Jan 2020 21:45:19 GMT""},{""version"":""v3"",""created"":""Tue, 28 Jan 2020 23:57:39 GMT""}]","2020-02-26"
"1911.09084","Marcel Oliver","Zymantas Darbenas, Marcel Oliver","Breakdown of Liesegang precipitation bands in a simplified fast reaction
  limit of the Keller-Rubinow model",,,,,"math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study solutions to the integral equation \[ \omega(x) = \Gamma - x^2
\int_{0}^1 K(\theta) \, H(\omega(x\theta)) \, \mathrm d \theta \] where
$\Gamma>0$, $K$ is a weakly degenerate kernel satisfying, among other
properties, $K(\theta) \sim k \, (1-\theta)^\sigma$ as $\theta \to 1$ for
constants $k>0$ and $\sigma \in (0, \log_2 3 -1)$, $H$ denotes the Heaviside
function, and $x \in [0,\infty)$. This equation arises from a
reaction-diffusion equation describing Liesegang precipitation band patterns
under certain simplifying assumptions. We argue that the integral equation is
an analytically tractable paradigm for the clustering of precipitation rings
observed in the full model. This problem is nontrivial as the right hand side
fails a Lipschitz condition so that classical contraction mapping arguments do
not apply.
  Our results are the following. Solutions to the integral equation, which
initially feature a sequence of relatively open intervals on which $\omega$ is
positive (""rings"") or negative (""gaps"") break down beyond a finite interval
$[0,x^*]$ in one of two possible ways. Either the sequence of rings accumulates
at $x^*$ (""non-degenerate breakdown"") or the solution cannot be continued past
one of its zeroes at all (""degenerate breakdown""). Moreover, we show that
degenerate breakdown is possible within the class of kernels considered.
Finally, we prove existence of generalized solutions which extend the integral
equation past the point of breakdown.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:46:32 GMT""},{""version"":""v2"",""created"":""Fri, 6 Dec 2019 18:19:25 GMT""},{""version"":""v3"",""created"":""Wed, 28 Oct 2020 13:03:36 GMT""}]","2020-10-29"
"1911.09086","Monica Arul","Monica Arul and Ahsan Kareem","Shapelets for earthquake detection",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces EQShapelets (EarthQuake Shapelets) a time-series
shape-based approach embedded in machine learning to autonomously detect
earthquakes. It promises to overcome the challenges in the field of seismology
related to automated detection and cataloging of earthquakes. EQShapelets are
amplitude and phase-independent, i.e., their detection sensitivity is
irrespective of the magnitude of the earthquake and the time of occurrence.
They are also robust to noise and other spurious signals. The detection
capability of EQShapelets is tested on one week of continuous seismic data
provided by the Northern California Seismic Network (NCSN) obtained from a
station in central California near the Calaveras Fault. EQShapelets combined
with a Random Forest classifier, detected all of the cataloged earthquakes and
281 uncataloged events with lower false detection rate thus offering a better
performance than autocorrelation and FAST algorithms. The primary advantage of
EQShapelets over competing methods is the interpretability and insight it
offers. Shape-based approaches are intuitive, visually meaningful and offers
immediate insight into the problem domain that goes beyond their use in
accurate detection. EQShapelets, if implemented at a large scale, can
significantly reduce catalog completeness magnitudes and can serve as an
effective tool for near real-time earthquake monitoring and cataloging.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:50:25 GMT""}]","2019-11-21"
"1911.09087","Siarhei Finski","Siarhei Finski","Quillen metric for singular families of Riemann surfaces with cusps and
  compact perturbation theorem","40 pages, 5 figures",,,,"math.DG math.AG","http://creativecommons.org/licenses/by/4.0/","  We study the behavior of the Quillen metric for the family of Riemann
surfaces with cusps when the additional cusps are created by degeneration.
  More precisely, in our previous paper, we've seen that the renormalization of
the Quillen metric associated with a family of Riemann surfaces with cusps
extends continuously over the locus of singular curves. The main result of this
article shows that, modulo some explicit universal constant, this continuous
extension coincides with the Quillen metric of the normalization of singular
curves. This result shows that the Quillen metric is compatible with the
adjunction of cusps. When this theorem is applied directly to the moduli space
of curves, we obtain the compatibility of the Quillen metric with clutching
morphisms in the moduli space of pointed stable curves.
  As one application, we obtain the compatibility between our definition of the
analytic torsion and the definition of Takhtajan-Zograf using lengths of closed
geodesics.
  As a consequence of the proof of the main theorem, we get an explicit
relation in terms of Bott-Chern forms between the Quillen metric associated
with a cusped metric and the Quillen metric associated with a metric on the
compactified Riemann surface. This refines relative compact perturbation
theorem we obtained before by pinning down the universal constant.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:53:28 GMT""}]","2019-11-21"
"1911.09088","Maxime Gheysens","Maxime Gheysens","The homeomorphism group of the first uncountable ordinal","Second version: various additions to make a bridge with results of
  the companion paper arXiv:2011.15009 (new paragraph at the end of the
  introduction, new Remark 11, new paragraphs in Remarks 18 and 20). Also, new
  Footnote 2 and new Remark 19. Some results have different labelling or
  shifted numbering in comparison to the first version",,,,"math.GR math.GN","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the topology of pointwise convergence on scattered spaces is
compatible with the group structure of their homeomorphism group. We then
establish a few topological properties of the homeomorphism group of the first
uncountable ordinal, such as amenability and Roelcke-precompactness.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:53:34 GMT""},{""version"":""v2"",""created"":""Tue, 1 Dec 2020 13:26:54 GMT""}]","2020-12-02"
"1911.09089","Sergei Merkulov","Assar Andersson and Sergei Merkulov","From deformation theory of wheeled props to classification of Kontsevich
  formality maps","18 pages; in v2 misprints are corrected and two new references are
  added",,,,"math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study homotopy theory of the wheeled prop controlling Poisson structures
on arbitrary formal graded finite-dimensional manifolds and prove, in
particular, that Grothendieck-Teichmueller group acts on that wheeled prop
faithfully and homotopy non-trivially. Next we apply this homotopy theory to
the study of the deformation complex of an arbitrary Maxim Kontsevich formality
map and compute the full cohomology group of that deformation complex in terms
of the cohomology of a certain graph complex introduced earlier by Maxim
Kontsevich in [K1] and studied by Thomas Willwacher in [W1].
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:56:28 GMT""},{""version"":""v2"",""created"":""Mon, 25 Nov 2019 19:17:48 GMT""}]","2019-11-27"
"1911.09090","Charles Blakemore","Charles P. Blakemore, Denzal Martin, Alexander Fieguth, Akio Kawasaki,
  Nadav Priel, Alexander D. Rider, Giorgio Gratta","Absolute pressure and gas species identification with an optically
  levitated rotor","7 pages, 5 figures. Updated formatting to be consistent with journal
  version","Journal of Vacuum Science & Technology B 38, 024201 (2020)","10.1116/1.5139638",,"physics.ins-det physics.class-ph physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The authors describe a novel variety of spinning-rotor vacuum gauge in which
the rotor is a ${\sim}4.7{\text -}\mu$m-diameter silica microsphere, optically
levitated. A rotating electrostatic field is used to apply torque to the
permanent electric dipole moment of the silica microsphere and control its
rotational degrees of freedom. When released from a driving field, the
microsphere's angular velocity decays exponentially with a damping time
inversely proportional to the residual gas pressure, and dependent on gas
composition. The gauge is calibrated by measuring the rotor mass with
electrostatic co-levitation, and assuming a spherical shape, confirmed
separately, and uniform density. The gauge is cross-checked against a
capacitance manometer by observing the torsional drag due to a number of
different gas species. The techniques presented can be used to perform absolute
vacuum measurements localized in space, owing to the small dimensions of the
microsphere and the ability to translate the optical trap in three dimensions,
as well as measurements in magnetic field environments. In addition, the
dynamics of the microsphere, paired with a calibrated vacuum gauge, can be used
to measure the effective molecular mass of a gas mixture without the need for
ionization and at pressures up to approximately 1 mbar.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:57:55 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 00:45:21 GMT""}]","2020-02-27"
"1911.09091","Oliver Karras","Oliver Karras, Jil Kl\""under, Kurt Schneider","Tool-Supported Experiments for Continuously Collecting Data of
  Subjective Video Quality Assessments During Video Playback","2 pages, Fachgruppentreffen Requirements Engineering, GI
  Softwaretechnik-Trends",,,,"cs.SE cs.CY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The adequate use of documentation for communication is one challenge in
requirements engineering (RE). In recent years, several researchers addressed
this challenge by using videos as a communication mechanism. All of them
concluded that this way of using videos has the potential to facilitate
requirements communication. Nevertheless, software professionals are not
directors and thus do not necessarily know what constitutes a good video. This
lack of knowledge is one crucial reason why videos are still not an established
communication mechanism in RE. When videos shall be established in the RE
activities, practices, and techniques, requirements engineers have to acquire
the necessary knowledge to produce and use good videos on their own at moderate
costs, yet sufficient quality. In our research project ViViReq (see
Acknowledgment), we aspire to bridge this knowledge gap about what constitutes
a good video. Whether a video is good or not depends on its quality perceived
by its viewers. However, video quality is a rather ill-defined concept due to
numerous unspecified technical and subjective characteristics. As part of our
research plan, we develop a quality model for videos inspired by the idea of
Femmer and Vogelsang to define and evaluate the quality of videos as RE
artifacts. In addition to evaluating videos, this quality model can be used to
identify the relevant characteristics of videos for their specific purpose
which can be further used to specify requirements, their criteria for
satisfaction, and corresponding measures. Therefore, software professionals may
use the quality model as guidance for producing and using videos.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:59:55 GMT""},{""version"":""v2"",""created"":""Thu, 21 Nov 2019 07:47:43 GMT""}]","2019-11-22"
"1911.09100","Haoyu Zhao","Wei Chen, Weizhong Zhang, Haoyu Zhao","Gradient Method for Continuous Influence Maximization with Budget-Saving
  Considerations","To appear in AAAI-20, 43 pages",,,,"math.OC cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Continuous influence maximization (CIM) generalizes the original influence
maximization by incorporating general marketing strategies: a marketing
strategy mix is a vector $\boldsymbol x = (x_1,\dots,x_d)$ such that for each
node $v$ in a social network, $v$ could be activated as a seed of diffusion
with probability $h_v(\boldsymbol x)$, where $h_v$ is a strategy activation
function satisfying DR-submodularity. CIM is the task of selecting a strategy
mix $\boldsymbol x$ with constraint $\sum_i x_i \le k$ where $k$ is a budget
constraint, such that the total number of activated nodes after the diffusion
process, called influence spread and denoted as $g(\boldsymbol x)$, is
maximized. In this paper, we extend CIM to consider budget saving, that is,
each strategy mix $\boldsymbol x$ has a cost $c(\boldsymbol x)$ where $c$ is a
convex cost function, we want to maximize the balanced sum $g(\boldsymbol x) +
\lambda(k - c(\boldsymbol x))$ where $\lambda$ is a balance parameter, subject
to the constraint of $c(\boldsymbol x) \le k$. We denote this problem as
CIM-BS. The objective function of CIM-BS is neither monotone, nor DR-submodular
or concave, and thus neither the greedy algorithm nor the standard result on
gradient method could be directly applied. Our key innovation is the
combination of the gradient method with reverse influence sampling to design
algorithms that solve CIM-BS: For the general case, we give an algorithm that
achieves $\left(\frac{1}{2}-\varepsilon\right)$-approximation, and for the case
of independent strategy activations, we present an algorithm that achieves
$\left(1-\frac{1}{e}-\varepsilon\right)$ approximation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:08:04 GMT""}]","2019-11-22"
"1911.09101","Santiago Paternain Mr","Santiago Paternain, Miguel Calvo-Fullana, Luiz F. O. Chamon and
  Alejandro Ribeiro","Safe Policies for Reinforcement Learning via Primal-Dual Methods","arXiv admin note: text overlap with arXiv:1910.13393",,,,"eess.SY cs.LG cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study the learning of safe policies in the setting of
reinforcement learning problems. This is, we aim to control a Markov Decision
Process (MDP) of which we do not know the transition probabilities, but we have
access to sample trajectories through experience. We define safety as the agent
remaining in a desired safe set with high probability during the operation
time. We therefore consider a constrained MDP where the constraints are
probabilistic. Since there is no straightforward way to optimize the policy
with respect to the probabilistic constraint in a reinforcement learning
framework, we propose an ergodic relaxation of the problem. The advantages of
the proposed relaxation are threefold. (i) The safety guarantees are maintained
in the case of episodic tasks and they are kept up to a given time horizon for
continuing tasks. (ii) The constrained optimization problem despite its
non-convexity has arbitrarily small duality gap if the parametrization of the
policy is rich enough. (iii) The gradients of the Lagrangian associated with
the safe-learning problem can be easily computed using standard policy gradient
results and stochastic approximation tools. Leveraging these advantages, we
establish that primal-dual algorithms are able to find policies that are safe
and optimal. We test the proposed approach in a navigation task in a continuous
domain. The numerical results show that our algorithm is capable of dynamically
adapting the policy to the environment and the required safety levels.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:56:39 GMT""},{""version"":""v2"",""created"":""Wed, 12 Jan 2022 20:00:13 GMT""}]","2022-01-14"
"1911.09102","Shibesh Kumar Jas Pacif","S. K. J. Pacif, Md Salahuddin Khan, L. K. Paikroy and Shalini Singh","An Accelerating Cosmological Model from a Parametrization of Hubble
  Parameter","12 Pages, 12 Figures","Modern Physics Letters A, Vol. 33, No. 1 (2020) 2050011 (16 pages)","10.1142/S021773232050011X",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In view of late-time cosmic acceleration, a dark energy cosmological model is
revisited wherein Einstein's cosmological constant is considered as a candidate
of dark energy. Exact solution of Einstein field equations (EFEs) is derived in
a homogeneous isotropic background in classical general relativity. The
solution procedure is adopted, in a model independent way (or the cosmological
parametrization). A simple parametrization of the Hubble parameter (H) as a
function of cosmic time `t' is considered which produces an exponential type of
evolution of the scale factor (a) and also shows a negative value of
deceleration parameter at the present time with a signature flip from early
deceleration to late acceleration. Cosmological dynamics of the model obtained
have been discussed illustratively for different phases of the evolution of the
universe. The evolution of different cosmological parameters are shown
graphically for at and closed cases of Friedmann-Lemaitre-Robertson-Walker
(FLRW) space-time for the presented model (open case is incompatible to the
present scenario). We have also constrained our model parameters with the
updated (36 points) observational Hubble dataset.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:23:15 GMT""}]","2019-11-22"
"1911.09103","Andrew White","Rainier Barrett and Andrew D. White","Investigating Active Learning and Meta-Learning for Iterative Peptide
  Design","19 pages, 8 figures, 9 tables",,,,"q-bio.BM cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Often the development of novel functional peptides is not amenable to high
throughput or purely computational screening methods. Peptides must be
synthesized one at a time in a process that does not generate large amounts of
data. One way this method can be improved is by ensuring that each experiment
provides the best improvement in both peptide properties and predictive
modeling accuracy. Here, we study the effectiveness of active learning,
optimizing experiment order, and meta-learning, transferring knowledge between
contexts, to reduce the number of experiments necessary to build a predictive
model. We present a multi-task benchmark database of peptides designed to
advance these methods for experimental design. Each task is binary
classification of peptides represented as a sequence string. We find neither
active learning method tested to be better than random choice. The
meta-learning method Reptile was found to improve average accuracy across
datasets. Combining meta-learning with active learning offers inconsistent
benefits.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:33:01 GMT""},{""version"":""v2"",""created"":""Thu, 6 Feb 2020 14:46:46 GMT""},{""version"":""v3"",""created"":""Mon, 27 Jul 2020 23:33:27 GMT""},{""version"":""v4"",""created"":""Thu, 10 Dec 2020 22:02:17 GMT""}]","2020-12-14"
"1911.09104","Harun Siljak","Harun Siljak","Reversible Computation in Wireless Communications","Book chapter in IC 1405 COST Action on Reversible Computation book.
  arXiv admin note: text overlap with arXiv:1911.06438",,,,"cs.ET cs.SY eess.SY nlin.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This chapter presents the pioneering work in applying reversible computation
paradigms to wireless communications. These applications range from developing
reversible hardware architectures for underwater acoustic communications to
novel distributed optimisation procedures in large radio-frequency antenna
arrays based on reversing Petri nets. Throughout the chapter, we discuss the
rationale for introducing reversible computation in the domain of wireless
communications, exploring the inherently reversible properties of communication
channels and systems formed by devices in a wireless network.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:53:04 GMT""}]","2019-11-22"
"1911.09105","Gregory Wornell","Shao-Lun Huang, Anuran Makur, Gregory W. Wornell, and Lizhong Zheng","On Universal Features for High-Dimensional Learning and Inference",,,,,"cs.LG cs.IT math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of identifying universal low-dimensional features
from high-dimensional data for inference tasks in settings involving learning.
For such problems, we introduce natural notions of universality and we show a
local equivalence among them. Our analysis is naturally expressed via
information geometry, and represents a conceptually and computationally useful
analysis. The development reveals the complementary roles of the singular value
decomposition, Hirschfeld-Gebelein-R\'enyi maximal correlation, the canonical
correlation and principle component analyses of Hotelling and Pearson, Tishby's
information bottleneck, Wyner's common information, Ky Fan $k$-norms, and
Brieman and Friedman's alternating conditional expectations algorithm. We
further illustrate how this framework facilitates understanding and optimizing
aspects of learning systems, including multinomial logistic (softmax)
regression and the associated neural network architecture, matrix factorization
methods for collaborative filtering and other applications, rank-constrained
multivariate linear regression, and forms of semi-supervised learning.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:00 GMT""}]","2019-11-22"
"1911.09106","Jacob Bourjaily","Jacob L. Bourjaily, Enrico Herrmann, Cameron Langer, Andrew J. McLeod,
  and Jaroslav Trnka","All-Multiplicity Non-Planar MHV Amplitudes in sYM at Two Loops","Corrected a sign mistake for the pentabox numerators (table IV).
  Minor improvements and references added in v2. 4+3 pages, 22 figures, 4
  tables, infinity of new amplitudes. Ancillary files contain a Mathematica
  implementation of our result","Phys. Rev. Lett. 124, 111603 (2020)","10.1103/PhysRevLett.124.111603",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give a closed-form, prescriptive representation of all-multiplicity
two-loop MHV amplitude integrands in fully-color-dressed (non-planar) maximally
supersymmetric Yang-Mills theory.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 29 Apr 2020 20:04:23 GMT""},{""version"":""v3"",""created"":""Sun, 30 May 2021 13:19:43 GMT""}]","2021-06-01"
"1911.09107","Patrick Komiske","Anders Andreassen, Patrick T. Komiske, Eric M. Metodiev, Benjamin
  Nachman, and Jesse Thaler","OmniFold: A Method to Simultaneously Unfold All Observables","8 pages, 3 figures, 1 table, 1 poem; v2: updated to approximate PRL
  version","Phys. Rev. Lett. 124, 182001 (2020)","10.1103/PhysRevLett.124.182001","MIT-CTP 5155","hep-ph hep-ex physics.data-an stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collider data must be corrected for detector effects (""unfolded"") to be
compared with many theoretical calculations and measurements from other
experiments. Unfolding is traditionally done for individual, binned observables
without including all information relevant for characterizing the detector
response. We introduce OmniFold, an unfolding method that iteratively reweights
a simulated dataset, using machine learning to capitalize on all available
information. Our approach is unbinned, works for arbitrarily high-dimensional
data, and naturally incorporates information from the full phase space. We
illustrate this technique on a realistic jet substructure example from the
Large Hadron Collider and compare it to standard binned unfolding methods. This
new paradigm enables the simultaneous measurement of all observables, including
those not yet invented at the time of the analysis.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:00 GMT""},{""version"":""v2"",""created"":""Thu, 16 Apr 2020 16:50:38 GMT""}]","2020-05-13"
"1911.09108","Justin Elenewski","Gabriela Wojtowicz, Justin E. Elenewski, Marek M. Rams, Michael Zwolak","Open System Tensor Networks and Kramers' Crossover for Quantum Transport","7 pages, 4 figures","Phys. Rev. A 101, 050301 (2020)","10.1103/PhysRevA.101.050301",,"cond-mat.str-el cond-mat.mes-hall quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Tensor networks are a powerful tool for many-body ground states with limited
entanglement. These methods can nonetheless fail for certain time-dependent
processes - such as quantum transport or quenches - where entanglement growth
is linear in time. Matrix-product-state decompositions of the resulting
out-of-equilibrium states require a bond dimension that grows exponentially,
imposing a hard limit on simulation timescales. However, in the case of
transport, if the reservoir modes of a closed system are arranged according to
their scattering structure, the entanglement growth can be made logarithmic.
Here, we apply this ansatz to open systems via extended reservoirs that have
explicit relaxation. This enables transport calculations that can access steady
states, time dynamics and noise, and periodic driving (e.g., Floquet states).
We demonstrate the approach by calculating the transport characteristics of an
open, interacting system. These results open a path to scalable and numerically
systematic many-body transport calculations with tensor networks.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:00 GMT""},{""version"":""v2"",""created"":""Wed, 13 May 2020 04:34:08 GMT""}]","2020-05-20"
"1911.09109","Ivan Esteban","Pilar Coloma, Ivan Esteban, M. C. Gonzalez-Garcia, Michele Maltoni","Improved global fit to Non-Standard neutrino Interactions using COHERENT
  energy and timing data","25 pages, 9 figures, 2 tables. Added an appendix with updated results
  accounting for the data available in July 2020",,"10.1007/JHEP02(2020)023","YITP-SB-19-38, IFT-UAM/CSIC-19-152, IFIC-19-49","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a global fit to neutrino oscillation and coherent neutrino-nucleus
scattering data, using both timing and energy information from the COHERENT
experiment. The results are used to set model-independent bounds on
four-fermion effective operators inducing non-standard neutral-current neutrino
interactions. We quantify the allowed ranges for their Wilson coefficients, as
well as the status of the LMA-D solution, for a wide class of new physics
models with arbitrary ratios between the strength of the operators involving up
and down quarks. Our results are presented for the COHERENT experiment alone,
as well as in combination with the global data from oscillation experiments. We
also quantify the dependence of our results for COHERENT with respect to the
choice of quenching factor, nuclear form factor, and the treatment of the
backgrounds.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 28 Feb 2020 11:55:02 GMT""},{""version"":""v3"",""created"":""Fri, 2 Oct 2020 13:43:40 GMT""}]","2020-10-05"
"1911.09110","Shashank Shalgar","Shashank Shalgar, Ian Padilla-Gay and Irene Tamborra","Neutrino propagation hinders fast pairwise flavor conversions","Accepted in JCAP, 20 pages, 12 Figures. Supplementary material:
  https://sid.erda.dk/share_redirect/BAdkN7XRul/index.html","JCAP06(2020)048","10.1088/1475-7516/2020/06/048",,"astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutrino flavor conversions may dramatically affect the inner working of
compact astrophysical objects as well as the synthesis of the heavier elements.
We present the first sophisticated numerical solution of the neutrino flavor
conversion within a (2+1+1) dimensional setup: we include the advective term in
the neutrino equations of motion and track the flavor evolution in two spatial
dimensions, one angular variable, and time. Notably, the advective term hinders
the development of neutrino pairwise conversions, if the conditions favoring
such conversions (i.e., crossings between the angular distributions of $\nu_e$
and $\bar\nu_e$ or a non-negligible flux of neutrinos traveling backward with
respect to the main propagation direction) exist for time scales shorter than
the typical time scale of the advective term. As a consequence, fast pairwise
conversions can only occur when the conditions favoring flavor conversions are
self-sustained and global, such as the ones induced by the lepton emission
self-sustained asymmetry (LESA) in core-collapse supernovae. Our work
highlights the major impact of the dynamical evolution of the neutrino field on
the growth of flavor instabilities and the strong interplay between classical
and quantum effects. Critical limitations of the linear stability analysis,
used to predict neutrino flavor instabilities, are also pointed out.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jan 2020 11:24:10 GMT""},{""version"":""v3"",""created"":""Mon, 23 Mar 2020 23:58:37 GMT""},{""version"":""v4"",""created"":""Thu, 25 Jun 2020 10:36:20 GMT""}]","2020-07-01"
"1911.09111","Marcel Oliver","Zymantas Darbenas, Rein van der Hout, Marcel Oliver","Long-time asymptotics of solutions to the Keller-Rubinow model for
  Liesegang rings in the fast reaction limit",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the Keller--Rubinow model for Liesegang rings in one spatial
dimension in the fast reaction limit as introduced by Hilhorst, van der Hout,
Mimura, and Ohnishi in 2007. Numerical evidence suggests that solutions to this
model converge, independent of the initial concentration, to a universal
profile for large times in parabolic similarity coordinates. For the
concentration function, the notion of convergence appears to be similar to
attraction to a stable equilibrium point in phase space. The reaction term,
however, is discontinuous so that it can only convergence in a much weaker,
averaged sense. This also means that most of the traditional analytical tools
for studying the long-time behavior fail on this problem.
  In this paper, we identify the candidate limit profile as the solution of a
certain one-dimensional boundary value problem which can be solved explicitly.
We distinguish two nontrivial regimes. In the first, the transitional regime,
precipitation is restricted to a bounded region in space. We prove that the
concentration converges to a single asymptotic profile. In the second, the
supercritical regime, we show that the concentration converges to one of a
one-parameter family of asymptotic profiles, selected by a solvability
condition for the one-dimensional boundary value problem. Here, our convergence
result is only conditional: we prove that if convergence happens, either
pointwise for the concentration or in an averaged sense for the precipitation
function, then the other field converges likewise; convergence in concentration
is uniform, and the asymptotic profile is indeed the profile selected by the
solvability condition. A careful numerical study suggests that the actual
behavior of the equation is indeed the one suggested by the theorem.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:01 GMT""},{""version"":""v2"",""created"":""Thu, 25 Nov 2021 18:37:43 GMT""}]","2021-11-29"
"1911.09112","Kirsty Taggart","Kirsty Taggart, Daniel Perley","Core-collapse, superluminous, and gamma-ray burst supernova host galaxy
  populations at low redshift: the importance of dwarf and starbursting
  galaxies","Accepted by MNRAS, 34 pages, 13 figures",,"10.1093/mnras/stab174",,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a comprehensive study of an unbiased sample of 150 nearby (<z> =
0.014) core-collapse supernova (CCSN) host galaxies drawn from the All-Sky
Automated Survey for Supernovae (ASAS-SN) for direct comparison to the nearest
LGRB and SLSN hosts. We use public imaging surveys to gather multi-wavelength
photometry for all CCSN host galaxies and fit their spectral energy
distributions (SEDs) to derive stellar masses and integrated star formation
rates. CCSNe populate galaxies across a wide range of stellar masses, from blue
and compact dwarf galaxies to large spiral galaxies. We find 33(+4,-4) per cent
of CCSNe are in dwarf galaxies (M < 10^9 M_Sun) and 2(+2,-1) per cent are in
dwarf starburst galaxies (sSFR > 10^-8 yr^-1). We reanalyse low-redshift SLSN
and LGRB hosts from the literature (out to $z<0.3$) in a homogeneous way and
compare against the CCSN host sample. The relative SLSN to CCSN supernova rate
is increased in low-mass galaxies and at high specific star-formation rates.
These parameters are strongly covariant and we cannot break the degeneracy
between them with our current sample, although there is some evidence that both
factors may play a role. Larger unbiased samples of CCSNe from projects such as
ZTF and LSST will be needed to determine whether host-galaxy mass (a proxy for
metallicity) or specific star-formation rate (a proxy for star-formation
intensity and potential IMF variation) is more fundamental in driving the
preference for SLSNe and LGRBs in unusual galaxy environments.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:01 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jul 2020 11:28:30 GMT""},{""version"":""v3"",""created"":""Mon, 29 Mar 2021 13:21:26 GMT""}]","2021-03-30"
"1911.09113","Huanqing Chen","Huanqing Chen","The Role of Quasar Radiative Feedback on Galaxy Formation during Cosmic
  Reionization","13 pages, 14 figures, comments welcome",,"10.3847/1538-4357/ab80c6",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent observations have found that many $z\sim 6$ quasar fields lack
galaxies. This unexpected lack of galaxies may potentially be explained by
quasar radiation feedback. In this paper I present a suite of 3D radiative
transfer cosmological simulations of quasar fields. I find that quasar
radiation suppresses star formation in low mass galaxies, mainly by
photo-dissociating their molecular hydrogen. Photo-heating also plays a role,
but only after $\sim$100 Myr. However, galaxies which already have stellar mass
above $10^5 M_\odot$ when the quasar turns on will not be suppressed
significantly. Quasar radiative feedback suppresses the faint end of the galaxy
luminosity function (LF) within $1$ pMpc, but to a far lesser degree than the
field-to-field variation of the LF. My study also suggests that by using the
number of bright galaxies ($M_{1500}<-16$) around quasars, we can potentially
recover the underlying mass overdensity, which allows us to put reliable
constraints on quasar environments.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:01 GMT""},{""version"":""v2"",""created"":""Wed, 27 May 2020 04:47:50 GMT""}]","2020-05-28"
"1911.09114","Laurent Eyer","Laurent Eyer, Maria S\""uveges, Joris De Ridder, Sara Regibo, Nami
  Mowlavi, Berry Holl, Lorenzo Rimoldini, Francois Bouchy","Multivariate Time-series Analysis of Variable Objects in the Gaia
  Mission","Published in PASP, 12 pages, 5 figures","Publications of the Astronomical Society of the Pacific, Volume
  131, Issue 1002, pp. 088001 (2019)","10.1088/1538-3873/ab2511",,"astro-ph.IM astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In astronomy, we are witnessing an enormous increase in the number of source
detections, precision, and diversity of measurements. Additionally, multi-epoch
data is becoming the norm, making time-series analyses an important aspect of
current astronomy. The Gaia mission is an outstanding example of a multi-epoch
survey that provides measurements in a large diversity of domains, with its
broad-band photometry; spectrophotometry in blue and red (used to derive
astrophysical parameters); spectroscopy (employed to infer radial velocities, v
sin(i), and other astrophysical parameters); and its extremely precise
astrometry. Most of all that information is provided for sources covering the
entire sky. Here, we present several properties related to the Gaia time
series, such as the time sampling; the different types of measurements; the
Gaia G, G BP and G RP-band photometry; and Gaia-inspired studies using the
CORrelation-RAdial-VELocities data to assess the potential of the information
on the radial velocity, the FWHM, and the contrast of the cross-correlation
function. We also present techniques (which are used or are under development)
that optimize the extraction of astrophysical information from the different
instruments of Gaia, such as the principal component analysis and the
multi-response regression. The detailed understanding of the behavior of the
observed phenomena in the various measurement domains can lead to richer and
more precise characterization of the Gaia data, including the definition of
more informative attributes that serve as input to (our) machine-learning
algorithms.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:01 GMT""}]","2019-11-22"
"1911.09115","Steven B. Giddings","Steven B. Giddings and Sean Weinberg","Gauge-invariant observables in gravity and electromagnetism: black hole
  backgrounds and null dressings","23 pages","Phys. Rev. D 102, 026010 (2020)","10.1103/PhysRevD.102.026010","CERN-TH-2019-157","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address questions regarding construction and implications of
gauge-invariant ""dressed"" observables in nontrivial background geometries such
as that of a black hole. Formally, such observables can be constructed, e.g. by
locating points with geodesics launched from infinity. However, practical
complications arise in non-trivial geometries, and in particular for
observables behind black hole horizons. Greater simplicity can be achieved by
considering null constructions where the dressing lies along a null geodesic,
or null surface such as a cone. We first investigate basic properties of these
null dressings in the simpler context of electromagnetism. Since null
constructions provide simple dressings for gauge-invariant observables inside
black holes, they also allow us to investigate the question of compatibility of
observables inside and outside black holes, and in particular the idea of black
hole complementarity. While such observables in general have non-vanishing
state-dependent commutators, the failure to commute does not appear
particularly enhanced by the presence of the horizon.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:01 GMT""}]","2020-07-15"
"1911.09116","Isabel Santos-Santos","Isabel M.E. Santos-Santos, Julio F. Navarro, Andrew Robertson,
  Alejandro Ben\'itez-Llambay, Kyle A. Oman, Mark R. Lovell, Carlos S. Frenk,
  Aaron D. Ludlow, Azadeh Fattahi, Adam Ritz","Baryonic clues to the puzzling diversity of dwarf galaxy rotation curves","20 pages, 16 figures, 1 table. Accepted for publication in MNRAS.
  Updated acknowledgements",,"10.1093/mnras/staa1072",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use a compilation of disc galaxy rotation curves to assess the role of the
luminous component (""baryons"") in the rotation curve diversity problem. As in
earlier work, we find that rotation curve shape correlates with baryonic
surface density: high surface density galaxies have rapidly-rising rotation
curves consistent with cuspy cold dark matter halos; slowly-rising rotation
curves (characteristic of galaxies with inner mass deficits or ""cores"") occur
only in low surface density galaxies. The correlation, however, seems too weak
to be the main driver of the diversity. In addition, dwarf galaxies exhibit a
clear trend, from ""cuspy"" systems where baryons are unimportant in the inner
mass budget to ""cored"" galaxies where baryons actually dominate. This trend
constrains the various scenarios proposed to explain the diversity, such as (i)
baryonic inflows and outflows during galaxy formation; (ii) dark matter
self-interactions; (iii) variations in the baryonic mass structure coupled to
rotation velocities through the ""mass discrepancy-acceleration relation""
(MDAR); or (iv) non-circular motions in gaseous discs. Together with analytical
modeling and cosmological hydrodynamical simulations, our analysis shows that
each of these scenarios has promising features, but none seems to fully account
for the observed diversity. The MDAR, in particular, is inconsistent with the
observed trend between rotation curve shape and baryonic importance; either the
trend is caused by systematic errors in the data or the MDAR does not apply.
The origin of the dwarf galaxy rotation curve diversity and its relation to the
structure of cold dark matter halos remains an open issue.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:02 GMT""},{""version"":""v2"",""created"":""Sat, 23 Nov 2019 00:54:12 GMT""},{""version"":""v3"",""created"":""Sat, 18 Apr 2020 07:54:56 GMT""},{""version"":""v4"",""created"":""Tue, 28 Apr 2020 17:43:46 GMT""}]","2020-05-06"
"1911.09117","Shi-Xin Zhang","Shi-Xin Zhang, Zhou-Quan Wan, and Hong Yao","Automatic Differentiable Monte Carlo: Theory and Application","11.5 pages + supplemental materials, 4 figures",,,,"physics.comp-ph cond-mat.dis-nn cond-mat.stat-mech cond-mat.str-el cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Differentiable programming has emerged as a key programming paradigm
empowering rapid developments of deep learning while its applications to
important computational methods such as Monte Carlo remain largely unexplored.
Here we present the general theory enabling infinite-order automatic
differentiation on expectations computed by Monte Carlo with unnormalized
probability distributions, which we call ""automatic differentiable Monte Carlo""
(ADMC). By implementing ADMC algorithms on computational graphs, one can also
leverage state-of-the-art machine learning frameworks and techniques to
traditional Monte Carlo applications in statistics and physics. We illustrate
the versatility of ADMC by showing some applications: fast search of phase
transitions and accurately finding ground states of interacting many-body
models in two dimensions. ADMC paves a promising way to innovate Monte Carlo in
various aspects to achieve higher accuracy and efficiency, e.g. easing or
solving the sign problem of quantum many-body models through ADMC.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:03 GMT""}]","2019-11-25"
"1911.09118","Maxim Trushin","Maxim Trushin, Soumya Sarkar, Sinu Mathew, Sreetosh Goswami, Prasana
  Sahoo, Yan Wang, Jieun Yang, Weiwei Li, Judith L. MacManus-Driscoll, Manish
  Chhowalla, Shaffique Adam, and T. Venkatesan","Evidence of Rotational Fr\""ohlich Coupling in Polaronic Trions","5+ pages (4 figures) + Suppl. Materials (7 figures), to appear in
  Phys. Rev. Lett. (August 2020)","Phys. Rev. Lett. 125, 086803 (2020)","10.1103/PhysRevLett.125.086803",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Electrons commonly couple through Fr\""ohlich interactions with longitudinal
optical phonons to form polarons. However, trions possess a finite angular
momentum and should therefore couple instead to rotational optical phonons.
This creates a polaronic trion whose binding energy is determined by the
crystallographic orientation of the lattice. Here, we demonstrate theoretically
within the Fr\""ohlich approach and experimentally by photoluminescence emission
that the bare trion binding energy (20 meV) is significantly enhanced by the
phonons at the interface between the two-dimensional semiconductor MoS$_2$ and
the bulk transition metal oxide SrTiO$_3$. The low-temperature {binding energy}
changes from 60 meV in [001]-oriented substrates to 90 meV for [111]
orientation, as a result of the counter-intuitive interplay between the
rotational axis of the MoS$_2$ trion and that of the SrTiO$_3$ phonon mode.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:03 GMT""},{""version"":""v2"",""created"":""Wed, 12 Aug 2020 12:14:26 GMT""}]","2020-08-26"
"1911.09119","Sriram Shastry","B Sriram Shastry and Peizhi Mai","Aspects of the Normal State Resistivity of Cuprate Superconductors","27 pages, 6 Figures, With extended discussion of theory and added
  references","Phys. Rev. B 101, 115121 (2020)","10.1103/PhysRevB.101.115121",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Planar normal state resistivity data taken from three families of cuprate
superconductors are compared with theoretical calculations from the recent
extremely correlated Fermi liquid theory (ECFL). The two hole doped cuprate
materials $LSCO$ and $BSLCO$ and the electron doped material $LCCO$ have
yielded rich data sets at several densities $\delta$ and temperatures T,
thereby enabling a systematic comparison with theory. The recent ECFL
resistivity calculations for the highly correlated $t$-$t'$-$J$ model by us
give the resistivity for a wide set of model parameters. After using X-ray
diffraction and angle resolved photoemission data to fix parameters appearing
in the theoretical resistivity, only one parameter, the magnitude of the
hopping $t$, remains undetermined. For each data set, the slope of the
experimental resistivity at a single temperature-density point is sufficient to
determine $t$, and hence the resistivity on absolute scale at all remaining
densities and temperatures. This procedure is shown to give a fair account of
the entire data.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:03 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jan 2020 21:03:56 GMT""},{""version"":""v3"",""created"":""Mon, 3 Feb 2020 19:50:05 GMT""}]","2021-10-05"
"1911.09120","Andrea Caputo","A.Caputo, M. Regis, M. Taoso","Searching for Sterile Neutrino with X-ray Intensity Mapping","Typo corrected in Eq.4","JCAP 2003 (2020) no.03, 001","10.1088/1475-7516/2020/03/001",,"astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cosmological X-ray emission associated to the possible radiative decay of
sterile neutrinos is composed by a collection of lines at different energies.
For a given mass, each line corresponds to a given redshift. In this work, we
cross correlate such line emission with catalogs of galaxies tracing the dark
matter distribution at different redshifts. We derive observational prospects
by correlating the X-ray sky that will be probed by the eROSITA and Athena
missions with current and near future photometric and spectroscopic galaxy
surveys. A relevant and unexplored fraction of the parameter space of sterile
neutrinos can be probed by this technique.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:03 GMT""},{""version"":""v2"",""created"":""Mon, 9 Mar 2020 08:39:35 GMT""},{""version"":""v3"",""created"":""Mon, 6 Jul 2020 07:03:38 GMT""}]","2020-07-07"
"1911.09121","Alex Kim","Alex G. Kim and Eric V. Linder","Complementarity of Peculiar Velocity Surveys and Redshift Space
  Distortions for Testing Gravity","6 pages, 4 figures","Phys. Rev. D 101, 023516 (2020)","10.1103/PhysRevD.101.023516",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Peculiar-velocity surveys of the low-redshift universe have significant
leverage to constrain the growth rate of cosmic structure and test gravity.
Wide-field imaging surveys combined with multi-object spectrographs (e.g. ZTF2,
LSST, DESI, 4MOST) can use Type Ia supernovae as informative tracers of the
velocity field, reaching few percent constraints on the growth rate $f\sigma_8$
at $z\lesssim0.2$ where density tracers cannot do better than $\sim10\%$.
Combining the high-redshift DESI survey mapping redshift space distortions with
a low-redshift supernova peculiar velocity survey using LSST and DESI can
determine the gravitational growth index to $\sigma(\gamma)\approx0.02$,
testing general relativity. We study the characteristics needed for the
peculiar velocity survey, and how its complementarity with clustering surveys
improves when going from a $\Lambda$CDM model assumption to a $w_0$-$w_a$
cosmology.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:03 GMT""}]","2020-01-29"
"1911.09122","Nicole Yunger Halpern","Adam Bene Watts, Nicole Yunger Halpern, Aram Harrow","Nonlinear Bell inequality for macroscopic measurements","5 pages + appendices. Published version","Phys. Rev. A 103, 010202 (2021)","10.1103/PhysRevA.103.L010202","MIT-CTP/5279","quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The correspondence principle suggests that quantum systems grow classical
when large. Classical systems cannot violate Bell inequalities. Yet agents
given substantial control can violate Bell inequalities proven for large-scale
systems. We consider agents who have little control, implementing only general
operations suited to macroscopic experimentalists: preparing small-scale
entanglement and measuring macroscopic properties while suffering from noise.
That experimentalists so restricted can violate a Bell inequality appears
unlikely, in light of earlier literature. Yet we prove a Bell inequality that
such an agent can violate, even if experimental errors have variances that
scale as the system size. A violation implies nonclassicality, given
limitations on particles' interactions. A product of singlets violates the
inequality; experimental tests are feasible for photons, solid-state systems,
atoms, and trapped ions. Consistently with known results, violations of our
Bell inequality cannot disprove local hidden-variables theories. By rejecting
the disproof goal, we show, one can certify nonclassical correlations under
reasonable experimental assumptions.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:04 GMT""},{""version"":""v2"",""created"":""Tue, 2 Feb 2021 19:00:05 GMT""}]","2021-02-10"
"1911.09123","Mikko Laine","M. Laine, P. Schicho, Y. Schroder","A QCD Debye mass in a broad temperature range","18 pages. v2: minor clarifications","Phys. Rev. D 101, 023532 (2020)","10.1103/PhysRevD.101.023532",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Debye mass sets a scale for the screening of static charges and the
scattering of fast charges within a gauge plasma. Inspired by its potential
cosmological applications, we determine a QCD Debye mass at 2-loop order in a
broad temperature range (1 GeV ... 10 TeV), demonstrating how quark mass
thresholds get smoothly crossed. Along the way, integration-by-parts identities
pertinent to massive loops at finite temperature are illuminated.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:06 GMT""},{""version"":""v2"",""created"":""Fri, 31 Jan 2020 07:54:38 GMT""}]","2020-02-03"
"1911.09124","Anna Genina","Anna Genina, Justin I. Read, Carlos S. Frenk, Shaun Cole, Alejandro
  Benitez-Llambay, Aaron D. Ludlow, Julio F. Navarro, Kyle A. Oman, Andrew
  Robertson","To beta or not to beta: can higher-order Jeans analysis break the
  mass-anisotropy degeneracy in simulated dwarfs?","22 pages, 13 figures. Accepted in MNRAS",,"10.1093/mnras/staa2352",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We test a non-parametric higher-order Jeans analysis method, GravSphere, on
32 simulated dwarf galaxies comparable to classical Local Group dwarfs like
Fornax. The galaxies are selected from the APOSTLE suite of cosmological
hydrodynamics simulations with Cold Dark Matter (CDM) and Self-Interacting Dark
Matter (SIDM) models, allowing us to investigate cusps and cores in density
distributions. We find that, for CDM dwarfs, the recovered enclosed mass
profiles have a bias of no more than 10 per cent, with a 50 per cent scatter in
the inner regions and a 20 per cent scatter near the half-light radius,
consistent with standard mass estimators. The density profiles are also
recovered with a bias of no more than 10 per cent and a scatter of 30 per cent
in the inner regions. For SIDM dwarfs, the mass and density profiles are
recovered within our 95 per cent confidence intervals, but are biased towards
cuspy dark matter distributions. This is mainly due to a lack of sufficient
constraints from the data. We explore the sources of scatter in the accuracy of
the recovered profiles and suggest a $\chi^2$ statistic to separate successful
models from biased ones. Finally, we show that the uncertainties on the mass
profiles obtained with GravSphere are smaller than those for comparable Jeans
methods, and that they can be further improved if stronger priors, motivated by
cosmological simulations, are placed on the velocity anisotropy. We conclude
that GravSphere is a promising Jeans-based approach for modelling dark matter
distributions in dwarf galaxies.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:06 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 20:30:18 GMT""}]","2020-08-19"
"1911.09125","Newlin Weatherford","Newlin C. Weatherford, Sourav Chatterjee, Kyle Kremer, and Frederic A.
  Rasio","A Dynamical Survey of Stellar-Mass Black Holes in 50 Milky Way Globular
  Clusters","25 pages, 8 figures, 6 tables; accepted for publication to ApJ",,"10.3847/1538-4357/ab9f98",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent numerical simulations of globular clusters (GCs) have shown that
stellar-mass black holes (BHs) play a fundamental role in driving cluster
evolution and shaping their present-day structure. Rapidly mass-segregating to
the center of GCs, BHs act as a dynamical energy source via repeated
super-elastic scattering, delaying onset of core collapse and limiting mass
segregation for visible stars. While recent discoveries of BH candidates in
Galactic and extragalactic GCs have further piqued interest in BH-mediated
cluster dynamics, numerical models show that even if significant BH populations
remain in today's GCs, they are typically in configurations that are not
directly detectable. We demonstrated in Weatherford et al. (2018) that an
anti-correlation between a suitable measure of mass segregation ($\Delta$) in
observable stellar populations and the number of retained BHs in GC models can
be applied to indirectly probe BH populations in real GCs. Here, we estimate
the number and total mass of BHs presently retained in 50 Milky Way GCs from
the ACS Globular Cluster Survey by measuring $\Delta$ between populations of
main sequence stars, using correlations found between $\Delta$ and BH retention
in the CMC Cluster Catalog models. We demonstrate that the range in $\Delta$'s
distribution from our models matches that for observed GCs to a remarkable
degree. Our results further provide the narrowest constraints to-date on the
retained BH populations in the GCs analyzed. Of these 50 GCs, we identify NGCs
2808, 5927, 5986, 6101, and 6205 to presently contain especially large BH
populations, each with total BH mass exceeding $10^3\,\rm{M_{\odot}}$.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:07 GMT""},{""version"":""v2"",""created"":""Tue, 23 Jun 2020 18:00:04 GMT""}]","2020-08-12"
"1911.09126","Anurag Anshu","Anurag Anshu, Debbie Leung, and Dave Touchette","Incompressibility of classical distributions","25 pages, to appear in IEEE Transactions on Information Theory",,,,"quant-ph cs.IT math-ph math.IT math.MP","http://creativecommons.org/licenses/by/4.0/","  In blind compression of quantum states, a sender Alice is given a specimen of
a quantum state $\rho$ drawn from a known ensemble (but without knowing what
$\rho$ is), and she transmits sufficient quantum data to a receiver Bob so that
he can decode a near perfect specimen of $\rho$. For many such states drawn iid
from the ensemble, the asymptotically achievable rate is the number of qubits
required to be transmitted per state. The Holevo information is a lower bound
for the achievable rate, and is attained for pure state ensembles, or in the
related scenario of entanglement-assisted visible compression of mixed states
wherein Alice knows what state is drawn.
  In this paper, we prove a general and robust lower bound on the achievable
rate for ensembles of classical states, which holds even in the least demanding
setting when Alice and Bob share free entanglement and a constant per-copy
error is allowed. We apply the bound to a specific ensemble of only two states
and prove a near-maximal separation (saturating the dimension bound in leading
order) between the best achievable rate and the Holevo information for constant
error. This also implies that the ensemble is incompressible -- compression
does not reduce the communication cost by much. Since the states are classical,
the observed incompressibility is not fundamentally quantum mechanical. We
lower bound the difference between the achievable rate and the Holevo
information in terms of quantitative limitations to clone the specimen or to
distinguish the two classical states.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:12 GMT""},{""version"":""v2"",""created"":""Thu, 25 Nov 2021 19:34:58 GMT""}]","2021-11-29"
"1911.09127","Junichiro Kawamura","Tetsutaro Higaki and Junichiro Kawamura","A low-scale flavon model with a $Z_N$ symmetry","47 pages, 6 figures and 4 tables; v2: version published in JHEP","J. High Energ. Phys. 2020, 129 (2020)","10.1007/JHEP03(2020)129",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a model that explains the fermion mass hierarchy by the
Froggatt-Nielsen mechanism with a discrete $Z_N^F$ symmetry. As a concrete
model, we study a supersymmetric model with a single flavon coupled to the
minimal supersymmetric Standard Model. Flavon develops a TeV scale vacuum
expectation value for realizing flavor hierarchy, an appropriate $\mu$-term and
the electroweak scale, hence the model has a low cutoff scale. We demonstrate
how the flavon is successfully stabilized together with the Higgs bosons in the
model. The discrete flavor symmetry $Z_N^F$ controls not only the Standard
Model fermion masses, but also the Higgs potential and a mass of the Higgsino
which is a good candidate for dark matter. The hierarchy in the Higgs-flavon
sector is determined in order to make the model anomaly-free and realize a
stable electroweak vacuum. We show that this model can explain the fermion mass
hierarchy, realistic Higgs-flavon potential and thermally produced dark matter
at the same time. We discuss flavor violating processes induced by the light
flavon which would be detected in future experiments.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:35 GMT""},{""version"":""v2"",""created"":""Mon, 30 Mar 2020 01:10:41 GMT""}]","2020-03-31"
"1911.09128","Jean-Jacques Forneron","Jean-Jacques Forneron","A Scrambled Method of Moments",,,,,"econ.EM stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quasi-Monte Carlo (qMC) methods are a powerful alternative to classical
Monte-Carlo (MC) integration. Under certain conditions, they can approximate
the desired integral at a faster rate than the usual Central Limit Theorem,
resulting in more accurate estimates. This paper explores these methods in a
simulation-based estimation setting with an emphasis on the scramble of Owen
(1995). For cross-sections and short-panels, the resulting Scrambled Method of
Moments simply replaces the random number generator with the scramble
(available in most softwares) to reduce simulation noise. Scrambled Indirect
Inference estimation is also considered. For time series, qMC may not apply
directly because of a curse of dimensionality on the time dimension. A simple
algorithm and a class of moments which circumvent this issue are described.
Asymptotic results are given for each algorithm. Monte-Carlo examples
illustrate these results in finite samples, including an income process with
""lots of heterogeneity.""
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:01:04 GMT""}]","2019-11-22"
"1911.09129","Pilar Coloma","Pilar Coloma, Pilar Hern\'andez, V\'ictor Mu\~noz and Ian. M.
  Shoemaker","New constraints on Heavy Neutral Leptons from Super-Kamiokande data","6 pages, 4 figures. v2: Minor changes, references added. Version
  accepted for publication in EPJC",,"10.1140/epjc/s10052-020-7795-z",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heavy neutral leptons are predicted in many extensions of the Standard Model
with massive neutrinos. If kinematically accessible, they can be copiously
produced from kaon and pion decays in atmospheric showers, and subsequently
decay inside large neutrino detectors. We perform a search for these long-lived
particles using Super-Kamiokande multi-GeV neutrino data and derive stringent
limits on the mixing with electron, muon and tau neutrinos as a function of the
long-lived particle mass. We also present the limits on the branching ratio
versus lifetime plane, which are helpful in determining the constraints in
non-minimal models where the heavy neutral leptons have new interactions with
the Standard Model.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:01:17 GMT""},{""version"":""v2"",""created"":""Mon, 2 Mar 2020 08:36:19 GMT""}]","2020-04-22"
"1911.09130","Rafael A. Porto","Gregor K\""alin and Rafael A. Porto","From Boundary Data to Bound States II: Scattering Angle to Dynamical
  Invariants (with Twist)","29 Pages. 2 Figures. v2 Published version",,"10.1007/JHEP02(2020)120","DESY 19-201, SLAC-PUB-17487, UUITP-46/19","hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We recently introduced in [1910.03008] a ""boundary-to-bound"" dictionary
between gravitational scattering data and observables for bound states of
non-spinning bodies. In this paper, we elaborate further on this (holographic)
map. We start by deriving the following -- remarkably simple -- formula
relating the periastron advance to the scattering angle: $\Delta \Phi(J,{\cal
E}) =\chi(J,{\cal E}) + \chi (-J,{\cal E})$, via analytic continuation in
angular momentum and binding energy. Using explicit expressions from
[1910.03008], we confirm its validity to all orders in the Post-Minkowskian
(PM) expansion. Furthermore, we reconstruct the radial action for the bound
state directly from the knowledge of the scattering angle. The radial action
enables us to write compact expressions for dynamical invariants in terms of
the deflection angle to all PM orders, which can also be written as a function
of the PM-expanded amplitude. As an example, we reproduce our result in
[1910.03008] for the periastron advance, and compute the radial and azimuthal
frequencies and redshift variable to two-loops. Agreement is found in the
overlap between PM and Post-Newtonian (PN) schemes. Last but not least, we
initiate the study of our dictionary including spin. We demonstrate that the
same relation between deflection angle and periastron advance applies for
aligned-spin contributions, with $J$ the (canonical) total angular momentum.
Explicit checks are performed to display perfect agreement using
state-of-the-art PN results in the literature. Using the map between test- and
two-body dynamics, we also compute the periastron advance up to quadratic order
in the spin, to one-loop and to all orders in velocity. We conclude with a
discussion on the generalized ""impetus formula"" for spinning bodies and black
holes as ""elementary particles"".
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:01:26 GMT""},{""version"":""v2"",""created"":""Mon, 1 Jun 2020 18:19:30 GMT""}]","2020-06-03"
"1911.09131","Samuel Yee","Samuel W. Yee, Joshua N. Winn, Heather A. Knutson, Kishore C. Patra,
  Shreyas Vissapragada, Michael M. Zhang, Matthew J. Holman, Avi Shporer, Jason
  T. Wright","The Orbit of WASP-12b is Decaying","16 pages, 6 tables, 5 figures, accepted to AJ",,"10.3847/2041-8213/ab5c16",,"astro-ph.EP astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  WASP-12b is a transiting hot Jupiter on a 1.09-day orbit around a late-F
star. Since the planet's discovery in 2008, the time interval between transits
has been decreasing by $29\pm 2$ msec year$^{-1}$. This is a possible sign of
orbital decay, although the previously available data left open the possibility
that the planet's orbit is slightly eccentric and is undergoing apsidal
precession. Here, we present new transit and occultation observations that
provide more decisive evidence for orbital decay, which is favored over apsidal
precession by a $\Delta\mathrm{BIC}$ of 22.3 or Bayes factor of 70,000. We also
present new radial-velocity data that rule out the R{\o}mer effect as the cause
of the period change. This makes WASP-12 the first planetary system for which
we can be confident that the orbit is decaying. The decay timescale for the
orbit is $P/\dot{P} = 3.25\pm 0.23$ Myr. Interpreting the decay as the result
of tidal dissipation, the modified stellar tidal quality factor is $Q'_\star =
1.8 \times10^{5}$.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:02:45 GMT""}]","2020-01-08"
"1911.09132","Jacob Lustig-Yaeger","Jacob Lustig-Yaeger, Victoria S. Meadows, Andrew P. Lincowski","A mirage of the cosmic shoreline: Venus-like clouds as a statistical
  false positive for exoplanet atmospheric erosion","13 pages, 4 figures, accepted for publication in ApJ Letters",,"10.3847/2041-8213/ab5965",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Near-term studies of Venus-like atmospheres with JWST promise to advance our
knowledge of terrestrial planet evolution. However, the remote study of Venus
in the Solar System and the ongoing efforts to characterize gaseous exoplanets
both suggest that high altitude aerosols could limit observational studies of
lower atmospheres, and potentially make it challenging to recognize exoplanets
as ""Venus-like"". To support practical approaches for exo-Venus characterization
with JWST, we use Venus-like atmospheric models with self-consistent cloud
formation of the seven TRAPPIST-1 exoplanets to investigate the atmospheric
depth that can be probed using both transmission and emission spectroscopy. We
find that JWST/MIRI LRS secondary eclipse emission spectroscopy in the 6 $\mu$m
opacity window could probe at least an order of magnitude deeper pressures than
transmission spectroscopy, potentially allowing access to the sub-cloud
atmosphere for the two hot innermost TRAPPIST-1 planets. In addition, we
identify two confounding effects of sulfuric acid aerosols that may carry
strong implications for the characterization of terrestrial exoplanets with
transmission spectroscopy: (1) there exists an ambiguity between cloud-top and
solid surface in producing the observed spectral continuum; and (2) the
cloud-forming region drops in altitude with semi-major axis, causing an
increase in the observable cloud-top pressure with decreasing stellar
insolation. Taken together, these effects could produce a trend of thicker
atmospheres observed at lower stellar insolation---a convincing false positive
for atmospheric escape and an empirical ""cosmic shoreline"". However, developing
observational and theoretical techniques to identify Venus-like exoplanets and
discriminate them from stellar windswept worlds will enable advances in the
emerging field of terrestrial comparative planetology.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:03:36 GMT""}]","2020-01-08"
"1911.09133","Harro Wimmel","Harro Wimmel","Synthesis of Reduced Asymmetric Choice Petri Nets","27 pages, 10 figures, V2 due to font problem with ulsy.sty (one font
  symbol had been erroneously replaced with a greek Psi by LiveTeX)",,,,"cs.FL cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A Petri net is choice-free if any place has at most one transition in its
postset (consuming its tokens) and it is (extended) free-choice (EFC) if the
postsets of any two places are either equal or disjoint. Asymmetric choice (AC)
extends EFC such that two places may also have postsets where one is contained
in the other. In reduced AC nets this containment is limited: If the postsets
are neither disjoint nor equal, one is a singleton and the other has exactly
two transitions. The aim of Petri net synthesis is to find an unlabelled Petri
net in some target class with a reachability graph isomorphic to a given finite
labelled transition system (lts). Choice-free nets have strong properties,
allowing to often easily detect when synthesis will fail or at least to quicken
the synthesis. With EFC as the target class, only few properties can be checked
ahead and there seem to be no short cuts lowering the complexity of the
synthesis (compared to arbitrary Petri nets). For AC nets no synthesis
procedure is known at all. We show here how synthesis to a superclass of
reduced AC nets (not containing the full AC net class) can be done.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:07:10 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 10:28:05 GMT""}]","2019-11-25"
"1911.09134","Laura Fumagalli","P. Ares, T. Cea, M. Holwill, Y. B. Wang, R. Roldan, F. Guinea, D. V.
  Andreeva, L. Fumagalli, K. S. Novoselov, C. R. Woods","Piezoelectricity in monolayer hexagonal boron nitride",,,"10.1002/adma.201905504",,"cond-mat.mes-hall cond-mat.mtrl-sci cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-dimensional (2D) hexagonal boron nitride (hBN) is a wide-bandgap van der
Waals crystal with a unique combination of properties, including exceptional
strength, large oxidation resistance at high temperatures and optical
functionalities. Furthermore, in recent years hBN crystals have become the
material of choice for encapsulating other 2D crystals in a variety of
technological applications, from optoelectronic and tunnelling devices to
composites. Monolayer hBN, which has no center of symmetry, has been predicted
to exhibit piezoelectric properties, yet experimental evidence is lacking.
Here, by using electrostatic force microscopy, we observed this effect as a
strain-induced change in the local electric field around bubbles and creases,
in agreement with theoretical calculations. No piezoelectricity was found in
bilayer and bulk hBN, where the centre of symmetry is restored. These results
add piezoelectricity to the known properties of monolayer hBN, which makes it a
desirable candidate for novel electromechanical and stretchable optoelectronic
devices, and pave a way to control the local electric field and carrier
concentration in van der Waals heterostructures via strain. The experimental
approach used here also shows a way to investigate the piezoelectric properties
of other materials on the nanoscale by using electrostatic scanning probe
techniques.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:13:36 GMT""}]","2019-11-22"
"1911.09135","Vishwesh Jatala","Vishwesh Jatala, Loc Hoang, Roshan Dathathri, Gurbinder Gill, V
  Krishna Nandivada, Keshav Pingali","An Adaptive Load Balancer For Graph Analytical Applications on GPUs",,,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Load-balancing among the threads of a GPU for graph analytics workloads is
difficult because of the irregular nature of graph applications and the high
variability in vertex degrees, particularly in power-law graphs. We describe a
novel load balancing scheme to address this problem. Our scheme is implemented
in the IrGL compiler to allow users to generate efficient load balanced code
for a GPU from high-level sequential programs. We evaluated several graph
analytics applications on up to 16 distributed GPUs using IrGL to compile the
code and the Gluon substrate for inter-GPU communication. Our experiments show
that this scheme can achieve an average speed-up of 2.2x on inputs that suffer
from severe load imbalance problems when previous state-of-the-art
load-balancing schemes are used.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:14:45 GMT""},{""version"":""v2"",""created"":""Thu, 27 Feb 2020 18:09:32 GMT""}]","2020-02-28"
"1911.09136","Kevin Woods","Tristram Bogart, John Goodrick, and Kevin Woods","Periodic behavior in families of numerical and affine semigroups via
  parametric Presburger arithmetic","10 pages",,,,"math.CO math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $f_1(n), \ldots, f_k(n)$ be polynomial functions of $n$. For fixed
$n\in\mathbb{N}$, let $S_n\subseteq \mathbb{N}$ be the numerical semigroup
generated by $f_1(n),\ldots,f_k(n)$. As $n$ varies, we show that many
invariants of $S_n$ are eventually quasi-polynomial in $n$, such as the
Frobenius number, the type, the genus, and the size of the $\Delta$-set. The
tool we use is expressibility in the logical system of parametric Presburger
arithmetic. Generalizing to higher dimensional families of semigroups, we also
examine affine semigroups $S_n\subseteq \mathbb{N}^m$ generated be vectors
whose coordinates are polynomial functions of $n$, and we prove similar
results; for example, the Betti numbers are eventually quasi-polynomial
functions of $n$.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:17:18 GMT""}]","2019-11-22"
"1911.09137","Stefan Ivi\'c","Stefan Ivi\'c","Motion control for autonomous heterogeneous multi-agent area search in
  uncertain conditions","v1",,"10.1109/TCYB.2020.3022952",,"math.OC cs.MA cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using multiple mobile robots in search missions offers a lot of benefits, but
one needs a suitable and competent motion control algorithm which is able to
consider sensors characteristics, the uncertainty of target detection and
complexity of needed maneuvers in order to make a multi-agent search
autonomous. This paper provides a methodology for an autonomous two-dimensional
search using multiple unmanned search agents. The proposed methodology relies
on an accurate calculation of target occurrence probability distribution based
on the initial estimated target distribution and continuous action of spatial
variant search agent sensors. The core of the autonomous search process is a
high-level motion control for multiple search agents which utilizes the
probabilistic model of target occurrence via Heat Equation Driven Area Coverage
(HEDAC) method. This centralized motion control algorithm is tailored for
handling a group of search agents which are heterogeneous in both motion and
sensing characteristics. The motion of agents is directed by the gradient of
the potential field which provides near-ergodic exploration of the search
space. The proposed method is tested on three realistic search mission
simulations and compared with three alternative methods, where HEDAC
outperforms all alternatives in all tests. Conventional search strategies need
about double the time to achieve proportionate detection rate when compared to
HEDAC controlled search. The scalability test showed that increasing the number
of HEDAC controlled search agents, although somewhat deteriorating the search
efficiency, provides needed speed-up of the search. This study shows the
flexibility and competence of the proposed method and gives a strong foundation
for possible real-world applications.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:19:14 GMT""}]","2020-10-29"
"1911.09138","Aleksandra Grokhovskaya","Aleksandra Grokhovskaya and Sergei N. Dodonov","Large Scale Distribution of Galaxies in The Field HS 47.5-22. I. Data
  Analysis Technique","Accepted for publication in Astrophysical Bulletin, 9 pages, 8
  figures, 1 table",,"10.1134/S1990341319040047",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present the results of methodological works on automated analysis of the
large scale distribution of galaxies. Selecting candidates for clusters and
groups of galaxies was carried out using two complementary methods of
determining the density contrast maps in the narrow layers of the
three-dimensional large scale distribution of galaxies: the filtering algorithm
with an adaptive core and the Voronoi tesselation. The developed algorithms
were tested on 10 data sets of the MICE model catalog; additionally, we
determined the statistical parameters of the obtained results (completeness,
sample purity, etc.). The constructed density contrast maps were also used to
determine voids.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:19:18 GMT""}]","2020-01-08"
"1911.09139","Mohd Aman","Nabiullah Khan, Talha Usman and Mohd Aman","Certain hybrid polynomials associated with Sheffer sequences","21 pages",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Inspired by the framework of operational methods and based on the generating
functions of Legendre-Gould Hopper polynomials and Sheffer sequences, we
discuss certain new mixed type polynomials and their important properties. We
show that the use of operational nature allows the relevant polynomials to be
unified and general in nature. It is illustrated how the polynomials, we
develop, provide an easy derivation of a wide class of new and known
polynomials, and their respective properties.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:25:56 GMT""}]","2019-11-22"
"1911.09140","Ricardo P\'erez-Marco","Ricardo P\'erez-Marco","The e\~ne product over a commutative ring","22 pages",,,,"math.CA math.CV math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define the e\~ne product for the multiplicative group of polynomials and
formal power series with coefficients on a commutative ring and unitary
constant coefficient. This defines a commutative ring structure where
multiplication is the additive structure and the e\~ne product is the
multiplicative one. For polynomials with complex coefficients, the e\~ne
product acts as a multiplicative convolution of their divisor. We study its
algebraic properties, its relation to symmetric functions on an infinite number
of variables, to tensor products, and Hecke operators. The exponential
linearizes also the e\~ne product. The e\~ne product extends to rational
functions and formal meromorphic functions. We also study the analytic
properties over the complex numbers, and for entire functions. The e\~ne
product respects Hadamard-Weierstrass factorization and is related to the
Hadamard product. The e\~ne product plays a central role in predicting the
phenomenon of the ""statistics on Riemann zeros"" for Riemann zeta function and
general Dirichlet $L$-functions discovered by the author. It also gives reasons
to believe in the Riemann Hypothesis as explained in the survey ""Notes on the
Riemann Hypothesis"".
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:29:47 GMT""}]","2019-11-22"
"1911.09141","Joost Vercruysse","Marcelo Muniz S . Alves, Eliezer Batista, Felipe Castro, Glauber
  Quadros, Joost Vercruysse","Partial corepresentations of Hopf Algebras","41 papes, v2:several small corrections, final version as accepted for
  publication in Journal of Algebra",,,,"math.RA math.CT math.QA math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the notion of a partial corepresentation of a given Hopf algebra
$H$ over a coalgebra $C$ and the closely related concept of a partial
$H$-comodule. We prove that there exists a universal coalgebra $H^{par}$,
associated to the original Hopf algebra $H$, such that the category of regular
partial $H$-comodules is isomorphic to the category of $H^{par}$-comodules. We
introduce the notion of a Hopf coalgebroid and show that the universal
coalgebra $H^{par}$ has the structure of a Hopf coalgebroid over a suitable
coalgebra.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:37:43 GMT""},{""version"":""v2"",""created"":""Tue, 9 Mar 2021 08:26:10 GMT""}]","2021-03-10"
"1911.09142","Calvin W. Johnson","Calvin W. Johnson","Unmixing symmetries","5 pages, 4 figures, 1 table","Phys. Rev. Lett. 124, 172502 (2020)","10.1103/PhysRevLett.124.172502",,"nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The low-lying spectra of atomic nuclei display diverse behaviors, for example
rotational bands, which can be described phenomenologically by simple symmetry
groups such as spatial SU(3). This leads to the idea of dynamical symmetry,
where the Hamiltonian commutes with the Casimir operator(s) of a group, and is
block-diagonal in subspaces defined by the group's irreducible representations
or irreps. Detailed microscopic calculations, however, show these symmetries
are in fact often strongly mixed and the wave function fragmented across many
irreps. More commonly the fragmentation across members of a band are similar,
or a quasi-dynamical symmetry. In this Letter I explicitly, albeit numerically,
construct unitary transformations from a quasi-dynamical symmetry to a
dynamical symmetry, adapting the similarity renormalization group, or SRG. The
standard SRG produces unsatisfactory results, forcing the induced dynamical
symmetry to be dominated by high-weight irreps irrespective of the original
decomposition. Using spectral distribution theory to rederive and diagnose
standard SRG, I introduce a new form of SRG. The new SRG transforms a
quasi-dynamical symmetry to a dynamical symmetry, that is, unmixes the mixed
symmetries, with intuitively more appealing results.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:42:20 GMT""},{""version"":""v2"",""created"":""Wed, 29 Apr 2020 17:18:46 GMT""}]","2020-04-30"
"1911.09143","Xinshao Wang Mr","Xinshao Wang, Elyor Kodirov, Yang Hua, Neil M. Robertson","ID-aware Quality for Set-based Person Re-identification","A Set-based Person Re-identification Baseline: Simple Average Fusion
  of Global Spatial Representations, without temporal information, without
  parts/poses/attributes information",,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Set-based person re-identification (SReID) is a matching problem that aims to
verify whether two sets are of the same identity (ID). Existing SReID models
typically generate a feature representation per image and aggregate them to
represent the set as a single embedding. However, they can easily be perturbed
by noises--perceptually/semantically low quality images--which are inevitable
due to imperfect tracking/detection systems, or overfit to trivial images. In
this work, we present a novel and simple solution to this problem based on
ID-aware quality that measures the perceptual and semantic quality of images
guided by their ID information. Specifically, we propose an ID-aware Embedding
that consists of two key components: (1) Feature learning attention that aims
to learn robust image embeddings by focusing on 'medium' hard images. This way
it can prevent overfitting to trivial images, and alleviate the influence of
outliers. (2) Feature fusion attention is to fuse image embeddings in the set
to obtain the set-level embedding. It ignores noisy information and pays more
attention to discriminative images to aggregate more discriminative
information. Experimental results on four datasets show that our method
outperforms state-of-the-art approaches despite the simplicity of our approach.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:49:27 GMT""}]","2019-11-22"
"1911.09144","Daniel Gonz\'alez","Daniel Gonz\'alez-Campos, Marco Antonio P\'erez-de la Rosa and Juan
  Bory-Reyes","Reconstruction of solutions to a generalized Moisil-Teodorescu system in
  Jordan domains with rectfiable boundary",,"Compl. Anal. Oper. Theory, Volume 14, Issue 1, 1-18, 2020","10.1007/s11785-020-00983-7",,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we consider the problem of reconstructing solutions to a
generalized Moisil-Teodorescu system in Jordan domains of $\mathbb{R}^{3}$ with
rectifiable boundary. In order to determine conditions for existence of
solutions to the problem we embed the system in an appropriate generalized
quaternionic setting.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:51:01 GMT""}]","2020-02-05"
"1911.09145","Justin Sirignano","Jonathan B. Freund, Jonathan F. MacArt, and Justin Sirignano","DPM: A deep learning PDE augmentation method (with application to
  large-eddy simulation)",,,,,"cs.LG cs.CE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine learning for scientific applications faces the challenge of limited
data. We propose a framework that leverages a priori known physics to reduce
overfitting when training on relatively small datasets. A deep neural network
is embedded in a partial differential equation (PDE) that expresses the known
physics and learns to describe the corresponding unknown or unrepresented
physics from the data. Crafted as such, the neural network can also provide
corrections for erroneously represented physics, such as discretization errors
associated with the PDE's numerical solution. Once trained, the deep learning
PDE model (DPM) can make out-of-sample predictions for new physical parameters,
geometries, and boundary conditions.
  Our approach optimizes over the functional form of the PDE. Estimating the
embedded neural network requires optimizing over the entire PDE, which itself
is a function of the neural network. Adjoint partial differential equations are
used to efficiently calculate the high-dimensional gradient of the objective
function with respect to the neural network parameters. A stochastic adjoint
method (SAM), similar in spirit to stochastic gradient descent, further
accelerates training.
  The approach is demonstrated and evaluated for turbulence predictions using
large-eddy simulation (LES), a filtered version of the Navier--Stokes equation
containing unclosed sub-filter-scale terms. The DPM outperforms the widely-used
constant-coefficient and dynamic Smagorinsky models, even for filter sizes so
large that these established models become qualitatively incorrect. It also
significantly outperforms a priori trained models, which do not account for the
full PDE. A relaxation of the discrete enforcement of the divergence-free
constraint is also considered, instead allowing the DPM to approximately
enforce incompressibility physics.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:51:14 GMT""}]","2019-11-22"
"1911.09146","Jaskaran Grover","Jaskaran Grover, Changliu Liu, Katia Sycara","Deadlock Analysis and Resolution in Multi-Robot Systems (Extended
  Version)",,,,,"cs.RO cs.MA cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Collision avoidance for multirobot systems is a well studied problem.
Recently, control barrier functions (CBFs) have been proposed for synthesizing
controllers guarantee collision avoidance and goal stabilization for multiple
robots. However, it has been noted reactive control synthesis methods (such as
CBFs) are prone to deadlock, an equilibrium of system dynamics causes robots to
come to a standstill before reaching their goals. In this paper, we formally
derive characteristics of deadlock in a multirobot system uses CBFs. We propose
a novel approach to analyze deadlocks resulting from optimization based
controllers (CBFs) by borrowing tools from duality theory and graph
enumeration. Our key insight is system deadlock is characterized by a
force-equilibrium on robots and we show how complexity of deadlock analysis
increases approximately exponentially with the number of robots. This analysis
allows us to interpret deadlock as a subset of the state space, and we prove
this set is non-empty, bounded and located on the boundary of the safety set.
Finally, we use these properties to develop a provably correct decentralized
algorithm for deadlock resolution which ensures robots converge to their goals
while avoiding collisions. We show simulation results of the resolution
algorithm for two and three robots and experimentally validate this algorithm
on Khepera-IV robots.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:52:00 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 04:04:44 GMT""}]","2020-07-14"
"1911.09147","Aurora Perez Martinez Prof","R. Gonzalez Felipe, A. Perez Mart{\i}nez, H. Perez Rojas, and G.
  Quintero Angulo","Quantum magnetic collapse of a partially bosonized npe-gas: Implications
  for astrophysical jets","10 pages, 11 figures and one appendix",,,,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a possible mechanism for astrophysical jet production from a neutron
star composed by a partially bosonized npe-gas. We obtain that the expulsion of
a stable stream of matter might be triggered by the quantum magnetic collapse
of one or various components of the gas, while its collimation is due to the
formation of a strong self-generated magnetic field.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:53:21 GMT""}]","2019-11-22"
"1911.09148","Srivatsan Ravi Mr","Giulio Malavolta and Pedro Moreno-Sanchez and Aniket Kate and Matteo
  Maffei and Srivatsan Ravi","Concurrency and Privacy with Payment-Channel Networks",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Permissionless blockchains protocols such as Bitcoin are inherently limited
in transaction throughput and latency. Current efforts to address this key
issue focus on off-chain payment channels that can be combined in a
Payment-Channel Network (PCN) to enable an unlimited number of payments without
requiring to access the blockchain other than to register the initial and final
capacity of each channel. While this approach paves the way for low latency and
high throughput of payments, its deployment in practice raises several privacy
concerns as well as technical challenges related to the inherently concurrent
nature of payments, such as race conditions and deadlocks, that have been
understudied so far. In this work, we lay the foundations for privacy and
concurrency in PCNs, presenting a formal definition in the Universal
Composability framework as well as practical and provably secure solutions. In
particular, we present Fulgor and Rayo. Fulgor is the first payment protocol
for PCNs that provides provable privacy guarantees for PCNs and is fully
compatible with the Bitcoin scripting system. However, Fulgor is a blocking
protocol and therefore prone to deadlocks of concurrent payments as in
currently available PCNs. Instead, Rayo is the first protocol for PCNs that
enforces non-blocking progress (i.e., at least one of the concurrent payments
terminates). We show through a new impossibility result that non-blocking
progress necessarily comes at the cost of weaker privacy. At the core of Fulgor
and Rayo is Multi-Hop HTLC, a new smart contract, compatible with the Bitcoin
scripting system, that provides conditional payments while reducing running
time and communication overhead with respect to previous approaches.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:54:54 GMT""}]","2019-11-22"
"1911.09149","Gonzalo Quiroga","C. N. Kozameh, J. I. Nieva, and G. D. Quiroga","A relativistic center of mass in general relativity",,"Phys. Rev. D 101, 024028 (2020)","10.1103/PhysRevD.101.024028",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The center of mass and spin for isolated sources of gravitational radiation
that move at relativistic speeds are defined. As a first step, we also present
these definitions in flat space. This contradicts some general wisdom given in
textbooks claiming that such definitions are not covariant and thus, have no
physical meaning. We then generalize the definitions to asymptotically flat
spacetimes giving their equations of motion when gravitational radiation is
emitted by the isolated sources. The resulting construction has some
similarities with the Mathisson-Papapetrou equations which describes the motion
of the particle in an external field. We analyze the relationship between the
center of mass velocity and the Bondi linear momentum and show they are not
proportional to each other. A similar situation happens between the total and
intrinsic angular momentum when the Bondi momentum vanishes. We claim that
extra terms should be added in other approaches to adequately describe the time
evolution of isolated sources of gravitational radiation.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:00:50 GMT""}]","2020-01-15"
"1911.09150","Bundit Laekhanukit","Chun-Hsiang Chan, Bundit Laekhanukit, Hao-Ting Wei, Yuhao Zhang","Polylogarithmic Approximation Algorithm for k-Connected Directed Steiner
  Tree on Quasi-Bipartite Graphs",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the k-Connected Directed Steiner Tree problem (k-DST), we are given a
directed graph G=(V, E) with edge (or vertex) costs, a root vertex r, a set of
q terminals T, and a connectivity requirement k>0; the goal is to find a
minimum-cost subgraph H of G such that H has k internally disjoint paths from
the root r to each terminal t . The k-DST problem is a natural generalization
of the classical Directed Steiner Tree problem (DST) in the fault-tolerant
setting in which the solution subgraph is required to have an r,t-path, for
every terminal t, even after removing k-1 edges or vertices.
  Despite being a classical problem, there are not many positive results on the
problem, especially for the case k >= 3. In this paper, we will present an
O(log k log q)-approximation algorithm for k-DST when an input graph is
quasi-bipartite, i.e., when there is no edge joining two non-terminal vertices.
To the best of our knowledge, our algorithm is the only known non-trivial
approximation algorithm for k-DST, for k >= 3, that runs in polynomial-time
regardless of the structure of the optimal solution. In addition, our algorithm
is tight for every constant k, due to the hardness result inherited from the
Set Cover problem.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:02:45 GMT""}]","2019-11-22"
"1911.09151","Sebastian Ankargren","Sebastian Ankargren and M{\aa}ns Unosson and Yukai Yang","A Flexible Mixed-Frequency Vector Autoregression with a Steady-State
  Prior",,,,,"econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a Bayesian vector autoregressive (VAR) model for mixed-frequency
data. Our model is based on the mean-adjusted parametrization of the VAR and
allows for an explicit prior on the 'steady states' (unconditional means) of
the included variables. Based on recent developments in the literature, we
discuss extensions of the model that improve the flexibility of the modeling
approach. These extensions include a hierarchical shrinkage prior for the
steady-state parameters, and the use of stochastic volatility to model
heteroskedasticity. We put the proposed model to use in a forecast evaluation
using US data consisting of 10 monthly and 3 quarterly variables. The results
show that the predictive ability typically benefits from using mixed-frequency
data, and that improvements can be obtained for both monthly and quarterly
variables. We also find that the steady-state prior generally enhances the
accuracy of the forecasts, and that accounting for heteroskedasticity by means
of stochastic volatility usually provides additional improvements, although not
for all variables.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:06:12 GMT""}]","2019-11-22"
"1911.09152","Alireza Amanihamedani","MohammadAmin Fazli, Alireza Amanihamedani","Governance of Social Welfare in Networked Markets",,,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper aims to investigate how a central authority (e.g. a government)
can increase social welfare in a network of markets and firms. In these
networks, modeled using a bipartite graph, firms compete with each other
\textit{\`a la} Cournot. Each firm can supply homogeneous goods in markets
which it has access to. The central authority may take different policies for
its aim. In this paper, we assume that the government has a budget by which it
can supply some goods and inject them into various markets. We discuss how the
central authority can best allocate its budget for the distribution of goods to
maximize social welfare. We show that the solution is highly dependent on the
structure of the network. Then, using the network's structural features, we
present a heuristic algorithm for our target problem. Finally, we compare the
performance of our algorithm with other heuristics with experimentation on real
datasets.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:07:35 GMT""}]","2019-11-22"
"1911.09153","Tyler Lu","Ivan Vendrov, Tyler Lu, Qingqing Huang, Craig Boutilier","Gradient-based Optimization for Bayesian Preference Elicitation","To appear in the Thirty-Fourth AAAI Conference on Artificial
  Intelligence (AAAI-20)",,,,"cs.LG cs.AI stat.ML","http://creativecommons.org/licenses/by/4.0/","  Effective techniques for eliciting user preferences have taken on added
importance as recommender systems (RSs) become increasingly interactive and
conversational. A common and conceptually appealing Bayesian criterion for
selecting queries is expected value of information (EVOI). Unfortunately, it is
computationally prohibitive to construct queries with maximum EVOI in RSs with
large item spaces. We tackle this issue by introducing a continuous formulation
of EVOI as a differentiable network that can be optimized using gradient
methods available in modern machine learning (ML) computational frameworks
(e.g., TensorFlow, PyTorch). We exploit this to develop a novel, scalable Monte
Carlo method for EVOI optimization, which is more scalable for large item
spaces than methods requiring explicit enumeration of items. While we emphasize
the use of this approach for pairwise (or k-wise) comparisons of items, we also
demonstrate how our method can be adapted to queries involving subsets of item
attributes or ""partial items,"" which are often more cognitively manageable for
users. Experiments show that our gradient-based EVOI technique achieves
state-of-the-art performance across several domains while scaling to large item
spaces.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:08:25 GMT""}]","2019-11-22"
"1911.09154","Denis Rosset","Denis Rosset and Felipe Montealegre-Mora and Jean-Daniel Bancal","RepLAB: a computational/numerical approach to representation theory","8 pages of text + 2 pages of references","Quantum Theory and Symmetries, CRM Series in Mathematical Physics,
  Springer, pp 643-653 (2021)","10.1007/978-3-030-55777-5_60",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a MATLAB/Octave toolbox to decompose finite dimensionial
representations of compact groups. Surprisingly, little information about the
group and the representation is needed to perform that task. We discuss
applications to semidefinite programming.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:08:27 GMT""}]","2021-03-31"
"1911.09155","Rolf Haag","Rolf Haag","m-Axial and m-Circular 3m-Polygons","24 pages,8 figures, 8 tables",,,,"math.CO math.GR math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The present article includes the enumeration of $n$-polygons with two certain
symmetry properties: For a number $3m$ of vertices, we count the $3m$-polygons
with $m$ symmetry axes and the $3m$-polygons, that match after three elementary
rotations, but have no symmetry axes. For those polygons we give complete lists
of representatives of their equivalence-classes and closed formulas for their
number.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:12:23 GMT""}]","2019-11-22"
"1911.09156","Javier S\'anchez-Monedero","Javier S\'anchez-Monedero and Lina Dencik","The politics of deceptive borders: 'biomarkers of deceit' and the case
  of iBorderCtrl",,,,,"cs.CY cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper critically examines a recently developed proposal for a border
control system called iBorderCtrl, designed to detect deception based on facial
recognition technology and the measurement of micro-expressions, termed
'biomarkers of deceit'. Funded under the European Commission's Horizon 2020
programme, we situate our analysis in the wider political economy of 'emotional
AI' and the history of deception detection technologies. We then move on to
interrogate the design of iBorderCtrl using publicly available documents and
assess the assumptions and scientific validation underpinning the project
design. Finally, drawing on a Bayesian analysis we outline statistical
fallacies in the foundational premise of mass screening and argue that it is
very unlikely that the model that iBorderCtrl provides for deception detection
would work in practice. By interrogating actual systems in this way, we argue
that we can begin to question the very premise of the development of
data-driven systems, and emotional AI and deception detection in particular,
pushing back on the assumption that these systems are fulfilling the tasks they
claim to be attending to and instead ask what function such projects carry out
in the creation of subjects and management of populations. This function is not
merely technical but, rather, we argue, distinctly political and forms part of
a mode of governance increasingly shaping life opportunities and fundamental
rights.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:17:11 GMT""},{""version"":""v2"",""created"":""Mon, 23 Dec 2019 20:22:23 GMT""},{""version"":""v3"",""created"":""Fri, 10 Jan 2020 12:48:18 GMT""},{""version"":""v4"",""created"":""Tue, 23 Jun 2020 12:18:36 GMT""}]","2020-06-24"
"1911.09157","Gal Dalal","Gal Dalal, Balazs Szorenyi, Gugan Thoppe","A Tale of Two-Timescale Reinforcement Learning with the Tightest
  Finite-Time Bound",,,,,"cs.LG math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Policy evaluation in reinforcement learning is often conducted using
two-timescale stochastic approximation, which results in various gradient
temporal difference methods such as GTD(0), GTD2, and TDC. Here, we provide
convergence rate bounds for this suite of algorithms. Algorithms such as these
have two iterates, $\theta_n$ and $w_n,$ which are updated using two distinct
stepsize sequences, $\alpha_n$ and $\beta_n,$ respectively. Assuming $\alpha_n
= n^{-\alpha}$ and $\beta_n = n^{-\beta}$ with $1 > \alpha > \beta > 0,$ we
show that, with high probability, the two iterates converge to their respective
solutions $\theta^*$ and $w^*$ at rates given by $\|\theta_n - \theta^*\| =
\tilde{O}( n^{-\alpha/2})$ and $\|w_n - w^*\| = \tilde{O}(n^{-\beta/2});$ here,
$\tilde{O}$ hides logarithmic terms. Via comparable lower bounds, we show that
these bounds are, in fact, tight. To the best of our knowledge, ours is the
first finite-time analysis which achieves these rates. While it was known that
the two timescale components decouple asymptotically, our results depict this
phenomenon more explicitly by showing that it in fact happens from some finite
time onwards. Lastly, compared to existing works, our result applies to a
broader family of stepsizes, including non-square summable ones.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:21:21 GMT""},{""version"":""v2"",""created"":""Wed, 4 Dec 2019 13:07:57 GMT""}]","2019-12-05"
"1911.09158","Fanghui Liu","Fanghui Liu, Xiaolin Huang, Yudong Chen, Jie Yang, Johan A.K. Suykens","Random Fourier Features via Fast Surrogate Leverage Weighted Sampling","accepted by AAAI-20",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a fast surrogate leverage weighted sampling
strategy to generate refined random Fourier features for kernel approximation.
Compared to the current state-of-the-art method that uses the leverage weighted
scheme [Li-ICML2019], our new strategy is simpler and more effective. It uses
kernel alignment to guide the sampling process and it can avoid the matrix
inversion operator when we compute the leverage function. Given n observations
and s random features, our strategy can reduce the time complexity from
O(ns^2+s^3) to O(ns^2), while achieving comparable (or even slightly better)
prediction performance when applied to kernel ridge regression (KRR). In
addition, we provide theoretical guarantees on the generalization performance
of our approach, and in particular characterize the number of random features
required to achieve statistical guarantees in KRR. Experiments on several
benchmark datasets demonstrate that our algorithm achieves comparable
prediction performance and takes less time cost when compared to [Li-ICML2019].
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:24:41 GMT""}]","2019-11-22"
"1911.09159","JInglai Li","Yuzhou Gao, Tengchao Yu, Jinglai Li","Bayesian optimization with local search",,,,,"stat.ML cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Global optimization finds applications in a wide range of real world
problems. The multi-start methods are a popular class of global optimization
techniques, which are based on the ideas of conducting local searches at
multiple starting points. In this work we propose a new multi-start algorithm
where the starting points are determined in a Bayesian optimization framework.
Specifically, the method can be understood as to construct a new function by
conducting local searches of the original objective function, where the new
function attains the same global optima as the original one. Bayesian
optimization is then applied to find the global optima of the new local search
defined function.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:25:49 GMT""},{""version"":""v2"",""created"":""Fri, 29 May 2020 19:21:57 GMT""},{""version"":""v3"",""created"":""Tue, 30 Jun 2020 11:46:57 GMT""}]","2020-07-01"
"1911.09160","Jung-Shen Tai","Jung-Shen B. Tai, Ivan I. Smalyukh","Three-dimensional crystals of adaptive knots",,"Science 365, 1449 (2019)","10.1126/science.aay1638",,"cond-mat.soft cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Starting from Gauss and Kelvin, knots in fields were postulated behaving like
particles, but experimentally they were found only as transient features or
required complex boundary conditions to exist and couldn't self-assemble into
three-dimensional crystals. We introduce energetically stable micrometer-sized
knots in helical fields of chiral liquid crystals. While spatially localized
and freely diffusing in all directions, they resemble colloidal particles and
atoms, self-assembling into crystalline lattices with open and closed
structures. These knots are robust and topologically distinct from the host
medium, though they can be morphed and reconfigured by weak stimuli under
conditions like in displays. A combination of energy-minimizing numerical
modeling and optical imaging uncovers the internal structure and topology of
individual helical field knots and various hierarchical crystalline
organizations they form.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:25:56 GMT""}]","2019-11-22"
"1911.09161","Skyler Degenkolb","David Wurm, Douglas H. Beck, Tim Chupp, Skyler Degenkolb, Katharina
  Fierlinger, Peter Fierlinger, Hanno Filter, Sergey Ivanov, Christopher Klau,
  Michael Kreuz, Eddy Leli\`evre-Berna, Tobias Lins, Joachim Meichelb\""ock,
  Thomas Neulinger, Robert Paddock, Florian R\""ohrer, Martin Rosner, Anatolii
  P. Serebrov, Jaideep Taggart Singh, Rainer Stoepler, Stefan Stuiber, Michael
  Sturm, Bernd Taubenheim, Xavier Tonon, Mark Tucker, Maurits van der Grinten,
  Oliver Zimmer","The PanEDM Neutron Electric Dipole Moment Experiment at the ILL","8 pages, 4 figures; submitted to the Proceedings of the International
  Workshop on Particle Physics at Neutron Sources PPNS 2018, Grenoble, France,
  May 24-26, 2018",,"10.1051/epjconf/201921902006",,"physics.ins-det hep-ex nucl-ex","http://creativecommons.org/licenses/by/4.0/","  The neutron's permanent electric dipole moment $d_n$ is constrained to below
$3\times10^{-26} e~\text{cm}$ (90% C.L.) [ arXiv:hep-ex/0602020,
arXiv:1509.04411 ], by experiments using ultracold neutrons (UCN). We plan to
improve this limit by an order of magnitude or more with PanEDM, the first
experiment exploiting the ILL's new UCN source SuperSUN. SuperSUN is expected
to provide a high density of UCN with energies below 80 neV, implying extended
statistical reach with respect to existing sources, for experiments that rely
on long storage or spin-precession times. Systematic errors in PanEDM are
strongly suppressed by passive magnetic shielding, with magnetic field and
gradient drifts at the single fT level. A holding-field homogeneity on the
order of $10^{-4}$ is achieved in low residual fields, via a high static
damping factor and built-in coil system. No comagnetometer is needed for the
first order-of-magnitude improvement in $d_n$, thanks to high magnetic
stability and an assortment of sensors outside the UCN storage volumes. PanEDM
will be commissioned and upgraded in parallel with SuperSUN, to take full
advantage of the source's output in each phase. Commissioning is ongoing in
2019, and a new limit in the mid $10^{-27} e~\text{cm}$ range should be
possible with two full reactor cycles of data in the commissioned apparatus.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:33:08 GMT""}]","2020-01-08"
"1911.09162","Changjian Shui","Changjian Shui, Fan Zhou, Christian Gagn\'e, Boyu Wang","Deep Active Learning: Unified and Principled Method for Query and
  Training","AISTATS 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we are proposing a unified and principled method for both the
querying and training processes in deep batch active learning. We are providing
theoretical insights from the intuition of modeling the interactive procedure
in active learning as distribution matching, by adopting the Wasserstein
distance. As a consequence, we derived a new training loss from the theoretical
analysis, which is decomposed into optimizing deep neural network parameters
and batch query selection through alternative optimization. In addition, the
loss for training a deep neural network is naturally formulated as a min-max
optimization problem through leveraging the unlabeled data information.
Moreover, the proposed principles also indicate an explicit
uncertainty-diversity trade-off in the query batch selection. Finally, we
evaluate our proposed method on different benchmarks, consistently showing
better empirical performances and a better time-efficient query strategy
compared to the baselines.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:36:45 GMT""},{""version"":""v2"",""created"":""Wed, 26 Feb 2020 14:39:02 GMT""}]","2020-02-27"
"1911.09163","Guido De Philippis","Lorenzo Brasco and Guido De Philippis and Giovanni Franzina","Positive solutions to the sublinear Lane-Emden equation are isolated",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that on a smooth bounded set, the positive least energy solution of
the Lane-Emden equation with sublinear power is isolated. As a corollary, we
obtain that the first $q-$eigenvalue of the Dirichlet-Laplacian is not an
accumulation point of the $q-$spectrum, on a smooth bounded set. Our results
extend to a suitable class of Lipschitz domains, as well.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:36:53 GMT""}]","2019-11-22"
"1911.09164","Naoki Kitazawa","Naoki Kitazawa","New observations on cohomology rings of Reeb spaces of explicit fold
  maps and manifolds admitting these maps","21 pages, some presentations revised, There are 6 theorems as new
  results in this version, this version is submitted to a refereed journal,
  mistakes etc. are due to my carelessness",,,,"math.KT math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a branch of algebraic and differential topology of manifolds, the theory
of Morse functions and their higher dimensional versions or fold maps and its
application to algebraic and differential topology of manifolds is fundamental,
important and interesting. This paper is on explicit construction of fold maps
and homology groups and cohomology rings of their Reeb spaces: they are defined
as the spaces of all connected components of preimages of the maps, and in
suitable situations inherit some topological information such as homology
groups and cohomology rings of the manifolds. Explicit construction of the maps
is a fundamental and difficult task even on manifolds which are not so
complicated. The author has constructed explicit fold maps systematically and
performed several calculations of homology groups and cohomology rings of the
Reeb spaces. This paper concerns new observations on this task.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:37:45 GMT""},{""version"":""v10"",""created"":""Fri, 17 Apr 2020 06:43:05 GMT""},{""version"":""v11"",""created"":""Fri, 22 May 2020 19:08:17 GMT""},{""version"":""v2"",""created"":""Sun, 1 Dec 2019 21:11:25 GMT""},{""version"":""v3"",""created"":""Sun, 2 Feb 2020 17:56:39 GMT""},{""version"":""v4"",""created"":""Tue, 25 Feb 2020 18:10:58 GMT""},{""version"":""v5"",""created"":""Wed, 11 Mar 2020 06:45:46 GMT""},{""version"":""v6"",""created"":""Sun, 15 Mar 2020 07:48:01 GMT""},{""version"":""v7"",""created"":""Wed, 18 Mar 2020 19:37:29 GMT""},{""version"":""v8"",""created"":""Thu, 26 Mar 2020 18:32:15 GMT""},{""version"":""v9"",""created"":""Thu, 16 Apr 2020 06:49:32 GMT""}]","2020-05-26"
"1911.09165","Jason Li","Anupam Gupta, Euiwoong Lee, Jason Li","The Karger-Stein Algorithm is Optimal for $k$-cut",,,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the $k$-cut problem, we are given an edge-weighted graph and want to find
the least-weight set of edges whose deletion breaks the graph into $k$
connected components. Algorithms due to Karger-Stein and Thorup showed how to
find such a minimum $k$-cut in time approximately $O(n^{2k-2})$. The best lower
bounds come from conjectures about the solvability of the $k$-clique problem
and a reduction from $k$-clique to $k$-cut, and show that solving $k$-cut is
likely to require time $\Omega(n^k)$. Our recent results have given
special-purpose algorithms that solve the problem in time $n^{1.98k + O(1)}$,
and ones that have better performance for special classes of graphs (e.g., for
small integer weights). In this work, we resolve the problem for general
graphs, by showing that for any fixed $k \geq 2$, the Karger-Stein algorithm
outputs any fixed minimum $k$-cut with probability at least $\hat{O}(n^{-k})$,
where $\hat{O}(\cdot)$ hides a $2^{O(\ln \ln n)^2}$ factor. This also gives an
extremal bound of $\hat{O}(n^k)$ on the number of minimum $k$-cuts in an
$n$-vertex graph and an algorithm to compute a minimum $k$-cut in similar
runtime. Both are tight up to $\hat{O}(1)$ factors. The first main ingredient
in our result is a fine-grained analysis of how the graph shrinks---and how the
average degree evolves---under the Karger-Stein process. The second ingredient
is an extremal result bounding the number of cuts of size at most $(2-\delta)
OPT/k$, using the Sunflower lemma.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:38:24 GMT""}]","2019-11-22"
"1911.09166","Antoine Song","Antoine Song","Morse index, Betti numbers and singular set of bounded area minimal
  hypersurfaces","v2: Section 4 improved, minor corrections, results unchanged. v3:
  Corrections suggested by referees, correction suggested by Giada Franz and
  Santiago Cordero Misteli. To appear in Duke Math. J",,,,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a combinatorial argument to study closed minimal hypersurfaces
of bounded area and high Morse index. Let $(M^{n+1},g)$ be a closed Riemannian
manifold and $\Sigma\subset M$ be a closed embedded minimal hypersurface with
area at most $A>0$ and with a singular set of Hausdorff dimension at most
$n-7$. We show the following bounds: there is $C_A>0$ depending only on $n$,
$g$, and $A$ so that $$\sum_{i=0}^n b^i(\Sigma) \leq C_A
\big(1+index(\Sigma)\big) \quad \text{ if $3\leq n+1\leq 7$},$$
$$\mathcal{H}^{n-7}\big(Sing(\Sigma)\big) \leq C_A
\big(1+index(\Sigma)\big)^{7/n} \quad \text{ if $n+1\geq 8$},$$ where $b^i$
denote the Betti numbers over any field, $\mathcal{H}^{n-7}$ is the
$(n-7)$-dimensional Hausdorff measure and $Sing(\Sigma)$ is the singular set of
$\Sigma$. In fact in dimension $n+1=3$, $C_A$ depends linearly on $A$. We list
some open problems at the end of the paper.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:50:49 GMT""},{""version"":""v2"",""created"":""Fri, 5 Jun 2020 06:34:24 GMT""},{""version"":""v3"",""created"":""Tue, 23 Aug 2022 07:00:25 GMT""}]","2022-08-24"
"1911.09167","Gigi Leung","Gigi Y. C. Leung, Ryan Leaman, Glenn van de Ven and Giuseppina
  Battaglia","A dwarf-dwarf merger and dark matter core as a solution to the Globular
  Cluster problems in the Fornax dSph","18 pages, 15 figures, accepted by MNRAS",,"10.1093/mnras/stz3017",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The five globular clusters (GCs) of the Fornax dSph are puzzling for two
reasons; the mass in GCs is high with respect to the galaxy's old stellar mass,
and their survival and large distance (> 1 kpc) is at odds with naive
expectations of dynamical friction. We present here a semi-analytic model,
simultaneously addressing both problems in a comprehensive evolutionary
framework for Fornax. Key to the model is inclusion of: 1) hydrodynamical
constraints on the GC formation locations, 2) self-consistent velocity
distribution functions in the dynamical friction calculations and 3) expansion
of GC orbits due to a past dwarf-dwarf merger in the orbit integrations. The
latter is crucial for reconciling the dynamical survival of the clusters, and
their chemical properties with respect to the Fornax field stars. We find that
in order for four of the GCs to survive at their observed projected location, a
dark matter core of radius > 1.5 kpc and a dwarf merger with dynamical mass
ratio of 1:5 to 1:2 with Fornax is required. We support the merger scenario by
showing that aspects of the field star metallicity distribution function and
anomalous chemical properties of GC5, are representative of a merging galaxy
which is ~1/3 less massive than Fornax. Together the chemical and dynamical
models suggest a scenario where three in-situ GCs in proto-Fornax were ejected
to the outskirts during the merger, a GC4 formed during the merger at about 10
Gyrs ago, with GC5 being brought in by the merging galaxy to Fornax.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:52:36 GMT""}]","2020-01-08"
"1911.09168","Hamed Aghdam","Hamed H. Aghdam, Abel Gonzalez-Garcia, Joost van de Weijer, Antonio M.
  L\'opez","Active Learning for Deep Detection Neural Networks","Accepted at ICCV 2019",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cost of drawing object bounding boxes (i.e. labeling) for millions of
images is prohibitively high. For instance, labeling pedestrians in a regular
urban image could take 35 seconds on average. Active learning aims to reduce
the cost of labeling by selecting only those images that are informative to
improve the detection network accuracy. In this paper, we propose a method to
perform active learning of object detectors based on convolutional neural
networks. We propose a new image-level scoring process to rank unlabeled images
for their automatic selection, which clearly outperforms classical scores. The
proposed method can be applied to videos and sets of still images. In the
former case, temporal selection rules can complement our scoring process. As a
relevant use case, we extensively study the performance of our method on the
task of pedestrian detection. Overall, the experiments show that the proposed
method performs better than random selection. Our codes are publicly available
at www.gitlab.com/haghdam/deep_active_learning.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:57:44 GMT""}]","2019-11-22"
"1911.09169","Carsten van de Bruck","Philippe Brax, Carsten van de Bruck, Anne-Christine Davis","The Swampland and Screened Modified Gravity","24 pages","Phys. Rev. D 101, 083514 (2020)","10.1103/PhysRevD.101.083514",,"hep-th astro-ph.CO gr-qc hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the implications of the swampland conjectures on scalar-tensor
theories defined in the Einstein frame in which the scalar interaction is
screened. We show that chameleon models are not in the swampland provided the
coupling to matter is larger than unity and the mass of the scalar field is
much larger than the Hubble rate. We apply these conditions to the inverse
power law chameleon and the symmetron. We then focus on the dilaton of string
theory in the strong coupling limit, as defined in the string frame. We show
that solar system tests of gravity imply that viable dilaton models are not in
the swampland. In the future of the Universe, if the low energy description
with a single scalar is still valid and the coupling to matter remains finite,
we find that the scalar field energy density must vanish for models with the
chameleon and symmetron mechanisms. Hence in these models dark energy is only a
transient phenomenon. This is not the case for the strongly coupled dilaton,
which keeps evolving slowly, leading to a quasi de Sitter space-time.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:59:39 GMT""}]","2020-04-15"
"1911.09170","Henning Schmidt","E. K. Anderson, A. F. Schmidt-May, P. K. Najeeb, G. Eklund, K. C.
  Chartkunchand, S. Ros\'en, {\AA}. Larson, K. Hansen, H. Cederquist, H.
  Zettergren, H. T. Schmidt","Spontaneous electron emission from hot silver dimer anions: Breakdown of
  the Born-Oppenheimer approximation",,"Phys. Rev. Lett. 124, 173001 (2020)","10.1103/PhysRevLett.124.173001",,"physics.atm-clus","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the first experimental evidence of spontaneous electron emission
from a homonuclear dimer anion through direct measurements of $\rm{Ag}_2^-
\rightarrow \rm{Ag}_2 + \rm{e}^-$ decays on milliseconds and seconds time
scales. This observation is very surprising as there is no avoided crossing
between adiabatic energy curves to mediate such a process. The process is weak
but yet dominates the decay signal after 100 ms when ensembles of internally
hot Ag$_2^-$ ions are stored in the cryogenic ion-beam storage ring, DESIREE,
for 10 seconds. The electron emission process is associated with an
instantaneous, very large, reduction of the vibrational energy of the dimer
system. This represents a dramatic deviation from a Born-Oppenheimer
description of dimer dynamics.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:00:59 GMT""}]","2020-05-06"
"1911.09171","Siyu Heng","Siyu Heng, Bo Zhang, Xu Han, Scott A. Lorch, Dylan S. Small","Re-Evaluating Strengthened-IV Designs: Asymptotic Efficiency, Bias
  Formula, and the Validity and Power of Sensitivity Analyses","86 pages, 4 figures, 6 tables",,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Instrumental variables (IVs) are extensively used to estimate treatment
effects when the treatment and outcome are confounded by unmeasured
confounders; however, weak IVs are often encountered in empirical studies and
may cause problems. Many studies have considered building a stronger IV from
the original, possibly weak, IV in the design stage of a matched study at the
cost of not using some of the samples in the analysis. It is widely accepted
that strengthening an IV tends to render nonparametric tests more powerful and
will increase the power of sensitivity analyses in large samples. In this
article, we re-evaluate this conventional wisdom to bring new insights into
this topic. We consider matched observational studies from three perspectives.
First, we evaluate the trade-off between IV strength and sample size on
nonparametric tests assuming the IV is valid and exhibit conditions under which
strengthening an IV increases power and conversely conditions under which it
decreases power. Second, we derive a necessary condition for a valid
sensitivity analysis model with continuous doses. We show that the $\Gamma$
sensitivity analysis model, which has been previously used to come to the
conclusion that strengthening an IV increases the power of sensitivity analyses
in large samples, does not apply to the continuous IV setting and thus this
previously reached conclusion may be invalid. Third, we quantify the bias of
the Wald estimator with a possibly invalid IV under an oracle and leverage it
to develop a valid sensitivity analysis framework; under this framework, we
show that strengthening an IV may amplify or mitigate the bias of the
estimator, and may or may not increase the power of sensitivity analyses. We
also discuss how to better adjust for the observed covariates when building an
IV in matched studies.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:07:16 GMT""},{""version"":""v2"",""created"":""Sat, 8 Aug 2020 02:44:46 GMT""},{""version"":""v3"",""created"":""Fri, 15 Oct 2021 21:43:51 GMT""}]","2021-10-19"
"1911.09172","Hans Koch","Hans Koch and Sasha Kocic","Renormalization and universality of the Hofstadter spectrum",,,"10.1088/1361-6544/ab8693",,"math-ph math.MP math.SP quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a renormalization transformation $R$ for skew-product maps of the
type that arise in a spectral analysis of the Hofstadter Hamiltonian. Periodic
orbits of $R$ determine universal constants analogous to the critical exponents
in the theory of phase transitions. Restricting to skew-product maps over a
circle-rotations by the golden mean, we find several periodic orbits for $R$,
and we conjecture that there are infinitely many. Interestingly, all scaling
factors that have been determined to high accuracy appear to be algebraically
related to the circle-rotation number. We present evidence that these values
describe (among other things) local scaling properties of the Hofstadter
spectrum.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:09:19 GMT""}]","2020-08-26"
"1911.09174","Xian-Min Jin","Yao Wang, Yi-Jun Chang, Jun Gao, Yong-Heng Lu, Zhi-Qiang Jiao,
  Fang-Wei Ye, Xian-Min Jin","Observation of Magic Angle and Wall State in Twisted Bilayer Photonic
  Graphene","22 pages, 6 figures, Comments welcome",,,,"cond-mat.mes-hall cond-mat.mtrl-sci physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graphene, a one-layer honeycomb lattice of carbon atoms, exhibits
unconventional phenomena and attracts much interest since its discovery.
Recently, an unexpected Mott-like insulator state induced by moir\'e pattern
and a superconducting state are observed in magic-angle-twisted bilayer
graphene, especially, without correlations between electrons, which gives more
hints for the understanding and investigation of strongly correlated phenomena.
The photon as boson, behaving differently with fermion, can also retrieve the
unconventional phenomena of graphene, such as the bearded edge state which is
even never been observed in graphene due to the unstability. Here, we present a
direct observation of magic angle and wall state in twisted bilayer photonic
graphene. We successfully observe the strong localization and rapid diffusion
of photon at the regions with AA and AB stacking order around the magic angle,
respectively. Most importantly, we find a wall state showing the photon
distribution distinctly separate at the regions with AA and AB/BA stacking
order in the lowest-energy band. The mechanism underlying the wall states may
help to understand the existence of both Mott-like insulating state and
superconducting state in magic-angle twisted bilayer graphene. The
accessibility of magic angle in twisted bilayer photonic graphene adds the
boson behavior into graphene superlattice and the observation of wall state
will also deep the understanding of matter.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:10:29 GMT""}]","2019-11-22"
"1911.09175","Sebin Gracy","Sebin Gracy, Philip.E.Pare, Henrik Sandberg and Karl Henrik Johansson","Analysis and distributed control of periodic epidemic processes",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studies epidemic processes over discrete-time periodic
time-varying networks. We focus on the susceptible-infected-susceptible (SIS)
model that accounts for a (possibly) mutating virus. We say that an agent is in
the disease-free state if it is not infected by the virus. Our objective is to
devise a control strategy which ensures that all agents in a network
exponentially (resp. asymptotically) converge to the disease-free equilibrium
(DFE). Towards this end, we first provide a) sufficient conditions for
exponential (resp. asymptotic) convergence to the DFE; and b) a necessary and
sufficient condition for asymptotic convergence to the DFE. The sufficient
condition for global exponential stability (GES) (resp. global asymptotic
stability (GAS)) of the DFE is in terms of the joint spectral radius of a set
of suitably-defined matrices, whereas the necessary and sufficient condition
for GAS of the DFE involves the spectral radius of an appropriately-defined
product of matrices. Subsequently, we leverage the stability results in order
to design a distributed control strategy for eradicating the epidemic.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:10:53 GMT""},{""version"":""v2"",""created"":""Fri, 27 Mar 2020 10:00:07 GMT""},{""version"":""v3"",""created"":""Thu, 16 Apr 2020 23:28:49 GMT""},{""version"":""v4"",""created"":""Mon, 17 Aug 2020 12:53:36 GMT""},{""version"":""v5"",""created"":""Tue, 17 Nov 2020 12:39:48 GMT""}]","2020-11-18"
"1911.09176","Luowen Qian","Kai-Min Chung, Tai-Ning Liao, Luowen Qian","Lower Bounds for Function Inversion with Quantum Advice","ITC full version",,,,"quant-ph cs.CC cs.CR cs.DS","http://creativecommons.org/licenses/by/4.0/","  Function inversion is the problem that given a random function $f: [M] \to
[N]$, we want to find pre-image of any image $f^{-1}(y)$ in time $T$. In this
work, we revisit this problem under the preprocessing model where we can
compute some auxiliary information or advice of size $S$ that only depends on
$f$ but not on $y$. It is a well-studied problem in the classical settings,
however, it is not clear how quantum algorithms can solve this task any better
besides invoking Grover's algorithm, which does not leverage the power of
preprocessing.
  Nayebi et al. proved a lower bound $ST^2 \ge \tilde\Omega(N)$ for quantum
algorithms inverting permutations, however, they only consider algorithms with
classical advice. Hhan et al. subsequently extended this lower bound to fully
quantum algorithms for inverting permutations. In this work, we give the same
asymptotic lower bound to fully quantum algorithms for inverting functions for
fully quantum algorithms under the regime where $M = O(N)$.
  In order to prove these bounds, we generalize the notion of quantum random
access code, originally introduced by Ambainis et al., to the setting where we
are given a list of (not necessarily independent) random variables, and we wish
to compress them into a variable-length encoding such that we can retrieve a
random element just using the encoding with high probability. As our main
technical contribution, we give a nearly tight lower bound (for a wide
parameter range) for this generalized notion of quantum random access codes,
which may be of independent interest.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:13:26 GMT""},{""version"":""v2"",""created"":""Wed, 8 Apr 2020 05:23:57 GMT""}]","2020-04-09"
"1911.09178","Chengjiang Long","Ling Zhang, Chengjiang Long, Xiaolong Zhang, Chunxia Xiao","RIS-GAN: Explore Residual and Illumination with Generative Adversarial
  Networks for Shadow Removal","The paper was accepted to the Thirty-Fourth AAAI Conference on
  Artificial Intelligence (AAAI'2020)",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Residual images and illumination estimation have been proved very helpful in
image enhancement. In this paper, we propose a general and novel framework
RIS-GAN which explores residual and illumination with Generative Adversarial
Networks for shadow removal. Combined with the coarse shadow-removal image, the
estimated negative residual images and inverse illumination maps can be used to
generate indirect shadow-removal images to refine the coarse shadow-removal
result to the fine shadow-free image in a coarse-to-fine fashion. Three
discriminators are designed to distinguish whether the predicted negative
residual images, shadow-removal images, and the inverse illumination maps are
real or fake jointly compared with the corresponding ground-truth information.
To our best knowledge, we are the first one to explore residual and
illumination for shadow removal. We evaluate our proposed method on two
benchmark datasets, i.e., SRD and ISTD, and the extensive experiments
demonstrate that our proposed method achieves the superior performance to
state-of-the-arts, although we have no particular shadow-aware components
designed in our generators.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:29:48 GMT""},{""version"":""v2"",""created"":""Tue, 24 Dec 2019 19:05:50 GMT""}]","2019-12-30"
"1911.09179","Kaicheng Yang","Kai-Cheng Yang, Onur Varol, Pik-Mai Hui, Filippo Menczer","Scalable and Generalizable Social Bot Detection through Data Selection","AAAI 2020",,"10.1609/aaai.v34i01.5460",,"cs.CY cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Efficient and reliable social bot classification is crucial for detecting
information manipulation on social media. Despite rapid development,
state-of-the-art bot detection models still face generalization and scalability
challenges, which greatly limit their applications. In this paper we propose a
framework that uses minimal account metadata, enabling efficient analysis that
scales up to handle the full stream of public tweets of Twitter in real time.
To ensure model accuracy, we build a rich collection of labeled datasets for
training and validation. We deploy a strict validation system so that model
performance on unseen datasets is also optimized, in addition to traditional
cross-validation. We find that strategically selecting a subset of training
data yields better model accuracy and generalization than exhaustively training
on all available data. Thanks to the simplicity of the proposed model, its
logic can be interpreted to provide insights into social bot characteristics.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:31:36 GMT""}]","2020-06-05"
"1911.09180","Sravan Kumar Pulipati","Sravan Pulipati, Viduneth Ariyarathna, Udara De Silva, Najath Akram,
  Elias Alwan, Arjuna Madanayake, Soumyajit Mandal and Theodore S. Rappaport","A Direct- Conversion Digital Beamforming Array Receiver with 800 MHz
  Channel Bandwidth at 28 GHz using Xilinx RF SoC","5 pages",,"10.1109/COMCAS44984.2019.8958039",,"eess.SP","http://creativecommons.org/publicdomain/zero/1.0/","  This paper discusses early results associated with a fully-digital
direct-conversion array receiver at 28~GHz. The proposed receiver makes use of
commercial off-the-shelf (COTS) electronics, including the receiver chain. The
design consists of a custom 28~GHz patch antenna sub-array providing gain in
the elevation plane, with azimuthal plane beamforming provided by real-time
digital signal processing (DSP) algorithms running on a Xilinx Radio Frequency
System on Chip (RF SoC). The proposed array receiver employs element-wise
fully-digital array processing that supports ADC sample rates up to 2~GS/second
and up to 1~GHz of operating bandwidth per antenna. The RF mixed-signal data
conversion circuits and DSP algorithms operate on a single-chip RF SoC solution
installed on the Xilinx ZCU1275 prototyping platform.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:32:11 GMT""}]","2020-07-24"
"1911.09181","Ed Thiemann","E. M. B. Thiemann, F. G. Eparvier, D. Woodraska, P. C. Chamberlin, J.
  Machol, T. Eden, A. R. Jones, R. Meisner, S. Mueller, M. Snow, R. Viereck, T.
  N. Woods","The GOES-R EUVS Model for EUV Irradiance Variability","Accepted by Journal of Space Weather and Space Climate on 20 November
  2019",,,,"astro-ph.SR","http://creativecommons.org/licenses/by/4.0/","  The Geostationary Operational Environmental Satellite R (GOES-R) series of
four satellites are the next generation NOAA GOES satellites. Once on orbit and
commissioned, they are renamed GOES 16-19, making critical terrestrial and
space weather measurements through 2035. GOES 16 and 17 are currently on orbit,
having been launched in 2016 and 2018, respectively. The GOES-R satellites
include the EUV and X-ray Irradiance Sensors (EXIS) instrument suite, which
measures calibrated solar irradiance in 8 lines or bands between 25 and 285 nm
with the Extreme Ultraviolet Sensors (EUVS) instrument. EXIS also includes the
X-Ray Sensor (XRS) instrument, which measures solar soft X-ray irradiance at
the legacy GOES bands. The EUVS measurements are used as inputs to the EUVS
Model, a solar spectral irradiance model for space weather operations that
predicts irradiance in twenty-two 5 nm wide intervals from 5 nm to 115 nm, and
one 10 nm wide interval from 117 to 127 nm at 30 second cadence. Once fully
operational, NOAA will distribute the EUVS Model irradiance with 1 minute
latency as a primary space weather data product, ushering in a new era of rapid
dissemination and measurement continuity of EUV irradiance spectra. This paper
describes the EUVS Model algorithms, data sources, calibration methods and
associated uncertainties. Typical model (relative) uncertainties are less than
$\sim$5\% for variability at time-scales longer than 6 hours, and are
$\sim$25\% for solar flare induced variability. The absolute uncertainties,
originating from the instruments used to calibrate the EUVS Model, are
$\sim$10\%. Examples of model results are presented at both sub-daily and
multi-year timescales to demonstrate the model's capabilities and limitations.
Example solar flare irradiances are also modeled.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:32:36 GMT""}]","2019-11-22"
"1911.09182","Andrey Sarantsev Mr","Olga Rumyantseva, Andrey Sarantsev, Nikolay Strigul","Autoregressive Modeling of Forest Dynamics","17 pages, 14 figures. Keywords: Forest biomass dynamics; random walk
  model; AR(1) process; Bayesian analysis; patch dynamics. Published in MDPI
  Forests, open access",,,,"q-bio.QM q-bio.PE stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we employ autoregressive models developed in financial
engineering for modeling of forest dynamics. Autoregressive models have some
theoretical advantage over currently employed forest modeling approaches such
as Markov chains and individual-based models, as autoregressive models are both
analytically tractable and operate with continuous state space. We perform time
series statistical analysis of forest biomass and basal area recorded in Quebec
provincial forest inventories in 1970-2007. The geometric random walk model
adequately describes the yearly average dynamics. For individual patches, we
fit an AR(1) process capable to model negative feedback (mean-reversion).
Overall, the best fit also turns out to be geometric random walk, however, the
normality tests for residuals fail. In contrast, yearly means are adequately
described by normal fluctuations, with annual growth, on average, 2.3%, but
with standard deviation of order 40%. We use Bayesian analysis to account for
uneven number of observations per year. This work demonstrates that
autoregressive models represent a valuable tool for modeling of forest
dynamics. In particular, they quantify stochastic effects of environmental
disturbances and develop predictive empirical models on short and intermediate
temporal scales.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:32:40 GMT""}]","2019-11-22"
"1911.09183","Sergei Dyda","Sergei Dyda, Christopher S. Reynolds, Yan-Fei Jiang","Line Driven Acceleration using Multi-Frequency Radiation Hydrodynamics","10 pages, 6 figures",,,,"astro-ph.HE astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use multi-frequency radiation hydrodynamics (rad-HD) to simulate radiative
acceleration of a spherically symmetric stellar wind. We demonstrate the rad-HD
capabilities of Athena++ for a series of test problems with multi-group
radiation transfer. We then model the radiative transfer of a single spectral
line through a spherically symmetric, isothermal, ""CAK""-type line driven wind.
We find that correctly accounting for the Doppler shift of the absorbed
radiation, the force is well described by the analytic Sobolev line transfer in
the supersonic parts of the solution where the flow is stationary and the
effects of Abbott waves is negligible. Unlike in the analytic, steady-state
solution re-radiation is important and leads to non-trivial radiation energy
density and fluxes in the outer parts of the wind. We discuss a variety of
applications to these multi-group methods that are currently computationally
tractable.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:34:33 GMT""}]","2019-11-22"
"1911.09184","St\'ephane K\'ena-Cohen","Junjia Wang, Adrien Rousseau, Mei Yang, Tony Low, S\'ebastien
  Francoeur and St\'ephane K\'ena-Cohen","Mid-infrared polarized emission from black phosphorus light-emitting
  diodes",,,"10.1021/acs.nanolett.0c00581",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mid-infrared (MIR) spectral range is of immense use for civilian and
military applications. The large number of vibrational absorption bands in this
range can be used for gas sensing, process control and spectroscopy. In
addition, there exists transparency windows in the atmosphere such as that
between 3.6-3.8 $\mu$m, which are ideal for free-space optical communication,
range finding and thermal imaging. A number of different semiconductor
platforms have been used for MIR light-emission. This includes InAsSb/InAs
quantum wells, InSb/AlInSb, GaInAsSbP pentanary alloys, and intersubband
transitions in group III-V compounds. These approaches, however, are costly and
lack the potential for integration on silicon and silicon-on-insulator
platforms. In this respect, two-dimensional (2D) materials are particularly
attractive due to the ease with which they can be heterointegrated. Weak
interactions between neighbouring atomic layers in these materials allows for
deposition on arbitrary substrates and van der Waals heterostructures enable
the design of devices with targeted optoelectronic properties. In this Letter,
we demonstrate a light-emitting diode (LED) based on the 2D semiconductor black
phosphorus (BP). The device, which is composed of a BP/molybdenum disulfide
(MoS$_2$) heterojunction emits polarized light at $\lambda$ = 3.68 $\mu$m with
room-temperature internal and external quantum efficiencies (IQE and EQE) of
~1$\%$ and $\sim3\times10^{-2}\%$, respectively. The ability to tune the
bandgap, and consequently emission wavelength of BP, with layer number, strain
and electric field make it a particularly attractive platform for MIR emission.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:39:33 GMT""}]","2020-06-24"
"1911.09185","Mikhail Charnotskii","Mikhail Charnotskii","Four methods for generation of turbulent phase screens: comparison",,,,,"eess.IV physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new method for generation of the phase screen samples with
arbitrary spatial spectrum: Sparse Spectrum with uniform wave vectors (SU).
Similar to the known Sparse Spectrum (SS) technique, it uses trigonometric
series with random discrete support on the wave vector plane, but, unlike the
SS technique, the random wave vectors are uniformly distributed on the
individual segments of the wave vector plane partition. We compare the accuracy
and computational effectiveness of the SU technique with ubiquitous
subharmonics complemented DFT method, SS method, and recently published,
randomized DFT technique [J. Opt. Soc. Am. B 36, 3249 (2019)]. SSU and SS
algorithms generate unbiased samples, for screens with bounded phase variance,
and show the superior computational effectiveness for one megapixel and larger
screens.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:43:04 GMT""},{""version"":""v2"",""created"":""Mon, 2 Dec 2019 00:06:48 GMT""}]","2019-12-03"
"1911.09186","Karl Grosse-Erdmann","St\'ephane Charpentier, Karl Grosse-Erdmann, and Quentin Menet","Chaos and frequent hypercyclicity for weighted shifts",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Bayart and Ruzsa [Ergodic Theory Dynam. Systems 35 (2015)] have recently
shown that every frequently hypercyclic weighted shift on $\ell^p$ is chaotic.
This contrasts with an earlier result of Bayart and Grivaux [Proc. London Math.
Soc. (3) 94 (2007)] who constructed a non-chaotic frequently hypercyclic
weighted shift on $c_0$. We first generalize the Bayart-Ruzsa theorem to all
Banach sequence spaces in which the unit sequences are a boundedly complete
unconditional basis. We then study the relationship between frequent
hypercyclicity and chaos for weighted shifts on Fr\'echet sequence spaces, in
particular on K\""othe sequence spaces, and then on the special class of power
series spaces. We obtain, rather curiously, that every frequently hypercyclic
weighted shift on $H(\mathbb{D})$ is chaotic, while $H(\mathbb{C})$ admits a
non-chaotic frequently hypercyclic weighted shift.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:49:17 GMT""},{""version"":""v2"",""created"":""Thu, 28 Nov 2019 10:25:40 GMT""}]","2019-12-02"
"1911.09187","Viviana Casasola","Viviana Casasola, Simone Bianchi, Pieter De Vis, Laura Magrini, Edvige
  Corbelli, Christopher J. R. Clark, Jacopo Fritz, Angelos Nersesian, Sebastien
  Viaene, Maarten Baes, Letizia P. Cassara', Jon Davies, Ilse De Looze, Wouter
  Dobbels, Maud Galametz, Frederic Galliano, Anthony P. Jones, Suzanne C.
  Madden, Aleksandr V. Mosenkov, Ana Trcka, Emmanuel Xilouris","The ISM scaling relations in DustPedia late-type galaxies: A benchmark
  study for the Local Universe","Accepted for publication in A&A, 21 pages, 14 Figures, 7 Tables, 2
  Appendices (with 3 Tables). Published version, unchanged results with respect
  to the previously posted version","A&A 633, A100 (2020)","10.1051/0004-6361/201936665",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The purpose of this work is the characterization of the main scaling
relations between all the ISM components (dust, atomic/molecular/total gas),
gas-phase metallicity, and other galaxy properties, such as Mstar and galaxy
morphology, for late-type galaxies in the Local Universe. This study is
performed by extracting late-type galaxies from the entire DustPedia sample and
by exploiting the large and homogeneous dataset available thanks to the
DustPedia project. The sample consists of 436 galaxies with morphological stage
from T = 1 to 10, Mstar from 6 x 10^7 to 3 x 10^11 Msun, SFR from 6 x 10^(-4)
to 60 Msun/yr, and 12 + log(O/H) from 8 to 9.5. The scaling relations involving
the molecular gas are studied by assuming both a constant and a
metallicity-dependent XCO. The analysis has been performed by means of the
survival analysis technique. We confirm that the dust mass correlates very well
with the total gas mass, and find -- for the first time -- that the dust mass
correlates better with the atomic gas mass than the molecular one. We
characterize important mass ratios such as gas fraction, molecular-to-atomic
gas mass ratio, dust-to-total gas mass ratio (DGR), and dust-to-stellar mass
ratio. Only the assumption of a metallicity-dependent XCO reproduces the
expected decrease of the DGR with increasing morphological stage and decreasing
gas-phase metallicity, with a slope of about 1. DGR, gas-phase metallicity, and
the dust-to-stellar mass ratio are, for our galaxy sample, directly linked to
the galaxy morphology. The molecular-to-atomic gas mass ratio and the DGR show
a positive correlation for low molecular gas fractions, but for molecular gas
rich galaxies this trend breaks down. This trend has never been found
previously, to our knowledge. It provides new constraints for theoretical
models of galaxy evolution and a reference for high-redshift studies.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:49:32 GMT""},{""version"":""v2"",""created"":""Thu, 19 Dec 2019 19:37:27 GMT""}]","2020-01-22"
"1911.09188","Christopher George","Christopher A. George and Bradley M. West","Localized Compression: Applying Convolutional Neural Networks to
  Compressed Images","6 pages, 1 figure",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the challenge of applying existing convolutional neural network
(CNN) architectures to compressed images. Existing CNN architectures represent
images as a matrix of pixel intensities with a specified dimension; this
desired dimension is achieved by downgrading or cropping. Downgrading and
cropping are attractive in that the result is also an image; however, an
algorithm producing an alternative ""compressed"" representation could yield
better classification performance. This compression algorithm need not be
reversible, but must be compatible with the CNN's operations. This problem is
thus the counterpart of the well-studied problem of applying compressed CNNs to
uncompressed images, which has attracted great interest as CNNs are deployed to
size-, weight-, and power- (SWaP)-limited devices. We introduce Localized
Compression, a generalization of downgrading in which the original image is
divided into blocks and each block is compressed to a smaller size using either
sampling- or random-matrix-based techniques. By aligning the size of the
compressed blocks with the size of the CNN's convolutional region, localized
compression can be made compatible with any CNN architecture. Our experimental
results show that Localized Compression results in classification accuracy
approximately 1-2% higher than is achieved by downgrading to the equivalent
resolution.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:55:36 GMT""}]","2019-11-22"
"1911.09189","Alexander Alemi","Ravid Shwartz-Ziv, Alexander A. Alemi","Information in Infinite Ensembles of Infinitely-Wide Neural Networks","2nd Symposium on Advances in Approximate Bayesian Inference, 2019","Proceedings of The 2nd Symposium on Advances in Approximate
  Bayesian Inference, PMLR 118:1-17 2019",,,"cs.LG cs.IT math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this preliminary work, we study the generalization properties of infinite
ensembles of infinitely-wide neural networks. Amazingly, this model family
admits tractable calculations for many information-theoretic quantities. We
report analytical and empirical investigations in the search for signals that
correlate with generalization.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:56:11 GMT""},{""version"":""v2"",""created"":""Sat, 23 Nov 2019 23:17:55 GMT""},{""version"":""v3"",""created"":""Mon, 7 Nov 2022 17:52:19 GMT""}]","2022-11-08"
"1911.09190","Sarthak Parikh","Sarthak Parikh","A multipoint conformal block chain in $d$ dimensions","35 pages + appendices + references, several figures. Mathematica
  notebook containing the main result included as an ancillary file",,"10.1007/JHEP05(2020)120",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conformal blocks play a central role in CFTs as the basic, theory-independent
building blocks. However, only limited results are available concerning
multipoint blocks associated with the global conformal group. In this paper, we
systematically work out the $d$-dimensional $n$-point global conformal blocks
(for arbitrary $d$ and $n$) for external and exchanged scalar operators in the
so-called comb channel. We use kinematic aspects of holography and previously
worked out higher-point AdS propagator identities to first obtain the geodesic
diagram representation for the $(n+2)$-point block. Subsequently, upon taking a
particular double-OPE limit, we obtain an explicit power series expansion for
the $n$-point block expressed in terms of powers of conformal cross-ratios.
Interestingly, the expansion coefficient is written entirely in terms of
Pochhammer symbols and $(n-4)$ factors of the generalized hypergeometric
function ${}_3F_2$, for which we provide a holographic explanation. This
generalizes the results previously obtained in the literature for $n=4, 5$. We
verify the results explicitly in embedding space using conformal Casimir
equations.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:01:17 GMT""}]","2020-06-24"
"1911.09191","Yudier Pe\~na P\'erez","Yudier Pe\~na P\'erez, Ricardo Abreu Blaya, Mart\'in Patricio \'Arciga
  Alejandre, Juan Bory Reyes","Biquaternionic Reformulation of a Fractional Monochromatic Maxwell
  System",,"Advances in High Energy Physics. Volume 2020 (2020) 1-9","10.1155/2020/6894580",,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we propose a biquaternionic reformulation of a fractional
monochromatic Maxwell system. Additionally, some examples are given to
illustrate how the quaternionic fractional approach emerges in linear
hydrodynamic and elasticity.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:07:36 GMT""}]","2020-02-04"
"1911.09192","Yingchao Lu","Yingchao Lu, Hui Li, Kirk A. Flippo, Kwyntero Kelso, Andy Liao,
  Shengtai Li and Edison Liang","MPRAD: A Monte Carlo and ray-tracing code for the proton radiography in
  high-energy-density plasma experiments","11 pages, 4 figures",,"10.1063/1.5123392",,"physics.plasm-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Proton radiography is used in various high-energy-density (HED) plasma
experiments. In this paper, we describe a Monte Carlo and ray-tracing
simulation tool called MPRAD that can be used for modeling the deflection of
proton beams in arbitrary three dimensional electromagnetic fields, as well as
the diffusion of the proton beams by Coulomb scattering and stopping power. The
Coulomb scattering and stopping power models in cold matter and fully ionized
plasma are combined using interpolation. We discuss the application of MPRAD in
a few setups relevant to HED plasma experiments where the plasma density can
play a role in diffusing the proton beams and affecting the prediction and
interpretation of the proton images. It is shown how the diffusion due to
plasma density can affect the resolution and dynamical range of the proton
radiography.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:08:36 GMT""}]","2020-01-08"
"1911.09193","Nicol\'as Grandi","Laura Cruciani, Nicolas Grandi","Holographic metals at finite doping","12 pages, 5 figures",,,,"hep-th cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct the electron star solution to the model that was recently
proposed by Kiritsis and Li in order to describe a holographic superconductor
at finite doping. We do so by finding a map between the doped model and the
standard undoped one. In this way, we are able to describe the holographic
metallic phase at finite doping. In particular, we study the gauge field
fluctuations and find the dependence of the electric conductivity on the doping
parameter.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:09:50 GMT""}]","2019-11-22"
"1911.09194","Angela Fan","Angela Fan, Jack Urbanek, Pratik Ringshia, Emily Dinan, Emma Qian,
  Siddharth Karamcheti, Shrimai Prabhumoye, Douwe Kiela, Tim Rocktaschel,
  Arthur Szlam, Jason Weston","Generating Interactive Worlds with Text",,,,,"cs.AI cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Procedurally generating cohesive and interesting game environments is
challenging and time-consuming. In order for the relationships between the game
elements to be natural, common-sense has to be encoded into arrangement of the
elements. In this work, we investigate a machine learning approach for world
creation using content from the multi-player text adventure game environment
LIGHT. We introduce neural network based models to compositionally arrange
locations, characters, and objects into a coherent whole. In addition to
creating worlds based on existing elements, our models can generate new game
content. Humans can also leverage our models to interactively aid in
worldbuilding. We show that the game environments created with our approach are
cohesive, diverse, and preferred by human evaluators compared to other machine
learning based world construction algorithms.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:20:52 GMT""},{""version"":""v2"",""created"":""Wed, 4 Dec 2019 19:46:21 GMT""}]","2019-12-06"
"1911.09195","Alex Wang","Alex L. Wang and Fatma Kilinc-Karzan","On the tightness of SDP relaxations of QCQPs",,,,,"math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quadratically constrained quadratic programs (QCQPs) are a fundamental class
of optimization problems well-known to be NP-hard in general. In this paper we
study conditions under which the standard semidefinite program (SDP) relaxation
of a QCQP is tight. We begin by outlining a general framework for proving such
sufficient conditions. Then using this framework, we show that the SDP
relaxation is tight whenever the quadratic eigenvalue multiplicity, a parameter
capturing the amount of symmetry present in a given problem, is large enough.
We present similar sufficient conditions under which the projected epigraph of
the SDP gives the convex hull of the epigraph in the original QCQP. Our results
also imply new sufficient conditions for the tightness (as well as convex hull
exactness) of a second order cone program relaxation of simultaneously
diagonalizable QCQPs.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:21:18 GMT""},{""version"":""v2"",""created"":""Sat, 23 Nov 2019 03:28:55 GMT""},{""version"":""v3"",""created"":""Fri, 13 Nov 2020 19:19:01 GMT""}]","2020-11-17"
"1911.09196","Yingchao Lu","Yingchao Lu, Shengtai Li, Hui Li, Kirk A. Flippo, Dan Barnak, Andrew
  Birkel, Brandon Lahmann, Chikang Li, Alexander M. Rasmus, Kwyntero Kelso,
  Alex Zylstra, Edison Liang, Petros Tzeferacos, and Don Lamb","Modeling hydrodynamics, magnetic fields and synthetic radiographs for
  high-energy-density plasma flows in shock-shear targets","14 pages, 7 figures",,"10.1063/1.5126149",,"physics.plasm-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Three-dimensional FLASH radiation-magnetohydrodynamics (radiation-MHD)
modeling is carried out to study the hydrodynamics and magnetic fields in the
shock-shear derived platform. Simulations indicate that fields of tens of Tesla
can be generated via Biermann battery effect due to vortices and mix in the
counter-propagating shock-induced shear layer. Synthetic proton radiography
simulations using MPRAD and synthetic X-ray image simulations using SPECT3D are
carried out to predict the observable features in the diagnostics. Quantifying
the effects of magnetic fields in inertial confinement fusion (ICF) and
high-energy-density (HED) plasmas represents frontier research that has
far-reaching implications in basic and applied sciences.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:21:59 GMT""}]","2020-02-19"
"1911.09197","James Davis","James Davis","Do top conferences contain well cited papers or junk?",,,,,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to answer questions about top conference publication patterns,
citation data is collected and analyzed for several computer science
conferences, with focus on computer vision and graphics. Both top and second
tier conferences are included, and sampling occurred for two different 5 year
periods. Example questions include: Do top conferences contain well cited
papers or junk? (Yes) Are top conferences similarly cited? (No) Are second tier
conferences as good as first tier conferences? (Sometimes) Has something been
changing at CVPR? (Yes)
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:24:08 GMT""}]","2019-11-22"
"1911.09198","Dmitri K. Efetov","Petr Stepanov, Ipsita Das, Xiaobo Lu, Ali Fahimniya, Kenji Watanabe,
  Takashi Taniguchi, Frank H. L. Koppens, Johannes Lischner, Leonid Levitov and
  Dmitri K. Efetov","Untying the insulating and superconducting orders in magic-angle
  graphene",,,"10.1038/s41586-020-2459-6",,"cond-mat.supr-con cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The coexistence of superconducting and correlated insulating states in
magic-angle twisted bilayer graphene prompts fascinating questions about the
relationship of these orders. Independent control of the microscopic mechanisms
governing these phases could help uncover their individual roles and shed light
on their intricate interplay. Here we report on direct tuning of electronic
interactions in this system by changing its separation from a metallic
screening layer. We observe quenching of correlated insula-tors in devices with
screening layer separations that are smaller than a typical Wannier orbital
size of 15nm, and with the twist angles slightly deviating from the magic value
1.10 plus(minus) 0.05 degrees. Upon extinction of the insulating orders, the
vacated phase space is taken over by superconducting domes that feature
critical temperatures comparable to those in the devices with strong
insulators. In addition, we find that insulators at half-filling can reappear
in small out-of-plane magnetic fields of 0.4 T, giving rise to quantized Hall
states with a Chern number of 2. Our study suggests reexamination of the
often-assumed mother-child relation between the insulating and superconducting
phases in moire graphene, and illustrates a new approach to directly probe
microscopic mechanisms of superconductivity in strongly-correlated systems.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:31:51 GMT""},{""version"":""v2"",""created"":""Thu, 24 Dec 2020 12:59:30 GMT""}]","2020-12-25"
"1911.09199","Jingru Yi","Jingru Yi, Hui Tang, Pengxiang Wu, Bo Liu, Daniel J. Hoeppner,
  Dimitris N. Metaxas, Lianyi Han, Wei Fan","Object-Guided Instance Segmentation for Biological Images","accepted to AAAI2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Instance segmentation of biological images is essential for studying object
behaviors and properties. The challenges, such as clustering, occlusion, and
adhesion problems of the objects, make instance segmentation a non-trivial
task. Current box-free instance segmentation methods typically rely on local
pixel-level information. Due to a lack of global object view, these methods are
prone to over- or under-segmentation. On the contrary, the box-based instance
segmentation methods incorporate object detection into the segmentation,
performing better in identifying the individual instances. In this paper, we
propose a new box-based instance segmentation method. Mainly, we locate the
object bounding boxes from their center points. The object features are
subsequently reused in the segmentation branch as a guide to separate the
clustered instances within an RoI patch. Along with the instance normalization,
the model is able to recover the target object distribution and suppress the
distribution of neighboring attached objects. Consequently, the proposed model
performs excellently in segmenting the clustered objects while retaining the
target object details. The proposed method achieves state-of-the-art
performances on three biological datasets: cell nuclei, plant phenotyping
dataset, and neural cells.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:38:35 GMT""}]","2019-11-22"
"1911.09200","Wesley Tansey","Jackson H. Loper, Lihua Lei, William Fithian, Wesley Tansey","Smoothed Nested Testing on Directed Acyclic Graphs","Revised with genetic interaction maps application and new theory of
  PRDS",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of multiple hypothesis testing when there is a
logical nested structure to the hypotheses. When one hypothesis is nested
inside another, the outer hypothesis must be false if the inner hypothesis is
false. We model the nested structure as a directed acyclic graph, including
chain and tree graphs as special cases. Each node in the graph is a hypothesis
and rejecting a node requires also rejecting all of its ancestors. We propose a
general framework for adjusting node-level test statistics using the known
logical constraints. Within this framework, we study a smoothing procedure that
combines each node with all of its descendants to form a more powerful
statistic. We prove a broad class of smoothing strategies can be used with
existing selection procedures to control the familywise error rate, false
discovery exceedance rate, or false discovery rate, so long as the original
test statistics are independent under the null. When the null statistics are
not independent but are derived from positively-correlated normal observations,
we prove control for all three error rates when the smoothing method is
arithmetic averaging of the observations. Simulations and an application to a
real biology dataset demonstrate that smoothing leads to substantial power
gains.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:40:30 GMT""},{""version"":""v2"",""created"":""Mon, 15 Mar 2021 20:04:58 GMT""}]","2021-03-17"
"1911.09201","Danilo Dominguez Perez","Danilo Dominguez Perez and Wei Le","Testing Criteria for Mobile Apps Based on Callback Sequences",,,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  App quality has been shown to be the most important indicator of app
adoption. To assure quality, developers mainly use testing to find bugs in app
and apply structural and GUI test coverage criteria. However, mobile apps have
more behaviors than the GUI actions, e.g. an app also handles events from
sensors and executes long-running background tasks through Android API calls to
Services and AsyncTasks. Our studies found that there are important app
behaviors via callback interactions that should be covered in testing, as data
sharing between callbacks is common and is the cause of many existing bugs. We
design a family of test criteria based on callback sequences and use the
Callback Control Flow Automata (CCFA) to measure the coverage for testing. Our
experiments show that guiding by our criteria, testing can find more bugs and
trigger bugs faster than the state-of-the-art tools.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:52:35 GMT""}]","2019-11-22"
"1911.09202","Stanislaw Jadach","Stanis{\l}aw Jadach and Maciej Skrzypek","Theory challenges at future lepton colliders","submitted to Acta Physica Polonica B",,"10.5506/APhysPolB.50.1705","IFJPAN-IV-2019-16","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High energy, high luminosity, future lepton colliders, circular or linear,
may possibly give us hint about fundamental laws of Nature governing at very
short distances and very short time intervals, the same which have brought our
Universe to live. Currently considered projects are on one hand linear
electron-positron colliders, which offer higher energy and lower beam
intensities and on the other hand circular electron-positron colliders, limited
in energy but offering tremendous interaction rates. On the far future horizon,
muon circular colliders are the only viable projects which can explore $>10$TeV
teritory of the lepton colliders. Experiments in all these future colliders
will require theoretical calculations, mainly of Standard Model processes
(including QED), at the precision level one or even two orders better than
available today. After briefly characterization of theory puzzles in the
fundamental interactions we shall overview main challenges in the precision
calculations of the Standard Model effects, which have to be removed from data,
in order to reveal traces of new unexpected phenomena.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:53:31 GMT""}]","2020-02-19"
"1911.09203","Ajit C. Balram","Ajit C. Balram, J. K. Jain and Maissam Barkeshli","$\mathbb{Z}_{n}$ superconductivity of composite bosons and the $7/3$
  fractional quantum Hall effect","17 pages, 7 figures, published version","Phys. Rev. Research 2, 013349 (2020)","10.1103/PhysRevResearch.2.013349",,"cond-mat.str-el cond-mat.mes-hall hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The topological $p$-wave pairing of composite fermions, believed to be
responsible for the 5/2 fractional quantum Hall effect (FQHE), has generated
much exciting physics. Motivated by the parton theory of the FQHE, we consider
the possibility of a new kind of emergent ""superconductivity"" in the 1/3 FQHE,
which involves condensation of clusters of $n$ composite bosons. From a
microscopic perspective, the state is described by the $n\bar{n}111$ parton
wave function ${\cal P}_{\rm LLL} \Phi_n\Phi_n^*\Phi_1^3$, where $\Phi_n$ is
the wave function of the integer quantum Hall state with $n$ filled Landau
levels and ${\cal P}_{\rm LLL}$ is the lowest-Landau-level projection operator.
It represents a $\mathbb{Z}_{n}$ superconductor of composite bosons, because
the factor $\Phi_1^3\sim \prod_{j<k}(z_j-z_k)^3$, where $z_j=x_j-iy_j$ is the
coordinate of the $j$th electron, binds three vortices to electrons to convert
them into composite bosons, which then condense into the $\mathbb{Z}_{n}$
superconducting state $|\Phi_n|^2$. From a field theoretical perspective, this
state can be understood by starting with the usual Laughlin theory and gauging
a $\mathbb{Z}_n$ subgroup of the $U(1)$ charge conservation symmetry. We find
from detailed quantitative calculations that the $2\bar{2}111$ and
$3\bar{3}111$ states are at least as plausible as the Laughlin wave function
for the exact Coulomb ground state at filling $\nu=7/3$, suggesting that this
physics is possibly relevant for the 7/3 FQHE. The $\mathbb{Z}_{n}$ order leads
to several observable consequences, including quasiparticles with fractionally
quantized charges of magnitude $e/(3n)$ and the existence of multiple neutral
collective modes. It is interesting that the FQHE may be a promising venue for
the realization of exotic $\mathbb{Z}_{n}$ superconductivity.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:53:59 GMT""},{""version"":""v2"",""created"":""Sun, 22 Mar 2020 01:24:47 GMT""}]","2020-03-24"
"1911.09204","Akshay Gadi Patil","Jiongchao Jin, Akshay Gadi Patil, Zhang Xiong, Hao Zhang","DR-KFS: A Differentiable Visual Similarity Metric for 3D Shape
  Reconstruction",,,,,"cs.GR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a differential visual similarity metric to train deep neural
networks for 3D reconstruction, aimed at improving reconstruction quality. The
metric compares two 3D shapes by measuring distances between multi-view images
differentiably rendered from the shapes. Importantly, the image-space distance
is also differentiable and measures visual similarity, rather than pixel-wise
distortion. Specifically, the similarity is defined by mean-squared errors over
HardNet features computed from probabilistic keypoint maps of the compared
images. Our differential visual shape similarity metric can be easily plugged
into various 3D reconstruction networks, replacing their distortion-based
losses, such as Chamfer or Earth Mover distances, so as to optimize the network
weights to produce reconstructions with better structural fidelity and visual
quality. We demonstrate this both objectively, using well-known shape metrics
for retrieval and classification tasks that are independent from our new
metric, and subjectively through a perceptual study.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 22:57:51 GMT""},{""version"":""v2"",""created"":""Thu, 28 Nov 2019 21:34:27 GMT""},{""version"":""v3"",""created"":""Sat, 28 Mar 2020 20:29:58 GMT""},{""version"":""v4"",""created"":""Tue, 31 Mar 2020 18:16:52 GMT""}]","2020-04-02"
"1911.09205","Rafael A. M\'endez-S\'anchez","A.M. Mart\'inez-Arg\""uello, V. Dom\'inguez-Rocha, R.A.
  M\'endez-S\'anchez, M. Mart\'inez-Mares","Experimental validation of the theoretical prediction for the optical
  $S$ matrix","7pages, 5 figures","Phys. Rev. B 101, 214112 (2020)","10.1103/PhysRevB.101.214112",,"cond-mat.dis-nn cond-mat.mtrl-sci nlin.CD nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Scattering of waves is omnipresent in nature in systems with sizes varying
from $10^{-15}$ to $10^{25}$ m. Within this 40 orders of magnitude, in a great
number of systems, the scattering can be separated in an averaged response that
crosses rapidly the scattering region and a fluctuating delayed response. This
fact is the basis of the optical model; the averaged response, represented by
the optical matrix $\langle S\rangle$, is composed with the fluctuating part
that can be taken as a random matrix. Although the optical model was developed
more than 60 years ago, a theoretical prediction for the optical matrix was
obtained until very recently. The validity of such prediction is experimentally
demonstrated here. This is done studying the scattering of torsional waves in a
quasi-1D elastic system in which a locally periodic system is built; the
distribution of the scattering matrix is calculated completely free of
parameters. In contradistinction to all previous works, in microwaves and in
elasticity, in which the value of $\langle S\rangle$ is obtained from the
experiment, here the theoretical prediction is used to compare with the
experiment. Numerical simulations show that the theoretical value is still
valid when strong disorder is present. Several applications of the theoretical
expression for the optical matrix in other areas of physics are proposed.
Possible extensions of this work are also discussed.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:05:30 GMT""}]","2020-07-08"
"1911.09206","Volodymyr Gorkavenko","Volodymyr M. Gorkavenko","Search for hidden particles in intensity frontier experiment SHiP","8 pages, 3 figures. The work was presented at the conference ""New
  trends in high energy physics"", May 12-18, Odessa, Ukraine","Ukr. J. Phys. 2019. Vol. 64, No. 8689, p.689","10.15407/ujpe64.8.689",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the undeniable success of the Standard Model of particle physics (SM)
there are some phenomena (neutrino oscillations, baryon asymmetry of the
Universe, dark matter, etc.) that SM cannot explain. These phenomena indicate
that the SM has to be modified. Most likely there are new particles beyond the
SM. There are many experiments to search for new physics that can be divided
into two types: energy and intensity frontier. In experiments of the first
type, one tries to directly produce and detect new heavy particles. In
experiments of the second type, one tries to directly produce and detect new
light particles that feebly interact with SM particles. Future intensity
frontier SHiP experiment (\textbf{S}earch for \textbf{Hi}dden
\textbf{P}articles) at the CERN SPS is discussed. Its advantages and technical
characteristics are given.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:05:53 GMT""}]","2019-11-22"
"1911.09207","Margarida Carvalho","Margarida Carvalho and Andrea Lodi","Game theoretical analysis of Kidney Exchange Programs",,"European Journal of Operational Research, Volume 305, Issue 1,
  2023, Pages 373-385","10.1016/j.ejor.2022.05.027",,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of a kidney exchange program (KEP) is to maximize number of
transplants within a pool of incompatible patient-donor pairs by exchanging
donors. A KEP can be modelled as a maximum matching problem in a graph. A KEP
between incompatible patient-donor from pools of several hospitals, regions or
countries has the potential to increase the number of transplants. These
entities aim is to maximize the transplant benefit for their patients, which
can lead to strategic behaviours. Recently, this was formulated as a
non-cooperative two-player game and the game solutions (equilibria) were
characterized when the entities objective function is the number of their
patients receiving a kidney. In this paper, we generalize these results for
$N$-players and discuss the impact in the game solutions when transplant
information quality is introduced. Furthermore, the game theory model is
analyzed through computational experiments on instances generated through the
Canada Kidney Paired Donation Program. These experiments highlighting the
importance of using the concept of Nash equilibrium, as well as, the
anticipation of the necessity to further research for supporting police makers
once measures on transplant quality are available.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:06:49 GMT""},{""version"":""v2"",""created"":""Sun, 23 Feb 2020 18:04:24 GMT""},{""version"":""v3"",""created"":""Wed, 9 Dec 2020 00:38:36 GMT""}]","2023-04-25"
"1911.09208","Suyash Gupta","Suyash Gupta, Sajjad Rahnama, Mohammad Sadoghi","Permissioned Blockchain Through the Looking Glass: Architectural and
  Implementation Lessons Learned","To appear in the proceedings of 40th IEEE International Conference on
  Distributed Computing Systems",,,,"cs.DB cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Since the inception of Bitcoin, the distributed systems community has shown
interest in the design of efficient blockchain systems. However, initial
blockchain applications (like Bitcoin) attain very low throughput, which has
promoted the design of permissioned blockchain systems. These permissioned
blockchain systems employ classical Byzantine-Fault Tolerant (BFT) protocols to
reach consensus. However, existing permissioned blockchain systems still attain
low throughputs (of the order 10K txns/s). As a result, existing works blame
this low throughput on the associated BFT protocol and expend resources in
developing optimized protocols. We believe such blames only depict a one-sided
story. In specific, we raise a simple question: can a well-crafted system based
on a classical BFT protocol outperform a modern protocol? We show that
designing such a well-crafted system is possible and illustrate that even if
such a system employs a three-phase protocol, it can outperform another system
utilizing a single-phase protocol. This endeavor requires us to dissect a
permissioned blockchain system and highlight different factors that affect its
performance. Based on our insights, we present the design of our
enterprise-grade, high-throughput yielding permissioned blockchain system,
ResilientDB, that employs multi-threaded deep pipelines, to balance tasks at a
replica, and provides guidelines for future designs.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:07:53 GMT""},{""version"":""v2"",""created"":""Mon, 27 Apr 2020 04:42:18 GMT""}]","2020-04-28"
"1911.09209","Vasilios Mavroudis Mr","Vasilios Mavroudis","Bounded Temporal Fairness for FIFO Financial Markets",,,,,"q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Financial exchange operators cater to the needs of their users while
simultaneously ensuring compliance with the financial regulations. In this
work, we focus on the operators' commitment for fair treatment of all competing
participants. We first discuss unbounded temporal fairness and then investigate
its implementation and infrastructure requirements for exchanges. We find that
these requirements can be fully met only under ideal conditions and argue that
unbounded fairness in FIFO markets is unrealistic. To further support this
claim, we analyse several real-world incidents and show that subtle
implementation inefficiencies and technical optimizations suffice to give
unfair advantages to a minority of the participants. We finally introduce,
{\epsilon}-fairness, a bounded definition of temporal fairness and discuss how
it can be combined with non-continuous market designs to provide equal
participant treatment with minimum divergence from the existing market
operation.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:08:48 GMT""}]","2019-11-25"
"1911.09210","Charanjit Khosa","Charanjit K. Khosa (1), Lucy Mars (1), Joel Richards (1), Veronica
  Sanz (1, 2 and 3) ((1) Department of Physics and Astronomy, University of
  Sussex, Brighton, UK, (2) Alan Turing Institute, British Library, London, UK
  and (3) Instituto de F\'isica Corpuscular (IFIC), Universidad de
  Valencia-CSIC, Valencia, Spain)","Convolutional Neural Networks for Direct Detection of Dark Matter","17 figures, 4 tables (matches the published version)",,"10.1088/1361-6471/ab8e94",,"hep-ph astro-ph.IM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The XENON1T experiment uses a time projection chamber (TPC) with liquid Xenon
to search for Weakly Interacting Massive Particles (WIMPs), a proposed Dark
Matter particle, via direct detection. As this experiment relies on capturing
rare events, the focus is on achieving a high recall of WIMP events. Hence the
ability to distinguish between WIMP and the background is extremely important.
To accomplish this, we suggest using Convolutional Neural Networks (CNNs); a
Machine Learning procedure mainly used in image recognition tasks. To explore
this technique we use XENON collaboration open-source software to simulate the
TPC graphical output of Dark Matter signals and main backgrounds. A CNN turns
out to be a suitable tool for this purpose, as it can identify features in the
images that differentiate the two types of events without the need to
manipulate or remove data in order to focus on a particular region of the
detector. We find that the CNN can distinguish between the dominant background
events (ER) and 500 GeV WIMP events with a recall of 93.4\%, precision of
81.2\% and an accuracy of 87.2\%.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:10:45 GMT""},{""version"":""v2"",""created"":""Fri, 31 Jul 2020 08:55:02 GMT""}]","2020-08-03"
"1911.09211","Jonathan J. Fortney","Adam J. R. W. Smith, Y. Katherina Feng, Jonathan J. Fortney, Tyler D.
  Robinson, Mark S. Marley, Roxana E. Lupu, Nikole K. Lewis","Detecting and Characterizing Water Vapor in the Atmospheres of Earth
  Analogs through Observation of the 0.94 Micron Feature in Reflected Light","Accepted to AJ",,"10.3847/1538-3881/ab5a8a",,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The characterization of rocky, Earth-like planets is an important goal for
future large ground- and space-based telescopes. In support of developing an
efficient observational strategy, we have applied Bayesian statistical
inference to interpret the albedo spectrum of cloudy true-Earth analogs that
include a diverse spread in their atmospheric water vapor mixing ratios. We
focus on detecting water-bearing worlds by characterizing their atmospheric
water vapor content via the strong 0.94$\,\mu$m H$_2$O absorption feature, with
several observational configurations. Water vapor is an essential signpost when
assessing planetary habitability, and determining its presence is important in
vetting whether planets are suitable for hosting life. We find that R=140
spectroscopy of the absorption feature combined with a same-phase green optical
photometric point at $0.525-0.575\,\mu$m is capable of distinguishing worlds
with less than $0.1\times$ Earth-like water vapor levels from worlds with
$1\times$ Earth-like levels or greater at a signal-to-noise ratio of 5 or
better with $2\sigma$ confidence. This configuration can differentiate between
$0.01\times$ and $0.1\times$ Earth-like levels when the signal-to-noise ratio
is 10 or better at the same confidence. However, strong constraints on the
water vapor mixing ratio remained elusive with this configuration even at
signal-to-noise of 15. We find that adding the same-phase optical photometric
point does not significantly help characterize the H$_2$O mixing ratio, but
does enable an upper limit on atmospheric ozone levels. Finally, we find that a
0.94$\,\mu$m photometric point, instead of spectroscopy, combined with the
green-optical point, fails to produce meaningful information about atmospheric
water content.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:13:44 GMT""}]","2020-10-02"
"1911.09212","Vitali Kapovitch","Vitali Kapovitch","Mixed curvature almost flat manifolds",,"Geom. Topol. 25 (2021) 2017-2059","10.2140/gt.2021.25.2017",,"math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a mixed curvature analogue of Gromov's almost flat manifolds theorem
for upper sectional and lower Bakry-Emery Ricci curvature bounds.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:21:17 GMT""}]","2021-07-21"
"1911.09213","A. Bashir","L. X. Guti\'errez-Guerrero, Adnan Bashir, Marco A. Bedolla, E.
  Santopinto","Masses of Light and Heavy Mesons and Baryons: A Unified Picture","15 pages, 8 figures","Phys. Rev. D 100, 114032 (2019)","10.1103/PhysRevD.100.114032",,"nucl-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute masses of positive parity spin-$1/2$ and $3/2$ baryons composed of
$u$, $d$, $s$, $c$ and $b$ quarks in a quark-diaquark picture. The mathematical
foundation for this analysis is implemented through a symmetry-preserving
Schwinger-Dyson equations treatment of a vector-vector contact interaction,
which preserves key features of quantum chromodynamics, such as confinement,
chiral symmetry breaking and low energy Goldberger-Treiman relations. This
study requires a computation of diquark correlations containing these quarks
which in turn are readily inferred from solving the Bethe-Salpeter equations of
the corresponding mesons. Therefore, it serves as a unified formalism for a
multitude of mesons and baryons. It builds on our previous works on the study
of masses, decay constants and form factors of quarkonia and light mesons,
employing the same model. We use two sets of parameters, one which remains
exactly the same for both the light and heavy sector hadrons, and another where
the coupling strength is allowed to evolve according to the available mass
scales of quarks. Our results are in very good agreement with the existing
experimental data as well as predictions of other theoretical approaches
whenever comparison is possible.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:24:38 GMT""}]","2019-12-25"
"1911.09214","Jia-Jie Zhu","Jia-Jie Zhu, Georg Martius","Fast Non-Parametric Learning to Accelerate Mixed-Integer Programming for
  Online Hybrid Model Predictive Control",,,,,"math.OC cs.LG cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Today's fast linear algebra and numerical optimization tools have pushed the
frontier of model predictive control (MPC) forward, to the efficient control of
highly nonlinear and hybrid systems. The field of hybrid MPC has demonstrated
that exact optimal control law can be computed, e.g., by mixed-integer
programming (MIP) under piecewise-affine (PWA) system models. Despite the
elegant theory, online solving hybrid MPC is still out of reach for many
applications. We aim to speed up MIP by combining geometric insights from
hybrid MPC, a simple-yet-effective learning algorithm, and MIP warm start
techniques. Following a line of work in approximate explicit MPC, the proposed
learning-control algorithm, LNMS, gains computational advantage over MIP at
little cost and is straightforward for practitioners to implement.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:29:53 GMT""},{""version"":""v2"",""created"":""Thu, 7 May 2020 19:14:33 GMT""}]","2020-05-11"
"1911.09215","Saba Eskandarian","Saba Eskandarian, Henry Corrigan-Gibbs, Matei Zaharia, Dan Boneh","Express: Lowering the Cost of Metadata-hiding Communication with
  Cryptographic Privacy",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing systems for metadata-hiding messaging that provide cryptographic
privacy properties have either high communication costs, high computation
costs, or both. In this paper, we introduce Express, a metadata-hiding
communication system that significantly reduces both communication and
computation costs. Express is a two-server system that provides cryptographic
security against an arbitrary number of malicious clients and one malicious
server. In terms of communication, Express only incurs a constant-factor
overhead per message sent regardless of the number of users, whereas previous
cryptographically-secure systems Pung and Riposte had communication costs
proportional to roughly the square root of the number of users. In terms of
computation, Express only uses symmetric key cryptographic primitives and makes
both practical and asymptotic improvements on protocols employed by prior work.
These improvements enable Express to increase message throughput, reduce
latency, and consume over 100x less bandwidth than Pung and Riposte, dropping
the end to end cost of running a realistic whistleblowing application by 6x.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:29:55 GMT""},{""version"":""v2"",""created"":""Thu, 24 Sep 2020 15:44:05 GMT""}]","2020-09-25"
"1911.09216","David Lowry-Duda","Thomas A. Hulse, Chan Ieong Kuan, David Lowry-Duda, Alexander Walker","Triple Correlation Sums of Coefficients of Cusp Forms","17 pages (now with consistent author naming)",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We produce nontrivial asymptotic estimates for shifted sums of the form $\sum
a(h)b(m)c(2m-h)$, in which $a(n),b(n),c(n)$ are un-normalized Fourier
coefficients of holomorphic cusp forms. These results are unconditional, but we
demonstrate how to strengthen them under the Riemann Hypothesis. As an
application, we show that there are infinitely many three term arithmetic
progressions $n-h, n, n+h$ such that $a(n-h)a(n)a(n+h) \neq 0$.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:30:12 GMT""},{""version"":""v2"",""created"":""Tue, 18 Aug 2020 14:20:49 GMT""}]","2020-08-19"
"1911.09217","Mat\'ias Mendieta","Christopher Neff, Mat\'ias Mendieta, Shrey Mohan, Mohammadreza
  Baharani, Samuel Rogers, Hamed Tabkhi","REVAMP$^2$T: Real-time Edge Video Analytics for Multi-camera
  Privacy-aware Pedestrian Tracking","Published as an article paper in IEEE Internet of Things Journal:
  Special Issue on Privacy and Security in Distributed Edge Computing and
  Evolving IoT",,"10.1109/JIOT.2019.2954804",,"cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article presents REVAMP$^2$T, Real-time Edge Video Analytics for
Multi-camera Privacy-aware Pedestrian Tracking, as an integrated end-to-end IoT
system for privacy-built-in decentralized situational awareness. REVAMP$^2$T
presents novel algorithmic and system constructs to push deep learning and
video analytics next to IoT devices (i.e. video cameras). On the algorithm
side, REVAMP$^2$T proposes a unified integrated computer vision pipeline for
detection, re-identification, and tracking across multiple cameras without the
need for storing the streaming data. At the same time, it avoids facial
recognition, and tracks and re-identifies pedestrians based on their key
features at runtime. On the IoT system side, REVAMP$^2$T provides
infrastructure to maximize hardware utilization on the edge, orchestrates
global communications, and provides system-wide re-identification, without the
use of personally identifiable information, for a distributed IoT network. For
the results and evaluation, this article also proposes a new metric,
Accuracy$\cdot$Efficiency (\AE), for holistic evaluation of IoT systems for
real-time video analytics based on accuracy, performance, and power efficiency.
REVAMP$^2$T outperforms current state-of-the-art by as much as thirteen-fold
\AE~improvement.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:34:20 GMT""},{""version"":""v2"",""created"":""Mon, 25 Nov 2019 16:40:40 GMT""}]","2019-11-26"
"1911.09218","Yifeng Gao","Yifeng Gao and Jessica Lin","Discovering Subdimensional Motifs of Different Lengths in Large-Scale
  Multivariate Time Series","Accepted by ICDM 2019",,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Detecting repeating patterns of different lengths in time series, also called
variable-length motifs, has received a great amount of attention by researchers
and practitioners. Despite the significant progress that has been made in
recent single dimensional variable-length motif discovery work, detecting
variable-length \textit{subdimensional motifs}---patterns that are
simultaneously occurring only in a subset of dimensions in multivariate time
series---remains a difficult task. The main challenge is scalability. On the
one hand, the brute-force enumeration solution, which searches for motifs of
all possible lengths, is very time consuming even in single dimensional time
series. On the other hand, previous work show that index-based fixed-length
approximate motif discovery algorithms such as random projection are not
suitable for detecting variable-length motifs due to memory requirement. In
this paper, we introduce an approximate variable-length subdimensional motif
discovery algorithm called \textbf{C}ollaborative \textbf{HI}erarchy based
\textbf{M}otif \textbf{E}numeration (CHIME) to efficiently detect
variable-length subdimensional motifs given a minimum motif length in
large-scale multivariate time series. We show that the memory cost of the
approach is significantly smaller than that of random projection. Moreover, the
speed of the proposed algorithm is significantly faster than that of the
state-of-the-art algorithms. We demonstrate that CHIME can efficiently detect
meaningful variable-length subdimensional motifs in large real world
multivariate time series datasets.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:35:15 GMT""}]","2019-11-22"
"1911.09219","Matthew Guzdial","Andrew Hoyt, Matthew Guzdial, Yalini Kumar, Gillian Smith, and Mark O.
  Riedl","Integrating Automated Play in Level Co-Creation","2 pages, 2 figures, AIIDE Workshop on Experimental AI in Games","AIIDE Workshop on Experimental AI in Games 2019",,,"cs.AI cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In level co-creation an AI and human work together to create a video game
level. One open challenge in level co-creation is how to empower human users to
ensure particular qualities of the final level, such as challenge. There has
been significant prior research into automated pathing and automated
playtesting for video game levels, but not in how to incorporate these into
tools. In this demonstration we present an improvement of the Morai Maker
mixed-initiative level editor for Super Mario Bros. that includes automated
pathing and challenge approximation features.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:36:42 GMT""}]","2019-11-22"
"1911.09220","Will Pazner","Robert Anderson, Julian Andrej, Andrew Barker, Jamie Bramwell,
  Jean-Sylvain Camier, Jakub Cerveny, Veselin Dobrev, Yohann Dudouit, Aaron
  Fisher, Tzanio Kolev, Will Pazner, Mark Stowell, Vladimir Tomov, Johann Dahm,
  David Medina, Stefano Zampini","MFEM: a modular finite element methods library","36 pages, 21 figures",,"10.1016/j.camwa.2020.06.009",,"cs.MS cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  MFEM is an open-source, lightweight, flexible and scalable C++ library for
modular finite element methods that features arbitrary high-order finite
element meshes and spaces, support for a wide variety of discretization
approaches and emphasis on usability, portability, and high-performance
computing efficiency. MFEM's goal is to provide application scientists with
access to cutting-edge algorithms for high-order finite element meshing,
discretizations and linear solvers, while enabling researchers to quickly and
easily develop and test new algorithms in very general, fully unstructured,
high-order, parallel and GPU-accelerated settings. In this paper we describe
the underlying algorithms and finite element abstractions provided by MFEM,
discuss the software implementation, and illustrate various applications of the
library.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:49:09 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jul 2020 18:16:51 GMT""}]","2020-07-15"
"1911.09221","Hugo Rosado","Lehilton Lelis Chaves Pedrosa, Hugo Kooki Kasuya Rosado","A 2-approximation for the $k$-prize-collecting Steiner tree problem",,,,,"cs.CC cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the $k$-prize-collecting Steiner tree problem. An instance is
composed of an integer $k$ and a graph $G$ with costs on edges and penalties on
vertices. The objective is to find a tree spanning at least $k$ vertices which
minimizes the cost of the edges in the tree plus the penalties of vertices not
in the tree. This is one of the most fundamental network design problems and is
a common generalization of the prize-collecting Steiner tree and the
$k$-minimum spanning tree problems. Our main result is a 2-approximation
algorithm, which improves on the currently best known approximation factor of
3.96 and has a faster running time. The algorithm builds on a modification of
the primal-dual framework of Goemans and Williamson, and reveals interesting
properties that can be applied to other similar problems.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:52:03 GMT""}]","2019-11-22"
"1911.09222","Saba Eskandarian","Saba Eskandarian, Mihai Christodorescu, Payman Mohassel","Privacy-Preserving Payment Splitting",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Widely used payment splitting apps allow members of a group to keep track of
debts between members by sending charges for expenses paid by one member on
behalf of others. While offering a great deal of convenience, these apps gain
access to sensitive data on users' financial transactions. In this paper, we
present a payment splitting app that hides all transaction data within a group
from the service provider, provides privacy protections between users in a
group, and provides integrity against malicious users or even a malicious
server.
  The core protocol proceeds in a series of rounds in which users either submit
real data or cover traffic, and the server blindly updates balances, informs
users of charges, and computes integrity checks on user-submitted data. Our
protocol requires no cryptographic operations on the server, and after a
group's initial setup, the only cryptographic tool users need is AES.
  We implement the payment splitting protocol as an Android app and the
accompanying server. We find that, for realistic group sizes, it requires fewer
than 50 milliseconds per round of computation on a user's phone and the server
requires fewer than 300 microseconds per round for each group, meaning that our
protocol enjoys excellent performance and scalability properties.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:53:23 GMT""}]","2019-11-22"
"1911.09223","Hafiz Rahman Dr.","E. Ruskov, and P. Ney, and H. U. Rahman","The staged Z-pinch as a potential high-gain fusion energy source:
  Rebuttal to I. R. Lindemuth et al",,,,,"physics.plasm-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Magneto-Inertial Fusion Technology Inc. has been working on a Z-pinch concept
where a high atomic number liner is compressing a fusion fuel
(deuterium-deuterium, or deuterium-tritium) target. The viability of this so
called Staged Z-pinch (SZP) concept as a potential high-gain fusion energy
source has been questioned in a recent publication by Lindemuth et al [1]. The
authors attempted to reproduce previously published MACH2 simulation results
[2-4] for Z-machine parameters using three different MHD codes: Hydra, Raven
and MHRDR. Their conclusion was that ""there is no conceivable modification of
the parameters that would lead to high-gain fusion conditions using these other
codes"". Although they used well established MHD codes to check the SZP concept,
and correct input current profiles, we show that their Lagrangian formalism was
likely not treating the vacuum/liner boundary properly. Proper modeling using
Lagrangian, Eulerian or Adaptive Lagrangian-Eulerian (ALE) formalism indeed
confirms that fusion energy production > 1 MJ can be expected without alpha
heating, and significantly higher if alpha heating is included. It is shown
that magnetosonic shocks play an important role in preheating the target plasma
and in piling liner mass at the liner/target interface, which substantially
increases the ram pressure just before the pinch stagnation time.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 00:03:52 GMT""}]","2019-11-22"
"1911.09224","Yuqian Zhou","Kuangxiao Gu, Yuqian Zhou, Thomas Huang","FLNet: Landmark Driven Fetching and Learning Network for Faithful
  Talking Facial Animation Synthesis","Accepted by AAAI 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Talking face synthesis has been widely studied in either appearance-based or
warping-based methods. Previous works mostly utilize single face image as a
source, and generate novel facial animations by merging other person's facial
features. However, some facial regions like eyes or teeth, which may be hidden
in the source image, can not be synthesized faithfully and stably. In this
paper, We present a landmark driven two-stream network to generate faithful
talking facial animation, in which more facial details are created, preserved
and transferred from multiple source images instead of a single one.
Specifically, we propose a network consisting of a learning and fetching
stream. The fetching sub-net directly learns to attentively warp and merge
facial regions from five source images of distinctive landmarks, while the
learning pipeline renders facial organs from the training face space to
compensate. Compared to baseline algorithms, extensive experiments demonstrate
that the proposed method achieves a higher performance both quantitatively and
qualitatively. Codes are at https://github.com/kgu3/FLNet_AAAI2020.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 00:07:43 GMT""}]","2019-11-22"
"1911.09225","Natasha Dobrinen","Natasha Dobrinen and Sonia Navarro Flores","Ramsey degrees of ultrafilters, pseudointersection numbers, and the
  tools of topological Ramsey spaces","25 pages",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper investigates properties of $\sigma$-closed forcings which generate
ultrafilters satisfying weak partition relations. The Ramsey degree of an
ultrafilter $\mathcal{U}$ for $n$-tuples, denoted $t(\mathcal{U},n)$, is the
smallest number $t$ such that given any $l\ge 2$ and coloring
$c:[\omega]^n\rightarrow l$, there is a member $X\in\mathcal{U}$ such that the
restriction of $c$ to $[X]^n$ has no more than $t$ colors. Many well-known
$\sigma$-closed forcings are known to generate ultrafilters with finite Ramsey
degrees, but finding the precise degrees can sometimes prove elusive or quite
involved, at best. In this paper, we utilize methods of topological Ramsey
spaces to calculate Ramsey degrees of several classes of ultrafilters generated
by $\sigma$-closed forcings. These include a hierarchy of forcings due to
Laflamme which generate weakly Ramsey and weaker rapid p-points, forcings of
Baumgartner and Taylor and of Blass and generalizations, and the collection of
non-p-points generated by the forcings
$\mathcal{P}(\omega^k)/\mathrm{Fin}^{\otimes k}$. We provide a general approach
to calculating the Ramsey degrees of these ultrafilters, obtaining new results
as well as streamlined proofs of previously known results. In the second half
of the paper, we calculate pseudointersection and tower numbers for these
$\sigma$-closed forcings and their relationships with the classical
pseudointersection number $\mathfrak{p}$.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 00:22:32 GMT""}]","2019-11-22"
"1911.09226","Anna Karlsson","Anna Karlsson","A paradox regarding monogamy of entanglement","19 pages. v2: added \S 1.2, \S 4 shortened, appendices edited",,,,"hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In density matrix theory, entanglement is monogamous. However, we show that
qubits can be arbitrarily entangled in a different, recently constructed model
of qubit entanglement [arXiv:1907.11805]. We illustrate the differences between
these two models, analyse how the density matrix property of monogamy of
entanglement originates in assumptions of classical correlations in the
construction of that model, and explain the counterexample to monogamy in the
alternative model. We conclude that monogamy of entanglement is a theoretical
assumption, not necessarily a physical property, and discuss how contemporary
theory relies on that assumption. The properties of entanglement entropy are
very different in the two models; a priori, the entropy in the alternative
model is classical.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 00:30:26 GMT""},{""version"":""v2"",""created"":""Fri, 7 Feb 2020 15:55:48 GMT""}]","2020-02-10"
"1911.09227","Behrooz Semnani","Behrooz Semnani, Jeremy Flannery, Rubayet Al Maruf, Michal Bajcsy","Spin-Preserving Chiral Photonic Crystal Mirror",,,"10.1038/s41377-020-0256-5",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Chirality refers to a geometric phenomenon in which objects are not
superimposable on their mirror image. Structures made of nano-scale chiral
elements can display chiroptical effects, such as dichroism for left- and
right- handed circularly polarized light, which makes them of high interest for
applications ranging from quantum information processing and quantum optics to
circular dichroism spectroscopy and molecular recognition. At the same time,
strong effects have been challenging to achieve even in synthetic optical media
and chiroptical effects for light with normal incidence has been speculated to
be prohibited in lossless, thin, quasi-two-dimensional structures. Here, we
report on our experimental realization of a giant chiroptical effect in a thin
monolithic photonic crystal mirror. Unlike conventional mirrors, our structure
selectively reflects only one spin state of light, while preserving its
handedness, with a near unity level of circular dichroism. The operational
principle of the photonic-crystal mirror relies on Guided Mode Resonance (GMR)
with simultaneous excitation of leaky TE and TM Bloch modes in the photonic
crystal slab. Such modes are not reliant on the suppression of their radiative
losses through the long-range destructive interference and even small areas of
the photonic-crystal exhibit robust circular dichroism. Despite its simplicity,
the mirror strongly surpasses the performance of earlier reported structures
and, contrary to a prevailed notion, demonstrates that near unity reflectivity
contrast for the opposite helicities is achievable in a quasi-two-dimensional
structure.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 00:38:57 GMT""}]","2020-02-25"
"1911.09228","Weitang Liu","Weitang Liu, Lifeng Wei, James Sharpnack, John D. Owens","Unsupervised Object Segmentation with Explicit Localization Module",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel architecture that iteratively discovers and
segments out the objects of a scene based on the image reconstruction quality.
Different from other approaches, our model uses an explicit localization module
that localizes objects of the scene based on the pixel-level reconstruction
qualities at each iteration, where simpler objects tend to be reconstructed
better at earlier iterations and thus are segmented out first. We show that our
localization module improves the quality of the segmentation, especially on a
challenging background.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 00:50:48 GMT""}]","2019-11-22"
"1911.09229","Guofu Yu","Bo-Jian Shen, Guo-Fu Yu","Matrix integral solutions to the related Leznov lattice equations",,,,,"nlin.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Matrix integrals used in random matrix theory for the study of eigenvalues of
matrix ensembles have been shown to provide $ \tau $-functions for several
hierarchies of integrable equations. In this paper, we construct the matrix
integral solutions to the Leznov lattice equation, semi-discrete and
full-discrete version and the Pfaffianized Leznov lattice systems,
respectively. We demonstrate that the partition function of Jacobi unitary
ensemble is a solution to the semi-discrete Leznov lattice and the partition
function of Jacobi orthogonal/symplectic ensemble gives solutions of the
Pfaffianized Leznov lattice.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 00:52:37 GMT""}]","2019-11-22"
"1911.09230","Atsushi Masumori","Atsushi Masumori, Lana Sinapayen, Takashi Ikegami","Predictive Coding as Stimulus Avoidance in Spiking Neural Networks",,,,,"cs.NE q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predictive coding can be regarded as a function which reduces the error
between an input signal and a top-down prediction. If reducing the error is
equivalent to reducing the influence of stimuli from the environment,
predictive coding can be regarded as stimulation avoidance by prediction. Our
previous studies showed that action and selection for stimulation avoidance
emerge in spiking neural networks through spike-timing dependent plasticity
(STDP). In this study, we demonstrate that spiking neural networks with random
structure spontaneously learn to predict temporal sequences of stimuli based
solely on STDP.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 00:54:55 GMT""}]","2019-11-22"
"1911.09231","Stan Birchfield","Timothy E. Lee, Jonathan Tremblay, Thang To, Jia Cheng, Terry Mosier,
  Oliver Kroemer, Dieter Fox, Stan Birchfield","Camera-to-Robot Pose Estimation from a Single Image","ICRA 2020. Project page is at
  https://research.nvidia.com/publication/2020-03_DREAM",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an approach for estimating the pose of an external camera with
respect to a robot using a single RGB image of the robot. The image is
processed by a deep neural network to detect 2D projections of keypoints (such
as joints) associated with the robot. The network is trained entirely on
simulated data using domain randomization to bridge the reality gap.
Perspective-n-point (PnP) is then used to recover the camera extrinsics,
assuming that the camera intrinsics and joint configuration of the robot
manipulator are known. Unlike classic hand-eye calibration systems, our method
does not require an off-line calibration step. Rather, it is capable of
computing the camera extrinsics from a single frame, thus opening the
possibility of on-line calibration. We show experimental results for three
different robots and camera sensors, demonstrating that our approach is able to
achieve accuracy with a single frame that is comparable to that of classic
off-line hand-eye calibration using multiple frames. With additional frames
from a static pose, accuracy improves even further. Code, datasets, and
pretrained models for three widely-used robot manipulators are made available.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:06:19 GMT""},{""version"":""v2"",""created"":""Thu, 5 Dec 2019 02:22:10 GMT""},{""version"":""v3"",""created"":""Thu, 5 Mar 2020 03:30:33 GMT""},{""version"":""v4"",""created"":""Thu, 23 Apr 2020 19:22:25 GMT""}]","2020-04-27"
"1911.09232","Juan Diego S\'anchez Torres Dr.","J. E. Carvajal-Rubio and J. D. S\'anchez-Torres and M. Defoort and A.
  G. Loukianov","On the Discretization of Robust Exact Filtering Differentiators",,,,,"eess.SY cs.SY math.OC","http://creativecommons.org/licenses/by-nc-sa/4.0/","  This paper deals with the design of discrete-time algorithms for the robust
filtering differentiator. Two discrete-time realizations of the filtering
differentiator are introduced. The first one, which is based on an exact
discretization of the continuous differentiator, is an explicit one, while the
second one is an implicit algorithm which enables to remove the numerical
chattering phenomenon and to preserve the estimation accuracy properties. Some
numerical comparisons between the proposed scheme and an existing discrete-time
algorithm show the interest of the proposed implicit discrete-time realization
of the filtering differentiator, especially when large sampling periods are
considered.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:12:08 GMT""}]","2019-11-22"
"1911.09233","Jonathan Tremblay","Visak Kumar, Tucker Hermans, Dieter Fox, Stan Birchfield, Jonathan
  Tremblay","Contextual Reinforcement Learning of Visuo-tactile Multi-fingered
  Grasping Policies",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Using simulation to train robot manipulation policies holds the promise of an
almost unlimited amount of training data, generated safely out of harm's way.
One of the key challenges of using simulation, to date, has been to bridge the
reality gap, so that policies trained in simulation can be deployed in the real
world. We explore the reality gap in the context of learning a contextual
policy for multi-fingered robotic grasping. We propose a Grasping Objects
Approach for Tactile (GOAT) robotic hands, learning to overcome the reality gap
problem. In our approach we use human hand motion demonstration to initialize
and reduce the search space for learning. We contextualize our policy with the
bounding cuboid dimensions of the object of interest, which allows the policy
to work on a more flexible representation than directly using an image or point
cloud. Leveraging fingertip touch sensors in the hand allows the policy to
overcome the reduction in geometric information introduced by the coarse
bounding box, as well as pose estimation uncertainty. We show our learned
policy successfully runs on a real robot without any fine tuning, thus bridging
the reality gap.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:12:49 GMT""},{""version"":""v2"",""created"":""Sun, 24 Nov 2019 06:00:53 GMT""}]","2019-11-26"
"1911.09234","Ugo Rosolia","Ugo Rosolia, Xiaojing Zhang, and Francesco Borrelli","Robust Learning Model Predictive Control for Linear Systems Performing
  Iterative Tasks",,,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A robust Learning Model Predictive Controller (LMPC) for uncertain systems
performing iterative tasks is presented. At each iteration of the control task
the closed-loop state, input and cost are stored and used in the controller
design. This paper first illustrates how to construct robust invariant sets and
safe control policies exploiting historical data. Then, we propose an iterative
LMPC design procedure, where data generated by a robust controller at iteration
$j$ are used to design a robust LMPC at the next $j+1$ iteration. We show that
this procedure allows us to iteratively enlarge the domain of the control
policy and it guarantees recursive constraints satisfaction, input to state
stability and performance bounds for the certainty equivalent closed-loop
system. The use of an adaptive prediction horizon is the key element of the
proposed design. The effectiveness of the proposed control scheme is
illustrated on a linear system subject to bounded additive disturbance.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:23:12 GMT""},{""version"":""v2"",""created"":""Wed, 24 Jun 2020 05:30:52 GMT""},{""version"":""v3"",""created"":""Thu, 20 May 2021 06:03:44 GMT""},{""version"":""v4"",""created"":""Fri, 21 May 2021 20:34:15 GMT""},{""version"":""v5"",""created"":""Fri, 2 Jul 2021 21:57:14 GMT""}]","2021-07-06"
"1911.09235","Sarvenaz Memarzadeh","Sarvenaz Memarzadeh, Jongbum Kim, Yigit Aytac, Thomas E. Murphy,
  Jeremy N. Munday","Surface Plasmon Assisted Control of Hot-Electron Relaxation Time",,,,,"physics.optics physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Surface plasmon mediated hot carrier generation is widely utilized for the
manipulation of the electron-photon interactions in many types of
optoelectronic devices including solar cells, photodiodes, and optical
modulators. A diversity of plasmonic systems such as nanoparticles, resonators,
and waveguides have been introduced to enhance hot carrier generation; however,
the impact of the propagating surface plasmons on hot carrier lifetime has not
been clearly demonstrated. Here, we systematically study the hot carrier
relaxation in thin film gold (Au) samples under surface plasmon coupling with
the Kretschmann configuration. We observe that the locally confined electric
field at the surface of the metal significantly affects the hot carrier
distribution and electron temperature, which results in a slowing of the hot
electrons relaxation time, regardless of the average value of the absorbed
power in the Au thin film. This result could be extended to other plasmonic
nanostructures, enabling the control of hot carrier lifetimes throughout the
optical frequency range.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:29:09 GMT""}]","2019-11-22"
"1911.09236","Nobuhiro Okabe","Nobuhiro Okabe, Simon Dicker, Dominique Eckert, Tony Mroczkowski,
  Fabio Gastaldello, Yen-Ting Lin, Mark Devlin, Charles E. Romero, Mark
  Birkinshaw, Craig Sarazin, Cathy Horellou, Tetsu Kitayama, Keiichi Umetsu,
  Mauro Sereno, Brian S. Mason, John A. ZuHone, Ayaka Honda, Hiroki Akamatsu,
  I-Non Chiu, Kotaro Kohno, Kai-Yang Lin, Elinor Medezinski, Satoshi Miyazaki,
  Ikuyuki Mitsuishi, Atsushi J. Nishizawa, Masamune Oguri, Naomi Ota, Florian
  Pacaud, Marguerite Pierre, Jonathan Sievers, Vernesa Smolcic, Sara
  Stanchfield, Keigo Tanaka, Ryoichi Yamamoto, Chong Yang, and Atsushi Yoshida","Active gas features in three HSC-SSP CAMIRA clusters revealed by high
  angular resolution analysis of MUSTANG-2 SZE and XXL X-ray observations","36 pages, 25 figures, 5 tables; accepted for the publication in MNRAS",,"10.1093/mnras/staa2330",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present results from simultaneous modeling of high angular resolution
GBT/MUSTANG-2 90 GHz Sunyaev-Zel'dovich effect (SZE) measurements and XMM-XXL
X-ray images of three rich galaxy clusters selected from the HSC-SSP Survey.
The combination of high angular resolution SZE and X-ray imaging enables a
spatially resolved multi-component analysis, which is crucial to understand
complex distributions of cluster gas properties. The targeted clusters have
similar optical richnesses and redshifts, but exhibit different dynamical
states in their member galaxy distributions: a single-peaked cluster, a
double-peaked cluster, and a cluster belonging to a supercluster. A large-scale
residual pattern in both regular Compton-parameter $y$ and X-ray surface
brightness distributions is found in the single-peaked cluster, indicating a
sloshing mode. The double-peaked cluster shows an X-ray remnant cool core
between two SZE peaks associated with galaxy concentrations. The temperatures
of the two peaks reach $\sim20-30$ keV in contrast to the cool core component
of $\sim2$ keV, indicating a violent merger. The main SZE signal for the
supercluster is elongated along a direction perpendicular to the major axis of
the X-ray core, suggesting a minor merger before core passage. The $S_X$ and
$y$ distributions are thus perturbed at some level, regardless of the optical
properties. We find that the integrated Compton $y$ parameter and the
temperature for the major merger are boosted from those expected by the
weak-lensing mass and those for the other two clusters show no significant
deviations, which is consistent with predictions of numerical simulations.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:34:09 GMT""},{""version"":""v2"",""created"":""Sat, 1 Aug 2020 07:27:27 GMT""}]","2020-09-15"
"1911.09237","Chen Zhou","Chen Zhou","Lefschetz theorem for holomorphic one-forms on weakly 1-complete
  manifolds",,,"10.1007/s00208-020-02141-y",,"math.DG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a holomorphic one-form $\mathbf{\xi}$ on a weakly 1-complete manifold $X$
with certain properties, we discussed the connectivity of the pair $(\hat{X},
F^{-1}(z))$, where $\pi : \hat{X} \to X$ is a covering map and
$dF=\pi^*\mathbf{\xi}$. We also discussed the criteria about when such a
manifold $X$ admits a proper holomorphic mapping onto a Riemann surface.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:35:28 GMT""},{""version"":""v2"",""created"":""Wed, 13 Jul 2022 00:47:43 GMT""},{""version"":""v3"",""created"":""Thu, 15 Dec 2022 14:05:36 GMT""}]","2022-12-16"
"1911.09238","Steven Miller","Madeleine Farris, Noah Luntzlara, Steven J. Miller, Lily Shao and
  Mengxi Wang","Recurrence Relations and Benford's Law","Version 1.0, 24 pages, 1 image",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There are now many theoretical explanations for why Benford's law of digit
bias surfaces in so many diverse fields and data sets. After briefly reviewing
some of these, we discuss in depth recurrence relations. As these are discrete
analogues of differential equations and model a variety of real world
phenomena, they provide an important source of systems to test for Benfordness.
Previous work showed that fixed depth recurrences with constant coefficients
are Benford modulo some technical assumptions which are usually met; we briefly
review that theory and then prove some new results extending to the case of
linear recurrence relations with non-constant coefficients. We prove that, for
certain families of functions $f$ and $g$, a sequence generated by a recurrence
relation of the form $a_{n+1} = f(n)a_n + g(n)a_{n-1}$ is Benford for all
initial values. The proof proceeds by parameterizing the coefficients to obtain
a recurrence relation of lower degree, and then converting to a new parameter
space. From there we show that for suitable choices of $f$ and $g$ where $f(n)$
is nondecreasing and $g(n)/f(n)^2 \to 0$ as $n \to \infty$, the main term
dominates and the behavior is equivalent to equidistribution problems
previously studied. We also describe the results of generalizing further to
higher-degree recurrence relations and multiplicative recurrence relations with
non-constant coefficients, as well as the important case when $f$ and $g$ are
values of random variables.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:47:38 GMT""}]","2019-11-22"
"1911.09239","Ugo Rosolia","Ugo Rosolia and Francesco Borrelli","Minimum Time Learning Model Predictive Control",,,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a Learning Model Predictive Control (LMPC) strategy
for linear and nonlinear time optimal control problems. Our work builds on
existing LMPC methodologies and it guarantees finite time convergence
properties for the closed-loop system. We show how to construct a time varying
safe set and terminal cost function using closed-loop data. The resulting LMPC
policy is time varying and it guarantees recursive constraint satisfaction and
non-decreasing performance. Computational efficiency is obtained by convexifing
the safe set and terminal cost function. We demonstrate that, for a class of
nonlinear system and convex constraints, the convex LMPC formulation guarantees
recursive constraint satisfaction and non-decreasing performance. Finally, we
illustrate the effectiveness of the proposed strategies on minimum time
obstacle avoidance and racing examples.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:51:35 GMT""},{""version"":""v2"",""created"":""Thu, 19 Mar 2020 19:47:48 GMT""},{""version"":""v3"",""created"":""Sat, 18 Jul 2020 21:15:45 GMT""},{""version"":""v4"",""created"":""Sun, 4 Oct 2020 06:24:22 GMT""}]","2020-10-06"
"1911.09240","Bohdan Bulanyi","Bohdan Bulanyi and Antoine Lemenant","Regularity for the planar optimal p-compliance problem","56 pages",,,,"math.OC math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we prove a partial $C^{1,\alpha}$ regularity result in
dimension $N=2$ for the optimal $p$-compliance problem, extending for $p\not =
2$ some of the results obtained by A. Chambolle, J. Lamboley, A. Lemenant, E.
Stepanov (2017). Because of the lack of good monotonicity estimates for the
$p$-energy when $p\not = 2$, we employ an alternative technique based on a
compactness argument leading to a $p$-energy decay at any flat point. We
finally obtain that every optimal set has no loop, is Ahlfors regular, and
$C^{1,\alpha}$ at $\mathcal{H}^1$-a.e. point for every $p \in (1 ,+\infty)$.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:04:04 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jul 2020 12:36:08 GMT""},{""version"":""v3"",""created"":""Mon, 12 Apr 2021 07:11:30 GMT""}]","2021-04-13"
"1911.09241","Saku Sugawara","Saku Sugawara, Pontus Stenetorp, Kentaro Inui, Akiko Aizawa","Assessing the Benchmarking Capacity of Machine Reading Comprehension
  Datasets","11 pages, AAAI2020, with extra examples, data:
  https://github.com/Alab-NII/mrc-ablation",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing analysis work in machine reading comprehension (MRC) is largely
concerned with evaluating the capabilities of systems. However, the
capabilities of datasets are not assessed for benchmarking language
understanding precisely. We propose a semi-automated, ablation-based
methodology for this challenge; By checking whether questions can be solved
even after removing features associated with a skill requisite for language
understanding, we evaluate to what degree the questions do not require the
skill. Experiments on 10 datasets (e.g., CoQA, SQuAD v2.0, and RACE) with a
strong baseline model show that, for example, the relative scores of a baseline
model provided with content words only and with shuffled sentence words in the
context are on average 89.2% and 78.5% of the original score, respectively.
These results suggest that most of the questions already answered correctly by
the model do not necessarily require grammatical and complex reasoning. For
precise benchmarking, MRC datasets will need to take extra care in their design
to ensure that questions can correctly evaluate the intended skills.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:04:52 GMT""}]","2019-11-22"
"1911.09242","Son Doan <","Son Doan, Amanda Ritchart, Nicholas Perry, Juan D Chaparro, Mike
  Conway","How Do You #relax When You're #stressed? A Content Analysis and
  Infodemiology Study of Stress-Related Tweets","38 pages,12 figures, 6 tables, 5 Appendix (full version) -- shorter
  version published in JMIR Public Health Surveill 2017;3(2):e35","JMIR Public Health Surveill 2017;3(2):e35","10.2196/publichealth.5939",,"cs.CL cs.AI cs.CY","http://creativecommons.org/licenses/by/4.0/","  Background: Stress is a contributing factor to many major health problems in
the United States, such as heart disease, depression, and autoimmune diseases.
Relaxation is often recommended in mental health treatment as a frontline
strategy to reduce stress, thereby improving health conditions.
  Objective: The objective of our study was to understand how people express
their feelings of stress and relaxation through Twitter messages.
  Methods: We first performed a qualitative content analysis of 1326 and 781
tweets containing the keywords ""stress"" and ""relax"", respectively. We then
investigated the use of machine learning algorithms to automatically classify
tweets as stress versus non stress and relaxation versus non relaxation.
Finally, we applied these classifiers to sample datasets drawn from 4 cities
with the goal of evaluating the extent of any correlation between our automatic
classification of tweets and results from public stress surveys.
  Results: Content analysis showed that the most frequent topic of stress
tweets was education, followed by work and social relationships. The most
frequent topic of relaxation tweets was rest and vacation, followed by nature
and water. When we applied the classifiers to the cities dataset, the
proportion of stress tweets in New York and San Diego was substantially higher
than that in Los Angeles and San Francisco.
  Conclusions: This content analysis and infodemiology study revealed that
Twitter, when used in conjunction with natural language processing techniques,
is a useful data source for understanding stress and stress management
strategies, and can potentially supplement infrequently collected survey-based
stress data.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:08:14 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 19:06:20 GMT""}]","2019-12-05"
"1911.09243","Dongliang He","Ya Wang, Dongliang He, Fu Li, Xiang Long, Zhichao Zhou, Jinwen Ma,
  Shilei Wen","Multi-Label Classification with Label Graph Superimposing","AAAI 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Images or videos always contain multiple objects or actions. Multi-label
recognition has been witnessed to achieve pretty performance attribute to the
rapid development of deep learning technologies. Recently, graph convolution
network (GCN) is leveraged to boost the performance of multi-label recognition.
However, what is the best way for label correlation modeling and how feature
learning can be improved with label system awareness are still unclear. In this
paper, we propose a label graph superimposing framework to improve the
conventional GCN+CNN framework developed for multi-label recognition in the
following two aspects. Firstly, we model the label correlations by
superimposing label graph built from statistical co-occurrence information into
the graph constructed from knowledge priors of labels, and then multi-layer
graph convolutions are applied on the final superimposed graph for label
embedding abstraction. Secondly, we propose to leverage embedding of the whole
label system for better representation learning. In detail, lateral connections
between GCN and CNN are added at shallow, middle and deep layers to inject
information of label system into backbone CNN for label-awareness in the
feature learning process. Extensive experiments are carried out on MS-COCO and
Charades datasets, showing that our proposed solution can greatly improve the
recognition performance and achieves new state-of-the-art recognition
performance.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:08:20 GMT""}]","2019-11-22"
"1911.09244","Vesna Mitrovic","R. Cong, Ravindra Nanguneri, Brenda Rubenstein, and V. F. Mitrovi\'c","Evidence for orbital ordering in Ba$_2$NaOsO$_6$, a Mott insulator with
  strong spin orbit coupling, from First Principles","6 pages, 4 Figures, accepted for publication in PRB",,,,"cond-mat.str-el cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present first principles calculations of the magnetic and orbital
properties of Ba$_2$NaOsO$_6$ (BNOO), a 5$d^1$ Mott insulator with strong spin
orbit coupling (SOC) in its low temperature emergent quantum phases. Our
computational method takes into direct consideration recent NMR results that
established that BNOO develops a local octahedral distortion preceding the
formation of long range magnetic order. We found that the two-sublattice canted
ferromagnetic ground state identified in Lu \etal, Nature Comm. {\bf 8}, 14407
(2017) is accompanied by a two-sublattice staggered orbital ordering pattern in
which the $t_{2g}$ orbitals are selectively occupied as a result of strong spin
orbit coupling. The staggered orbital order found here using first principles
calculations asserts the previous proposal of Chen \etal, Phys. Rev. B {\bf
82}, 174440 (2010) and Lu \etal, Nature Comm. {\bf 8}, 14407 (2017), that
two-sublattice magnetic structure is the very manifestation of staggered
quadrupolar order. Therefore, our results affirm the essential role of
multipolar spin interactions in the microscopic description of magnetism in
systems with locally entangled spin and orbital degrees of freedom.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:15:25 GMT""}]","2019-11-22"
"1911.09245","Diogo Luvizon","Diogo C Luvizon, Hedi Tabia, David Picard","Consensus-based Optimization for 3D Human Pose Estimation in Camera
  Coordinates","Source code is available at
  https://github.com/dluvizon/3d-pose-consensus",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  3D human pose estimation is frequently seen as the task of estimating 3D
poses relative to the root body joint. Alternatively, we propose a 3D human
pose estimation method in camera coordinates, which allows effective
combination of 2D annotated data and 3D poses and a straightforward multi-view
generalization. To that end, we cast the problem as a view frustum space pose
estimation, where absolute depth prediction and joint relative depth
estimations are disentangled. Final 3D predictions are obtained in camera
coordinates by the inverse camera projection. Based on this, we also present a
consensus-based optimization algorithm for multi-view predictions from
uncalibrated images, which requires a single monocular training procedure.
Although our method is indirectly tied to the training camera intrinsics, it
still converges for cameras with different intrinsic parameters, resulting in
coherent estimations up to a scale factor. Our method improves the state of the
art on well known 3D human pose datasets, reducing the prediction error by 32%
in the most common benchmark. We also reported our results in absolute pose
position error, achieving 80~mm for monocular estimations and 51~mm for
multi-view, on average.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:19:08 GMT""},{""version"":""v2"",""created"":""Thu, 28 Nov 2019 03:08:10 GMT""},{""version"":""v3"",""created"":""Fri, 20 Aug 2021 13:53:55 GMT""}]","2021-08-23"
"1911.09246","William Trenberth","William J. Trenberth","Global well-posedness for the two-dimensional stochastic complex
  Ginzburg-Landau equation","43 pages",,,,"math.AP math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the stochastic complex Ginzburg-Landau equation (SCGL) with an
additive space-time white noise forcing on the two-dimensional torus. This
equation is singular and thus we need to renormalize the nonlinearity in order
to give proper meaning to the equation. Unlike the real-valued stochastic
quantization equation, SCGL is complex valued and hence we are forced to work
with the generalized Laguerre polynomials for the sake of renormalization. In
handling nonlinearities of arbitrary degree, we derive a useful algebraic
identity on the renormalization in the complex-valued setting and prove that
the renormalized SCGL is locally well-posed. We prove global well-posedness
using an energy estimate and almost sure global well-posedness under different
conditions using an invariant measure argument.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:19:31 GMT""}]","2019-11-22"
"1911.09247","Zewei Chu","Zewei Chu, Mingda Chen, Jing Chen, Miaosen Wang, Kevin Gimpel, Manaal
  Faruqui and Xiance Si","How to Ask Better Questions? A Large-Scale Multi-Domain Dataset for
  Rewriting Ill-Formed Questions","AAAI 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a large-scale dataset for the task of rewriting an ill-formed
natural language question to a well-formed one. Our multi-domain question
rewriting MQR dataset is constructed from human contributed Stack Exchange
question edit histories. The dataset contains 427,719 question pairs which come
from 303 domains. We provide human annotations for a subset of the dataset as a
quality estimate. When moving from ill-formed to well-formed questions, the
question quality improves by an average of 45 points across three aspects. We
train sequence-to-sequence neural models on the constructed dataset and obtain
an improvement of 13.2% in BLEU-4 over baseline methods built from other data
resources. We release the MQR dataset to encourage research on the problem of
question rewriting.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:24:21 GMT""}]","2019-11-22"
"1911.09248","Sida Peng","Sida Peng and Yang Ning","Regression Discontinuity Design under Self-selection",,,,,"stat.ME econ.EM","http://creativecommons.org/licenses/by/4.0/","  In Regression Discontinuity (RD) design, self-selection leads to different
distributions of covariates on two sides of the policy intervention, which
essentially violates the continuity of potential outcome assumption. The
standard RD estimand becomes difficult to interpret due to the existence of
some indirect effect, i.e. the effect due to self selection. We show that the
direct causal effect of interest can still be recovered under a class of
estimands. Specifically, we consider a class of weighted average treatment
effects tailored for potentially different target populations. We show that a
special case of our estimands can recover the average treatment effect under
the conditional independence assumption per Angrist and Rokkanen (2015), and
another example is the estimand recently proposed in Fr\""olich and Huber
(2018). We propose a set of estimators through a weighted local linear
regression framework and prove the consistency and asymptotic normality of the
estimators. Our approach can be further extended to the fuzzy RD case. In
simulation exercises, we compare the performance of our estimator with the
standard RD estimator. Finally, we apply our method to two empirical data sets:
the U.S. House elections data in Lee (2008) and a novel data set from Microsoft
Bing on Generalized Second Price (GSP) auction.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:28:59 GMT""}]","2019-11-22"
"1911.09249","Hasnine Haque","Hasnine Haque, Masahiro Hashimoto, Nozomu Uetake, Masahiro Jinzaki","Semantic Segmentation of Thigh Muscle using 2.5D Deep Learning Network
  Trained with Limited Datasets","7 pages, 5 figures, This manuscript was a detailed version of our
  accepted oral paper in RSNA 2018. Ref: Haque,H, Hashimoto,M, Uetake,N,
  Jinzaki,M, End to End Solution for Complete Thigh Muscle Semantic
  Segmentation from Musculoskeletal CT using Deep Learning.
  http://archive.rsna.org/2018/18006583.html",,,,"eess.IV cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Purpose: We propose a 2.5D deep learning neural network (DLNN) to
automatically classify thigh muscle into 11 classes and evaluate its
classification accuracy over 2D and 3D DLNN when trained with limited datasets.
Enables operator invariant quantitative assessment of the thigh muscle volume
change with respect to the disease progression. Materials and methods:
Retrospective datasets consist of 48 thigh volume (TV) cropped from CT DICOM
images. Cropped volumes were aligned with femur axis and resample in 2 mm
voxel-spacing. Proposed 2.5D DLNN consists of three 2D U-Net trained with
axial, coronal and sagittal muscle slices respectively. A voting algorithm was
used to combine the output of U-Nets to create final segmentation. 2.5D U-Net
was trained on PC with 38 TV and the remaining 10 TV were used to evaluate
segmentation accuracy of 10 classes within Thigh. The result segmentation of
both left and right thigh were de-cropped to original CT volume space. Finally,
segmentation accuracies were compared between proposed DLNN and 2D/3D U-Net.
Results: Average segmentation DSC score accuracy of all classes with 2.5D U-Net
as 91.18% and Average Surface distance (ASD) accuracy as 0.84 mm. We found,
mean DSC score for 2D U-Net was 3.3% lower than the that of 2.5D U-Net and mean
DSC score of 3D U-Net was 5.7% lower than that of 2.5D U-Net when trained with
same datasets. Conclusion: We achieved a faster computationally efficient and
automatic segmentation of thigh muscle into 11 classes with reasonable
accuracy. Enables quantitative evaluation of muscle atrophy with disease
progression.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:30:31 GMT""}]","2019-11-22"
"1911.09250","Lu Meng","Lu Meng, Bo Wang, Guang-Juan Wang and Shi-Lin Zhu","Hidden charm pentaquark states and $\Sigma_c^{(*)}\bar{D}^{(*)}$
  interaction in chiral perturbation theory","5 pages, 5 figures; contribution to the proceedings of the XVIII
  International Conference on Hadron Spectroscopy and Structure, HADRON-2019.
  August 16-21, Guilin, China",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We adopt the chiral perturbation theory to calculate the
$\Sigma_{c}^{(*)}\bar{D}^{(*)}$ interaction to the next-to-leading order (NLO)
and include the couple-channel effect in the loop diagrams. We reproduce the
three $P_c$ states in the molecular picture after including the
$\Lambda_{c}\bar{D}^{(*)}$ intermediate states. We also discuss some novel
observations arising from the loop diagrams.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:38:32 GMT""}]","2019-11-22"
"1911.09251","Tunhou Zhang","Tunhou Zhang, Hsin-Pai Cheng, Zhenwen Li, Feng Yan, Chengyu Huang, Hai
  Li, Yiran Chen","AutoShrink: A Topology-aware NAS for Discovering Efficient Neural
  Architecture",,,,"Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)","cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Resource is an important constraint when deploying Deep Neural Networks
(DNNs) on mobile and edge devices. Existing works commonly adopt the cell-based
search approach, which limits the flexibility of network patterns in learned
cell structures. Moreover, due to the topology-agnostic nature of existing
works, including both cell-based and node-based approaches, the search process
is time consuming and the performance of found architecture may be sub-optimal.
To address these problems, we propose AutoShrink, a topology-aware Neural
Architecture Search(NAS) for searching efficient building blocks of neural
architectures. Our method is node-based and thus can learn flexible network
patterns in cell structures within a topological search space. Directed Acyclic
Graphs (DAGs) are used to abstract DNN architectures and progressively optimize
the cell structure through edge shrinking. As the search space intrinsically
reduces as the edges are progressively shrunk, AutoShrink explores more
flexible search space with even less search time. We evaluate AutoShrink on
image classification and language tasks by crafting ShrinkCNN and ShrinkRNN
models. ShrinkCNN is able to achieve up to 48% parameter reduction and save 34%
Multiply-Accumulates (MACs) on ImageNet-1K with comparable accuracy of
state-of-the-art (SOTA) models. Specifically, both ShrinkCNN and ShrinkRNN are
crafted within 1.5 GPU hours, which is 7.2x and 6.7x faster than the crafting
time of SOTA CNN and RNN models, respectively.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:40:00 GMT""}]","2020-03-04"
"1911.09252","Harish N. S. Krishnamoorthy","H. N. S. Krishnamoorthy, G. Adamo, J. Yin, V. Savinov, N. I. Zheludev,
  and C. Soci","Infrared dielectric metamaterials from high refractive index
  chalcogenides","21 pages, 6 figures",,"10.1038/s41467-020-15444-0",,"physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  High-index dielectric materials are in great demand for nanophotonic devices
and applications, from ultrathin optical elements to metal-free sub-diffraction
light confinement and waveguiding. Here we show that chalcogenide topological
insulators are particularly apt candidates for dielectric nanophotonic
architectures in the infrared spectral range by reporting metamaterial
resonances in chalcogenide crystals sustained well inside the mid-infrared,
choosing Bi$_2$Te$_3$ as case study within this family of materials. Strong
resonant modulation of the incident electromagnetic field is achieved thanks to
the exceptionally high refractive index ranging between 7 and 8 throughout the
2-10 $\mu$m region. Analysis of the complex mode structure in the metamaterial
allude to the excitation of poloidal surface currents which could open pathways
for enhanced light-matter interaction and low-loss plasmonic configurations by
coupling to the spin-polarized topological surface carriers, thereby providing
new opportunities to combine dielectric, plasmonic and magnetic metamaterials
in a single platform.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:41:38 GMT""}]","2020-04-22"
"1911.09253","Fei Ma","Fei Ma, Ping Wang, Bing Yao","An extremal problem: How small scale-free graph can be",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The bloom of complex network study, in particular, with respect to scale-free
ones, is considerably triggering the research of scale-free graph itself.
Therefore, a great number of interesting results have been reported in the
past, including bounds of diameter. In this paper, we focus mainly on a problem
of how to analytically estimate the lower bound of diameter of scale-free
graph, i.e., how small scale-free graph can be. Unlike some pre-existing
methods for determining the lower bound of diameter, we make use of a
constructive manner in which one candidate model $\mathcal{G^*} (\mathcal{V^*},
\mathcal{E^*})$ with ultra-small diameter can be generated. In addition, with a
rigorous proof, we certainly demonstrate that the diameter of graph
$\mathcal{G^{*}}(\mathcal{V^{*}},\mathcal{E^{*}})$ must be the smallest in
comparison with that of any scale-free graph. This should be regarded as the
tight lower bound.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:50:00 GMT""}]","2019-11-22"
"1911.09254","Yujie Wu","Yujie Wu, Mitchell H. Gail, Stephanie A. Smith-Warner, Regina G.
  Ziegler, Molin Wang","Spline Analysis of Biomarker Data Pooled From Multiple Matched/Nested
  Case-Control Studies",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pooling biomarker data across multiple studies enables researchers to get
more precise estimates of the association between biomarker exposure
measurements and disease risks due to increased sample sizes. However,
biomarker measurements vary significantly across different assays and
laboratories, and therefore calibration of the local laboratory measurements to
a reference laboratory is necessary before pooling data. We propose two methods
that can estimate a nonlinear relationship between biomarker exposure
measurements and disease risks using spline functions with a nested
case-control study design: full calibration and internalized calibration. The
full calibration method calibrates all observations using a study-specific
calibration model while the internalized calibration method only calibrates
observations that do not have reference laboratory measurements available. We
compare the two methods with a naive method whereby data are pooled without
calibration. We find that: (1) Internalized and full calibration methods have
substantially better performance than the naive method in terms of average
relative bias and coverage rate. (2) Full calibration is more robust than
internalized calibration when the size of calibration subsets varies. We apply
our methods to a pooling project with nested case-control study design to
estimate the association of circulating Vitamin D levels with the risk of
colorectal cancer.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:50:10 GMT""}]","2019-11-22"
"1911.09255","Martin Mosny","Martin Mosny","A study of Higgs $\boldsymbol{CP}$ properties using the Higgs
  Characterization Model and top associated production","21 pages, 8 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study utilises the Higgs Characterization model to investigate the $CP$
properties of the Higgs coupling to the top quark using the $tH$ and
$t\bar{t}H$ generation processes. This is done via simulations of proton-proton
collisions with ATLAS detector conditions, which are calculated for seven
different $CP$ eigenstates using MadGraph5_aMC@NLO. Three orthogonal categories
of cuts are subsequently implemented to find the cut efficiencies, which are
used in conjunction with the cross-section to find the signal strength.
Comparing the signal strength with experimental results shows that one cannot
yet conclusively rule out any Higgs $CP$ eigenstates. Analysing histograms
showed that the most $CP$ sensitive variables were the transverse momenta of
the Higgs, leptons and photons, which showed a hardening as the Higgs coupling
became $CP$ odd.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:50:16 GMT""}]","2019-11-22"
"1911.09256","Ilan Morgenstern","Yonatan Gur, Gregory Macnamara, Ilan Morgenstern, and Daniela Saban","Information Disclosure and Promotion Policy Design for Platforms",,,,,"econ.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider a platform facilitating trade between sellers and buyers with the
objective of maximizing consumer surplus. Even though in many such marketplaces
prices are set by revenue-maximizing sellers, platforms can influence prices
through (i) price-dependent promotion policies that can increase demand for a
product by featuring it in a prominent position on the webpage and (ii) the
information revealed to sellers about the value of being promoted. Identifying
effective joint information design and promotion policies is a challenging
dynamic problem as sellers can sequentially learn the promotion value from
sales observations and update prices accordingly. We introduce the notion of
confounding promotion policies, which are designed to prevent a Bayesian seller
from learning the promotion value (at the expense of the short-run loss of
diverting some consumers from the best product offering). Leveraging these
policies, we characterize the maximum long-run average consumer surplus that is
achievable through joint information design and promotion policies when the
seller sets prices myopically. We then construct a Bayesian Nash equilibrium in
which the seller's best response to the platform's optimal policy is to price
myopically in every period. Moreover, the equilibrium we identify is
platform-optimal within the class of horizon-maximin equilibria, in which
strategies are not predicated on precise knowledge of the horizon length, and
are designed to maximize payoff over the worst-case horizon. Our analysis
allows one to identify practical long-run average optimal platform policies in
a broad range of demand models.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 02:52:44 GMT""},{""version"":""v2"",""created"":""Fri, 3 Apr 2020 06:32:14 GMT""},{""version"":""v3"",""created"":""Thu, 3 Feb 2022 02:50:38 GMT""},{""version"":""v4"",""created"":""Fri, 30 Sep 2022 01:31:28 GMT""},{""version"":""v5"",""created"":""Thu, 15 Dec 2022 08:07:47 GMT""}]","2022-12-16"
"1911.09257","Alexander Wong","Andrew Hryniowski and Alexander Wong","DeepLABNet: End-to-end Learning of Deep Radial Basis Networks with Fully
  Learnable Basis Functions","10 pages",,,,"cs.NE cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  From fully connected neural networks to convolutional neural networks, the
learned parameters within a neural network have been primarily relegated to the
linear parameters (e.g., convolutional filters). The non-linear functions
(e.g., activation functions) have largely remained, with few exceptions in
recent years, parameter-less, static throughout training, and seen limited
variation in design. Largely ignored by the deep learning community, radial
basis function (RBF) networks provide an interesting mechanism for learning
more complex non-linear activation functions in addition to the linear
parameters in a network. However, the interest in RBF networks has waned over
time due to the difficulty of integrating RBFs into more complex deep neural
network architectures in a tractable and stable manner. In this work, we
present a novel approach that enables end-to-end learning of deep RBF networks
with fully learnable activation basis functions in an automatic and tractable
manner. We demonstrate that our approach for enabling the use of learnable
activation basis functions in deep neural networks, which we will refer to as
DeepLABNet, is an effective tool for automated activation function learning
within complex network architectures.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:06:15 GMT""}]","2019-11-22"
"1911.09258","Guo Yanqiang","Xiaomin Guo, Chen Cheng, Tong Liu, Xin Fang, and Yanqiang Guo","Precise Photon Correlation Measurement of a Chaotic Laser","12 pages, 7 figures",,,,"quant-ph nlin.CD physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The second order photon correlation g^(2)(tau) of a chaotic optical-feedback
semiconductor laser is precisely measured using a Hanbury Brown-Twiss
interferometer. The accurate g^(2)(tau) with non-zero delay time is obtained
experimentally from the photon pair time interval distribution through a
ninth-order self-convolution correction. The experimental results agree well
with the theoretical analysis. The relative error of g^(2)(tau) is no more than
0.005 within 50 ns delay time. The bunching effect and coherence time of the
chaotic laser are measured via the precise photon correlation technique. This
technique provides a new tool to improve the accuracy of g^(2)(tau) measurement
and boost applications of quantum statistics and correlation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:08:02 GMT""}]","2019-11-22"
"1911.09259","Yuan Qi","Jiajing Wu, Qi Yuan, Dan Lin, Wei You, Weili Chen, Chuan Chen and
  Zibin Zheng","Who Are the Phishers? Phishing Scam Detection on Ethereum via Network
  Embedding",,"TSMC.2020.3016821","10.1109/TSMC.2020.3016821.",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, blockchain technology has become a topic in the spotlight but also
a hotbed of various cybercrimes. Among them, phishing scams on blockchain have
been found making a notable amount of money, thus emerging as a serious threat
to the trading security of the blockchain ecosystem. In order to create a
favorable environment for investment, an effective method for detecting
phishing scams is urgently needed in the blockchain ecosystem. To this end,
this paper proposes an approach to detect phishing scams on Ethereum by mining
its transaction records. Specifically, we first crawl the labeled phishing
addresses from two authorized websites and reconstruct the transaction network
according to the collected transaction records. Then, by taking the transaction
amount and timestamp into consideration, we propose a novel network embedding
algorithm called trans2vec to extract the features of the addresses for
subsequent phishing identification. Finally, we adopt the oneclass support
vector machine (SVM) to classify the nodes into normal and phishing ones.
Experimental results demonstrate that the phishing detection method works
effectively on Ethereum, and indicate the efficacy of trans2vec over existing
state-of-the-art algorithms on feature extraction for transaction networks.
This work is the first investigation on phishing detection on Ethereum via
network embedding and provides insights into how features of large-scale
transaction networks can be embedded.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:09:30 GMT""},{""version"":""v2"",""created"":""Tue, 17 Nov 2020 12:33:04 GMT""}]","2021-01-01"
"1911.09260","Yifan Cui","Yifan Cui, Eric Tchetgen Tchetgen","A semiparametric instrumental variable approach to optimal treatment
  regimes under endogeneity","To appear in Journal of the American Statistical Association",,,,"stat.ME math.ST stat.ML stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  There is a fast-growing literature on estimating optimal treatment regimes
based on randomized trials or observational studies under a key identifying
condition of no unmeasured confounding. Because confounding by unmeasured
factors cannot generally be ruled out with certainty in observational studies
or randomized trials subject to noncompliance, we propose a general
instrumental variable approach to learning optimal treatment regimes under
endogeneity. Specifically, we establish identification of both value function
$E[Y_{\mathcal{D}(L)}]$ for a given regime $\mathcal{D}$ and optimal regimes
$\text{argmax}_{\mathcal{D}} E[Y_{\mathcal{D}(L)}]$ with the aid of a binary
instrumental variable, when no unmeasured confounding fails to hold. We also
construct novel multiply robust classification-based estimators. Furthermore,
we propose to identify and estimate optimal treatment regimes among those who
would comply to the assigned treatment under a standard monotonicity
assumption. In this latter case, we establish the somewhat surprising result
that complier optimal regimes can be consistently estimated without directly
collecting compliance information and therefore without the complier average
treatment effect itself being identified. Our approach is illustrated via
extensive simulation studies and a data application on the effect of child
rearing on labor participation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:10:08 GMT""},{""version"":""v2"",""created"":""Thu, 6 Feb 2020 00:22:59 GMT""},{""version"":""v3"",""created"":""Mon, 13 Apr 2020 16:52:58 GMT""},{""version"":""v4"",""created"":""Thu, 21 May 2020 20:24:14 GMT""},{""version"":""v5"",""created"":""Fri, 12 Jun 2020 16:09:39 GMT""},{""version"":""v6"",""created"":""Thu, 25 Jun 2020 20:43:31 GMT""},{""version"":""v7"",""created"":""Sat, 4 Jul 2020 01:13:19 GMT""},{""version"":""v8"",""created"":""Mon, 10 Aug 2020 19:35:06 GMT""}]","2020-08-12"
"1911.09261","Akihiro Suzuki","Akihiro Suzuki, Takashi J. Moriya, Tomoya Takiwaki","Supernova ejecta interacting with a circumstellar disk. I.
  two-dimensional radiation-hydrodynamic simulations","35 pages, 22 figures, accepted for publication in ApJ",,"10.3847/1538-4357/ab5a83",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a series of two-dimensional radiation-hydrodynamic simulations of
the collision between supernova ejecta and circumstellar media (CSM). The
hydrodynamic interaction of a fast flow and the surrounding media efficiently
dissipates the kinetic energy of the fast flow and considered as a dominant
energy source for a specific class of core-collapse supernovae. Despite some
observational evidence for aspherical ejecta and/or CSM structure,
multi-dimensional effects in the ejecta-CSM interaction are relatively
unexplored. Our numerical simulations equipped with an adaptive mesh refinement
technique successfully reproduce hydrodynamic instabilities developing around
the ejecta-CSM interface. We also investigate effects of disk-like CSM on the
dynamical evolution of supernova ejecta and bolometric light curves. We find
that emission powered by ejecta-disk interaction exhibits significant viewing
angle dependence. For a line of sight close to the symmetry axis, the observer
directly sees the supernova ejecta, leading to a short brightening timescale.
For an observer seeing the emission through the CSM disk, thermal photons
diffuse throughout the CSM and thus the light curve is severely smeared out.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:12:16 GMT""}]","2020-01-08"
"1911.09262","Yao Sun","Yao Sun, Aayush Rajasekaran","An Interleaving Hybrid Consensus Protocol",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce Unity Interleave, a new consensus algorithm for public
blockchain settings. It is an eventual consistency protocol merging the
Proof-of-Work (PoW) and Proof-of-Stake (PoS) into a coherent stochastic
process. It builds upon research previously done for the Unity protocol,
improving security while maintaining fairness and scalability.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:12:44 GMT""}]","2019-11-22"
"1911.09263","Ziqi Liu","Ziqi Liu","A few results on associativity of hypermultiplications in polynomial
  hyperstructures over hyperfields","12 pages, undergraduate research",,,,"math.RA","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In Baker and Lorscheid's paper, they introduce a new hyperstructure: the
polynomial hyperstructure Poly$(\mathbb{F})$ over a hyperfield $\mathbb{F}$. In
this work, the author focuses on associativity of hypermultiplications in those
hyperstructures and gives elementary propositions. The author also shows
examples of polynomial hyperstructures over hyperfields with non-associative
hypermultiplications. Then, he proves that though the hypermultiplication in
Poly$(\mathbb{T})$ is associative for linear polynomials, it is not associative
in general. Moreover, he shows that if $1\boxplus_{\mathbb{F}}1$ is not a
singleton for hyperfield
$\mathbb{F}:=(\mathbb{F},\odot,\boxplus_{\mathbb{F}},1,0)$, the
hypermultiplication in Poly$(\mathbb{F})$ is not associative.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:17:15 GMT""},{""version"":""v2"",""created"":""Fri, 21 Feb 2020 03:58:09 GMT""},{""version"":""v3"",""created"":""Tue, 10 Mar 2020 12:28:37 GMT""},{""version"":""v4"",""created"":""Tue, 24 Mar 2020 05:35:59 GMT""},{""version"":""v5"",""created"":""Tue, 31 Mar 2020 10:59:09 GMT""},{""version"":""v6"",""created"":""Sun, 11 Oct 2020 08:12:35 GMT""}]","2020-10-13"
"1911.09264","Xiaofeng Yang","Xue Dong, Yang Lei, Sibo Tian, Yingzi Liu, Tonghe Wang, Tian Liu,
  Walter J. Curran, Hui Mao, Hui-Kuo Shu, Xiaofeng Yang","Air, bone and soft-tissue Segmentation on 3D brain MRI Using Semantic
  Classification Random Forest with Auto-Context Model","18 pages, 8 figures",,,,"physics.med-ph eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As bone and air produce weak signals with conventional MR sequences,
segmentation of these tissues particularly difficult in MRI. We propose to
integrate patch-based anatomical signatures and an auto-context model into a
machine learning framework to iteratively segment MRI into air, bone and soft
tissue. The proposed semantic classification random forest (SCRF) method
consists of a training stage and a segmentation stage. During training stage,
patch-based anatomical features were extracted from registered MRI-CT training
images, and the most informative features were identified to train a series of
classification forests with auto-context model. During segmentation stage, we
extracted selected features from MRI and fed them into the well-trained forests
for MRI segmentation. The DSC for air, bone and soft tissue obtained with
proposed SCRF were 0.976, 0.819 and 0.932, compared to 0.916, 0.673 and 0.830
with RF, 0.942, 0.791 and 0.917 with U-Net. SCRF also demonstrated superior
segmentation performances for sensitivity and specificity over RF and U-Net for
all three structure types. The proposed segmentation technique could be a
useful tool to segment bone, air and soft tissue, and have the potential to be
applied to attenuation correction of PET/MRI system, MRI-only radiation
treatment planning and MR-guided focused ultrasound surgery.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:19:59 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 15:26:35 GMT""}]","2019-11-25"
"1911.09265","Guo-Jun Qi","Xiao Wang, Daisuke Kihara, Jiebo Luo, and Guo-Jun Qi","EnAET: A Self-Trained framework for Semi-Supervised and Supervised
  Learning with Ensemble Transformations","10 pages, 3 figures, conference",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks have been successfully applied to many real-world
applications. However, such successes rely heavily on large amounts of labeled
data that is expensive to obtain. Recently, many methods for semi-supervised
learning have been proposed and achieved excellent performance. In this study,
we propose a new EnAET framework to further improve existing semi-supervised
methods with self-supervised information. To our best knowledge, all current
semi-supervised methods improve performance with prediction consistency and
confidence ideas. We are the first to explore the role of {\bf self-supervised}
representations in {\bf semi-supervised} learning under a rich family of
transformations. Consequently, our framework can integrate the self-supervised
information as a regularization term to further improve {\it all} current
semi-supervised methods. In the experiments, we use MixMatch, which is the
current state-of-the-art method on semi-supervised learning, as a baseline to
test the proposed EnAET framework. Across different datasets, we adopt the same
hyper-parameters, which greatly improves the generalization ability of the
EnAET framework. Experiment results on different datasets demonstrate that the
proposed EnAET framework greatly improves the performance of current
semi-supervised algorithms. Moreover, this framework can also improve {\bf
supervised learning} by a large margin, including the extremely challenging
scenarios with only 10 images per class. The code and experiment records are
available in \url{https://github.com/maple-research-lab/EnAET}.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:20:48 GMT""},{""version"":""v2"",""created"":""Mon, 1 Feb 2021 16:15:05 GMT""}]","2021-02-02"
"1911.09266","Katsuhiro Morita","Katsuhiro Morita and Takami Tohyama","Finite-temperature properties of the Kitaev-Heisenberg models on kagome
  and triangular lattices studied by improved finite-temperature Lanczos
  methods",,"Phys. Rev. Research 2, 013205 (2020)","10.1103/PhysRevResearch.2.013205",,"cond-mat.str-el cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Frustrated quantum spin systems such as the Heisenberg and Kitaev models on
various lattices, have been known to exhibit various exotic properties not only
at zero temperature but also for finite temperatures. Inspired by the
remarkable development of the quantum frustrated spin systems in recent years,
we investigate the finite-temperature properties of the $S=1/2$
Kitaev-Heisenberg models on kagome and triangular lattices by means of
finite-temperature Lanczos methods with improved accuracy. In both lattices,
multiple peaks are confirmed in the specific heat. To find the origin of the
multiple peaks, we calculate the static spin structure factor. The origin of
the high-temperature peak of the specific heat is attributed to a crossover
from the paramagnetic state to a short-range ordered state whose static spin
structure factor has zigzag or linear intensity distributions in momentum
space. In the triangular Kitaev model, the ""order by disorder"" due to quantum
fluctuation occurs. On the other hand, in the kagome Kitaev model it does not
occur even with both quantum and thermal fluctuations.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:21:31 GMT""},{""version"":""v2"",""created"":""Fri, 28 Feb 2020 03:19:59 GMT""}]","2020-03-04"
"1911.09267","Yujun Shen","Ceyuan Yang, Yujun Shen, Bolei Zhou","Semantic Hierarchy Emerges in Deep Generative Representations for Scene
  Synthesis","15 pages, 20 figures",,,,"cs.CV cs.GR cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the success of Generative Adversarial Networks (GANs) in image
synthesis, there lacks enough understanding on what generative models have
learned inside the deep generative representations and how photo-realistic
images are able to be composed of the layer-wise stochasticity introduced in
recent GANs. In this work, we show that highly-structured semantic hierarchy
emerges as variation factors from synthesizing scenes from the generative
representations in state-of-the-art GAN models, like StyleGAN and BigGAN. By
probing the layer-wise representations with a broad set of semantics at
different abstraction levels, we are able to quantify the causality between the
activations and semantics occurring in the output image. Such a quantification
identifies the human-understandable variation factors learned by GANs to
compose scenes. The qualitative and quantitative results further suggest that
the generative representations learned by the GANs with layer-wise latent codes
are specialized to synthesize different hierarchical semantics: the early
layers tend to determine the spatial layout and configuration, the middle
layers control the categorical objects, and the later layers finally render the
scene attributes as well as color scheme. Identifying such a set of
manipulatable latent variation factors facilitates semantic scene manipulation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:26:15 GMT""},{""version"":""v2"",""created"":""Fri, 29 Nov 2019 02:12:56 GMT""},{""version"":""v3"",""created"":""Tue, 11 Feb 2020 05:49:15 GMT""}]","2020-02-12"
"1911.09268","Michel Pleimling","Ryan Baker and Michel Pleimling","The effect of habitats and fitness on species coexistence in systems
  with cyclic dominance","21 pages, 9 figures, accepted for publication in Journal of
  Theoretical Biology","J. Theor. Biol. 486, 110084 (2020)","10.1016/j.jtbi.2019.110084",,"q-bio.PE cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cyclic dominance between species may yield spiral waves that are known to
provide a mechanism enabling persistent species coexistence. This observation
holds true even in presence of spatial heterogeneity in the form of quenched
disorder. In this work we study the effects on spatio-temporal patterns and
species coexistence of structured spatial heterogeneity in the form of habitats
that locally provide one of the species with an advantage. Performing extensive
numerical simulations of systems with three and six species we show that these
structured habitats destabilize spiral waves. Analyzing extinction events, we
find that species extinction probabilities display a succession of maxima as
function of time, that indicate a periodically enhanced probability for species
extinction. Analysis of the mean extinction time reveals that as a function of
the parameter governing the advantage of one of the species a transition
between stable coexistence and unstable coexistence takes place. We also
investigate how efficiency as a predator or a prey affects species coexistence.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:28:05 GMT""}]","2020-02-05"
"1911.09269","Hiroyasu Ejiri","Hiroyasu Ejiri","Axial-vector weak coupling at medium momentum for astro neutrinos and
  double beta decays",,,"10.1088/1361-6471/ab4dcb",,"nucl-ex nucl-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neutrino nuclear responses associated with medium momentum transfer of
q=20-80 MeV for astro neutrinos and double beta decays were studied by using
charge exchange reactions on Te128 and Te130. Gamow-Teller and spin dipole
nuclear matrix elements are found to be reduced with respect to the pnQRPA
matrix elements by the coefficient of around 0.35. The reduction is discussed
in terms of the quenching of axial vector coupling (g_A).
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:32:29 GMT""}]","2020-01-08"
"1911.09270","Akshata Krishnamurthy","Akshata Krishnamurthy, Joel Villasenor, Steve Kissel, George Ricker
  and Roland Vanderspek","An optical test bench for the precision characterization of absolute
  quantum efficiency for the TESS CCD detectors",,"Journal of Instrumentation, Volume 12, May 2017","10.1088/1748-0221/12/05/C05013",,"astro-ph.IM physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Transiting Exoplanet Survey Satellite (TESS) will search for planets
transiting bright stars with Ic<13. TESS has been selected by NASA for launch
in 2018 as an Astrophysics Explorer mission, and is expected to discover a
thousand or more planets that are smaller in size than Neptune. TESS will
employ four wide-field optical charge-coupled device (CCD) cameras with a
band-pass of 650 nm-1050 nm to detect temporary drops in brightness of stars
due to planetary transits. The 1050 nm limit is set by the quantum efficiency
(QE) of the CCDs. The detector assembly consists of four back-illuminated MIT
Lincoln Laboratory CCID-80 devices. Each CCID-80 device consists of 2048x2048
imaging array and 2048x2048 frame store regions. Very precise on-ground
calibration and characterization of CCD detectors will significantly assist in
the analysis of the science data obtained in space. The characterization of the
absolute QE of the CCD detectors is a crucial part of the characterization
process because QE affects the performance of the CCD significantly over the
redder wavelengths at which TESS will be operating. An optical test bench with
significantly high photometric stability has been developed to perform precise
QE measurements. The design of the test setup along with key hardware,
methodology, and results from the test campaign are presented.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:42:41 GMT""}]","2019-11-22"
"1911.09271","Bryan Li","Bryan Li, Xinyue Wang, Homayoon Beigi","Cantonese Automatic Speech Recognition Using Transfer Learning from
  Mandarin","v1, to be presented as poster at Natural Language, Dialog and Speech
  Symposium 2019",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  We propose a system to develop a basic automatic speech recognizer(ASR) for
Cantonese, a low-resource language, through transfer learning of Mandarin, a
high-resource language. We take a time-delayed neural network trained on
Mandarin, and perform weight transfer of several layers to a newly initialized
model for Cantonese. We experiment with the number of layers transferred, their
learning rates, and pretraining i-vectors. Key findings are that this approach
allows for quicker training time with less data. We find that for every epoch,
log-probability is smaller for transfer learning models compared to a
Cantonese-only model. The transfer learning models show slight improvement in
CER.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:48:46 GMT""}]","2019-11-22"
"1911.09272","Alexander Levine","Alexander Levine, Soheil Feizi","Robustness Certificates for Sparse Adversarial Attacks by Randomized
  Ablation",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, techniques have been developed to provably guarantee the robustness
of a classifier to adversarial perturbations of bounded L_1 and L_2 magnitudes
by using randomized smoothing: the robust classification is a consensus of base
classifications on randomly noised samples where the noise is additive. In this
paper, we extend this technique to the L_0 threat model. We propose an
efficient and certifiably robust defense against sparse adversarial attacks by
randomly ablating input features, rather than using additive noise.
Experimentally, on MNIST, we can certify the classifications of over 50% of
images to be robust to any distortion of at most 8 pixels. This is comparable
to the observed empirical robustness of unprotected classifiers on MNIST to
modern L_0 attacks, demonstrating the tightness of the proposed robustness
certificate. We also evaluate our certificate on ImageNet and CIFAR-10. Our
certificates represent an improvement on those provided in a concurrent work
(Lee et al. 2019) which uses random noise rather than ablation (median
certificates of 8 pixels versus 4 pixels on MNIST; 16 pixels versus 1 pixel on
ImageNet.) Additionally, we empirically demonstrate that our classifier is
highly robust to modern sparse adversarial attacks on MNIST. Our
classifications are robust, in median, to adversarial perturbations of up to 31
pixels, compared to 22 pixels reported as the state-of-the-art defense, at the
cost of a slight decrease (around 2.3%) in the classification accuracy. Code is
available at https://github.com/alevine0/randomizedAblation/.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:52:32 GMT""}]","2019-11-22"
"1911.09273","Zihan Liu","Zihan Liu, Genta Indra Winata, Zhaojiang Lin, Peng Xu, Pascale Fung","Attention-Informed Mixed-Language Training for Zero-shot Cross-lingual
  Task-oriented Dialogue Systems","Accepted as an oral presentation in AAAI 2020",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, data-driven task-oriented dialogue systems have achieved promising
performance in English. However, developing dialogue systems that support
low-resource languages remains a long-standing challenge due to the absence of
high-quality data. In order to circumvent the expensive and time-consuming data
collection, we introduce Attention-Informed Mixed-Language Training (MLT), a
novel zero-shot adaptation method for cross-lingual task-oriented dialogue
systems. It leverages very few task-related parallel word pairs to generate
code-switching sentences for learning the inter-lingual semantics across
languages. Instead of manually selecting the word pairs, we propose to extract
source words based on the scores computed by the attention layer of a trained
English task-related model and then generate word pairs using existing
bilingual dictionaries. Furthermore, intensive experiments with different
cross-lingual embeddings demonstrate the effectiveness of our approach.
Finally, with very few word pairs, our model achieves significant zero-shot
adaptation performance improvements in both cross-lingual dialogue state
tracking and natural language understanding (i.e., intent detection and slot
filling) tasks compared to the current state-of-the-art approaches, which
utilize a much larger amount of bilingual data.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:52:50 GMT""}]","2019-11-22"
"1911.09274","Pulong Ma","Pulong Ma and Anirban Mondal and Bledar Konomi and Jonathan Hobbs and
  Joon Song and Emily Kang","Computer Model Emulation with High-Dimensional Functional Output in
  Large-Scale Observing System Uncertainty Experiments","45 pages",,,,"stat.AP stat.CO stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observing system uncertainty experiments (OSUEs) have been recently proposed
as a cost-effective way to perform probabilistic assessment of retrievals for
NASA's Orbiting Carbon Observatory-2 (OCO-2) mission. One important component
in the OCO-2 retrieval algorithm is a full-physics forward model that describes
the mathematical relationship between atmospheric variables such as carbon
dioxide and radiances measured by the remote sensing instrument. This forward
model is complicated and computationally expensive but large-scale OSUEs
require evaluation of this model numerous times, which makes it infeasible for
comprehensive experiments. To tackle this issue, we develop a statistical
emulator to facilitate large-scale OSUEs in the OCO-2 mission with independent
emulation. Within each distinct spectral band, the emulator represents
radiances output at irregular wavelengths via a linear combination of basis
functions and random coefficients. These random coefficients are then modeled
with nearest-neighbor Gaussian processes with built-in input dimension
reduction via active subspace. The proposed emulator reduces dimensionality in
both input space and output space, so that fast computation is achieved within
a fully Bayesian inference framework. Validation experiments demonstrate that
this emulator outperforms other competing statistical methods and a reduced
order model that approximates the full-physics forward model.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:58:27 GMT""},{""version"":""v2"",""created"":""Mon, 2 Nov 2020 17:33:13 GMT""}]","2020-11-03"
"1911.09275","Hengshu Zhu","Dazhong Shen, Qi Zhang, Tong Xu, Hengshu Zhu, Wenjia Zhao, Zikai Yin,
  Peilun Zhou, Lihua Fang, Enhong Chen, Hui Xiong","A Machine Learning-enhanced Robust P-Phase Picker for Real-time Seismic
  Monitoring","Note that this paper is the English version of our work published in
  SCIENTIA SINICA Informationis
  (http://engine.scichina.com/doi/10.1360/SSI-2020-0214), which is suggested to
  be cited if needed",,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifying the arrival times of seismic P-phases plays a significant role in
real-time seismic monitoring, which provides critical guidance for emergency
response activities. While considerable research has been conducted on this
topic, efficiently capturing the arrival times of seismic P-phases hidden
within intensively distributed and noisy seismic waves, such as those generated
by the aftershocks of destructive earthquakes, remains a real challenge since
most common existing methods in seismology rely on laborious expert
supervision. To this end, in this paper, we present a machine learning-enhanced
framework based on ensemble learning strategy, EL-Picker, for the automatic
identification of seismic P-phase arrivals on continuous and massive waveforms.
More specifically, EL-Picker consists of three modules, namely, Trigger,
Classifier, and Refiner, and an ensemble learning strategy is exploited to
integrate several machine learning classifiers. An evaluation of the
aftershocks following the MS 8.0 Wenchuan earthquake demonstrates that
EL-Picker can not only achieve the best identification performance but also
identify 120% more seismic P-phase arrivals as complementary data. Meanwhile,
experimental results also reveal both the applicability of different machine
learning models for waveforms collected from different seismic stations and the
regularities of seismic P-phase arrivals that might be neglected during manual
inspection. These findings clearly validate the effectiveness, efficiency,
flexibility and stability of EL-Picker.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:03:03 GMT""},{""version"":""v2"",""created"":""Wed, 19 Aug 2020 09:12:04 GMT""},{""version"":""v3"",""created"":""Thu, 20 Aug 2020 07:28:25 GMT""}]","2020-08-21"
"1911.09276","Abbas Shiri","Massimo L. Villinger, Abbas Shiri, Soroush Shabahang, Ali K. Jahromi,
  Magued B. Nasr, Christopher H. Villinger, and Ayman F. Abouraddy","Doubling the near-infrared photocurrent in a solar cell via
  omni-resonant coherent perfect absorption",,,,,"physics.optics cs.SY eess.SY physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Minimizing the material usage in thin-film solar cells can reduce
manufacturing costs and enable mechanically flexible implementations, but
concomitantly diminishes optical absorption. Coherent optical effects can help
alleviate this inevitable drawback at discrete frequencies. For example,
coherent perfect absorption guarantees that light is fully absorbed in a thin
layer regardless of material or thickness but only on resonance. Here we show
that omni resonance delivers such coherent enhancement over a broad bandwidth
by structuring the optical field to nullify the angular dispersion intrinsic to
resonant structures. After embedding an amorphous-silicon thin film
photovoltaic cell in a planar cavity, pre conditioning the incident light using
an alignment free optical arrangement severs the link between the resonant
bandwidth and the cavity photon lifetime, thereby rendering the cavity omni
resonant. Coherently enhanced near infrared absorption doubles the photocurrent
over the targeted spectral range 660 to 740 nm where every wavelength
resonates. These results may pave the way to transparent solar cells that
optimally harvest near infrared light.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:04:35 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jan 2020 17:22:28 GMT""}]","2020-01-14"
"1911.09277","Alexander Kurganov","Alexander Kurganov, Yongle Liu and Vladimir Zeitlin","A Well-Balanced Central-Upwind Scheme for the Thermal Rotating Shallow
  Water Equations",,,"10.1016/j.jcp.2020.109414",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a well-balanced central-upwind scheme for rotating shallow water
model with horizontal temperature and/or density gradients---the thermal
rotating shallow water (TRSW). The scheme is designed using the flux
globalization approach: first, the source terms are incorporated into the
fluxes, which results in a hyperbolic system with global fluxes; second, we
apply the Riemann-problem-solver-free central-upwind scheme to the rewritten
system. We ensure that the resulting method is well-balanced by switching off
the numerical diffusion when the computed solution is near (at)
thermo-geostrophic equilibria.
  The designed scheme is successfully tested on a series of numerical examples.
Motivated by future applications to large-scale motions in the ocean and
atmosphere, the model is considered on the tangent plane to a rotating planet
both in mid-latitudes and at the Equator. The numerical scheme is shown to be
capable of quite accurately maintaining the equilibrium states in the presence
of nontrivial topography and rotation. Prior to numerical simulations, an
analysis of the TRSW model based on the use of Lagrangian variables is
presented, allowing one to obtain criteria of existence and uniqueness of the
equilibrium state, of the wave-breaking and shock formation, and of instability
development out of given initial conditions. The established criteria are
confirmed in the conducted numerical experiments.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:06:36 GMT""}]","2020-04-22"
"1911.09278","Venkatesh Sridhar","Venkatesh Sridhar, Xiao Wang, Gregery T. Buzzard, Charles A. Bouman","Distributed Iterative CT Reconstruction using Multi-Agent Consensus
  Equilibrium",,,,,"eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model-Based Image Reconstruction (MBIR) methods significantly enhance the
quality of computed tomographic (CT) reconstructions relative to analytical
techniques, but are limited by high computational cost. In this paper, we
propose a multi-agent consensus equilibrium (MACE) algorithm for distributing
both the computation and memory of MBIR reconstruction across a large number of
parallel nodes. In MACE, each node stores only a sparse subset of views and a
small portion of the system matrix, and each parallel node performs a local
sparse-view reconstruction, which based on repeated feedback from other nodes,
converges to the global optimum. Our distributed approach can also incorporate
advanced denoisers as priors to enhance reconstruction quality. In this case,
we obtain a parallel solution to the serial framework of Plug-n-play (PnP)
priors, which we call MACE-PnP. In order to make MACE practical, we introduce a
partial update method that eliminates nested iterations and prove that it
converges to the same global solution. Finally, we validate our approach on a
distributed memory system with real CT data. We also demonstrate an
implementation of our approach on a massive supercomputer that can perform
large-scale reconstruction in real-time.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:12:25 GMT""}]","2019-11-22"
"1911.09279","Yunlong Wang","Guang Jiang, Mengzhen Shi, Ying Su, Pengcheng An, Brian Y. Lim,
  Yunlong Wang","NaMemo: Enhancing Lecturers' Interpersonal Competence of Remembering
  Students' Names","DIS '20 Companion",,"10.1145/3393914.3395860",,"cs.HC cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Addressing students by their names helps a teacher to start building rapport
with students and thus facilitates their classroom participation. However, this
basic yet effective skill has become rather challenging for university
lecturers, who have to handle large-sized (sometimes exceeding 100) groups in
their daily teaching. To enhance lecturers' competence in delivering
interpersonal interaction, we developed NaMemo, a real-time name-indicating
system based on a dedicated face-recognition pipeline. This paper presents the
system design, the pilot feasibility test, and our plan for the following
study, which aims to evaluate NaMemo's impacts on learning and teaching, as
well as to probe design implications including privacy considerations.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:13:55 GMT""},{""version"":""v2"",""created"":""Sat, 14 Mar 2020 04:10:58 GMT""},{""version"":""v3"",""created"":""Tue, 17 Mar 2020 01:07:42 GMT""},{""version"":""v4"",""created"":""Sun, 19 Apr 2020 06:45:07 GMT""}]","2020-04-21"
"1911.09280","Boseong Jeon","Boseong Jeon and H.Jin Kim","Integrated Motion Planner for Real-time Aerial Videography with a Drone
  in a Dense Environment",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This letter suggests an integrated approach for a drone (or multirotor) to
perform an autonomous videography task in a 3-D obstacle environment by
following a moving object. The proposed system includes 1) a target motion
prediction module which can be applied to dense environments and 2) a
hierarchical chasing planner based on a proposed metric for visibility. In the
prediction module, we minimize observation error given that the target object
itself does not collide with obstacles. The estimated future trajectory of
target is obtained by covariant optimization. The other module, chasing
planner, is in a bi-level structure composed of preplanner and smooth planner.
In the first phase, we leverage a graph-search method to preplan a chasing
corridor which incorporates safety and visibility of target during a time
window. In the subsequent phase, we generate a smooth and dynamically feasible
path within the corridor using quadratic programming (QP). We validate our
approach with multiple complex scenarios and actual experiments. The source
code can be found in https://github.com/icsl-Jeon/traj_gen_vis
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:17:33 GMT""}]","2019-11-22"
"1911.09281","Abhijit Suprem","Abhijit Suprem and Calton Pu","Event Detection in Noisy Streaming Data with Combination of
  Corroborative and Probabilistic Sources",,"IEEE Collaboration in Computing 2019",,,"cs.LG cs.SI cs.SY eess.SY stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Global physical event detection has traditionally relied on dense coverage of
physical sensors around the world; while this is an expensive undertaking,
there have not been alternatives until recently. The ubiquity of social
networks and human sensors in the field provides a tremendous amount of
real-time, live data about true physical events from around the world. However,
while such human sensor data have been exploited for retrospective large-scale
event detection, such as hurricanes or earthquakes, they has been limited to no
success in exploiting this rich resource for general physical event detection.
  Prior implementation approaches have suffered from the concept drift
phenomenon, where real-world data exhibits constant, unknown, unbounded changes
in its data distribution, making static machine learning models ineffective in
the long term. We propose and implement an end-to-end collaborative drift
adaptive system that integrates corroborative and probabilistic sources to
deliver real-time predictions. Furthermore, out system is adaptive to concept
drift and performs automated continuous learning to maintain high performance.
We demonstrate our approach in a real-time demo available online for landslide
disaster detection, with extensibility to other real-world physical events such
as flooding, wildfires, hurricanes, and earthquakes.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:19:16 GMT""}]","2019-12-16"
"1911.09282","Chikako Ishizuka","C. Ishizuka, X. Zhang, M.D. Usang, F.A. Ivanyuk, S. Chiba","Fission of super-heavy elements: $^{132}$Sn-plus-the-rest, or
  $^{208}$Pb-plus-the-rest ?","4 pages, 4 figures","Phys. Rev. C 101, 011601 (2020)","10.1103/PhysRevC.101.011601",,"nucl-th astro-ph.HE nucl-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we try to settle down the controversial predictions on the
effect of doubly magic nuclei $^{132}$Sn and $^{208}$Pb on the mass
distributions of fission fragments of super-heavy nuclei. For this we have
calculated the mass distribution of super-heavy nuclei from $^{286}$Cn to
$^{306}$122 within the dynamical 4-dimensional Langevin approach. We have found
that in ""light"" super-heavies the influence of $^{208}$Pb on the mass
distributions is present but negligible small. In ""heavy"" super-heavies,
Z=120-122, the (quasi)symmetric peaks and strongly asymmetric peaks at fragment
mass $A_F$ close to $A_F$=208 are of comparable magnitude.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:20:38 GMT""},{""version"":""v2"",""created"":""Wed, 18 Dec 2019 02:27:41 GMT""},{""version"":""v3"",""created"":""Mon, 6 Jan 2020 02:17:17 GMT""}]","2020-02-05"
"1911.09283","Yongxin Chen","Zeji Yi, Zhefeng Cao, Evangelos Theodorou, Yongxin Chen","Nonlinear Covariance Control via Differential Dynamic Programming","7 pages, 5 figures",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider covariance control problems for nonlinear stochastic systems. Our
objective is to find an optimal control strategy to steer the state from an
initial distribution to a terminal one with specified mean and covariance. This
problem is considerably more complicated than previous studies on covariance
control for linear systems. We leverage a widely used technique - differential
dynamic programming - in nonlinear optimal control to achieve our goal. In
particular, we adopt the stochastic differential dynamic programming framework
to handle the stochastic dynamics. Additionally, to enforce the terminal
statistical constraints, we construct a Lagrangian and apply a primal-dual type
algorithm. Several examples are presented to demonstrate the effectiveness of
our framework.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:24:00 GMT""}]","2019-11-22"
"1911.09284","Klaus Mueller","Nafees Ahmed and Klaus Mueller","EnergyScout: A Consumer Oriented Dashboard for Smart Meter Data
  Analytics",,,,,"cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The increasing popularity of smart meters provides energy consumers in
households with unprecedented opportunities for understanding and modifying
their energy use. However, while a variety of solutions, both commercial and
academic,have been proposed, research on effective visual analysis tools is
still needed to achieve widespread adoption of smart meters. In this paper we
explore an interface that seeks to balance the tradeoff between complexity and
usability. We worked with real household data and in close collaboration with
consumer experts of a large local utility company. Based on their continued
feedback we designed EnergyScout - a dashboard with a versatile set of highly
interactive visual tools with which consumers can understand the energy
consumption of their household devices, discover the impact of their usage
patterns, compare them with usage patterns of the past, and see via what-if
analysis what effects a modification of these patterns may have, also in the
context of modulated incentivized pricing, social and personal events, outside
temperature, and weather. All of these are events which could explain certain
usage patterns and help motivate a modification of behavior. We tested
EnergyScout with various groups of people, households, and energy bill
responsibilities in order to gauge the merits of this system.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:26:42 GMT""}]","2019-11-22"
"1911.09285","Asaf Karagila","Asaf Karagila","Iterated failures of choice","Complete rewrite of the paper; 22 pages",,,,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We combine several folklore observations to provide a working framework for
iterating constructions which contradict the axiom of choice. We use this to
define a model in which any kind of structural failure must fail with a proper
class of counterexamples. For example, the rational numbers have a proper class
of non-isomorphic algebraic closures, every partial order embeds into the
cardinals of the model, every set is the image of a Dedekind-finite set, every
weak choice axiom of the form $\mathsf{AC}_X^Y$ fails with a proper class of
counterexamples, every field has a vector space with two linearly independent
vectors but without endomorphisms that are not scalar multiplication, etc.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:30:04 GMT""},{""version"":""v2"",""created"":""Tue, 26 Nov 2019 14:49:48 GMT""},{""version"":""v3"",""created"":""Fri, 23 Jul 2021 16:06:30 GMT""}]","2021-07-26"
"1911.09286","Shashank Acharya","Shashank Acharya, Wenjun Kou, Sourav Halder, Dustin A. Carlson, Peter
  J. Kahrilas, John E. Pandolfino and Neelesh A. Patankar","Pumping Patterns and Work Done during Peristalsis in Finite-length
  Elastic Tubes","Paper was updated based on comments. Some content was moved to
  supplementary materials section to reduce the length of the paper",,"10.1115/1.4050284",,"physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Balloon dilation catheters are often used to quantify the physiological state
of peristaltic activity in tubular organs and comment on their ability to
propel fluid which is important for healthy human function. To fully understand
this system's behavior, we analyzed the effect of a solitary peristaltic wave
on a fluid-filled elastic tube with closed ends. A reduced order model that
predicts the resulting tube wall deformations, flow velocities and pressure
variations is presented. This simplified model is compared with detailed
fluid-structure 3D immersed boundary simulations of peristaltic pumping in tube
walls made of hyperelastic material. The major dynamics observed in the 3D
simulations were also displayed by our 1D model under laminar flow conditions.
Using the 1D model, several pumping regimes were investigated and presented in
the form of a regime map that summarizes the system's response for a range of
physiological conditions. Finally, the amount of work done during a peristaltic
event in this configuration was defined and quantified. The variation of
elastic energy and work done during pumping was found to have a unique
signature for each regime. An extension of the 1D model is applied to enhance
patient data collected by the device and find the work done for a typical
esophageal peristaltic wave. This detailed characterization of the system's
behavior aids in better interpreting the clinical data obtained from dilation
catheters. Additionally, the pumping capacity of the esophagus can be
quantified for comparative studies between disease groups.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:38:04 GMT""},{""version"":""v2"",""created"":""Mon, 18 Jan 2021 07:24:17 GMT""}]","2021-02-25"
"1911.09287","Adam Dziedzic","Adam Dziedzic and John Paparrizos and Sanjay Krishnan and Aaron Elmore
  and Michael Franklin","Band-limited Training and Inference for Convolutional Neural Networks","Published at International Conference on Machine Learning (ICML)",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The convolutional layers are core building blocks of neural network
architectures. In general, a convolutional filter applies to the entire
frequency spectrum of the input data. We explore artificially constraining the
frequency spectra of these filters and data, called band-limiting, during
training. The frequency domain constraints apply to both the feed-forward and
back-propagation steps. Experimentally, we observe that Convolutional Neural
Networks (CNNs) are resilient to this compression scheme and results suggest
that CNNs learn to leverage lower-frequency components. In particular, we
found: (1) band-limited training can effectively control the resource usage
(GPU and memory); (2) models trained with band-limited layers retain high
prediction accuracy; and (3) requires no modification to existing training
algorithms or neural network architectures to use unlike other compression
schemes.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:43:02 GMT""}]","2019-11-22"
"1911.09288","Tal Golan","Tal Golan, Prashant C. Raju, Nikolaus Kriegeskorte","Controversial stimuli: pitting neural networks against each other as
  models of human recognition",,"Proceedings of the National Academy of Sciences. Nov 2020,
  201912334","10.1073/pnas.1912334117",,"cs.CV q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distinct scientific theories can make similar predictions. To adjudicate
between theories, we must design experiments for which the theories make
distinct predictions. Here we consider the problem of comparing deep neural
networks as models of human visual recognition. To efficiently compare models'
ability to predict human responses, we synthesize controversial stimuli: images
for which different models produce distinct responses. We applied this approach
to two visual recognition tasks, handwritten digits (MNIST) and objects in
small natural images (CIFAR-10). For each task, we synthesized controversial
stimuli to maximize the disagreement among models which employed different
architectures and recognition algorithms. Human subjects viewed hundreds of
these stimuli, as well as natural examples, and judged the probability of
presence of each digit/object category in each image. We quantified how
accurately each model predicted the human judgments. The best performing models
were a generative Analysis-by-Synthesis model (based on variational
autoencoders) for MNIST and a hybrid discriminative-generative Joint Energy
Model for CIFAR-10. These DNNs, which model the distribution of images,
performed better than purely discriminative DNNs, which learn only to map
images to labels. None of the candidate models fully explained the human
responses. Controversial stimuli generalize the concept of adversarial
examples, obviating the need to assume a ground-truth model. Unlike natural
images, controversial stimuli are not constrained to the stimulus distribution
models are trained on, thus providing severe out-of-distribution tests that
reveal the models' inductive biases. Controversial stimuli therefore provide
powerful probes of discrepancies between models and human perception.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 04:55:41 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jul 2020 04:47:43 GMT""}]","2020-11-25"
"1911.09289","Krishnendu Sengupta","E. Nakhmedov, B. D. Suleymanli, O. Z. Alekperov, F. Tatardar, H.
  Mammadov, A. A. Konovko, A. M. Saletsky, Yu. M. Shukrinov, K. Sengupta, and
  B. Tanatar","Josephson current between two $p$-wave superconducting nanowires in the
  presence of Rashba spin-orbit interaction and Zeeman magnetic fields","v1; 17 pages, 14 figs",,"10.1016/j.physc.2020.1353753",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Josephson current between two one-dimensional nanowires with proximity
induced $p$-wave superconducting pairing is calculated in the presence of
Rashba spin-orbit interaction, in-plane and normal magnetic fields. We show
that Andreev retro-tunneling is realized by means of three channels. The main
contribution to the Josephson current gives a scattering in a conventional
particle-hole channel, when an electron-like quasiparticle reflects to a
hole-like quasiparticle with opposite spin yielding a current which depends
only on the order parameters' phase differences $\varphi$ and oscillates with
$4\pi$ period. Second anomalous particle-hole channel, corresponding to the
Andreev reflection of an incident electron-like quasiparticle to an hole-like
quasiparticle with the same spin orientation, survives only in the presence of
the in-plane magnetic field. The contribution of this channel to the Josephson
current oscillates with $4\pi$ period not only with $\varphi$ but also with
orientational angle of the in-plane magnetic field $\theta$ resulting in a
magneto-Josephson effect. Third anomalous particle-particle channel, which
represents a reflection of an electron-like (hole-like) quasiparticle to a
electron-like (hole-like) quasiparticle with opposite spin-orientation,
oscillates only with the in-plane magnetic field orientation angle $\theta$. We
present a detailed theoretical analysis of both DC and AC Josephson effects in
such a system showing contributions from all these channels and discuss
experiments which can test our theory.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:02:56 GMT""}]","2020-10-28"
"1911.09290","Zhao Kang","Zhao Kang, Wangtao Zhou, Zhitong Zhao, Junming Shao, Meng Han, Zenglin
  Xu","Large-scale Multi-view Subspace Clustering in Linear Time","Accepted by AAAI 2020",,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A plethora of multi-view subspace clustering (MVSC) methods have been
proposed over the past few years. Researchers manage to boost clustering
accuracy from different points of view. However, many state-of-the-art MVSC
algorithms, typically have a quadratic or even cubic complexity, are
inefficient and inherently difficult to apply at large scales. In the era of
big data, the computational issue becomes critical. To fill this gap, we
propose a large-scale MVSC (LMVSC) algorithm with linear order complexity.
Inspired by the idea of anchor graph, we first learn a smaller graph for each
view. Then, a novel approach is designed to integrate those graphs so that we
can implement spectral clustering on a smaller graph. Interestingly, it turns
out that our model also applies to single-view scenario. Extensive experiments
on various large-scale benchmark data sets validate the effectiveness and
efficiency of our approach with respect to state-of-the-art clustering methods.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:10:29 GMT""}]","2019-11-22"
"1911.09291","Pablo Samuel Castro","Pablo Samuel Castro","Scalable methods for computing state similarity in deterministic Markov
  Decision Processes","To appear in Proceedings of the Thirty-Fourth AAAI Conference on
  Artificial Intelligence (AAAI-20)",,,,"cs.LG cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new algorithms for computing and approximating bisimulation
metrics in Markov Decision Processes (MDPs). Bisimulation metrics are an
elegant formalism that capture behavioral equivalence between states and
provide strong theoretical guarantees on differences in optimal behaviour.
Unfortunately, their computation is expensive and requires a tabular
representation of the states, which has thus far rendered them impractical for
large problems. In this paper we present a new version of the metric that is
tied to a behavior policy in an MDP, along with an analysis of its theoretical
properties. We then present two new algorithms for approximating bisimulation
metrics in large, deterministic MDPs. The first does so via sampling and is
guaranteed to converge to the true metric. The second is a differentiable loss
which allows us to learn an approximation even for continuous state MDPs, which
prior to this work had not been possible.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:11:20 GMT""}]","2019-11-22"
"1911.09292","Adam Dziedzic","Vanlin Sathya, Adam Dziedzic, Monisha Ghosh, Sanjay Krishnan","Machine Learning based detection of multiple Wi-Fi BSSs for LTE-U CSAT","Published at International Conference on Computing, Networking and
  Communications (ICNC 2020)",,,,"cs.NI cs.LG","http://creativecommons.org/licenses/by/4.0/","  According to the LTE-U Forum specification, a LTE-U base-station (BS) reduces
its duty cycle from 50% to 33% when it senses an increase in the number of
co-channel Wi-Fi basic service sets (BSSs) from one to two. The detection of
the number of Wi-Fi BSSs that are operating on the channel in real-time,
without decoding the Wi-Fi packets, still remains a challenge. In this paper,
we present a novel machine learning (ML) approach that solves the problem by
using energy values observed during LTE-U OFF duration. Observing the energy
values (at LTE-U BS OFF time) is a much simpler operation than decoding the
entire Wi-Fi packets. In this work, we implement and validate the proposed ML
based approach in real-time experiments, and demonstrate that there are two
distinct patterns between one and two Wi-Fi APs. This approach delivers an
accuracy close to 100% compared to auto-correlation (AC) and energy detection
(ED) approaches.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:14:05 GMT""}]","2019-11-22"
"1911.09293","Jin Zhang","Jin Zhang, Jeffrey M. McMahon, Artem R. Oganov, Xinfeng Li, Xiao Dong,
  Huafeng Dong, Shengnan Wang","High-Temperature Superconductivity in the Ti--H System at High Pressures",,,"10.1103/PhysRevB.101.134108",,"cond-mat.mtrl-sci cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Search for stable high-pressure compounds in the Ti--H system reveals the
existence of titanium hydrides with new stoichiometries, including
Ibam-Ti$_2$H$_5$, I4/m-Ti$_5$H$_{13}$, I$\bar{4}$-Ti$_5$H$_{14}$, Fddd-TiH$_4$,
Immm-Ti$_2$H$_{13}$, P$\bar{1}$-TiH$_{12}$, and C2/m-TiH$_{22}$. Our
calculations predict I4/mmm $\rightarrow$ R$\bar{3}$m and I4/mmm $\rightarrow$
Cmma transitions in TiH and TiH$_2$, respectively. Phonons and the
electron--phonon coupling of all searched titanium hydrides are analyzed at
high pressure. It is found that Immm-Ti$_2$H$_{13}$ rather than the highest
hydrogen content C2/m-TiH$_{22}$, exhibits the highest superconducting critical
temperature T$_{c}$. The estimated T$_{c}$ of Immm-Ti$_2$H$_{13}$ and
C2/m-TiH$_{22}$ are respectively 127.4--149.4 K ($\mu^{*}$=0.1-0.15) at 350 GPa
and 91.3--110.2 K at 250 GPa by numerically solving the Eliashberg equations.
One of the effects of pressure on T$_{c}$ can be attributed to the softening
and hardening of phonons with increasing pressure.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:21:08 GMT""}]","2020-05-20"
"1911.09294","Guiwen Tan","Lipo Wang and Guiwen Tan, Hui Cao","Multi-level scalar structure in complex system analyses","This paper will be revised and new results will be added",,,,"physics.flu-dyn physics.data-an stat.CO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The geometrical structure is among the most fundamental ingredients in
understanding complex systems. Is there any systematic approach in defining
structures quantitatively, rather than illustratively? If yes, what are the
basic principles to follow? By introducing the concept of extremal points at
different scale levels, a multi-level dissipation element approach has been
developed to define structures at different scale levels, in accordance with
the concept of structure hierarchy. Each dissipation element can be
characterized by the length scale and the scalar variance inside. Using the
two-dimensional fractal Brownian motion as a benchmark case, the conditional
mean of the scalar difference with respect to the length scale shows clearly a
power law and the scaling exponent is in agreement with the Hurst number. For
the 3D turbulence velocity component, the 1/3 scaling law can be represented.
These results indicate the important linkage between the turbulence physics and
ow structure, if well posed and defined. In principle, the multi-level
dissipation element idea is generally applicable in analyzing other multiscale
complex systems as well.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:24:37 GMT""},{""version"":""v2"",""created"":""Tue, 26 May 2020 12:15:04 GMT""}]","2020-05-27"
"1911.09295","Enia Xhakaj","Enia Xhakaj, Benedikt Diemer, Alexie Leauthaud, Asher Wasserman, Song
  Huang, Yifei Luo, Susmita Adhikari, Sukhdeep Singh","How Accurately Can We Detect the Splashback Radius of Dark Matter Halos
  and its Correlation With Accretion Rate?",,,"10.1093/mnras/staa3046",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The splashback radius ($R_{\rm sp}$) of dark matter halos has recently been
detected using weak gravitational lensing and cross-correlations with galaxies.
However, different methods have been used to measure $R_{\rm sp}$ and to assess
the significance of its detection. In this paper, we use simulations to study
the precision and accuracy to which we can detect the splashback radius with 3D
density, 3D subhalo, and weak lensing profiles. We study how well various
methods and tracers recover $R_{\rm sp}$ by comparing it with the value
measured directly from particle dynamics. We show that estimates of $R_{\rm
sp}$ from density and subhalo profiles correspond to different percentiles of
the underlying $R_{\rm sp}$ distribution of particle orbits. At low accretion
rates, a second caustic appears and can bias results. Finally, we show that
upcoming lensing surveys may be able to constrain the splashback-accretion rate
relation directly.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:28:34 GMT""}]","2020-11-04"
"1911.09296","Ritwik Gupta","Ritwik Gupta, Richard Hosfelt, Sandra Sajeev, Nirav Patel, Bryce
  Goodman, Jigar Doshi, Eric Heim, Howie Choset, Matthew Gaston","xBD: A Dataset for Assessing Building Damage from Satellite Imagery","9 pages, 10 figures",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present xBD, a new, large-scale dataset for the advancement of change
detection and building damage assessment for humanitarian assistance and
disaster recovery research. Natural disaster response requires an accurate
understanding of damaged buildings in an affected region. Current response
strategies require in-person damage assessments within 24-48 hours of a
disaster. Massive potential exists for using aerial imagery combined with
computer vision algorithms to assess damage and reduce the potential danger to
human life. In collaboration with multiple disaster response agencies, xBD
provides pre- and post-event satellite imagery across a variety of disaster
events with building polygons, ordinal labels of damage level, and
corresponding satellite metadata. Furthermore, the dataset contains bounding
boxes and labels for environmental factors such as fire, water, and smoke. xBD
is the largest building damage assessment dataset to date, containing 850,736
building annotations across 45,362 km\textsuperscript{2} of imagery.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:30:13 GMT""}]","2019-11-22"
"1911.09297","Jianfei Tao","J. F. Tao, J. Cai, Q. Z. Xia, and J. Liu","Subfemtosecond glory hologrammetry for vectorial optical waveform
  reconstruction",,"Phys. Rev. A 101, 043416 (2020)","10.1103/PhysRevA.101.043416",,"physics.atom-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a new method to characterize the temporal structure
of arbitrary optical laser pulses with low pulse energies. This approach is
based on strong field photoelectron holography with the glory rescattering
effect as the underlying mechanism in the near-forward direction. Utilizing the
subfemtosecond glory rescattering process as a fast temporal gate to sample the
unknown light pulse, the time-dependent vectorial electric field can be
retrieved from the streaking photoelectron momentum spectra. Our method avoids
the challenging task of generation or manipulation of attosecond pulses and
signifies important progress in arbitrary optical waveform characterization.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:36:41 GMT""},{""version"":""v2"",""created"":""Sun, 22 Dec 2019 14:28:18 GMT""}]","2020-04-29"
"1911.09298","Ligong Han","Ligong Han, Ruijiang Gao, Mun Kim, Xin Tao, Bo Liu, Dimitris Metaxas","Robust Conditional GAN from Uncertainty-Aware Pairwise Comparisons","Accepted for spotlight at AAAI-20",,,,"cs.LG cs.CV","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Conditional generative adversarial networks have shown exceptional generation
performance over the past few years. However, they require large numbers of
annotations. To address this problem, we propose a novel generative adversarial
network utilizing weak supervision in the form of pairwise comparisons (PC-GAN)
for image attribute editing. In the light of Bayesian uncertainty estimation
and noise-tolerant adversarial training, PC-GAN can estimate attribute rating
efficiently and demonstrate robust performance in noise resistance. Through
extensive experiments, we show both qualitatively and quantitatively that
PC-GAN performs comparably with fully-supervised methods and outperforms
unsupervised baselines.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:37:46 GMT""},{""version"":""v2"",""created"":""Thu, 5 Mar 2020 00:08:23 GMT""}]","2020-03-06"
"1911.09299","Bingyuan Liu","Bingyuan Liu, Jiantao Zhang, Xiaoting Zhang, Wei Zhang, Chuanhui Yu,
  Yuan Zhou","Furnishing Your Room by What You See: An End-to-End Furniture Set
  Retrieval Framework with Rich Annotated Benchmark Dataset","project website :
  https://www.kujiale.com/festatic/furnitureSetRetrieval",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Understanding interior scenes has attracted enormous interest in computer
vision community. However, few works focus on the understanding of furniture
within the scenes and a large-scale dataset is also lacked to advance the
field. In this paper, we first fill the gap by presenting DeepFurniture, a
richly annotated large indoor scene dataset, including 24k indoor images, 170k
furniture instances and 20k unique furniture identities. On the dataset, we
introduce a new benchmark, named furniture set retrieval. Given an indoor photo
as input, the task requires to detect all the furniture instances and search a
matched set of furniture identities. To address this challenging task, we
propose a feature and context embedding based framework. It contains 3 major
contributions: (1) An improved Mask-RCNN model with an additional mask-based
classifier is introduced for better utilizing the mask information to relieve
the occlusion problems in furniture detection context. (2) A multi-task style
Siamese network is proposed to train the feature embedding model for retrieval,
which is composed of a classification subnet supervised by self-clustered
pseudo attributes and a verification subnet to estimate whether the input pair
is matched. (3) In order to model the relationship of the furniture entities in
an interior design, a context embedding model is employed to re-rank the
retrieval results. Extensive experiments demonstrate the effectiveness of each
module and the overall system.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:42:19 GMT""},{""version"":""v2"",""created"":""Fri, 31 Jan 2020 10:50:06 GMT""}]","2020-02-03"
"1911.09300","Nikita Pavlov","N. S. Pavlov, T. K. Kim, A. Yaresko, Ki-Young Choi, I. A. Nekrasov and
  D. V. Evtushinsky","Weakness of Correlation Effect Manifestation in BaNi$_2$As$_2$: ARPES
  and LDA+DMFT study","31 pages, 10 figures","J. Phys. Chem. C 2021, 125, 51, 28075-28087","10.1021/acs.jpcc.1c08142",,"cond-mat.str-el cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The electronic spectral function of BaNi$_2$As$_2$ is investigated using both
the angle-resolved photoemission spectroscopy (ARPES) and a combined
computational scheme of local density approximation together with dynamical
mean-field theory (LDA+DMFT). In contrast to well studied isostructural iron
arsenide high temperature superconductors, the BaNi$_2$As$_2$ demonstrate weak
correlation effects although Ni-3d elections have even lager on-site
interaction than Fe-3d ones. LDA+DMFT effective mass enhancement for bands
crossing the Fermi level is found to be only about $1.2$ which agrees well with
ARPES data. This reduction of the correlation manifestation with respect to
iron pnictides comes from the increase of 3d-orbital filling, when going from
Fe to Ni. The electron correlations cause remarkable reconstruction of the bare
BaNi$_2$As$_2$ LDA band structure below $-0.8$ eV due to self-energy effect. A
simplified toy model to understand weakness of correlation effects in
BaNi$_2$As$_2$ and to describe the LDA+DMFT self-energy shape is discussed. For
more realistic comparison of LDA+DMFT spectral function maps with ARPES data we
take into account several experimental features: the photoemission
cross-section, the experimental energy and angular resolutions and the
photo-hole lifetime effects. Thus presented here LDA+DMFT calculations with
experimental features included provide nearly qualitative agreement with ARPES
data and assure the observation of a dramatic apparent decrease of the
correlation strength compared to the Fe compounds.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:57:13 GMT""},{""version"":""v2"",""created"":""Tue, 18 Jan 2022 10:42:59 GMT""}]","2022-01-19"
"1911.09301","Nishi Doshi","Nishi Doshi, Gitam Shikhenawis, Suman K Mitra","Image Aesthetics Assessment using Multi Channel Convolutional Neural
  Networks",,,,"Paper ID 33","cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image Aesthetics Assessment is one of the emerging domains in research. The
domain deals with classification of images into categories depending on the
basis of how pleasant they are for the users to watch. In this article, the
focus is on categorizing the images in high quality and low quality image. Deep
convolutional neural networks are used to classify the images. Instead of using
just the raw image as input, different crops and saliency maps of the images
are also used, as input to the proposed multi channel CNN architecture. The
experiments reported on widely used AVA database show improvement in the
aesthetic assessment performance over existing approaches.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:57:44 GMT""}]","2019-11-22"
"1911.09302","Nicol\'as Vald\'es-Meller","William Donnelly, Sydney Timmerman, Nicol\'as Vald\'es-Meller","Entanglement entropy and the large $N$ expansion of two-dimensional
  Yang-Mills theory","31 pages, 8 figures",,"10.1007/JHEP04(2020)182",,"hep-th gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Two-dimensional Yang-Mills theory is a useful model of an exactly solvable
gauge theory with a string theory dual at large $N$. We calculate entanglement
entropy in the $1/N$ expansion by mapping the theory to a system of $N$
fermions interacting via a repulsive entropic force. The entropy is a sum of
two terms: the ""Boltzmann entropy"", $\log \dim (R)$ per point of the entangling
surface, which counts the number of distinct microstates, and the ""Shannon
entropy"", $- \sum p_R \log p_R$, which captures fluctuations of the macroscopic
state. We find that the entropy scales as $N^2$ in the large $N$ limit, and
that at this order only the Boltzmann entropy contributes. We further show that
the Shannon entropy scales linearly with $N$, and confirm this behaviour with
numerical simulations. While the term of order $N$ is surprising from the point
of view of the string dual - in which only even powers of $N$ appear in the
partition function - we trace it to a breakdown of large $N$ counting caused by
the replica trick. This mechanism could lead to corrections to holographic
entanglement entropy larger than expected from semiclassical field theory.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:01:10 GMT""}]","2020-05-20"
"1911.09303","Hon Yin Wong","Aaron Chan and William Wong","Irreducible representations of the symmetric groups from slash
  homologies of p-complexes","16 pages, 2 figures. Rewritten the proof of first theorem.
  Substantial rearrangement of materials in other sections. Comments welcomed",,,,"math.RT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the 40s, Mayer introduced a construction of (simplicial) $p$-complex by
using the unsigned boundary map and taking coefficients of chains modulo $p$.
We look at such a $p$-complex associated to an $(n-1)$-simplex; in which case,
this is also a $p$-complex of representations of the symmetric group of rank
$n$ - specifically, of permutation modules associated to two-row compositions.
In this article, we calculate the so-called slash homology - a homology theory
introduced by Khovanov and Qi - of such a $p$-complex. We show that every
non-trivial slash homology group appears as an irreducible representation
associated to two-row partitions, and how this calculation leads to a basis of
these irreducible representations given by the so-called $p$-standard tableaux.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:01:10 GMT""},{""version"":""v2"",""created"":""Fri, 29 May 2020 14:20:50 GMT""}]","2020-06-01"
"1911.09304","Hang Jiang","Hang Jiang, Xianzhe Zhang, Jinho D. Choi","Automatic Text-based Personality Recognition on Monologues and
  Multiparty Dialogues Using Attentive Networks and Contextual Embeddings","Paper Accepted to AAAI-20 Student Abstract and Poster Program",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Previous works related to automatic personality recognition focus on using
traditional classification models with linguistic features. However, attentive
neural networks with contextual embeddings, which have achieved huge success in
text classification, are rarely explored for this task. In this project, we
have two major contributions. First, we create the first dialogue-based
personality dataset, FriendsPersona, by annotating 5 personality traits of
speakers from Friends TV Show through crowdsourcing. Second, we present a novel
approach to automatic personality recognition using pre-trained contextual
embeddings (BERT and RoBERTa) and attentive neural networks. Our models largely
improve the state-of-art results on the monologue Essays dataset by 2.49%, and
establish a solid benchmark on our FriendsPersona. By comparing results in two
datasets, we demonstrate the challenges of modeling personality in multi-party
dialogue.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:14:05 GMT""}]","2019-11-22"
"1911.09305","Hung Dang","Hung Dang and Ee-Chien Chang","Self-Expiring Data Capsule using Trusted Execution Environment",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data privacy is unarguably of extreme importance. Nonetheless, there exist
various daunting challenges to safe-guarding data privacy. These challenges
stem from the fact that data owners have little control over their data once it
has transgressed their local storage and been managed by third parties whose
trustworthiness is questionable at times. Our work seeks to enhance data
privacy by constructing a self-expiring data capsule. Sensitive data is
encapsulated into a capsule which is associated with an access policy an
expiring condition. The former indicates eligibility of functions that can
access the data, and the latter dictates when the data should become
inaccessible to anyone, including the previously eligible functions. Access to
the data capsule, as well as its dismantling once the expiring condition is
met, are governed by a committee of independent and mutually distrusting nodes.
The pivotal contribution of our work is an integration of hardware primitive,
state machine replication and threshold secret sharing in the design of the
self-expiring data encapsulation framework. We implement the proposed framework
in a system called TEEKAP. Our empirical experiments conducted on a realistic
deployment setting with the access control committee spanning across four
geographical regions reveal that TEEKAP can process access requests at scale
with sub-second latency.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:17:55 GMT""}]","2019-11-22"
"1911.09306","Sorna Prava Barik","Sorna Prava Barik, Rashmi R. Nayak and Kamal L. Panigrahi","On finite-size spiky strings in $AdS_3 \times S^3\times T^4$ with mixed
  fluxes","23 pages, Added references. To appear in JHEP",,,,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss finite-size corrections to the spiky strings in $AdS$ space which
is dual to the long $\mathcal{N}=4$ SYM operators of the form Tr($\Delta_+
^{J_1}\phi_1\Delta_+ ^{J_2}\phi_2...\Delta_+ ^{J_n}\phi_n$). We express the
finite-size dispersion relation in terms of Lambert $\mathbf{W}$-function. We
further establish the finite-size scaling relation between energy and angular
momentum of the spiky string in presence of mixed fluxes in terms of
$\mathbf{W}$-function. We comment on the solution in pure NS-NS background as
well.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:31:01 GMT""},{""version"":""v2"",""created"":""Wed, 4 Dec 2019 10:41:00 GMT""},{""version"":""v3"",""created"":""Thu, 30 Jan 2020 10:10:07 GMT""}]","2020-01-31"
"1911.09307","Ke Sun","Ke Sun, Bing Yu, Zhouchen Lin, Zhanxing Zhu","Patch-level Neighborhood Interpolation: A General and Effective
  Graph-based Regularization Strategy",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Regularization plays a crucial role in machine learning models, especially
for deep neural networks. The existing regularization techniques mainly reply
on the i.i.d. assumption and only employ the information of the current sample,
without the leverage of neighboring information between samples. In this work,
we propose a general regularizer called Patch-level Neighborhood
Interpolation~(\textbf{Pani}) that fully exploits the relationship between
samples. Furthermore, by explicitly constructing a patch-level graph in the
different network layers and interpolating the neighborhood features to refine
the representation of the current sample, our Patch-level Neighborhood
Interpolation can then be applied to enhance two popular regularization
strategies, namely Virtual Adversarial Training (VAT) and MixUp, yielding their
neighborhood versions. The first derived \textbf{Pani VAT} presents a novel way
to construct non-local adversarial smoothness by incorporating patch-level
interpolated perturbations. In addition, the \textbf{Pani MixUp} method extends
the original MixUp regularization to the patch level and then can be developed
to MixMatch, achieving the state-of-the-art performance. Finally, extensive
experiments are conducted to verify the effectiveness of the Patch-level
Neighborhood Interpolation in both supervised and semi-supervised settings.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:31:59 GMT""}]","2019-11-22"
"1911.09308","Noboru Ito","Noboru Ito and Jun Yoshida","Crossing change on Khovanov homology and a categorified Vassiliev skein
  relation","22 pages",,,,"math.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Khovanov homology is a categorification of the Jones polynomial, so it may be
seen as a kind of quantum invariant of knots and links. Although polynomial
quantum invariants are deeply involved with Vassiliev (aka. finite type)
invariants, the relation remains unclear in case of Khovanov homology. Aiming
at it, in this paper, we discuss a categorified version of Vassiliev skein
relation on Khovanov homology. More precisely, we will show that the
""genus-one"" operation gives rise to a crossing change on Khovanov complexes.
Invariance under Reidemeister moves turns out, and it enables us to extend
Khovanov homology to singular links. We then see that a long exact sequence of
Khovanov homology groups categorifies Vassiliev skein relation for the Jones
polynomials. In particular, the Jones polynomial is recovered even for singular
links. We in addition discuss the FI relation on Khovanov homology.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:49:46 GMT""}]","2019-11-22"
"1911.09309","Zhijie Chen","Zhijie Chen, Junchi Yan, Longyuan Li and Xiaokang Yang","Decoding Spiking Mechanism with Dynamic Learning on Neuron Population",,,,,"q-bio.NC cs.LG cs.NE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A main concern in cognitive neuroscience is to decode the overt neural spike
train observations and infer latent representations under neural circuits.
However, traditional methods entail strong prior on network structure and
hardly meet the demand for real spike data. Here we propose a novel neural
network approach called Neuron Activation Network that extracts neural
information explicitly from single trial neuron population spike trains. Our
proposed method consists of a spatiotemporal learning procedure on sensory
environment and a message passing mechanism on population graph, followed by a
neuron activation process in a recursive fashion. Our model is aimed to
reconstruct neuron information while inferring representations of neuron
spiking states. We apply our model to retinal ganglion cells and the
experimental results suggest that our model holds a more potent capability in
generating neural spike sequences with high fidelity than the state-of-the-art
methods, as well as being more expressive and having potential to disclose
latent spiking mechanism. The source code will be released with the final
paper.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:56:57 GMT""}]","2019-11-22"
"1911.09310","Lantao Yu","Yuxuan Song, Lantao Yu, Zhangjie Cao, Zhiming Zhou, Jian Shen, Shuo
  Shao, Weinan Zhang, Yong Yu","Improving Unsupervised Domain Adaptation with Variational Information
  Bottleneck",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Domain adaptation aims to leverage the supervision signal of source domain to
obtain an accurate model for target domain, where the labels are not available.
To leverage and adapt the label information from source domain, most existing
methods employ a feature extracting function and match the marginal
distributions of source and target domains in a shared feature space. In this
paper, from the perspective of information theory, we show that representation
matching is actually an insufficient constraint on the feature space for
obtaining a model with good generalization performance in target domain. We
then propose variational bottleneck domain adaptation (VBDA), a new domain
adaptation method which improves feature transferability by explicitly
enforcing the feature extractor to ignore the task-irrelevant factors and focus
on the information that is essential to the task of interest for both source
and target domains. Extensive experimental results demonstrate that VBDA
significantly outperforms state-of-the-art methods across three domain
adaptation benchmark datasets.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:07:17 GMT""}]","2019-11-22"
"1911.09311","Tenavi Nakamura-Zimmerer","Tenavi Nakamura-Zimmerer and Daniele Venturi and Qi Gong and Wei Kang","Density Propagation with Characteristics-based Deep Learning","This work has been submitted to IFAC for possible publication",,,,"math.DS stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Uncertainty propagation in nonlinear dynamic systems remains an outstanding
problem in scientific computing and control. Numerous approaches have been
developed, but are limited in their capability to tackle problems with more
than a few uncertain variables or require large amounts of simulation data. In
this paper, we propose a data-driven method for approximating joint probability
density functions (PDFs) of nonlinear dynamic systems with initial condition
and parameter uncertainty. Our approach leverages on the power of deep learning
to deal with high-dimensional inputs, but we overcome the need for huge
quantities of training data by encoding PDF evolution equations directly into
the optimization problem. We demonstrate the potential of the proposed method
by applying it to evaluate the robustness of a feedback controller for a
six-dimensional rigid body with parameter uncertainty.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:09:38 GMT""}]","2019-11-22"
"1911.09312","Tianwei Zhang","Tianwei Zhang and Jun Jiang and Yinqian Zhang","Revisiting and Evaluating Software Side-channel Vulnerabilities and
  Countermeasures in Cryptographic Applications",,,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We systematize software side-channel attacks with a focus on vulnerabilities
and countermeasures in the cryptographic implementations. Particularly, we
survey past research literature to categorize vulnerable implementations, and
identify common strategies to eliminate them. We then evaluate popular
libraries and applications, quantitatively measuring and comparing the
vulnerability severity, response time and coverage. Based on these
characterizations and evaluations, we offer some insights for side-channel
researchers, cryptographic software developers and users. We hope our study can
inspire the side-channel research community to discover new vulnerabilities,
and more importantly, to fortify applications against them.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:09:40 GMT""},{""version"":""v2"",""created"":""Thu, 12 Dec 2019 15:54:08 GMT""}]","2019-12-13"
"1911.09313","Zhenyu Wu","Zhenyu Wu, Mingxing Wen, Guohao Peng, Xiaoyu Tang, Danwei Wang","Magnetic-Assisted Initialization for Infrastructure-free Mobile Robot
  Localization",,,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most of the existing mobile robot localization solutions are either heavily
dependent on pre-installed infrastructures or having difficulty working in
highly repetitive environments which do not have sufficient unique features. To
address this problem, we propose a magnetic-assisted initialization approach
that enhances the performance of infrastructure-free mobile robot localization
in repetitive featureless environments. The proposed system adopts a
coarse-to-fine structure, which mainly consists of two parts: magnetic
field-based matching and laser scan matching. Firstly, the interpolated
magnetic field map is built and the initial pose of the mobile robot is partly
determined by the k-Nearest Neighbors (k-NN) algorithm. Next, with the fusion
of prior initial pose information, the robot is localized by laser scan
matching more accurately and efficiently. In our experiment, the mobile robot
was successfully localized in a featureless rectangular corridor with a success
rate of 88% and an average correct localization time of 6.6 seconds.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:11:06 GMT""}]","2019-11-22"
"1911.09314","Gudrun Heinrich","Long Chen, Gudrun Heinrich, Stephan Jahn, Stephen P. Jones, Matthias
  Kerner, Johannes Schlenk, Hiroshi Yokoya","Photon pair production in gluon fusion: Top quark effects at NLO with
  threshold matching","Version 2: figure 6 added; version published in JHEP","JHEP 04 (2020) 115","10.1007/JHEP04(2020)115","CERN-TH-2019-195, MPP-2019-236, PSI-PR-19-24, ZU-TH 48/19","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a calculation of the NLO QCD corrections to the loop-induced
production of a photon pair through gluon fusion, including massive top quarks
at two loops, where the two-loop integrals are calculated numerically. Matching
the fixed-order NLO results to a threshold expansion, we obtain accurate
results around the top quark pair production threshold. We analyse how the top
quark threshold corrections affect distributions of the photon pair invariant
mass and comment on the possibility of determining the top quark mass from
precision measurements of the diphoton invariant mass spectrum.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:11:11 GMT""},{""version"":""v2"",""created"":""Tue, 13 Oct 2020 14:13:58 GMT""}]","2020-10-14"
"1911.09315","Alberto Barbado Gonzalez","Alberto Barbado, \'Oscar Corcho, Richard Benjamins","Rule Extraction in Unsupervised Anomaly Detection for Model
  Explainability: Application to OneClass SVM","23 pages, 18 figures","Expert Systems with Applications Volume 189, 1 March 2022, 116100","10.1016/j.eswa.2021.116100",,"cs.LG cs.AI","http://creativecommons.org/licenses/by-sa/4.0/","  OneClass SVM is a popular method for unsupervised anomaly detection. As many
other methods, it suffers from the black box problem: it is difficult to
justify, in an intuitive and simple manner, why the decision frontier is
identifying data points as anomalous or non anomalous. Such type of problem is
being widely addressed for supervised models. However, it is still an uncharted
area for unsupervised learning. In this paper, we evaluate several rule
extraction techniques over OneClass SVM models, as well as present alternative
designs for some of those algorithms. Together with that, we propose algorithms
to compute metrics related with eXplainable Artificial Intelligence (XAI)
regarding the ""comprehensibility"", ""representativeness"", ""stability"" and
""diversity"" of the extracted rules. We evaluate our proposals with different
datasets, including real-world data coming from industry. With this, our
proposal contributes to extend XAI techniques to unsupervised machine learning
models.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:14:43 GMT""},{""version"":""v2"",""created"":""Wed, 1 Apr 2020 11:10:00 GMT""},{""version"":""v3"",""created"":""Sat, 6 Jun 2020 09:21:27 GMT""},{""version"":""v4"",""created"":""Mon, 29 Jun 2020 07:07:28 GMT""},{""version"":""v5"",""created"":""Thu, 1 Apr 2021 08:24:04 GMT""}]","2021-11-08"
"1911.09316","Zhijie Chen","Zhijie Chen, Bo Yang, Cailian Chen, Xinping Guan","A Pre-Allocation Design for Cost Minimization and Delay Constraint in
  Vehicular Offloading System",,,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  To accommodate exponentially increasing traffic demands of vehicle-based
applications, operators are utilizing offloading as a promising technique to
improve quality of service (QoS), which gives rise to the application of Mobile
Edge Computing (MEC). While the conventional offloading paradigms focus on
delay and energy tradeoff, they either fail to find efficient models to
represent delay, especially the queueing delay, or underestimate the role of
MEC Server. In this paper, we propose a novel \textbf{P}re-\textbf{A}llocation
\textbf{D}esign for vehicular \textbf{O}ffloading (\textbf{PADO}). A task delay
queue is constructed based on an allocate-execute separate (AES) mechanism. Due
to the dynamics of vehicular network, we are inspired to utilize Lyapunov
optimization to minimize the execution cost of each vehicle and guarantee task
delay. The MEC Server with energy harvesting devices is also taken into
consideration of the system. The transaction between vehicles and server is
decided by a Stackelberg Game framework. We conduct extensive experiments to
show the property and superiority of our proposed framework.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:16:50 GMT""}]","2019-11-22"
"1911.09317","Yongle Qi","Yongle Qi, Suzhen Wu","Effect of X-Ray Irradiation on Threshold Voltage of AlGaN/GaN HEMTs with
  pGaN and MIS Gate",,,,,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Characteristic electrical curves of GaN HEMT devices from Infineon and
Transphorm are compared at different X-ray radiation dose. It is shown that the
device with pGaN gate is more robust having a stable threshold voltage (Vth).
The Vth of device with MIS gate shifts towards negative direction firstly and
shifts to forward direction then. A qualitative analysis is performed in the
paper. Such dynamic phenomenon is caused by releasing and trapping effects of
radiation induced charges both in the dielectric layer and the interface of the
device. It is summarized that pGaN gate based GaN HEMT is a promising solution
for further space use of electric source
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:18:07 GMT""}]","2019-11-22"
"1911.09318","Hyunjong Park","Hyunjong Park, Bumsub Ham","Relation Network for Person Re-identification","Accepted by AAAI 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Person re-identification (reID) aims at retrieving an image of the person of
interest from a set of images typically captured by multiple cameras. Recent
reID methods have shown that exploiting local features describing body parts,
together with a global feature of a person image itself, gives robust feature
representations, even in the case of missing body parts. However, using the
individual part-level features directly, without considering relations between
body parts, confuses differentiating identities of different persons having
similar attributes in corresponding parts. To address this issue, we propose a
new relation network for person reID that considers relations between
individual body parts and the rest of them. Our model makes a single part-level
feature incorporate partial information of other body parts as well, supporting
it to be more discriminative. We also introduce a global contrastive pooling
(GCP) method to obtain a global feature of a person image. We propose to use
contrastive features for GCP to complement conventional max and averaging
pooling techniques. We show that our model outperforms the state of the art on
the Market1501, DukeMTMC-reID and CUHK03 datasets, demonstrating the
effectiveness of our approach on discriminative person representations.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:21:11 GMT""},{""version"":""v2"",""created"":""Mon, 25 Nov 2019 06:37:10 GMT""}]","2019-11-26"
"1911.09319","Son Doan <","Son Doan, Mike Conway, Nigel Collier","An Empirical Study of Sections in Classifying Disease Outbreak Reports","13 pages, 2 tables, book chapter in Web-Based Applications in
  Healthcare and Biomedicine. Annals of Information Systems, vol 7. Springer,
  Boston, MA, 2010","Web-Based Applications in Healthcare and Biomedicine, pp 47-58,
  2010","10.1007/978-1-4419-1274-9_4",,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifying articles that relate to infectious diseases is a necessary step
for any automatic bio-surveillance system that monitors news articles from the
Internet. Unlike scientific articles which are available in a strongly
structured form, news articles are usually loosely structured. In this chapter,
we investigate the importance of each section and the effect of section
weighting on performance of text classification. The experimental results show
that (1) classification models using the headline and leading sentence achieve
a high performance in terms of F-score compared to other parts of the article;
(2) all section with bag-of-word representation (full text) achieves the
highest recall; and (3) section weighting information can help to improve
accuracy.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:22:03 GMT""}]","2019-11-22"
"1911.09320","Chenze Shao","Chenze Shao, Jinchao Zhang, Yang Feng, Fandong Meng and Jie Zhou","Minimizing the Bag-of-Ngrams Difference for Non-Autoregressive Neural
  Machine Translation","AAAI 2020",,,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Non-Autoregressive Neural Machine Translation (NAT) achieves significant
decoding speedup through generating target words independently and
simultaneously. However, in the context of non-autoregressive translation, the
word-level cross-entropy loss cannot model the target-side sequential
dependency properly, leading to its weak correlation with the translation
quality. As a result, NAT tends to generate influent translations with
over-translation and under-translation errors. In this paper, we propose to
train NAT to minimize the Bag-of-Ngrams (BoN) difference between the model
output and the reference sentence. The bag-of-ngrams training objective is
differentiable and can be efficiently calculated, which encourages NAT to
capture the target-side sequential dependency and correlates well with the
translation quality. We validate our approach on three translation tasks and
show that our approach largely outperforms the NAT baseline by about 5.0 BLEU
scores on WMT14 En$\leftrightarrow$De and about 2.5 BLEU scores on WMT16
En$\leftrightarrow$Ro.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:26:05 GMT""}]","2019-11-22"
"1911.09321","Yury Kochetkov","Irina Busjatskaja and Yury Kochetkov","Dual quadrangles in the plane","9 pages, 9 figures",,,,"math.MG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider quadrangles of perimeter $2$ in the plane with marked directed
edge. To such quadrangle $Q$ a two-dimensional plane $\Pi\in\mathbb{R}^4$ with
orthonormal base is corresponded. Orthogonal plane $\Pi^\bot$ defines a plane
quadrangle $Q^\circ$ of perimeter $2$ and with marked directed edge. This
quadrangle is defined uniquely (up to rotation and symmetry). Quadrangles $Q$
and $Q^\circ$ will be called dual to each other. The following properties of
duality are proved: a) duality preserves convexity, non convexity and
self-intersection; b) duality preserves the length of diagonals; c) the sum of
lengths of corresponding edges in $Q$ and $Q^\circ$ is $1$.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:33:02 GMT""}]","2019-11-22"
"1911.09322","Minje Park","Minje Park","Data Proxy Generation for Fast and Efficient Neural Architecture Search",,,,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Due to the recent advances on Neural Architecture Search (NAS), it gains
popularity in designing best networks for specific tasks. Although it shows
promising results on many benchmarks and competitions, NAS still suffers from
its demanding computation cost for searching high dimensional architectural
design space, and this problem becomes even worse when we want to use a
large-scale dataset. If we can make a reliable data proxy for NAS, the
efficiency of NAS approaches increase accordingly. Our basic observation for
making a data proxy is that each example in a specific dataset has a different
impact on NAS process and most of examples are redundant from a relative
accuracy ranking perspective, which we should preserve when making a data
proxy. We propose a systematic approach to measure the importance of each
example from this relative accuracy ranking point of view, and make a reliable
data proxy based on the statistics of training and testing examples. Our
experiment shows that we can preserve the almost same relative accuracy ranking
between all possible network configurations even with 10-20$\times$ smaller
data proxy.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:39:57 GMT""}]","2019-11-22"
"1911.09323","Nejib Ghanmi","Nejib Ghanmi","Connections on the Rational Korselt Set of pq",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a positive integer $N$ and $\mathbb{A}$ a subset of $\mathbb{Q}$, let
$\mathbb{A}$-$\mathcal{KS}(N)$ denote the set of
$\alpha=\dfrac{\alpha_{1}}{\alpha_{2}}\in \mathbb{A}\setminus \{0,N\}$
verifying $\alpha_{2}r-\alpha_{1}$ divides $\alpha_{2}N-\alpha_{1}$ for every
prime divisor $r$ of $N$. The set $\mathbb{A}$-$\mathcal{KS}(N)$ is called the
set of $N$-Korselt bases in $\mathbb{A}$.
  Let $p, q$ be two distinct prime numbers. In this paper, we prove that each
$pq$-Korselt base in $\mathbb{Z}\setminus\{ q+p-1\}$ generates other(s) in
$\mathbb{Q}$-$\mathcal{KS}(pq)$. More precisely, we will prove that if
$(\mathbb{Q}\setminus\mathbb{Z})$-$\mathcal{KS}(pq)=\emptyset$ then
$\mathbb{Z}$-$\mathcal{KS}(pq)=\{ q+p-1\}$.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:44:38 GMT""},{""version"":""v2"",""created"":""Tue, 17 Dec 2019 01:30:14 GMT""}]","2019-12-18"
"1911.09324","Nejib Ghanmi","Nejib Ghanmi","Korselt Rational Bases and Sets",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a positive integer $N$ and $\mathbb{A}$ a subset of $\mathbb{Q}$, let
$\mathbb{A}$-$\mathcal{KS}(N)$ denote the set of
$\alpha=\dfrac{\alpha_{1}}{\alpha_{2}}\in \mathbb{A}\setminus \{0,N\}$
verifying $\alpha_{2}p-\alpha_{1}$ divides $\alpha_{2}N-\alpha_{1}$ for every
prime divisor $p$ of $N$. The set $\mathbb{A}$-$\mathcal{KS}(N)$ is called the
set of Korselt bases of $N$ in $\mathbb{A}$ or simply the $\mathbb{A}$-Korselt
set of $N$.
  In this paper, we prove that for each squarefree composite number
$N\in\mathbb{N}\setminus\{0,1\}$ the $\mathbb{Q}$-Korselt set of $N$ is finite
where we provide an upper and lower bounds for each Korselt base of $N$ in
$\mathbb{Q}$. Furthermore, we give a necessary and a sufficient condition for
the upper bound of a Korselt base to be reached.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:44:59 GMT""}]","2019-11-22"
"1911.09325","Yafeng Liu","Liu Yafeng, Chen Tian, Liu Zhongyu, Zhang Lei, Hu Yanjun and Ding
  Enjie","Simultaneous Implementation Features Extraction and Recognition Using
  C3D Network for WiFi-based Human Activity Recognition","11 pages, 8 figures, 5 tables",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Human actions recognition has attracted more and more people's attention.
Many technology have been developed to express human action's features, such as
image, skeleton-based, and channel state information(CSI). Among them, on
account of CSI's easy to be equipped and undemanding for light, and it has
gained more and more attention in some special scene. However, the relationship
between CSI signal and human actions is very complex, and some preliminary work
must be done to make CSI features easy to understand for computer. Nowadays,
many work departed CSI-based features' action dealing into two parts. One part
is for features extraction and dimension reduce, and the other part is for time
series problems. Some of them even omitted one of the two part work. Therefore,
the accuracies of current recognition systems are far from satisfactory. In
this paper, we propose a new deep learning based approach, i.e. C3D network and
C3D network with attention mechanism, for human actions recognition using CSI
signals. This kind of network can make feature extraction from spatial
convolution and temporal convolution simultaneously, and through this network
the two part of CSI-based human actions recognition mentioned above can be
realized at the same time. The entire algorithm structure is simplified. The
experimental results show that our proposed C3D network is able to achieve the
best recognition performance for all activities when compared with some
benchmark approaches.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:45:46 GMT""}]","2019-11-22"
"1911.09326","Quang-Hieu Pham","Quang-Hieu Pham, Mikaela Angelina Uy, Binh-Son Hua, Duc Thanh Nguyen,
  Gemma Roig, Sai-Kit Yeung","LCD: Learned Cross-Domain Descriptors for 2D-3D Matching","Accepted to AAAI 2020 (Oral)",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we present a novel method to learn a local cross-domain
descriptor for 2D image and 3D point cloud matching. Our proposed method is a
dual auto-encoder neural network that maps 2D and 3D input into a shared latent
space representation. We show that such local cross-domain descriptors in the
shared embedding are more discriminative than those obtained from individual
training in 2D and 3D domains. To facilitate the training process, we built a
new dataset by collecting $\approx 1.4$ millions of 2D-3D correspondences with
various lighting conditions and settings from publicly available RGB-D scenes.
Our descriptor is evaluated in three main experiments: 2D-3D matching,
cross-domain retrieval, and sparse-to-dense depth estimation. Experimental
results confirm the robustness of our approach as well as its competitive
performance not only in solving cross-domain tasks but also in being able to
generalize to solve sole 2D and 3D tasks. Our dataset and code are released
publicly at \url{https://hkust-vgd.github.io/lcd}.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 07:56:13 GMT""}]","2019-11-22"
"1911.09327","Wei-Hua Wang","Yi-Hsun Chen, Chih-Yi Cheng, Shao-Yu Chen, Jan Sebastian Dominic
  Rodriguez, Han-Ting Liao, Kenji Watanabe, Takashi Taniguchi, Chun-Wei Chen,
  Raman Sankar, Fang-Cheng Chou, Hsiang-Chih Chiu, and Wei-Hua Wang","Oxidized-monolayer Tunneling Barrier for Strong Fermi-level Depinning in
  Layered InSe Transistors",,,,,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In 2D-semiconductor-based field-effect transistors and optoelectronic
devices, metal-semiconductor junctions are one of the crucial factors
determining device performance. The Fermi-level (FL) pinning effect, which
commonly caused by interfacial gap states, severely limits the tunability of
junction characteristics, including barrier height and contact resistance. A
tunneling contact scheme has been suggested to address the FL pinning issue in
metal-2D-semiconductor junctions, whereas the experimental realization is still
elusive. Here, we show that an oxidized-monolayer-enabled tunneling barrier can
realize a pronounced FL depinning in indium selenide (InSe) transistors,
exhibiting a large pinning factor of 0.5 and a highly modulated Schottky
barrier height. The FL depinning can be attributed to the suppression of metal-
and disorder-induced gap states as a result of the high-quality tunneling
contacts. Structural characterizations indicate uniform and atomically thin
surface oxidation layer inherent from nature of van der Waals materials and
atomically sharp oxide-2D-semiconductor interfaces. Moreover, by effectively
lowering the Schottky barrier height, we achieve an electron mobility of 2160
cm$^2$/Vs and a contact barrier of 65 meV in two-terminal InSe transistors. The
realization of strong FL depinning in high-mobility InSe transistors with the
oxidized monolayer presents a viable strategy to exploit layered semiconductors
in contact engineering for advanced electronics and optoelectronics.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:06:08 GMT""}]","2019-11-22"
"1911.09328","Florian Griese","Sarah Latus (1), Florian Griese (2 and 3), Matthias Schl\""uter (1),
  Christoph Otte (1), Martin M\""oddel (2 and 3), Matthias Graeser (2 and 3),
  Thore Saathoff (1), Tobias Knopp (2 and 3), Alexander Schlaefer (1) ((1)
  Institute of Medical Technology Hamburg University of Technology, (2) Section
  for Biomedical Imaging University Medical Center Hamburg-Eppendorf, (3)
  Institute for Biomedical Imaging Hamburg University of Technology)","Bimodal intravascular volumetric imaging combining OCT and MPI","16 pages, 16 figures",,"10.1002/mp.13388",,"physics.med-ph physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Intravascular optical coherence tomography (IVOCT) is a catheter based image
modality allowing for high resolution imaging of vessels. It is based on a fast
sequential acquisition of A-scans with an axial spatial resolution in the range
of 5 to 10 {\mu}m, i.e., one order of magnitude higher than in conventional
methods like intravascular ultrasound or computed tomography angiography.
However, position and orientation of the catheter in patient coordinates cannot
be obtained from the IVOCT measurements alone. Hence, the pose of the catheter
needs to be established to correctly reconstruct the three-dimensional vessel
shape. Magnetic particle imaging (MPI) is a three-dimensional tomographic,
tracer-based and radiation-free image modality providing high temporal
resolution with unlimited penetration depth. Volumetric MPI images are
angiographic and hence suitable to complement IVOCT as a co-modality. We study
simultaneous bimodal IVOCT MPI imaging with the goal of estimating the IVOCT
pullback path based on the 3D MPI data. We present a setup to study and
evaluate simultaneous IVOCT and MPI image acquisition of differently shaped
vessel phantoms. First, the infuence of the MPI tracer concentration on the
optical properties required for IVOCT is analyzed. Second, using a
concentration allowing for simultaneous imaging, IVOCT and MPI image data is
acquired sequentially and simultaneously. Third, the luminal centerline is
established from the MPI image volumes and used to estimate the catheter
pullback trajectory for IVOCT image reconstruction. The image volumes are
compared to the known shape of the phantoms. We were able to identify a
suitable MPI tracer concentration of 2.5 mmol/L with negligible influence on
the IVOCT signal. The pullback trajectory estimated from MPI agrees well with
the centerline of the phantoms. (...)
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:10:52 GMT""}]","2019-11-22"
"1911.09329","Lavish Saluja","Lavish Saluja, Ashutosh Bhatia","Zero Knowledge Proof based authentication protocol using graph
  isomorphism","4 pages, 2 figures",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We live in an era of information and it is very important to handle the
exchange of information. While sending data to an authorized source, we need to
protect it from unauthorized sources, changes, and authentication. ZKP
technique can be used in designing secure authentication systems that dont
involve any direct exchange of information between the claimant and the
verifier thus preventing any possible leak of personal information. We propose
a Zero-Knowledge Proof (ZKP) algorithm based on isomorphic graphs. We suggest
most of the computations should be carried out on the users' web browser
without revealing the password to the server at any point in time. Instead, it
will generate random graphs and their permutations based on the login ID and
password.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:13:47 GMT""}]","2019-11-22"
"1911.09330","Krasimir Danov Prof.","V.I. Yavrukova, G.M. Radulova, K.D. Danov, P.A. Kralchevsky, H. Xu,
  Y.W. Ung, and J.T. Petkov","Rheology of mixed solutions of sulfonated methyl esters and betaine in
  relation to the growth of giant micelles and shampoo applications",,"Advances in Colloid and Interface Science 2020","10.1016/j.cis.2019.102062",,"physics.chem-ph cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is a review article on the rheological properties of mixed solutions of
sulfonated methyl esters (SME) and cocamidopropyl betaine (CAPB), which are
related to the synergistic growth of giant micelles. Effects of additives, such
as fatty alcohols, cocamide monoethanolamine (CMEA) and salt, which are
expected to boost the growth of wormlike micelles, are studied. We report and
systematize the most significant observed effects with an emphasis on the
interpretation at molecular level and understanding the rheological behavior of
these systems. The experiments show that the mixing of SME and CAPB produces a
significant rise of viscosity, which is greater than in the mixed solutions of
sodium dodecyl sulfate and CAPB. The addition of fatty alcohols, CMEA and
cationic polymer, leads to broadening of the synergistic peak in viscosity
without any pronounced effect on its height. The addition of NaCl leads to a
typical salt curve with high maximum, but in the presence of dodecanol this
maximum is much lower. At lower salt concentrations, the fatty alcohol acts as
a thickener, whereas at higher salt concentrations - as a thinning agent.
Depending on the shape of the frequency dependences of the measured storage and
loss moduli, the investigated micellar solutions behave as systems of standard
or nonstandard rheological behavior. The systems with standard behavior obey
the Maxwell viscoelastic model (at least) up to the crossover point and can be
analyzed in terms of the Cates reptation-reaction model. The systems with
nonstandard rheological behavior obey the Maxwell model only in a restricted
domain below the crossover frequency; they can be analyzed in the framework of
an augmented version of the Maxwell model. The methodology for data analysis
and interpretation could be applied to any other viscoelastic micellar system.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:19:19 GMT""}]","2020-02-26"
"1911.09331","Chris Fields","Chris Fields and Antonino Marcian\`o","Sharing nonfungible information requires shared nonfungible information","Published version","Quantum Reports 1 (2019) 252-259","10.3390/quantum1020022",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that sharing a quantum reference frame requires sharing measurement
operators that identify the reference frame in addition to operators that
measure its state. Observers restricted to finite resources cannot, in general,
operationally determine that they share such operators. Uncertainty about
whether system-identification operators are shared induces decoherence.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:20:37 GMT""}]","2019-11-22"
"1911.09332","Muhammad Usman","Shakeel Muhammad Ibrahim, Muhammad Sohail Ibrahim, Muhammad Usman,
  Imran Naseem and Muhammad Moinuddin","Heart Segmentation From MRI Scans Using Convolutional Neural Network","Accepted for oral presentation at 13th International Conference -
  Mathematics, Actuarial, Computer Science & Statistics (MACS 13) at IoBM,
  Karachi, Pakistan",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heart is one of the vital organs of human body. A minor dysfunction of heart
even for a short time interval can be fatal, therefore, efficient monitoring of
its physiological state is essential for the patients with cardiovascular
diseases. In the recent past, various computer assisted medical imaging systems
have been proposed for the segmentation of the organ of interest. However, for
the segmentation of heart using MRI, only few methods have been proposed each
with its own merits and demerits. For further advancement in this area of
research, we analyze automated heart segmentation methods for magnetic
resonance images. The analysis are based on deep learning methods that
processes a full MR scan in a slice by slice fashion to predict desired mask
for heart region. We design two encoder decoder type fully convolutional neural
network models
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:20:48 GMT""}]","2019-11-22"
"1911.09333","Zewei Sun","Zewei Sun, Shujian Huang, Hao-Ran Wei, Xin-yu Dai, Jiajun Chen","Generating Diverse Translation by Manipulating Multi-Head Attention","Accepted by AAAI 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Transformer model has been widely used on machine translation tasks and
obtained state-of-the-art results. In this paper, we report an interesting
phenomenon in its encoder-decoder multi-head attention: different attention
heads of the final decoder layer align to different word translation
candidates. We empirically verify this discovery and propose a method to
generate diverse translations by manipulating heads. Furthermore, we make use
of these diverse translations with the back-translation technique for better
data augmentation. Experiment results show that our method generates diverse
translations without severe drop in translation quality. Experiments also show
that back-translation with these diverse translations could bring significant
improvement on performance on translation tasks. An auxiliary experiment of
conversation response generation task proves the effect of diversity as well.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:22:07 GMT""}]","2019-11-22"
"1911.09334","Tianyi Li","Tianyi Li, Sujian Li","Incorporating Textual Evidence in Visual Storytelling",,"In Proceeding of DSNNLG 2019",,,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Previous work on visual storytelling mainly focused on exploring image
sequence as evidence for storytelling and neglected textual evidence for
guiding story generation. Motivated by human storytelling process which recalls
stories for familiar images, we exploit textual evidence from similar images to
help generate coherent and meaningful stories. To pick the images which may
provide textual experience, we propose a two-step ranking method based on image
object recognition techniques. To utilize textual information, we design an
extended Seq2Seq model with two-channel encoder and attention. Experiments on
the VIST dataset show that our method outperforms state-of-the-art baseline
models without heavy engineering.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:22:37 GMT""}]","2019-11-26"
"1911.09335","Aanjaneya Kumar","Aanjaneya Kumar, Suman Kulkarni and M. S. Santhanam","Extreme events in stochastic transport on networks",,"Chaos 30, 043111 (2020)","10.1063/1.5139018",,"physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Extreme events are emergent phenomena in multi-particle transport processes
on complex networks. In practice, such events could range from power blackouts
to call drops in cellular networks to traffic congestion on roads. All the
earlier studies of extreme events on complex networks have focused only on the
nodal events. If random walks are used to model transport process on a network,
it is known that degree of the nodes determines the extreme event properties.
In contrast, in this work, it is shown that extreme events on the edges display
a distinct set of properties from that of the nodes. It is analytically shown
that the probability for the occurrence of extreme events on an edge is
independent of the degree of the nodes linked by the edge and is dependent only
on the total number of edges on the network and the number of walkers on it.
Further, it is also demonstrated that non-trivial correlations can exist
between the extreme events on the nodes and the edges. These results are in
agreement with the numerical simulations on synthetic and real-life networks.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:24:29 GMT""}]","2020-10-27"
"1911.09336","Han Shi","Han Shi, Renjie Pi, Hang Xu, Zhenguo Li, James T. Kwok, Tong Zhang","Bridging the Gap between Sample-based and One-shot Neural Architecture
  Search with BONAS","Accepted by NeurIPS 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Neural Architecture Search (NAS) has shown great potentials in finding better
neural network designs. Sample-based NAS is the most reliable approach which
aims at exploring the search space and evaluating the most promising
architectures. However, it is computationally very costly. As a remedy, the
one-shot approach has emerged as a popular technique for accelerating NAS using
weight-sharing. However, due to the weight-sharing of vastly different
networks, the one-shot approach is less reliable than the sample-based
approach. In this work, we propose BONAS (Bayesian Optimized Neural
Architecture Search), a sample-based NAS framework which is accelerated using
weight-sharing to evaluate multiple related architectures simultaneously.
Specifically, we apply Graph Convolutional Network predictor as a surrogate
model for Bayesian Optimization to select multiple related candidate models in
each iteration. We then apply weight-sharing to train multiple candidate models
simultaneously. This approach not only accelerates the traditional sample-based
approach significantly, but also keeps its reliability. This is because
weight-sharing among related architectures are more reliable than those in the
one-shot approach. Extensive experiments are conducted to verify the
effectiveness of our method over many competing algorithms.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:29:00 GMT""},{""version"":""v2"",""created"":""Thu, 5 Mar 2020 09:23:45 GMT""},{""version"":""v3"",""created"":""Fri, 23 Oct 2020 03:47:56 GMT""},{""version"":""v4"",""created"":""Wed, 25 Nov 2020 02:13:43 GMT""}]","2020-11-26"
"1911.09337","Markus Gr\""uninger","P. Warzanowski, N. Borgwardt, K. Hopfer, T. C. Koethe, P. Becker, V.
  Tsurkan, A Loidl, M. Hermanns, P. H. M. van Loosdrecht, and M. Gr\""uninger","Multiple Spin-Orbit Excitons and the Electronic Structure of
  $\alpha$-RuCl$_3$","7 pages, 4 figures","Phys. Rev. Research 2, 042007 (2020)","10.1103/PhysRevResearch.2.042007",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The honeycomb compound $\alpha$-RuCl$_3$ is widely discussed as a proximate
Kitaev spin-liquid material. This scenario builds on spin-orbit entangled $j =
1/2$ moments arising for a $t_{2g}^5$ electron configuration with strong
spin-orbit coupling $\lambda$ and a large cubic crystal field. The low-energy
electronic structure of $\alpha$-RuCl$_3$, however, is still puzzling. In
particular infrared absorption features at 0.30 eV, 0.53 eV, and 0.75 eV seem
to be at odds with theory. Also the energy of the spin-orbit exciton, the
excitation from $j = 1/2$ to 3/2, and thus the value of $\lambda$ are
controversial. Combining infrared and Raman data, we show that the infrared
features can be attributed to single, double, and triple spin-orbit excitons.
We find $\lambda$ = 0.16 eV and $\Delta$ =42(4) meV for the observed non-cubic
crystal-field splitting, supporting the validity of the $j= 1/2$ picture for
$\alpha$-RuCl$_3$. The unusual strength of the double excitation is related to
the underlying hopping interactions which form the basis for dominant Kitaev
exchange.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:31:40 GMT""}]","2020-10-21"
"1911.09338","Chuyuan Xiong","Chuyuan Xiong, Deyuan Zhang, Tao Liu, Xiaoyong Du","Voice-Face Cross-modal Matching and Retrieval: A Benchmark",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cross-modal associations between voice and face from a person can be learnt
algorithmically, which can benefit a lot of applications. The problem can be
defined as voice-face matching and retrieval tasks. Much research attention has
been paid on these tasks recently. However, this research is still in the early
stage. Test schemes based on random tuple mining tend to have low test
confidence. Generalization ability of models can not be evaluated by small
scale datasets. Performance metrics on various tasks are scarce. A benchmark
for this problem needs to be established. In this paper, first, a framework
based on comprehensive studies is proposed for voice-face matching and
retrieval. It achieves state-of-the-art performance with various performance
metrics on different tasks and with high test confidence on large scale
datasets, which can be taken as a baseline for the follow-up research. In this
framework, a voice anchored L2-Norm constrained metric space is proposed, and
cross-modal embeddings are learned with CNN-based networks and triplet loss in
the metric space. The embedding learning process can be more effective and
efficient with this strategy. Different network structures of the framework and
the cross language transfer abilities of the model are also analyzed. Second, a
voice-face dataset (with 1.15M face data and 0.29M audio data) from Chinese
speakers is constructed, and a convenient and quality controllable dataset
collection tool is developed. The dataset and source code of the paper will be
published together with this paper.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:34:34 GMT""},{""version"":""v2"",""created"":""Mon, 30 Dec 2019 12:36:50 GMT""}]","2020-01-01"
"1911.09339","Kiet Nguyen Van","Vong Anh Ho, Duong Huynh-Cong Nguyen, Danh Hoang Nguyen, Linh Thi-Van
  Pham, Duc-Vu Nguyen, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen","Emotion Recognition for Vietnamese Social Media Text","PACLING 2019","In Proceeding of PACLING 2019",,,"cs.CL","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Emotion recognition or emotion prediction is a higher approach or a special
case of sentiment analysis. In this task, the result is not produced in terms
of either polarity: positive or negative or in the form of rating (from 1 to 5)
but of a more detailed level of analysis in which the results are depicted in
more expressions like sadness, enjoyment, anger, disgust, fear, and surprise.
Emotion recognition plays a critical role in measuring the brand value of a
product by recognizing specific emotions of customers' comments. In this study,
we have achieved two targets. First and foremost, we built a standard
Vietnamese Social Media Emotion Corpus (UIT-VSMEC) with exactly 6,927
emotion-annotated sentences, contributing to emotion recognition research in
Vietnamese which is a low-resource language in natural language processing
(NLP). Secondly, we assessed and measured machine learning and deep neural
network models on our UIT-VSMEC corpus. As a result, the CNN model achieved the
highest performance with the weighted F1-score of 59.74%. Our corpus is
available at our research website.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:39:21 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jan 2020 04:40:33 GMT""}]","2020-01-28"
"1911.09340","Beomki Yeo","Beomki Yeo, MyeongJae Lee, Yoshitaka Kuno","GPU-Accelerated Event Reconstruction for the COMET Phase-I Experiment",,"Comput. Phys. Comm. 258 (2021) 107606","10.1016/j.cpc.2020.107606",,"physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper discusses a parallelized event reconstruction of the COMET Phase-I
experiment. The experiment aims to discover charged lepton flavor violation by
observing 104.97 MeV electrons from neutrinoless muon-to-electron conversion in
muonic atoms. The event reconstruction of electrons with multiple helix turns
is a challenging problem because hit-to-turn classification requires a high
computation cost. The introduced algorithm finds an optimal seed of position
and momentum for each turn partition by investigating the residual sum of
squares based on distance-of-closest-approach (DCA) between hits and a track
extrapolated from the seed. Hits with DCA less than a cutoff value are
classified for the turn represented by the seed. The classification performance
was optimized by tuning the cutoff value and refining the set of classified
hits. The workload was parallelized over the seeds and the hits by defining two
GPU kernels, which record track parameters extrapolated from the seeds and
finds the DCAs of hits, respectively. A reasonable efficiency and momentum
resolution was obtained for a wide momentum region which covers both signal and
background electrons. The event reconstruction results from the CPU and GPU
were identical to each other. The benchmarked GPUs had an order of magnitude of
speedup over a CPU with 16 cores while the exact speed gains varied depending
on their architectures.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:40:31 GMT""},{""version"":""v2"",""created"":""Mon, 25 Nov 2019 05:41:36 GMT""},{""version"":""v3"",""created"":""Tue, 8 Sep 2020 07:46:00 GMT""}]","2020-09-22"
"1911.09341","Tomohiro Okuma","Tomohiro Okuma","Normal reduction numbers of normal surface singularities","18 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article consists of two parts. The first part is a survey on the normal
reduction numbers of normal surface singularities. It includes results on
elliptic singularities, cone-like singularities and homogeneous hypersurface
singularities. In the second part, we prove a new results on the normal
reduction numbers and related invariants of Brieskorn complete intersections.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:43:37 GMT""}]","2019-11-22"
"1911.09342","Johannes Zabl","Johannes Zabl, Nicolas F. Bouch\'e, Ilane Schroetter, Martin Wendt,
  Thierry Contini, Joop Schaye, Raffaella A. Marino, Sowgat Muzahid, Gabriele
  Pezzulli, Anne Verhamme, Lutz Wisotzki","MusE GAs FLOw and Wind (MEGAFLOW) IV: A two sightline tomography of a
  galactic wind","Submitted to MNRAS. After addressing referee's comments",,"10.1093/mnras/stz3607",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Galactic outflows are thought to eject baryons back out to the
circum-galactic medium (CGM). Studies based on metal absorption lines (MgII in
particular) in the spectra of background quasars indicate that the gas is
ejected anisotropically, with galactic winds likely leaving the host in a
bi-conical flow perpendicular to the galaxy disk. In this paper, we present a
detailed analysis of an outflow from a z = 0.7 ""green-valley"" galaxy
(log($M_*$/$\mathrm{M}_\odot$) = 9.9; SFR = 0.5
$\mathrm{M}_\odot\,\mathrm{yr}^{-1}$) probed by two background sources part of
the MUSE Gas Flow and Wind (MEGAFLOW) survey. Thanks to a fortuitous
configuration with a background quasar (SDSSJ1358+1145) and a bright background
galaxy at $z = 1.4$, both at impact parameters of $\approx 15\,\mathrm{kpc}$,
we can - for the first time - probe both the receding and approaching
components of a putative galactic outflow around a distant galaxy. We measure a
significant velocity shift between the MgII absorption from the two sightlines
($84\pm17\,\mathrm{km}\,\mathrm{s}^{-1}$), which is consistent with the
expectation from our simple fiducial wind model, possibly combined with an
extended disk contribution.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:44:56 GMT""}]","2020-02-05"
"1911.09343","Ke Zhu","Guochang Wang, Ke Zhu, Guodong Li, Wai Keung Li","Hybrid quantile estimation for asymmetric power GARCH models",,,,,"econ.EM stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Asymmetric power GARCH models have been widely used to study the higher order
moments of financial returns, while their quantile estimation has been rarely
investigated. This paper introduces a simple monotonic transformation on its
conditional quantile function to make the quantile regression tractable. The
asymptotic normality of the resulting quantile estimators is established under
either stationarity or non-stationarity. Moreover, based on the estimation
procedure, new tests for strict stationarity and asymmetry are also
constructed. This is the first try of the quantile estimation for
non-stationary ARCH-type models in the literature. The usefulness of the
proposed methodology is illustrated by simulation results and real data
analysis.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:45:30 GMT""}]","2019-11-22"
"1911.09344","Weizhu Qian","Weizhu Qian, Fabrice Lauri, Franck Gechter","Convolutional Mixture Density Recurrent Neural Network for Predicting
  User Location with WiFi Fingerprints","5 pages, 3 figures, conference paper",,,,"cs.LG eess.SP stat.ML","http://creativecommons.org/licenses/by/4.0/","  Predicting smartphone users activity using WiFi fingerprints has been a
popular approach for indoor positioning in recent years. However, such a high
dimensional time-series prediction problem can be very tricky to solve. To
address this issue, we propose a novel deep learning model, the convolutional
mixture density recurrent neural network (CMDRNN), which combines the strengths
of convolutional neural networks, recurrent neural networks and mixture density
networks. In our model, the CNN sub-model is employed to detect the feature of
the high dimensional input, the RNN sub-model is utilized to capture the time
dependency and the MDN sub-model is for predicting the final output. For
validation, we conduct the experiments on the real-world dataset and the
obtained results illustrate the effectiveness of our method.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:47:00 GMT""}]","2019-11-22"
"1911.09345","Naveed Akhtar Dr.","Nayyer Aafaq, Naveed Akhtar, Wei Liu, Ajmal Mian","Empirical Autopsy of Deep Video Captioning Frameworks","09 pages, 05 figures",,,,"cs.CV cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contemporary deep learning based video captioning follows encoder-decoder
framework. In encoder, visual features are extracted with 2D/3D Convolutional
Neural Networks (CNNs) and a transformed version of those features is passed to
the decoder. The decoder uses word embeddings and a language model to map
visual features to natural language captions. Due to its composite nature, the
encoder-decoder pipeline provides the freedom of multiple choices for each of
its components, e.g the choices of CNNs models, feature transformations, word
embeddings, and language models etc. Component selection can have drastic
effects on the overall video captioning performance. However, current
literature is void of any systematic investigation in this regard. This article
fills this gap by providing the first thorough empirical analysis of the role
that each major component plays in a contemporary video captioning pipeline. We
perform extensive experiments by varying the constituent components of the
video captioning framework, and quantify the performance gains that are
possible by mere component selection. We use the popular MSVD dataset as the
test-bed, and demonstrate that substantial performance gains are possible by
careful selection of the constituent components without major changes to the
pipeline itself. These results are expected to provide guiding principles for
future research in the fast growing direction of video captioning.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:47:36 GMT""}]","2019-11-22"
"1911.09346","Driss Bennis","Driss Bennis, J. R. Garcia Rozas, Lixin Mao and Luis Oyonarte","On proper and exact relative homological dimensions","To appear in a Special Issue of Algebra Colloquium; proceedings of
  The International Conference on Algebra and Related Topics (ICART 2018)",,,,"math.CT math.AC math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In Enochs' relative homological dimension theory occur the so called
(co)resolvent and (co)proper dimensions which are defined using proper and
coproper resolutions constructed by precovers and preenvelopes, respectively.
Recently, some authors have been interested in relative homological dimensions
defined by just exact sequences. In this paper, we contribute to the
investigation of these relative homological dimensions. We first study the
relation between these two kinds of relative homological dimensions and
establish some ""transfer results"" under adjoint pairs. Then, relative global
dimensions are studied which lead to nice characterizations of some properties
of particular cases of self-orthogonal subcategories. At the end of the paper,
relative derived functors are studied and generalizations of some known results
of balance for relative homology are established.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:47:58 GMT""},{""version"":""v2"",""created"":""Sat, 23 May 2020 15:24:58 GMT""}]","2020-05-26"
"1911.09347","Daniel Barlet","Daniel Barlet (IECL, IUF)","On symmetric partial differential operators",,,,,"math.AG math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let s 1 ,. .. , s k be the elementary symmetric functions of the complex
variables x 1 ,. .. , x k. We say that F $\in$ C[s 1 ,. .. , s k ] is a trace
function if their exists f $\in$ C[z] such that F (s 1 ,. .. , s k ] = k j=1 f
(x j) for all s $\in$ C k. We give an explicit finite family of second order
differential operators in the Weyl algebra W 2 := C[s 1 ,. .. , s k ]
$\partial$ $\partial$s 1 ,. .. , $\partial$ $\partial$s k which generates the
left ideal in W 2 of partial differential operators killing all trace
functions. The proof uses a theorem for symmetric differential operators
analogous to the usual symmetric functions theorem and the corresponding map
for symbols. As a corollary, we obtain for each integer k a holonomic system
which is a quotient of W 2 by an explicit left ideal whose local solutions are
linear combinations of the branches of the multivalued root of the universal
equation of degree k: z k + k h=1 (--1) h .s h .z k--h = 0.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:48:30 GMT""}]","2019-11-22"
"1911.09348","Ya Li","Ya Li, Da-Cheng Yan, Zhou Rui, Zhen-Jun Xiao","$S$, $P$ and $D$-wave resonance contributions to $B_{(s)} \to
  \eta_c(1S,2S) K\pi$ decays in the perturbative QCD approach","18 pages, 3 figures","Phys. Rev. D 101, 016015 (2020)","10.1103/PhysRevD.101.016015",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we analyze the three-body $B_{(s)} \to \eta_c(1S,2S) K \pi$
decays within the framework of the perturbative QCD approach (PQCD) under the
quasi-two-body approximation, where the kaon-pion invariant mass spectra are
dominated by the
$K_0^*(1430)^0,K_0^*(1950)^0,K^*(892)^0,K^*(1410)^0,K^*(1680)^0$ and
$K_2^*(1430)^0$ resonances. The time-like form factors are adopted to
parametrize the corresponding $S$, $P$, $D$-wave kaon-pion distribution
amplitudes for the concerned decay modes, which describe the final-state
interactions between the kaon and pion in the resonant region. The $K\pi$
$S$-wave component at low $K\pi$ mass is described by the LASS line shape,
while the time-like form factors of other resonances are modeled by the
relativistic Breit-Wigner function. We find the following main points: (a) the
PQCD predictions of the branching ratios for most considered $B \to
\eta_c(1S)(K^{*0}\to )K^+\pi^-$ decays agree well with the currently available
data within errors; (b) for ${\cal B}(B^0 \to \eta_c (K_0^*(1430)\to
)K^+\pi^-)$ and ${\cal B}(B^0 \to \eta_c K^+\pi^-({\rm NR}))$ (here NR means
nonresonant), our predictions of the branching ratios are a bit smaller than
the measured ones; and (c) the PQCD results for the $D$-wave contributions
considered in this work can be tested once the precise data from the future
LHCb and Belle-II experiments are available.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:50:16 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jan 2020 07:42:00 GMT""},{""version"":""v3"",""created"":""Mon, 20 Apr 2020 03:39:17 GMT""}]","2020-04-21"
"1911.09349","Di Xie","Jiaxu Chen and Jing Hao and Kai Chen and Di Xie and Shicai Yang and
  Shiliang Pu","An End-to-End Audio Classification System based on Raw Waveforms and
  Mix-Training Strategy","InterSpeech 2019",,,,"eess.AS cs.CV cs.LG cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Audio classification can distinguish different kinds of sounds, which is
helpful for intelligent applications in daily life. However, it remains a
challenging task since the sound events in an audio clip is probably multiple,
even overlapping. This paper introduces an end-to-end audio classification
system based on raw waveforms and mix-training strategy. Compared to
human-designed features which have been widely used in existing research, raw
waveforms contain more complete information and are more appropriate for
multi-label classification. Taking raw waveforms as input, our network consists
of two variants of ResNet structure which can learn a discriminative
representation. To explore the information in intermediate layers, a
multi-level prediction with attention structure is applied in our model.
Furthermore, we design a mix-training strategy to break the performance
limitation caused by the amount of training data. Experiments show that the
mean average precision of the proposed audio classification system on Audio Set
dataset is 37.2%. Without using extra training data, our system exceeds the
state-of-the-art multi-level attention model.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:54:48 GMT""}]","2019-11-22"
"1911.09350","Yun Fan","Yun Fan, Hualu Liu","$\mathbb{Z}_2\mathbb{Z}_4$-Additive Cyclic Codes Are Asymptotically Good",,,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a class of $\mathbb{Z}_2\mathbb{Z}_4$-additive cyclic codes
generated by pairs of polynomials, study their algebraic structures, and obtain
the generator matrix of any code in the class. Using a probabilistic method, we
prove that, for any positive real number $\delta<1/3$ such that the entropy at
$3\delta/2$ is less than $1/2$, the probability that the relative minimal
distance of a random code in the class is greater than $\delta$ is almost $1$;
and the probability that the rate of the random code equals to $1/3$ is also
almost $1$. As an obvious consequence, the $\mathbb{Z}_2\mathbb{Z}_4$-additive
cyclic codes are asymptotically good.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:57:03 GMT""}]","2019-11-22"
"1911.09351","Laura Scalfi","Laura Scalfi, David T. Limmer, Alessandro Coretti, Sara Bonella, Paul
  A. Madden, Mathieu Salanne, Benjamin Rotenberg","Charge fluctuations from molecular simulations in the constant-potential
  ensemble",,"Physical Chemistry Chemical Physics 22 (19), 10480-10489 (2020)","10.1039/C9CP06285H",,"cond-mat.stat-mech physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revisit the statistical mechanics of charge fluctuations in capacitors. In
constant-potential classical molecular simulations, the atomic charge of
electrode atoms are treated as additional degrees of freedom which evolve in
time so as to satisfy the constraint of fixed electrostatic potential for each
configuration of the electrolyte. The present work clarifies the role of the
overall electroneutrality constraint, as well as the link between the averages
computed within the Born-Oppenheimer approximation and that of the full
constant-potential ensemble. This allows us in particular to derive a complete
fluctuation-dissipation relation for the differential capacitance, that
includes a contribution from the charge fluctuations (around the charges
satisfying the constant-potential and electroneutrality constraints) also
present in the absence of an electrolyte. We provide a simple expression for
this contribution from the elements of the inverse of the matrix defining the
quadratic form of the fluctuating charges in the energy. We then illustrate
numerically the validity of our results, and recover the expected result for an
empty capacitor with structureless electrodes at large inter-electrode
distances. By considering a variety of liquids between graphite electrodes, we
confirm that this contribution to the total differential capacitance is small
compared to that induced by the thermal fluctuations of the electrolyte.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:57:45 GMT""}]","2021-05-17"
"1911.09352","Thomas R. Weikl","Thomas R. Weikl, Jinglei Hu, Batuhan Kav, and Bartosz Rozycki","Binding and segregation of proteins in membrane adhesion: Theory,
  modelling, and simulations","Review article with 39 pages and 11 figures in ""Advances in
  Biomembranes and Lipid Self-Assembly"", Volume 30 (2019)",,,,"q-bio.SC physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The adhesion of biomembranes is mediated by the binding of membrane-anchored
receptor and ligand proteins. The proteins can only bind if the separation
between apposing membranes is sufficiently close to the length of the protein
complexes, which leads to an interplay between protein binding and membrane
shape. In this article, we review current models of biomembrane adhesion and
novel insights obtained from the models. Theory and simulations with
elastic-membrane and coarse-grained molecular models of biomembrane adhesion
indicate that the binding of proteins in membrane adhesion strongly depends on
nanoscale shape fluctuations of the apposing membranes, which results in
binding cooperativity. A length mismatch between protein complexes leads to
repulsive interactions that are caused by membrane bending and act as a driving
force for the length-based segregation of proteins during membrane adhesion.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:02:39 GMT""}]","2019-11-22"
"1911.09353","Benoit Lavraud","B. Lavraud (IRAP), A. Cara, D. Payan (CNES), Y. Ballot, J.-A. Sauvaud
  (CESR), R. Mathon, T. Camus (CESR), O. Chassela (IRAP), H.-C. Seran, H. Tap,
  O. Bernal, M. Berthomier (CETP), P. Devoto, A. Fedorov (IKI), J. Rouzaud
  (CESR), J. Rubiella-Romeo, J.-D Techer, D. Zely, S. Galinier, D. Bruno","AMBRE: A Compact Instrument to Measure Thermal Ions, Electrons and
  Electrostatic Charging Onboard Spacecraft",,,"10.23919/AeroEMC.2019.8788933",,"astro-ph.IM astro-ph.EP physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Active Monitor Box of Electrostatic Risks (AMBER) is a double-head
thermal electron and ion electrostatic analyzer (energy range 0-30 keV) that
was launched onboard the Jason-3 spacecraft in 2016. The next generation AMBER
instrument, for which a first prototype was developed and then calibrated at
the end of 2017, constitutes a significant evolution that is based on a single
head to measure both species alternatively. The instrument developments focused
on several new subsystems (front-end electronics, high-voltage electronics,
mechanical design) that permit to reduce instrument resources down to ~ 1 kg
and 1.5 W. AMBER is designed as a generic radiation monitor with a twofold
purpose: (1) measure magnetospheric thermal ion and electron populations in the
range 0-35 keV, with significant scientific potential (e.g., plasmasphere, ring
current, plasma sheet), and (2) monitor spacecraft electrostatic charging and
the plasma populations responsible for it, for electromagnetic cleanliness and
operational purposes.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:05:13 GMT""}]","2023-01-04"
"1911.09354","Anthony Bordg","Anthony Bordg, Yijun He","Comment on ""Quantum Games and Quantum Strategies""",,,,,"quant-ph cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We point out a flaw in the unfair case of the quantum Prisoner's Dilemma as
introduced in the pioneering Letter ""Quantum Games and Quantum Strategies"" of
Eisert, Wilkens and Lewenstein. It is not true that the so-called miracle move
therein always gives quantum Alice a large reward against classical Bob and
outperforms tit-for-tat in an iterated game. Indeed, we introduce a new
classical strategy that becomes Bob's dominant strategy, should Alice play the
miracle move. Finally, we briefly survey the subsequent literature and turn to
the 3-parameter strategic space instead of the 2-parameter one of Eisert et al.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:05:16 GMT""}]","2019-11-22"
"1911.09355","Weizhu Qian","Weizhu Qian, Fabrice Lauri, Franck Gechter","A Probabilistic Approach for Discovering Daily Human Mobility Patterns
  with Mobile Data","10 pages, 14 figures, journal paper",,,,"cs.LG cs.AI eess.SP stat.ML","http://creativecommons.org/licenses/by/4.0/","  Discovering human mobility patterns with geo-location data collected from
smartphone users has been a hot research topic in recent years. In this paper,
we attempt to discover daily mobile patterns based on GPS data. We view this
problem from a probabilistic perspective in order to explore more information
from the original GPS data compared to other conventional methods. A
non-parameter Bayesian modeling method, Infinite Gaussian Mixture Model, is
used to estimate the probability density for the daily mobility. Then, we use
Kullback-Leibler divergence as the metrics to measure the similarity of
different probability distributions. And combining Infinite Gaussian Mixture
Model and Kullback-Leibler divergence, we derived an automatic clustering
algorithm to discover mobility patterns for each individual user without
setting the number of clusters in advance. In the experiments, the
effectiveness of our method is validated on the real user data collected from
different users. The results show that the IGMM-based algorithm outperforms the
GMM-based algorithm. We also test our methods on the dataset with different
lengths to discover the minimum data length for discovering mobility patterns.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:17:32 GMT""}]","2020-07-02"
"1911.09356","Cristina Cornelio PhD","Mustafa Canim, Cristina Cornelio, Arun Iyengar, Ryan Musa, Mariano
  Rodrigez Muro","Schemaless Queries over Document Tables with Dependencies",,,,,"cs.DB cs.AI cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unstructured enterprise data such as reports, manuals and guidelines often
contain tables. The traditional way of integrating data from these tables is
through a two-step process of table detection/extraction and mapping the table
layouts to an appropriate schema. This can be an expensive process. In this
paper we show that by using semantic technologies (RDF/SPARQL and database
dependencies) paired with a simple but powerful way to transform tables with
non-relational layouts, it is possible to offer query answering services over
these tables with minimal manual work or domain-specific mappings. Our method
enables users to exploit data in tables embedded in documents with little
effort, not only for simple retrieval queries, but also for structured queries
that require joining multiple interrelated tables.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:20:24 GMT""}]","2019-11-22"
"1911.09357","Oliviero Riganelli","Oliviero Riganelli, Daniela Micucci, Leonardo Mariani","Controlling Interactions with Libraries in Android Apps Through Runtime
  Enforcement","accepted for publication in ACM Transactions on Autonomous and
  Adaptive Systems (TAAS). Special Section on Best Papers from SEAMS 2017 (The
  conference paper is arXiv:1703.08005)",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Android applications are executed on smartphones equipped with a variety of
resources that must be properly accessed and controlled, otherwise the
correctness of the executions and the stability of the entire environment might
be negatively affected. For example, apps must properly acquire, use, and
release microphones, cameras, and other multimedia devices otherwise the
behavior of the apps that use the same resources might be compromised.
Unfortunately, several apps do not use resources correctly, for instance due to
faults and inaccurate design decisions. By interacting with these apps users
may experience unexpected behaviors, which in turn may cause instability and
sporadic failures, especially when resources are accessed. In this paper, we
present an approach that lets users protect their environment from the apps
that use resources improperly by enforcing the correct usage protocol. This is
achieved by using software enforcers that can observe executions and change
them when necessary. For instance, enforcers can detect that a resource has
been acquired but not released, and automatically perform the release
operation, thus giving the possibility to use that same resource to the other
apps. The main idea is that software libraries, in particular the ones
controlling access to resources, can be augmented with enforcers that can be
activated and deactivated on demand by users to protect their environment from
unwanted app behaviors. We call the software libraries augmented with one or
more enforcers proactive libraries because the activation of the enforcer
decorates the library with proactive behaviors that can guarantee the
correctness of the execution despite the invocation of the operations
implemented by the library.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:28:02 GMT""}]","2019-11-22"
"1911.09358","Mingtao Fu","Yongchao Xu, Mingtao Fu, Qimeng Wang, Yukang Wang, Kai Chen, Gui-Song
  Xia, Xiang Bai","Gliding vertex on the horizontal bounding box for multi-oriented object
  detection","Accepted by TPAMI 2020. The experiments of pedestrian detection are
  updated as the benchmark has been changed",,"10.1109/TPAMI.2020.2974745",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Object detection has recently experienced substantial progress. Yet, the
widely adopted horizontal bounding box representation is not appropriate for
ubiquitous oriented objects such as objects in aerial images and scene texts.
In this paper, we propose a simple yet effective framework to detect
multi-oriented objects. Instead of directly regressing the four vertices, we
glide the vertex of the horizontal bounding box on each corresponding side to
accurately describe a multi-oriented object. Specifically, We regress four
length ratios characterizing the relative gliding offset on each corresponding
side. This may facilitate the offset learning and avoid the confusion issue of
sequential label points for oriented objects. To further remedy the confusion
issue for nearly horizontal objects, we also introduce an obliquity factor
based on area ratio between the object and its horizontal bounding box, guiding
the selection of horizontal or oriented detection for each object. We add these
five extra target variables to the regression head of faster R-CNN, which
requires ignorable extra computation time. Extensive experimental results
demonstrate that without bells and whistles, the proposed method achieves
superior performances on multiple multi-oriented object detection benchmarks
including object detection in aerial images, scene text detection, pedestrian
detection in fisheye images.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:28:14 GMT""},{""version"":""v2"",""created"":""Wed, 8 Apr 2020 07:09:37 GMT""}]","2020-04-09"
"1911.09359","Guang Liu","Liu Guang and Wang Xiaojie and Li Ruifan","Multi-Scale RCNN Model for Financial Time-series Classification",,,,,"cs.LG q-fin.CP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Financial time-series classification (FTC) is extremely valuable for
investment management. In past decades, it draws a lot of attention from a wide
extent of research areas, especially Artificial Intelligence (AI). Existing
researches majorly focused on exploring the effects of the Multi-Scale (MS)
property or the Temporal Dependency (TD) within financial time-series.
Unfortunately, most previous researches fail to combine these two properties
effectively and often fall short of accuracy and profitability. To effectively
combine and utilize both properties of financial time-series, we propose a
Multi-Scale Temporal Dependent Recurrent Convolutional Neural Network
(MSTD-RCNN) for FTC. In the proposed method, the MS features are simultaneously
extracted by convolutional units to precisely describe the state of the
financial market. Moreover, the TD and complementary across different scales
are captured through a Recurrent Neural Network. The proposed method is
evaluated on three financial time-series datasets which source from the Chinese
stock market. Extensive experimental results indicate that our model achieves
the state-of-the-art performance in trend classification and simulated trading,
compared with classical and advanced baseline models.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:32:20 GMT""}]","2019-11-22"
"1911.09360","Pierre-Francois Marteau","Pierre-Fran\c{c}ois Marteau (EXPRESSION, UBS)","On the separation of shape and temporal patterns in time series
  -Application to signature authentication-",,,,,"cs.DM cs.IR eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we address the problem of separation of shape and time
components in time series. The concept ofshape that we tackle is termed
temporally neutral to consider that it may possibly exist outside of any
temporal specification, as it is the case for a geometric form. We propose to
exploit and adapt a probabilistic temporal alignment algorithm, initially
designed to estimate the centroid of a set of time series, to build some
heuristicelements of solution to this separation problem. We show on some
controlled synthetic data that this algorithm meets empirically our initial
objectives. We finally evaluate it on real data, in the context of some on-line
handwritten signature authentication benchmarks. On the three evaluated tasks,
our approach based on the separation of signature shape and associated temporal
patterns is positioned slightly above the current state of the art
demonstrating the applicative benefit of this separating problem.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:32:32 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 14:21:41 GMT""}]","2019-11-25"
"1911.09361","Arijit Saha","Arnob Kumar Ghosh, Ganesh C. Paul, Arijit Saha","Higher Order Topological Insulator via Periodic Driving","This is the published version","Phys. Rev. B 101, 235403 (2020)","10.1103/PhysRevB.101.235403",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically investigate a periodically driven semimetal based on a
square lattice. The possibility of engineering both Floquet Topological
Insulator featuring Floquet edge states and Floquet higher order topological
insulating phase, accommodating topological corner modes has been demonstrated
starting from the semimetal phase, based on Floquet Hamiltonian picture.
Topological phase transition takes place in the bulk quasi-energy spectrum with
the variation of the drive amplitude where Chern number changes sign from $+1$
to $-1$. This can be attributed to broken time-reversal invariance
($\mathcal{T}$) due to circularly polarized light. When the discrete four-fold
rotational symmetry ($\mathcal{C}_4$) is also broken by adding a Wilson mass
term along with broken $\mathcal{T}$, higher order topological insulator
(HOTI), hosting in-gap modes at all the corners, can be realized. The Floquet
quadrupolar moment, calculated with the Floquet states, exhibits a quantized
value of $ 0.5$ (modulo 1) identifying the HOTI phase. We also show the
emergence of the {\it{dressed corner modes}} at quasi-energy $\omega/2$
(remnants of zero modes in the quasi-static high frequency limit), where
$\omega$ is the driving frequency, in the intermediate frequency regime.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:33:34 GMT""},{""version"":""v2"",""created"":""Thu, 28 Nov 2019 09:17:53 GMT""},{""version"":""v3"",""created"":""Tue, 2 Jun 2020 05:32:08 GMT""}]","2020-06-24"
"1911.09362","Yuting Qian","Yuting Qian, Zhiyun Tan, Tan Zhang, Jiacheng Gao, Zhijun Wang, Zhong
  Fang, Chen Fang, and Hongming Weng","Layer Construction of Topological Crystalline Insulator LaSbTe",,"SCIENCE CHINA Physics, Mechanics & Astronomy, Volume 63, Issue 10:
  107011(2020)","10.1007/s11433-019-1515-4.",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Topological crystalline insulator (TCI) is one of the symmetry-protected
topological states. Any TCI can be deformed into a simple product state of
several decoupled two-dimensional (2D) topologically nontrivial layers in its
lattice respecting its crystalline symmetries called the layer construction
(LC) limit. In this work, based on first-principles calculations we have
revealed that both tetragonal LaSbTe (t-LaSbTe) and orthorhombic LaSbTe
(o-LaSbTe) can be interpreted as stacking of 2D topological insulators in each
lattice space. The structural phase transition from t-LaSbTe to o-LaSbTe due to
soft phonon modes demonstrates how the real space change can lead to the
modification of topological states. Their symmetry-based indicators and
topological invariants have been analyzed based on LC. We propose that LaSbTe
is an ideal example demonstrating the LC paradigm, which bridges the crystal
structures in real space to the band topology in momentum space.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:34:26 GMT""},{""version"":""v2"",""created"":""Tue, 19 May 2020 03:43:58 GMT""}]","2020-05-20"
"1911.09363","Tineke L. van den Berg","Tineke L. van den Berg, M. Reyes Calvo and Dario Bercioux","Living on the edge: Topology, electrostatics and disorder","12 pages, 9 figures","Phys. Rev. Research 2, 013171 (2020)","10.1103/PhysRevResearch.2.013171",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the co-existence of massless and massive topological edge states
at the interface between two materials with different topological phases. We
modify the well known Bernevig-Hughes-Zhang model to introduce a smooth
function describing the band inversion and the band bending due to
electrostatic effects between the bulk of the quantum well and the vacuum.
Within this minimal model we identify distinct parameter sets that can lead to
the co-existence of the two types of edge states, and that determine their
number and characteristics. We propose several experimental setups that could
demonstrate their presence in two-dimensional topological systems, as well as
ways to regulate or tune the contribution of the massive edge states to the
conductance of associated electronic devices. Our results suggest that such
states may also be present in novel two-dimensional Van der Waals topological
materials.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:40:01 GMT""}]","2020-02-26"
"1911.09364","Driss Bennis","Dirar Benkhadra, Driss Bennis and J. R. Garcia Rozas","The category of modules on an n-trivial extension: the basic properties","To appear Algebra Colloquium: Volume 27 (2020), Number 3. (Special
  Issue; proceedings of The International Conference on Algebra and Related
  Topics; ICART 2018)",,,,"math.CT math.AC math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we investigate a categorical aspect of $n$-trivial extension of
a ring by a family of modules. Namely, we introduce the right (resp., left)
$n$-trivial extension of a category by a family of endofunctors. Among other
results, projective, injective and flat objects of this category are
characterized. We end the paper with two applications. We characterize when an
$n$-trivial extension ring is $k$-perfect and we establish a result on the
selfinjective dimension of an $n$-trivial extension ring.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:40:54 GMT""},{""version"":""v2"",""created"":""Thu, 21 May 2020 15:45:25 GMT""}]","2020-05-22"
"1911.09365","Javier Segovia Aguas","Javier Segovia-Aguas and Sergio Jim\'enez and Anders Jonsson","Generalized Planning with Positive and Negative Examples","Accepted at AAAI-20 (oral presentation)",,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalized planning aims at computing an algorithm-like structure
(generalized plan) that solves a set of multiple planning instances. In this
paper we define negative examples for generalized planning as planning
instances that must not be solved by a generalized plan. With this regard the
paper extends the notion of validation of a generalized plan as the problem of
verifying that a given generalized plan solves the set of input positives
instances while it fails to solve a given input set of negative examples. This
notion of plan validation allows us to define quantitative metrics to asses the
generalization capacity of generalized plans. The paper also shows how to
incorporate this new notion of plan validation into a compilation for plan
synthesis that takes both positive and negative instances as input. Experiments
show that incorporating negative examples can accelerate plan synthesis in
several domains and leverage quantitative metrics to evaluate the
generalization capacity of the synthesized plans.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:41:56 GMT""}]","2019-11-22"
"1911.09366","Akihide Hanaki","Akihide Hanaki and Masayoshi Yoshikawa","A construction of pairs of non-commutative rank 8 association schemes
  from non-symmetric rank 3 association schemes","8 pages",,"10.5802/alco.167",,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We construct a pair of non-commutative rank 8 association schemes from a rank
3 non-symmetric association scheme. For the pair, two association schemes have
the same character table but different Frobenius-Schur indicators. This
situation is similar to the pair of the dihedral group and the quaternion group
of order 8. We also determine the structures of adjacency algebras of them over
the rational number field.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:42:00 GMT""}]","2021-09-06"
"1911.09367","Kirsten Larson","K. L. Larson, T. D\'iaz-Santos, L. Armus, G. C. Privon, S. T. Linden,
  A. S. Evans, J. Howell, V. Charmandaris, V. U, D. B. Sanders, S. Stierwalt,
  L. Barcos-Mu\~noz, J. Rich, A. Medling, D. Cook, A. Oklop\^ci\'c, E. J.
  Murphy, P. Bonfini","Star-forming Clumps in Local Luminous Infrared Galaxies",,,"10.3847/1538-4357/ab5dc3",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present $HST$ narrow-band near-infrared imaging of Pa$\alpha$ and
Pa$\beta$ emission of 48 local Luminous Infrared Galaxies (LIRGs) from the
Great Observatories All-Sky LIRG Survey (GOALS). These data allow us to measure
the properties of 810 spatially resolved star-forming regions (59 nuclei and
751 extra-nuclear clumps), and directly compare their properties to those found
in both local and high-redshift star-forming galaxies. We find that in LIRGs,
the star-forming clumps have radii ranging from $\sim90-900$ pc and star
formation rates (SFRs) of $\sim1\times10^{-3}$ to 10 M$_\odot$yr$^{-1}$, with
median values for extra-nuclear clumps of 170 pc and 0.03 M$_\odot$yr$^{-1}$.
The detected star-forming clumps are young, with a median stellar age of $8.7$
Myrs, and a median stellar mass of $5\times10^{5}$ M$_\odot$. The SFRs span the
range of those found in normal local star-forming galaxies to those found in
high-redshift star-forming galaxies at $\rm{z}=1-3$. The luminosity function of
the LIRG clumps has a flatter slope than found in lower-luminosity,
star-forming galaxies, indicating a relative excess of luminous star-forming
clumps. In order to predict the possible range of star-forming histories and
gas fractions, we compare the star-forming clumps to those measured in the
MassiveFIRE high-resolution cosmological simulation. The star-forming clumps in
MassiveFIRE cover the same range of SFRs and sizes found in the local LIRGs and
have total gas fractions that extend from 10 to 90%. If local LIRGs are similar
to these simulated galaxies, we expect future observations with ALMA will find
a large range of gas fractions, and corresponding star formation efficiencies,
among the star-forming clumps in LIRGs.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:42:56 GMT""}]","2020-01-29"
"1911.09368","Mariko Kubo","Mariko Kubo, Jun Toshikawa, Nobunari Kashikawa, Yi-Kuan Chiang,
  Roderik Overzier, Hisakazu Uchiyama, David L. Clements, David M. Alexander,
  Yuichi Matsuda, Tadayuki Kodama, Yoshiaki Ono, Tomotsugu Goto, Tai-An Cheng,
  and Kei Ito","Planck far-infrared detection of Hyper Suprime-Cam protoclusters at $\bf
  z\sim4$: hidden AGN and star formation activity","26 pages, 12 figures, Accepted for publication in ApJ",,"10.3847/1538-4357/ab5a80",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We perform a stacking analysis of {\it Planck}, {\it AKARI}, Infrared
Astronomical Satellite ($IRAS$), Wide-field Infrared Survey Eplorer ($WISE$),
and {\it Herschel} images of the largest number of (candidate) protoclusters at
$z\sim3.8$ selected from the Hyper Suprime-Cam Subaru Strategic Program
(HSC-SSP). Stacking the images of the $179$ candidate protoclusters, the
combined infrared (IR) emission of the protocluster galaxies in the observed
$12-850~\mu$m wavelength range is successfully detected with $>5\sigma$
significance (at $Planck$). This is the first time that the average IR spectral
energy distribution (SED) of a protocluster has been constrained at $z\sim4$.
The observed IR SEDs of the protoclusters exhibit significant excess emission
in the mid-IR compared to that expected from typical star-forming galaxies
(SFGs). They are reproduced well using SED models of intense starburst galaxies
with warm/hot dust heated by young stars, or by a population of active galactic
nuclei (AGN)/SFG composites. For the pure star-forming model, a total IR (from
8 to 1000 $\mu$m) luminosity of $19.3_{-4.2}^{+0.6}\times10^{13}~L_{\odot}$ and
a star formation rate (SFR) of $16.3_{-7.8}^{+1.0}\times10^3~M_{\odot}$
yr$^{-1}$ are found whereas for the AGN/SFG composite model,
$5.1_{-2.5}^{+2.5}\times10^{13}~L_{\odot}$ and
$2.1^{+6.3}_{-1.7}\times10^3~M_{\odot}$ yr$^{-1}$ are found. Uncertainty
remaining in the total SFRs; however, the IR luminosities of the most massive
protoclusters are likely to continue increasing up to $z\sim4$. Meanwhile, no
significant IR flux excess is observed around optically selected QSOs at
similar redshifts, which confirms previous results. Our results suggest that
the $z\sim4$ protoclusters trace dense, intensely star-forming environments
that may also host obscured AGNs missed by the selection in the optical.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:43:37 GMT""}]","2020-01-08"
"1911.09369","Wenjie Liu","Wenjie Liu and Yongguan Ke and Bo Zhu and Chaohong Lee","Modulation-induced long-range magnon bound states in one-dimensional
  optical lattices",,,"10.1088/1367-2630/abb2b7",,"cond-mat.str-el quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultracold two-level atoms in optical lattices offer an excellent experimental
platform to explore magnon excitations [Fukuhara et al 2013 Nat. Phys. 9, 235;
Fukuhara et al 2013 Nature 502, 76]. Here, we investigate how gradient magnetic
field and periodically modulated tunneling strength affect the two-magnon
excitations in these ultracold atomic systems. In the resonant condition where
the driving frequency matches and smooths the potential bias, the system gains
translational invariance in both space and time in the rotating frame, and thus
we can develop a Floquet-Bloch band theory for two magnons. We find a new kind
of bound states with relative distance no less than two sites, apart from the
conventional bound states with relative distance at one site, which indicates
the modulation-induced long-range interaction. We analytically derive an
effective Hamiltonian via the many-body perturbation theory for a deeper
understanding of such novel bound states and explore the interplay between
these two types of bound states. Moreover, we propose to probe
modulation-induced bound states via quantum walks. Our study not only provides
a scheme to form long-range magnon bound states, but also lays a cornerstone
for engineering exotic quantum states in multi-particle Floquet systems.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:55:05 GMT""},{""version"":""v2"",""created"":""Tue, 14 Apr 2020 10:01:33 GMT""}]","2020-10-28"
"1911.09370","Susana Ladra","Jos\'e Fuentes-Sep\'ulveda and Susana Ladra","Energy consumption in compact integer vectors: A study case","This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sk{\l}odowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941","IEEE Access 7, pp. 155625-155636 (2019)","10.1109/ACCESS.2019.2949655",,"cs.DS","http://creativecommons.org/licenses/by/4.0/","  In the field of algorithms and data structures analysis and design, most of
the researchers focus only on the space/time trade-off, and little attention
has been paid to energy consumption. Moreover, most of the efforts in the field
of Green Computing have been devoted to hardware-related issues, being green
software in its infancy. Optimizing the usage of computing resources,
minimizing power consumption or increasing battery life are some of the goals
of this field of research.
  As an attempt to address the most recent sustainability challenges, we must
incorporate the energy consumption as a first-class constraint when designing
new compact data structures. Thus, as a preliminary work to reach that goal, we
first need to understand the factors that impact on the energy consumption and
their relation with compression. In this work, we study the energy consumption
required by several integer vector representations. We execute typical
operations over datasets of different nature. We can see that, as commonly
believed, energy consumption is highly related to the time required by the
process, but not always. We analyze other parameters, such as number of
instructions, number of CPU cycles, memory loads, among others.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:56:37 GMT""}]","2019-11-22"
"1911.09371","Sunil Rudresh","Adithya Krishna, Sunil Rudresh, Vishal Shaw, Hemanth Reddy Sabbella,
  Chandra Sekhar Seelamantula, and Chetan Singh Thakur","Unlimited Dynamic Range Analog-to-Digital Conversion",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Analog-to-digital converters (ADCs) provide the link between continuous-time
signals and their discrete-time counterparts, and the Shannon-Nyquist sampling
theorem provides the mathematical foundation. Real-world signals have a
variable amplitude range, whereas ADCs, by design, have a limited input dynamic
range, which results in out-of-range signals getting clipped. In this paper, we
propose an unlimited dynamic range ADC (UDR-ADC) that is based on the modulo
operation (self-reset feature) to alleviate the problem of clipping. The
self-reset feature allows for wrapping of the input amplitudes, which preserves
the input dynamic range. We present the signal model and a reconstruction
technique to recover the original signal samples from the modulo measurements.
We validate the operation of the proposed ADC using circuit simulations in 65
nm complementary metal-oxide-semiconductor (CMOS) process technology. The
validation is supplemented by a hardware prototype designed using discrete
components. A performance assessment in terms of area, power requirement, and
the signal-to-quantization-noise ratio (SQNR) shows that the UDR-ADC
outperforms the standard ones.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:57:25 GMT""}]","2019-11-22"
"1911.09372","Giorgio Galanti","Giorgio Galanti","Axion-like particles and high energy astrophysics","6 pages, 3 figures, Proceeding of ""PHOTON 2019 - International
  Conference on the Structure and the Interactions of the Photon"", June 3-7,
  2019, Frascati - Italy, Frascati Physics Series Vol. 69 (2019)","Frascati Physics Series Vol. 69 (2019)",,,"astro-ph.HE hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Axion-like particles (ALPs) are light, neutral, pseudo-scalar bosons
predicted by several extensions of the Standard Model of particle physics --
such as the String Theory -- and are supposed to interact primarily only with
two photons. In the presence of an external magnetic field, photon-ALP
oscillations occur and can produce sizable astrophysical effects in the
very-high energy (VHE) band ($100 \, {\rm GeV} - 100 \, {\rm TeV}$). Photon-ALP
oscillations increase the transparency of the Universe to VHE photons partially
preventing the gamma-gamma absorption caused by the Extragalactic Background
Light (EBL). Moreover, they have important implications for active galactic
nuclei (AGN) by modifying their observed spectra both for flat spectrum radio
quasars (FSRQs) and BL Lacs. Many attempts have been made in order to constrain
the ALP parameter space by studying irregularities in spectra due to photon-ALP
conversion in galaxy clusters and the consequences of ALP emission by stars.
Upcoming new VHE photon detectors like CTA, HAWC, GAMMA-400, LHAASO,
TAIGA-HiSCORE, HERD and ASTRI will settle the issue.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:58:48 GMT""}]","2019-11-22"
"1911.09373","Zeyi Wen","Zeyi Wen, Zeyu Huang and Rui Zhang","Entity Extraction with Knowledge from Web Scale Corpora",,,,,"cs.CL cs.DB cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Entity extraction is an important task in text mining and natural language
processing. A popular method for entity extraction is by comparing substrings
from free text against a dictionary of entities. In this paper, we present
several techniques as a post-processing step for improving the effectiveness of
the existing entity extraction technique. These techniques utilise models
trained with the web-scale corpora which makes our techniques robust and
versatile. Experiments show that our techniques bring a notable improvement on
efficiency and effectiveness.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:01:16 GMT""}]","2019-11-22"
"1911.09374","Davide Chiesa","Davide Chiesa, Mario Carta, Valentina Fabrizio, Luca Falconi, Angelo
  Grossi, Massimiliano Nastasi, Mario Palomba, Stefano Pozzi, Ezio Previtali,
  Pier Giorgio Rancoita, Barbara Ranghetti, Mauro Tacconi","Characterization of TRIGA RC-1 neutron irradiation facilities for
  radiation damage testing",,"Eur. Phys. J. Plus (2020) 135: 349","10.1140/epjp/s13360-020-00334-7",,"physics.ins-det nucl-ex physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents the results of neutron flux measurements at two
irradiation facilities of the TRIGA Mark II reactor at ENEA Casaccia Research
Center, Italy. The goal of these measurements is to provide a complete
characterization of neutron irradiation facilities for accurate and precise
dose evaluation in radiation damage tests and, more generally, for all
applications that need a good knowledge of neutron flux in terms of intensity,
energy spectrum and spatial distribution. The neutron activation technique is
used to measure the activation rates of several reactions, chosen so to cover
the whole energy range of neutron flux spectrum. A multi-group neutron flux
measurement is obtained through an unfolding algorithm based on a Bayesian
statistical model. The obtained results prove that this experimental method
allows to measure the total neutron flux within 2% statistical uncertainty, and
to get at the same time a good description of its energy spectrum and spatial
distribution.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:01:47 GMT""},{""version"":""v2"",""created"":""Tue, 14 Apr 2020 10:42:04 GMT""}]","2020-04-15"
"1911.09375","Monika Sharma","Monika Sharma, Shikha Gupta, Arindam Chowdhury, Lovekesh Vig","ChartNet: Visual Reasoning over Statistical Charts using MAC-Networks",,"International Joint Conference on Neural Networks (IJCNN) 2019","10.1109/IJCNN.2019.8852427",,"cs.CV cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite the improvements in perception accuracies brought about via deep
learning, developing systems combining accurate visual perception with the
ability to reason over the visual percepts remains extremely challenging. A
particular application area of interest from an accessibility perspective is
that of reasoning over statistical charts such as bar and pie charts. To this
end, we formulate the problem of reasoning over statistical charts as a
classification task using MAC-Networks to give answers from a predefined
vocabulary of generic answers. Additionally, we enhance the capabilities of
MAC-Networks to give chart-specific answers to open-ended questions by
replacing the classification layer by a regression layer to localize the
textual answers present over the images. We call our network ChartNet, and
demonstrate its efficacy on predicting both in vocabulary and out of vocabulary
answers. To test our methods, we generated our own dataset of statistical chart
images and corresponding question answer pairs. Results show that ChartNet
consistently outperform other state-of-the-art methods on reasoning over these
questions and may be a viable candidate for applications containing images of
statistical charts.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:03:25 GMT""}]","2019-11-22"
"1911.09376","Jitesh Jhawar","Jitesh Jhawar (1) and Vishwesha Guttal (1) ((1) Center for Ecological
  Sciences, Indian Institute of Science, Bangalore, India)","Noise-induced Effects in Collective Dynamics and Inferring Local
  Interactions from Data","The article has 24 pages containing 5 main figures, 5 supplementary
  figures, 3 boxes and 1 table insides one of the box",,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In animal groups, individual decisions are best characterised by
probabilistic rules. Furthermore, animals of many species live in small groups.
Probabilistic interactions among small numbers of individuals lead to a so
called intrinsic noise at the group level. Theory predicts that the strength of
intrinsic noise is not a constant but often depends on the collective state of
the group; hence, it is also called a state-dependent noise or a multiplicative
noise. Surprisingly, such noise may produce collective order. However, only a
few empirical studies on collective behaviour have paid attention to such
effects due to the lack of methods that enable us to connect data with theory.
Here, we demonstrate a method to characterise the role of stochasticity
directly from high-resolution time-series data of collective dynamics. We do
this by employing two well-studied individual-based toy models of collective
behaviour. We argue that the group-level noise may encode important information
about the underlying processes at the individual scale. In summary, we describe
a method that enables us to establish connections between empirical data of
animal (or cellular) collectives with the phenomenon of noise-induced states, a
field that is otherwise largely limited to the theoretical literature.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:05:38 GMT""},{""version"":""v2"",""created"":""Tue, 21 Apr 2020 18:11:26 GMT""}]","2020-04-23"
"1911.09377","Louise Budzynski","Louise Budzynski, Guilhem Semerjian","The asymptotics of the clustering transition for random constraint
  satisfaction problems","35 pages, 8 figures","Journal of Statistical Physics, 181(5) (2020), 1490-1522","10.1007/s10955-020-02635-8",,"cond-mat.dis-nn cs.DM math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Random Constraint Satisfaction Problems exhibit several phase transitions
when their density of constraints is varied. One of these threshold phenomena,
known as the clustering or dynamic transition, corresponds to a transition for
an information theoretic problem called tree reconstruction. In this article we
study this threshold for two CSPs, namely the bicoloring of $k$-uniform
hypergraphs with a density $\alpha$ of constraints, and the $q$-coloring of
random graphs with average degree $c$. We show that in the large $k,q$ limit
the clustering transition occurs for $\alpha = \frac{2^{k-1}}{k} (\ln k + \ln
\ln k + \gamma_{\rm d} + o(1))$, $c= q (\ln q + \ln \ln q + \gamma_{\rm d}+
o(1))$, where $\gamma_{\rm d}$ is the same constant for both models. We
characterize $\gamma_{\rm d}$ via a functional equation, solve the latter
numerically to estimate $\gamma_{\rm d} \approx 0.871$, and obtain an analytic
lowerbound $\gamma_{\rm d} \ge 1 + \ln (2 (\sqrt{2}-1)) \approx 0.812$. Our
analysis unveils a subtle interplay of the clustering transition with the
rigidity (naive reconstruction) threshold that occurs on the same asymptotic
scale at $\gamma_{\rm r}=1$.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:06:22 GMT""},{""version"":""v2"",""created"":""Wed, 3 Jun 2020 13:03:59 GMT""}]","2020-11-19"
"1911.09378","Dale Frymark","Dale Frymark","Boundary Triples and Weyl $m$-functions for Powers of the Jacobi
  Differential Operator",,,,,"math.FA math.CA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The abstract theory of boundary triples is applied to the classical Jacobi
differential operator and its powers in order to obtain the Weyl $m$-function
for several self-adjoint extensions with interesting boundary conditions:
separated, periodic and those that yield the Friedrichs extension. These
matrix-valued Nevanlinna--Herglotz $m$-functions are, to the best knowledge of
the author, the first explicit examples to stem from singular higher-order
differential equations.
  The creation of the boundary triples involves taking pieces, determined in a
previous paper, of the principal and non-principal solutions of the
differential equation and putting them into the sesquilinear form to yield maps
from the maximal domain to the boundary space. These maps act like
quasi-derivatives, which are usually not well-defined for all functions in the
maximal domain of singular expressions. However, well-defined regularizations
of quasi-derivatives are produced by putting the pieces of the non-principal
solutions through a modified Gram--Schmidt process.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:09:25 GMT""}]","2019-11-22"
"1911.09379","Klaus Heeger","Robert Bredereck, Klaus Heeger, Du\v{s}an Knop, Rolf Niedermeier","Parameterized Complexity of Stable Roommates with Ties and Incomplete
  Lists Through the Lens of Graph Parameters","An extended abstract of this paper appears at ISAAC 2019",,,,"cs.CC cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We continue and extend previous work on the parameterized complexity analysis
of the NP-hard Stable Roommates with Ties and Incomplete Lists problem, thereby
strengthening earlier results both on the side of parameterized hardness as
well as on the side of fixed-parameter tractability. Other than for its famous
sister problem Stable Marriage which focuses on a bipartite scenario, Stable
Roommates with Incomplete Lists allows for arbitrary acceptability graphs whose
edges specify the possible matchings of each two agents (agents are represented
by graph vertices). Herein, incomplete lists and ties reflect the fact that in
realistic application scenarios the agents cannot bring all other agents into a
linear order. Among our main contributions is to show that it is W[1]-hard to
compute a maximum-cardinality stable matching for acceptability graphs of
bounded treedepth, bounded tree-cut width, and bounded disjoint paths modulator
number (these are each time the respective parameters). However, if we `only'
ask for perfect stable matchings or the mere existence of a stable matching,
then we obtain fixed-parameter tractability with respect to tree-cut width but
not with respect to treedepth. On the positive side, we also provide
fixed-parameter tractability results for the parameter feedback edge set
number.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:12:36 GMT""},{""version"":""v2"",""created"":""Fri, 5 Mar 2021 22:12:25 GMT""}]","2021-03-09"
"1911.09380","Alexandre Rodrigues Dr.","Alexandre A. P. Rodrigues","Unfolding a Bykov attractor: from an attracting torus to strange
  attractors",,,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we present a comprehensive mechanism for the emergence of
strange attractors in a two-parametric family of differential equations acting
on a three-dimensional sphere. When both parameters are zero, its flow exhibits
an attracting heteroclinic network (Bykov network) made by two 1-dimensional
connections and one 2-dimensional separatrix between two hyperbolic
saddles-foci with different Morse indices. After slightly increasing both
parameters, while keeping the one-dimensional connections unaltered, we focus
our attention in the case where the two-dimensional invariant manifolds of the
equilibria do not intersect. Under some conditions on the parameters and on the
eigenvalues of the linearisation of the vector field at the saddle-foci, we
prove the existence of many complicated dynamical objects, ranging from an
attracting quasi-periodic torus to H\'enon-like strange attractors, as a
consequence of the Torus-Breakdown Theory. The mechanism for the creation of
horseshoes and strange attractors is also discussed. Theoretical results are
applied to show the occurrence of strange attractors in some analytic
unfoldings of a Hopf-zero singularity.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:13:50 GMT""},{""version"":""v2"",""created"":""Thu, 28 Nov 2019 08:57:37 GMT""},{""version"":""v3"",""created"":""Mon, 16 Dec 2019 16:38:50 GMT""},{""version"":""v4"",""created"":""Wed, 18 Mar 2020 23:03:25 GMT""},{""version"":""v5"",""created"":""Sat, 16 May 2020 14:26:57 GMT""}]","2020-05-19"
"1911.09381","Pintu Barman","Pintu Barman, Anindita Deka, Shyamal Mondal, Debasree Chowdhury,
  Satyaranjan Bhattacharyya","Surface scaling behaviour of size-selected Ag-nanocluster film growing
  under subsequent shadowing process","13 pages, 9 figures",,"10.1088/1361-6463/ab87c3",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Surface morphology of size-selected silver nanocluster films grown by dc
magnetron sputtering has been investigated by means of an atomic force
microscopy (AFM). From the height-height correlation functions ( HHCF) obtained
from corresponding AFM images, the scaling exponents are calculated and two
types of growth regimes have been observed. In the first regime, the growth
exponent is found to be \b{eta}1 = 0.27\pm0.07 close to the KPZ growth
exponent, while in the second growth regime shadowing effect plays dominant
role which gives the growth exponent value \b{eta}2 = 0.88\pm0.28. On the other
hand for the whole deposition regime, the roughness exponent value is found to
be constant around {\alpha}= 0.76\pm0.02. UV-vis spectroscopy measurement
suggests how the average reflectance of the film surface changes with different
growth times.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:14:02 GMT""}]","2020-08-26"
"1911.09382","Robert Vandervorst","William D. Kalies, Konstantin Mischaikow, Robert C.A.M. Vandervorst","Lattice Structures for Attractors III",,,,,"math.DS math.CT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The theory of bounded, distributive lattices provides the appropriate
language for describing directionality and asymptotics in dynamical systems.
For bounded, distributive lattices the general notion of `set-difference'
taking values in a semilattice is introduced, and is called the Conley form.
The Conley form is used to build concrete, set-theoretical models of spectral,
or Priestley spaces, of bounded, distributive lattices and their finite
coarsenings. Such representations build order-theoretic models of dynamical
systems, which are used to develop tools for computing global characteristics
of a dynamical system.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:15:14 GMT""}]","2019-11-22"
"1911.09383","Krzysztof Domino","Natalia Kruszewska, Piotr Be{\l}dowski, Krzysztof Domino, Kanika D
  Lambert","Investigating conformation changes and network formation of mucin in
  joints functioning in human locomotion","Chapter 7 in A.Gadomski (ed.): Multiscale Locomotion: Its
  Active-Matter Addressing Physical Principles; UTP University of Science &
  Technology",,,,"physics.bio-ph q-bio.BM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many different processes take place to facilitate lubrication of the joints
functioning in human locomotion system. The main purpose of this is to avoid
destroying the articular cartilage. Viscoelastic properties of the joints
system are very sensitive on both temperature and concentration changes because
of the change in conformation presented in the system proteins and protein
network formation. We are searching for an answer to the question on how
changes in temperature and concentration influence the conformational entropy
of mucin protein which is a part of one of the key components, lubricin, which
is believed to be responsible for gel formation inside synovial fluid. We are
using molecular dynamic technique to obtain the information about dihedral
(phi, psi) angles of the mucin during protein self - assembly by means of the
computer simulation with a time duration up to 50 ns, parameterized by six
temperatures ranged between 300 - 315 K, and six concentrations 10.68 - 267.1
g/L. The results show that between c3 and c4 (160 g/L and 214 g/L) a transition
exists where crowding begins affecting the dynamics of protein network
formation. In such a concentration ranges mucin has a chance to change the
frictional properties of the system. Simultaneously there were no significant
changes in conformations of the mucins molecules even after they created
networks. The temperature changes also did not affect much of mucins
conformations but it introduced slightly modifications in dihedral angles and
after some critical value T=306 K it changed conformational entropy trend from
decreasing to raising.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:17:44 GMT""}]","2019-11-22"
"1911.09384","Niayesh Afshordi","Niayesh Afshordi (U-Waterloo and Perimeter)","On the origin of the LIGO ""mystery"" noise and the high energy particle
  physics desert","comments are welcome, 3 pages, 1 figure",,,,"gr-qc astro-ph.CO astro-ph.IM hep-ph hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the most ubiquitous features of quantum theories is the existence of
zero-point fluctuations in their ground states. For massive quantum fields,
these fluctuations decouple from infrared observables in ordinary field
theories. However, there is no ""decoupling theorem"" in Quantum Gravity, and we
recently showed that the vacuum stress fluctuations of massive quantum fields
source a red spectrum of metric fluctuations given by $\sim$ mass$^5$/frequency
in Planck units. I show that this signal is consistent with the reported
unattributed persistent noise, or ""mystery"" noise, in the Laser Interferometer
Gravitational-Wave Observatory (LIGO), for the Standard Model of Particle
Physics. If this interpretation is correct, then it implies that: 1) This will
be a fundamental irreducible noise for all gravitational wave interferometers,
and 2) There is no fundamental weakly-coupled massive particle heavier than
those in the Standard Model.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:23:15 GMT""}]","2019-11-22"
"1911.09385","Peter Cox","Peter Cox, Tony Gherghetta, Minh D. Nguyen","A Holographic Perspective on the Axion Quality Problem","20 pages, 5 figures","JHEP 01 (2020) 188","10.1007/JHEP01(2020)188","UMN-TH-3905/19","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The axion provides a compelling solution to the strong CP problem as well as
a candidate for the dark matter of the universe. However, the axion solution
relies on the spontaneous breaking of a global $U(1)_{PQ}$ symmetry, which is
also explicitly violated by quantum gravity. To preserve the axion solution,
gravitational violations of the $U(1)_{PQ}$ symmetry must be suppressed to
sufficiently high order. We present a simple, geometric solution of the axion
quality problem by modelling the axion with a bulk complex scalar field in a
slice of AdS$_5$, where the $U(1)_{PQ}$ symmetry is spontaneously broken in the
bulk but explicitly broken on the UV brane. By localising the axion field
towards the IR brane, gravitational violations of the PQ symmetry on the UV
brane are sufficiently sequestered. This geometric solution is holographically
dual to 4D strong dynamics where the global $U(1)_{PQ}$ is an accidental
symmetry to sufficiently high order.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:23:57 GMT""}]","2020-01-31"
"1911.09386","Jana Korunovska","Jana Korunovska, Bernadette Kamleitner and Sarah Spiekermann","The Power and Pitfalls of Transparent Privacy Policies in Social
  Networking Service Platforms",,,,,"cs.HC cs.CY cs.SI","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Users disclose ever-increasing amounts of personal data on Social Network
Service platforms (SNS). Unless SNSs' policies are privacy friendly, this
leaves them vulnerable to privacy risks because they ignore the privacy
policies. Designers and regulators have pushed for shorter, simpler and more
prominent privacy policies, however the evidence that transparent policies
increase informed consent is lacking. To answer this question, we conducted an
online experiment with 214 regular Facebook users asked to join a fictitious
SNS. We experimentally manipulated the privacy-friendliness of SNS's policy and
varied threats of secondary data use and data visibility. Half of our
participants incorrectly recalled even the most formally ""perfect"" and
easy-to-read privacy policies. Mostly, users recalled policies as more privacy
friendly than they were. Moreover, participants self-censored their disclosures
when aware that visibility threats were present, but were less sensitive to
threats of secondary data use. We present design recommendations to increase
informed consent.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:24:12 GMT""},{""version"":""v2"",""created"":""Wed, 4 Dec 2019 10:55:42 GMT""}]","2019-12-05"
"1911.09387","Valentina Klochkova G.","V.G. Klochkova","Unity and Diversity of Yellow Hypergiants Family","24 pages, 10 figures",,"10.1134/S1990341319040138",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We summarize the results of long-term spectral monitoring of yellow
hypergiants (YHGs) of northern hemisphere with a R$\ge$60000 resolution. The
spectra of these F-G stars of extremely high luminosity, compactly located at
the top of the Hertzsprung-Russell diagram revealed a variety of spectral
features: various types of H$\alpha$ profile, the presence (or absence) of
forbidden and permitted emissions, as well as circumstellar components.
Variability of spectral details of various nature is studied. Absolute
luminosity, circumstellar envelope expansion rate and amplitude of pulsations
are determined. The reliability of the YHG status for V1427 Aql is reliably
confirmed; manifestations of a significant dynamic instability of the upper
layers of the atmosphere of $\rho$ Cas after the 2017 ejection and
stratification of its gas envelope are registered; the lack of companion in the
system of the V509 Cas hypergiant is proven; a conclusion is made that the
V1302 Aql hypergiant is approaching to the low-temperature boundary of the
Yellow Void.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:24:25 GMT""}]","2020-01-08"
"1911.09388","Oliviero Riganelli","Marco Mobilio, Oliviero Riganelli, Daniela Micucci, Leonardo Mariani","FILO: FIx-LOcus Recommendation for Problems Caused by Android Framework
  Upgrade","accepted for inclusion in Proceedings of the International Symposium
  on Software Reliability Engineering (ISSRE) 2019",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dealing with the evolution of operating systems is challenging for developers
of mobile apps, who have to deal with frequent upgrades that often include
backward incompatible changes of the underlying API framework. As a consequence
of framework upgrades, apps may show misbehaviours and unexpected crashes once
executed within an evolved environment. Identifying the portion of the app that
must be modified to correctly execute on a newly released operating system can
be challenging. Although incompatibilities are visibile at the level of the
interactions between the app and its execution environment, the actual methods
to be changed are often located in classes that do not directly interact with
any external element. To facilitate debugging activities for problems
introduced by backward incompatible upgrades of the operating system, this
paper presents FILO, a technique that can recommend the method that must be
changed to implement the fix from the analysis of a single failing execution.
FILO can also select key symptomatic anomalous events that can help the
developer understanding the reason of the failure and facilitate the
implementation of the fix. Our evaluation with multiple known compatibility
problems introduced by Android upgrades shows that FILO can effectively and
efficiently identify the faulty methods in the apps.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:24:31 GMT""}]","2019-11-22"
"1911.09389","Yanting Pei","Yanting Pei, Yaping Huang, Xingyuan Zhang","Classification-driven Single Image Dehazing",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most existing dehazing algorithms often use hand-crafted features or
Convolutional Neural Networks (CNN)-based methods to generate clear images
using pixel-level Mean Square Error (MSE) loss. The generated images generally
have better visual appeal, but not always have better performance for
high-level vision tasks, e.g. image classification. In this paper, we
investigate a new point of view in addressing this problem. Instead of focusing
only on achieving good quantitative performance on pixel-based metrics such as
Peak Signal to Noise Ratio (PSNR), we also ensure that the dehazed image itself
does not degrade the performance of the high-level vision tasks such as image
classification. To this end, we present an unified CNN architecture that
includes three parts: a dehazing sub-network (DNet), a classification-driven
Conditional Generative Adversarial Networks sub-network (CCGAN) and a
classification sub-network (CNet) related to image classification, which has
better performance both on visual appeal and image classification. We conduct
comprehensive experiments on two challenging benchmark datasets for
fine-grained and object classification: CUB-200-2011 and Caltech-256.
Experimental results demonstrate that the proposed method outperforms many
recent state-of-the-art single image dehazing methods in terms of image
dehazing metrics and classification accuracy.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:25:54 GMT""}]","2019-11-22"
"1911.09390","Roberto Longo","Roberto Longo, Feng Xu","Von Neumann Entropy in QFT","25 pages",,"10.1007/s00220-020-03702-7",,"math-ph hep-th math.MP math.OA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the framework of Quantum Field Theory, we provide a rigorous, operator
algebraic notion of entanglement entropy associated with a pair of open double
cones $O \subset \tilde O$ of the spacetime, where the closure of $O$ is
contained in $\tilde O$. Given a QFT net $A$ of local von Neumann algebras
$A(O)$, we consider the von Neumann entropy $S_A(O, \tilde O)$ of the
restriction of the vacuum state to the canonical intermediate type $I$ factor
for the inclusion of von Neumann algebras $A(O)\subset A(\tilde O)$ (split
property). We show that this canonical entanglement entropy $S_A(O, \tilde O)$
is finite for the chiral conformal net on the circle generated by finitely many
free Fermions (here double cones are intervals). To this end, we first study
the notion of von Neumann entropy of a closed real linear subspace of a complex
Hilbert space, that we then estimate for the local free fermion subspaces. We
further consider the lower entanglement entropy $\underline S_A(O, \tilde O)$,
the infimum of the vacuum von Neumann entropy of $F$, where $F$ here runs over
all the intermediate, discrete type $I$ von Neumann algebras. We prove that
$\underline S_A(O, \tilde O)$ is finite for the local chiral conformal net
generated by finitely many commuting $U(1)$-currents.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:26:41 GMT""}]","2020-03-18"
"1911.09391","Eivind B{\o}hn","Eivind B{\o}hn, Signe Moe, Tor Arne Johansen","Accelerating Reinforcement Learning with Suboptimal Guidance","Submitted to IFAC 2020",,,,"cs.LG cs.AI cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement Learning in domains with sparse rewards is a difficult problem,
and a large part of the training process is often spent searching the state
space in a more or less random fashion for any learning signals. For control
problems, we often have some controller readily available which might be
suboptimal but nevertheless solves the problem to some degree. This controller
can be used to guide the initial exploration phase of the learning controller
towards reward yielding states, reducing the time before refinement of a viable
policy can be initiated. In our work, the agent is guided through an auxiliary
behaviour cloning loss which is made conditional on a Q-filter, i.e. it is only
applied in situations where the critic deems the guiding controller to be
better than the agent. The Q-filter provides a natural way to adjust the
guidance throughout the training process, allowing the agent to exceed the
guiding controller in a manner that is adaptive to the task at hand and the
proficiency of the guiding controller. The contribution of this paper lies in
identifying shortcomings in previously proposed implementations of the Q-filter
concept, and in suggesting some ways these issues can be mitigated. These
modifications are tested on the OpenAI Gym Fetch environments, showing clear
improvements in adaptivity and yielding increased performance in all robotic
environments tested.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:27:46 GMT""}]","2019-11-22"
"1911.09392","Ferit G\""urb\""uz","Naqash Sarfraz and Ferit Gurbuz","Weak And Strong Boundedness For P-adic Fractional Hausdorff Operator And
  Its Commutator",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, boundedness of Hausdorff operator on weak central Morrey space
is obtained. Furthermore, we investigate the weak bounds of p- adic fractional
Hausdorff Operator on weighted p-adic weak Lebesgue Space. We also obtain the
sufficient condition of commutators of p-adic fractional Hausdorff Operator by
taking symbol function from Lipschitz space. Moreover, strong type estimates
for fractional Hausdorff Operator and its commutator on weighted p-adic Lorentz
space are also acquired.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:29:23 GMT""}]","2019-11-22"
"1911.09393","Maria Roslova","Maria Roslova, Stef Smeets, Bin Wang, Thomas Thersleff, Hongyi Xu,
  Xiaodong Zou","InsteaDMatic: Towards cross-platform automated continuous rotation
  electron diffraction",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A DigitalMicrograph script InsteaDMatic has been developed to facilitate
rapid automated continuous rotation electron diffraction (cRED) data
acquisition. The script coordinates microscope functions, such as stage
rotation, camera functions relevant for data collection, and stores the
experiment metadata. The script is compatible with any microscope that can be
controlled by DigitalMicrograph and has been tested on both JEOL and Thermo
Fisher Scientific microscopes. A proof-of-concept has been performed through
employing InsteaDMatic for data collection and structure determination of a
ZSM-5 zeolite. The influence of illumination settings and electron dose rate on
the quality of diffraction data, unit cell determination and structure solution
has been investigated in order to optimize the data acquisition procedure.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:29:56 GMT""},{""version"":""v2"",""created"":""Tue, 28 Apr 2020 09:31:48 GMT""}]","2020-04-29"
"1911.09394","Tommaso Moraschini","R. Jansana and T. Moraschini","The Poset of All Logics I: Interpretations and Lattice Structure",,,,,"math.LO","http://creativecommons.org/licenses/by-nc-sa/4.0/","  A notion of interpretation between arbitrary logics is introduced, and the
poset Log of all logics ordered under interpretability is studied. It is shown
that in Log infima of arbitrarily large sets exist, but binary suprema in
general do not. On the other hand, the existence of suprema of sets of
equivalential logics is established. The relations between Log and the lattice
of interpretability types of varieties are investigated.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:30:31 GMT""}]","2019-11-22"
"1911.09395","Ivan Supic","Ivan \v{S}upi\'c, Matty J. Hoban, Laia Domingo Colomer, Antonio Ac\'in","Self-testing and certification using trusted quantum inputs","8 + 7 pages, comments welcome",,"10.1088/1367-2630/ab90d1",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Device-independent certification of quantum devices is of crucial importance
for the development of secure quantum information protocols. So far, the most
studied scenario corresponds to a system consisting of different
non-characterized devices that observers probe with classical inputs to obtain
classical outputs. The certification of relevant quantum properties follows
from the observation of correlations between these events that do not have a
classical counterpart. In the fully device-independent scenario no assumptions
are made on the devices and therefore their non-classicality follows from Bell
non-locality. There exist other scenarios, known as semidevice-independent, in
which assumptions are made on the devices, such as their dimension, and
non-classicality is associated to the observation of other types of
correlations with no classical analogue. More recently, the use of trusted
quantum inputs for certification has been introduced. The goal of this work is
to study the power of this formalism and describe self-testing protocols in
various settings using trusted quantum inputs. We also relate these different
types of self-testing to some of the most basic quantum information protocols,
such as quantum teleportation. Finally, we apply our findings to quantum
networks and provide methods for estimating the quality of the whole network,
as well as of parts of it.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:32:39 GMT""}]","2020-08-26"
"1911.09396","Prasun Dutta","P. K. Vishwakarma and P. Dutta","HI column density statistics of the cold neutral medium from absorption
  studies","6 pages, 4 figures","Monthly Notices of the Royal Astronomical Society, stz3148, 11
  Nov, 2019","10.1093/mnras/stz3148",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Physical properties of the tiny scale structures in the cold neutral medium
(CNM) of galaxies is a long-standing puzzle. Only a few lines of sights in our
Galaxy have been studies with mixed results on the scale-invariant properties
of such structures. Moreover, since these studies measure the variation of
neutral hydrogen optical depth, they do not directly constrain the density
structures. In this letter, we investigate the possibility of measuring the
properties of density and spin temperature structures of the \HI from
absorption studies of \HI. Our calculations show that irrespective of the
thermal properties of the clouds, the scale structure of the \HI column density
can be estimated, whereas, \HI absorption studies alone cannot shed much light
on either the amplitude of the density fluctuations and their temperature
structures. Detailed methodology and calculations with some fiducial examples
are presented.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:33:06 GMT""}]","2020-01-08"
"1911.09397","Boris Goldfarb","Gunnar Carlsson, Boris Goldfarb","Excision in equivariant fibred G-theory","23 pages","Ann. K-Th. 5 (2020) 721-756","10.2140/akt.2020.5.721",,"math.KT math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper provides a generalization of excision theorems in controlled
algebra in the context of equivariant G-theory with fibred control and families
of bounded actions. It also states and proves several characteristic features
of this theory such as existence of the fibred assembly and the fibrewise
trivialization.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:33:53 GMT""}]","2020-12-30"
"1911.09398","Ushak Rahaman","Luis Salvador Miranda, Pedro Pasquini, Ushak Rahaman, Soebur Razzaque","Searching for non-unitary neutrino oscillations in the present T2K and
  NO$\nu$A data","30 pages, 19 figures, 3 tables. Results for 2020 data from NOvA and
  T2K have been included, Accepted in EPJC",,,,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mixing of three active neutrino flavors is parameterized by the unitary
PMNS matrix. If there are more than three neutrino flavors and if the extra
generations are heavy isosinglets, the effective $3\times 3$ mixing matrix for
the three active neutrinos will be non-unitary. We have analyzed the latest T2K
and \nova data with the hypothesis of non-unitary mixing of the active
neutrinos. We found that the 2019 NO$\nu$A data slightly (at $\sim 1\, \sigma$
C.L.) prefer the non-unitary mixing over unitary mixing. In fact, allowing the
non-unitary mixing brings the \nova best-fit point in the
$\sin^2\theta_{23}-\delta_{CP}$ plane closer to the T2K best-fit point. The
2019 T2K data, on the other hand, cannot rule out any of the two mixing
schemes. A combined analysis of the NO$\nu$A and T2K 2019 data prefers the
non-unitary mixing at $1\, \sigma$ C.L.. We derive constraints on the
non-unitary mixing parameters using the best-fit to the combined NO$\nu$A and
T2K data. These constraints are weaker than previously found. The latest 2020
data from both the experiments prefer non-unitarity over unitary mixing at $1\,
\sigma$ C.L. The combined analysis preferes non-unitarity at $2\, \sigma$ C.L.
The stronger tension, which exists between the latest 2020 data of the two
experiments, also gets reduced with non-unitary analysis.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:41:47 GMT""},{""version"":""v2"",""created"":""Wed, 1 Jul 2020 15:48:29 GMT""},{""version"":""v3"",""created"":""Tue, 18 Aug 2020 16:55:59 GMT""},{""version"":""v4"",""created"":""Sun, 3 Jan 2021 14:53:30 GMT""},{""version"":""v5"",""created"":""Mon, 10 May 2021 13:53:20 GMT""}]","2021-05-11"
"1911.09399","Stefano Mangini","Fabio Benatti, Stefano Mancini and Stefano Mangini","Continuous Variable Quantum Perceptron","16 pages, 2 figures","International Journal of Quantum Information Vol. 17, No. 08,
  1941009 (2019)","10.1142/S0219749919410090",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a model of Continuous Variable Quantum Perceptron (CVQP) whose
architecture implements a classical perceptron. The necessary non-linearity is
obtained via measuring the output qubit and using the measurement outcome as
input to an activation function. The latter is chosen to be the so-called ReLu
activation function by virtue of its practical feasibility and the advantages
it provides in learning tasks. The encoding of classical data into realistic
finitely squeezed states and the use of superposed (entangled) input states for
specific binary problems are discussed.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:44:24 GMT""},{""version"":""v2"",""created"":""Mon, 2 Dec 2019 16:53:25 GMT""}]","2020-03-25"
"1911.09400","Carsten Dubs","Carsten Dubs (1), Oleksii Surzhenko (1), Ronny Thomas (2), Julia Osten
  (2), Tobias Schneider (2), Kilian Lenz (2), J\""org Grenzer (2), Ren\'e
  H\""ubner (2), Elke Wendler (3)","Low damping and microstructural perfection of sub-40nm-thin yttrium iron
  garnet films grown by liquid phase epitaxy",,"Phys. Rev. Materials 4, 024416 (2020)","10.1103/PhysRevMaterials.4.024416",,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The field of magnon spintronics is experiencing an increasing interest in the
development of solutions for spin-wave-based data transport and processing
technologies that are complementary or alternative to modern CMOS
architectures. Nanometer-thin yttrium iron garnet (YIG) films have been the
gold standard for insulator-based spintronics to date, but a potential process
technology that can deliver perfect, homogeneous large-diameter films is still
lacking. We report that liquid phase epitaxy (LPE) enables the deposition of
nanometer-thin YIG films with low ferromagnetic resonance losses and
consistently high magnetic quality down to a thickness of 20 nm. The obtained
epitaxial films are characterized by an ideal stoichiometry and perfect film
lattices, which show neither significant compositional strain nor geometric
mosaicity, but sharp interfaces. Their magneto-static and dynamic behavior is
similar to that of single crystalline bulk YIG. We found, that the Gilbert
damping coefficient alpha is independent of the film thickness and close to 1 x
10-4, and that together with an inhomogeneous peak-to-peak linewidth broadening
of delta H0|| = 0.4 G, these values are among the lowest ever reported for YIG
films with a thickness smaller than 40 nm. These results suggest, that
nanometer-thin LPE films can be used to fabricate nano- and micro-scaled
circuits with the required quality for magnonic devices. The LPE technique is
easily scalable to YIG sample diameters of several inches.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:44:25 GMT""}]","2020-03-04"
"1911.09401","Kai Xie","Ying Wen, Kai Xie, Lianghua He","Segmenting Medical MRI via Recurrent Decoding Cell","8 pages, 7 figures, AAAI-20",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The encoder-decoder networks are commonly used in medical image segmentation
due to their remarkable performance in hierarchical feature fusion. However,
the expanding path for feature decoding and spatial recovery does not consider
the long-term dependency when fusing feature maps from different layers, and
the universal encoder-decoder network does not make full use of the
multi-modality information to improve the network robustness especially for
segmenting medical MRI. In this paper, we propose a novel feature fusion unit
called Recurrent Decoding Cell (RDC) which leverages convolutional RNNs to
memorize the long-term context information from the previous layers in the
decoding phase. An encoder-decoder network, named Convolutional Recurrent
Decoding Network (CRDN), is also proposed based on RDC for segmenting
multi-modality medical MRI. CRDN adopts CNN backbone to encode image features
and decode them hierarchically through a chain of RDCs to obtain the final
high-resolution score map. The evaluation experiments on BrainWeb, MRBrainS and
HVSMR datasets demonstrate that the introduction of RDC effectively improves
the segmentation accuracy as well as reduces the model size, and the proposed
CRDN owns its robustness to image noise and intensity non-uniformity in medical
MRI.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:46:42 GMT""}]","2019-11-22"
"1911.09402","Ahmet Zahid Yalcin","Ahmet Zahid Yalcin and Mustafa Kagan Cetin and Melda Yuksel","Max-Min Fair Precoder Design and Power Allocation for MU-MIMO NOMA","13 pages, 7 figures",,,,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, a downlink multiple input multiple output (MIMO)
non-orthogonal multiple access (NOMA) wireless communication system is
considered. In NOMA systems, the base station has unicast data for all users,
and multiple users in a group share the same resources. The objective is to
design transmit precoders and power allocation coefficients jointly that
provide max-min fairness (MMF) among the strongest users in each group, while
maintaining minimum target rates for all the other users. The problem is solved
via two main iterative approaches. The first method is based on semi-definite
relaxation (SDR) and successive convex approximation (SCA), and the second
method is based on the equivalency between achievable rate and minimum mean
square error (MMSE) expressions. For the latter approach, Karush-Kuhn-Tucker
(KKT) optimality conditions are derived and the expressions satisfied by the
optimal receivers, MMSE weights and the optimal precoders are obtained.
Proposed algorithms are compared with rate-splitting (RS), orthogonal multiple
access (OMA) and multi-user linear precoding (MULP) schemes in terms of MMF
rates, energy efficiency and complexity. It is shown that while RS has the best
MMF rates and energy efficiency, the MMSE approach based on KKT optimality
conditions has the least complexity. Moreover, the SDR/SCA approach offers an
excellent tradeoff. It offers high MMF rates, low complexity and superior
energy efficiency.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:47:54 GMT""},{""version"":""v2"",""created"":""Wed, 5 Aug 2020 14:41:59 GMT""}]","2020-08-06"
"1911.09403","Oleksandr Tsyplyatyev","R. Smit, P. Kopietz, O. Tsyplyatyev","Heat capacity of anisotropic Heisenberg antiferromagnet within the spin
  Hartree-Fock approach in quasi-1D Regime",,"Eur. Phys. J. B 92, 252 (2019)","10.1140/epjb/e2019-100387-9",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the anisotropic quantum Heisenberg antiferromagnet for spin-1/2 that
interpolates smoothly between the one-dimensional (1D) and the two-dimensional
(2D) limits. Using the spin Hartree-Fock approach we construct a quantitative
theory of heat capacity in the quasi-1D regime with a finite coupling between
spin chains. This theory reproduces closely the exact result of Bethe Ansatz in
the 1D limit and does not produces any spurious phase transitions for any
anisotropy in the quasi-1D regime at finite temperatures in agreement with the
Mermin-Wagner theorem. We study the static spin-spin correlation function in
order to analyse the interplay of lattice geometry and anisotropy in these
systems. We compare the square and triangular lattice. For the latter we find
that there is a quantum transition point at an intermediate anisotropy of
$\sim0.6$. This quantum phase transition establishes that the quasi-1D regime
extends upto a particular point in this geometry. For the square lattice the
change from the 1D to 2D occurs smoothly as a function of anisotropy, i.e. it
is of the crossover type. Comparing the newly developed theory to the available
experimental data on the heat capacity of $\rm{Cs}_2\rm{CuBr}_4$ and
$\rm{Cs}_2\rm{CuCl}_4$ we extract the microscopic constants of the exchange
interaction that previously could only be measured using inelastic neutron
scattering in high magnetic fields.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:56:15 GMT""}]","2019-11-22"
"1911.09404","Martin Barrere","Mart\'in Barr\`ere, Chris Hankin, Demetrios G. Eliades, Nicolas
  Nicolau, Thomas Parisini","Assessing Cyber-Physical Security in Industrial Control Systems","10 pages, 10 figures. Keywords: security metrics, cyber-physical
  security, AND-OR graphs, hypergraphs, MAX-SAT resolution, ICS, CPS","6th International Symposium for ICS & SCADA Cyber Security
  Research 2019 (ICS-CSR), pp. 49-58 (2019)","10.14236/ewic/icscsr19.7",,"cs.CR cs.NI cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Over the last years, Industrial Control Systems (ICS) have become
increasingly exposed to a wide range of cyber-physical threats. Efficient
models and techniques able to capture their complex structure and identify
critical cyber-physical components are therefore essential. AND/OR graphs have
proven very useful in this context as they are able to semantically grasp
intricate logical interdependencies among ICS components. However, identifying
critical nodes in AND/OR graphs is an NP-complete problem. In addition, ICS
settings normally involve various cyber and physical security measures that
simultaneously protect multiple ICS components in overlapping manners, which
makes this problem even harder. In this paper, we present an extended security
metric based on AND/OR hypergraphs which efficiently identifies the set of
critical ICS components and security measures that should be compromised, with
minimum cost (effort) for an attacker, in order to disrupt the operation of
vital ICS assets. Our approach relies on MAX-SAT techniques, which we have
incorporated in META4ICS, a Java-based security metric analyser for ICS. We
also provide a thorough performance evaluation that shows the feasibility of
our method. Finally, we illustrate our methodology through a case study in
which we analyse the security posture of a realistic Water Transport Network
(WTN).
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:02:48 GMT""}]","2019-11-22"
"1911.09405","Antonio M. Garcia-Garcia","Bo Fan and Antonio M. Garc\'ia-Garc\'ia","Enhanced, phase coherent, multifractal-like, two-dimensional
  superconductivity","24 pages, 10 figures, added references, corrected typos","Phys. Rev. B 101, 104509 (2020)","10.1103/PhysRevB.101.104509",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the interplay of superconductivity and disorder by solving
numerically the Bogoliubov-de-Gennes equations in a two dimensional lattice of
size $80\times80$ which makes possible to investigate the weak-coupling limit.
In contrast with results in the strong coupling region, we observe enhancement
of superconductivity and intriguing multifractal-like features such as a broad
log-normal spatial distribution of the order parameter, a parabolic singularity
spectrum, and level statistics consistent with those of a disordered metal at
the Anderson transition. The calculation of the superfluid density, including
small phase fluctuations, reveals that, despite this intricate spatial
structure, phase coherence still holds for sufficiently weak disorder. It only
breaks down for stronger disorder but before the insulating transition takes
place.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:06:07 GMT""},{""version"":""v2"",""created"":""Sun, 29 Dec 2019 15:01:06 GMT""}]","2020-03-25"
"1911.09406","Hongming Nie","Yan Gao, Hongming Nie","Perturbations of graphs for Newton maps","23 pages",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the convergence of graphs consisting of finitely many internal rays
for degenerating Newton maps. We state a sufficient condition to guarantee the
convergence. As an application, we investigate the boundedness of hyperbolic
components in the moduli space of quartic Newton maps. We prove that such a
hyperbolic component is bounded if and only if every element has degree $2$ on
the immediate basin of each root.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:06:33 GMT""}]","2019-11-22"
"1911.09407","Bohdan Novosyadlyj Prof.","B. Novosyadlyj, V. Shulga, Yu. Kulinich, W. Han","Redshifted 21-cm emission signal from the halos in Dark Ages","18 pages, 10 figures, 7 tables; accepted for publication in Physics
  of the Dark Universe","Physics of the Dark Universe 27 (2020) 100422","10.1016/j.dark.2019.100422",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The emission in the hyperfine structure 21 cm line of atomic hydrogen arising
in the halos with masses $\sim10^6-10^{10}$ M$_\odot$ from the Dark Ages in the
models with Warm Dark Matter (WDM) is analysed. The halos are assumed to be
formed from Gaussian density peaks of cosmological density perturbations at
$10\lesssim z\lesssim50$. Semi-analytical modelling of the formation of
individual spherical halos in multi-component models shows that gas in them has
the kinetic temperature in the range of $60-800$ K under adiabatic compression
of the collapsing halo, and the temperature of each halo depends on the time of
virialization. It is shown that inelastic collisions between neutral hydrogen
atoms are the dominant excitation mechanism for hyperfine structure levels,
which pulls the spin temperature closer to the kinetic temperature. The
brightness temperature of individual halos is in the range of 1-10 K, depending
on the mass of the halo and its virialization redshift, and increasing as these
two increase. The apparent angular radii of such halos are in the range
0.06-1.2 arcseconds, their surface number density decreasing exponentially from
a few per arcmin$^2$ for the lowest mass and redshift to nearly zero for higher
values. Assuming a 1 MHz observation bandwidth the surface number density of
the halo at various redshifts is evaluated as well as beam-averaged
differential antenna temperatures and fluxes of hydrogen emission from halos of
different masses. The beam-averaged signal strongly depends on the cut-off
scale in the mass function of dark ages halos that may be caused by
free-streaming of WDM particles. The finding is compared with the upper limits
on the amplitude of the power spectrum of the hydrogen 21-cm line fluctuations
derived from the recent observation data obtained with MWA and LOFAR.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:07:11 GMT""}]","2020-02-25"
"1911.09408","Yunxiao Chen","Yunxiao Chen, Yan Lu, and Irini Moustaki","Detection of Two-Way Outliers in Multivariate Data and Application to
  Cheating Detection in Educational Tests",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The paper proposes a new latent variable model for the simultaneous (two-way)
detection of outlying individuals and items for item-response-type data. The
proposed model is a synergy between a factor model for binary responses and
continuous response times that captures normal item response behaviour and a
latent class model that captures the outlying individuals and items. A
statistical decision framework is developed under the proposed model that
provides compound decision rules for controlling local false
discovery/nondiscovery rates of outlier detection. Statistical inference is
carried out under a Bayesian framework, for which a Markov chain Monte Carlo
algorithm is developed. The proposed method is applied to the detection of
cheating in educational tests due to item leakage using a case study of a
computer-based nonadaptive licensure assessment. The performance of the
proposed method is evaluated by simulation studies.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:08:16 GMT""},{""version"":""v2"",""created"":""Mon, 21 Dec 2020 21:54:15 GMT""},{""version"":""v3"",""created"":""Tue, 29 Jun 2021 10:40:38 GMT""},{""version"":""v4"",""created"":""Fri, 22 Oct 2021 10:06:35 GMT""}]","2021-10-25"
"1911.09409","Suad Krila\v{s}evi\'c","Suad Krila\v{s}evi\'c and Sergio Grammatico","An integral Nash equilibrium control scheme for a class of multi-agent
  linear systems","8 pages",,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose an integral Nash equilibrium seeking control (I-NESC) law which
steers the multi-agent system composed of a special class of linear agents to
the neighborhood of the Nash equilibrium in noncooperative strongly monotone
games. First, we prove that there exist parameters of the integral controller
such that the system converges to the Nash equilibrium in the full-information
case, in other words, without the parameter estimation scheme used in extremum
seeking algorithms. Then we prove that there exist parameters of the I-NESC
such that the system converges to the neighborhood of the Nash equilibrium in
the limited information case where parameter estimation is used. We provide a
simulation example that demonstrates that smaller perturbation frequencies and
amplitudes are needed to attain similar convergence speed as the existing
state-of-the-art algorithm.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:08:50 GMT""}]","2019-11-22"
"1911.09410","Rodrigo Coelho C. V.","Rodrigo C. V. Coelho, Nuno A. M. Ara\'ujo, and Margarida M. Telo da
  Gama","Propagation of active nematic-isotropic interfaces on substrates",,"Soft Matter, 2020,16, 4256-4266","10.1039/C9SM02306B",,"cond-mat.soft physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by results for the propagation of active-passive interfaces of
bacterial Serratia marcescens swarms [Nat. Comm., 9, 5373 (2018)] we use a
hydrodynamic multiphase model to investigate the propagation of interfaces of
active nematics on substrates. We characterize the active nematic phase of the
model and discuss its description of the statistical dynamics of the swarms. We
show that the velocicity correlation functions and the energy spectrum of the
active turbulent phase of the model scale with the active length, for a range
of activities. In addition, the energy spectrum exhibits two power-law regimes
with exponents close to those reported for other models and bacterial swarms.
Although the exponent of the rising branch of the spectrum (small wavevector)
appears to be independent of the activity, the exponent of the decay changes
with activity systematically, albeit slowly. We characterize also the
propagation of circular and flat active-passive interfaces. We find that the
closing time of the circular passive domain decays quadratically with the
activity and that the structure factor of the flat interface is similar to that
reported for swarms, with an activity dependent exponent. Finally, the effect
of the substrate friction was investigated. We found an activity dependent
threshold, above which the turbulent active nematic forms isolated islands that
shrink until the system becomes isotropic and below which the active nematic
expands, with a well defined propagating interface. The interface may be
stopped by a fricion gradient.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:10:28 GMT""}]","2021-02-25"
"1911.09411","Anderson Ara","Anderson Ara, Mateus Maia, Samuel Mac\^edo and Francisco Louzada","Random Machines: A bagged-weighted support vector model with free kernel
  choice",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Improvement of statistical learning models in order to increase efficiency in
solving classification or regression problems is still a goal pursued by the
scientific community. In this way, the support vector machine model is one of
the most successful and powerful algorithms for those tasks. However, its
performance depends directly from the choice of the kernel function and their
hyperparameters. The traditional choice of them, actually, can be
computationally expensive to do the kernel choice and the tuning processes. In
this article, it is proposed a novel framework to deal with the kernel function
selection called Random Machines. The results improved accuracy and reduced
computational time. The data study was performed in simulated data and over 27
real benchmarking datasets.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:11:22 GMT""}]","2019-11-22"
"1911.09412","Michal Kocvara","Michal Kocvara","Decomposition of arrow type positive semidefinite matrices with
  application to topology optimization",,,"10.1007/s10107-020-01526-w",,"math.OC cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Decomposition of large matrix inequalities for matrices with chordal sparsity
graph has been recently used by Kojima et al.\ \cite{kim2011exploiting} to
reduce problem size of large scale semidefinite optimization (SDO) problems and
thus increase efficiency of standard SDO software. A by-product of such a
decomposition is the introduction of new dense small-size matrix variables. We
will show that for arrow type matrices satisfying suitable assumptions, the
additional matrix variables have rank one and can thus be replaced by vector
variables of the same dimensions. This leads to significant improvement in
efficiency of standard SDO software. We will apply this idea to the problem of
topology optimization formulated as a large scale linear semidefinite
optimization problem. Numerical examples will demonstrate tremendous speed-up
in the solution of the decomposed problems, as compared to the original large
scale problem. In our numerical example the decomposed problems exhibit linear
growth in complexity, compared to the more than cubic growth in the original
problem formulation. We will also give a connection of our approach to the
standard theory of domain decomposition and show that the additional vector
variables are outcomes of the corresponding discrete Steklov-Poincar\'{e}
operators.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:11:48 GMT""}]","2021-05-19"
"1911.09413","Carlos Abia","C. Abia, P. de Laverny, S. Cristallo, G. Kordopatis, O. Straniero","Properties of carbon stars in the Solar neighbourhood based on Gaia DR2
  astrometry","Accepted in Astronomy & Astrophysics","A&A 633, A135 (2020)","10.1051/0004-6361/201936831",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find that the combined LF of N- and SC-type stars are consistent with a
Gaussian distribution peaking at M_bol~ -5.2 mag. The resulting LF however
shows two tails at lower and higher luminosities more extended than those
previously found, indicating that AGB carbon stars with Solar metallicity may
reach M_bol~-6.0 mag. We find that J-type stars are about half a magnitude
fainter on average than N- and SC-type stars, while R-hot stars are half a
magnitude brighter than previously found. The Galactic spatial distribution and
velocity components of the N-, SC- and J-type stars are very similar, while
about 30 % of the R-hot stars in the sample are located at distances larger
than ~ 500 pc from the Galactic Plane, and show a significant drift with
respect to the local standard of rest. The LF derived for N- and SC-type in the
Solar neighbourhood fully agrees with the expected luminosity of stars of 1.5-3
M_o on the AGB. On a theoretical basis, the existence of an extended low
luminosity tail would require a contribution of extrinsic low mass carbon
stars, while the high luminosity one would imply that stars with mass up to ~5
Mo may become carbon star on the AGB. J-type stars not only differ
significantly in their chemical composition with respect to the N- and SC-types
but also in their LF, which reinforces the idea that these carbon stars belong
to a dvifferent type whose origin is still unknown. The derived luminosities of
R-hot stars make these stars unlikely to be in the red-clump as previously
claimed. On the other hand, the derived spatial distribution and kinematic
properties, together with their metallicity, indicate that most of the N-, SC-
and J-type stars belong to the thin disc population, while a significant
fraction of R-hot stars show characteristics compatible with the thick disc.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:12:57 GMT""}]","2020-01-22"
"1911.09414","Pieter Belmans","Pieter Belmans and Maxim Smirnov","Hochschild cohomology of generalised Grassmannians","45 pages, 2 appendices, close to published version",,,,"math.AG math.DG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compute the Hochschild-Kostant-Rosenberg decomposition of the Hochschild
cohomology of generalised Grassmannians, i.e. partial flag varieties associated
to maximal parabolic subgroups in a simple algebraic group. We explain how the
decomposition is concentrated in global sections for so-called (co)minuscule
and (co)adjoint generalised Grassmannians, and we suggest that for (almost) all
other cases the same vanishing of the higher cohomology does not hold. Our
methods give an explicit partial description of the Gerstenhaber algebra
structure for the Hochschild cohomology of cominuscule and adjoint generalised
Grassmannians. We also consider the case of adjoint partial flag varieties in
type A, which are associated to certain submaximal parabolic subgroups.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:15:57 GMT""},{""version"":""v2"",""created"":""Fri, 12 May 2023 18:36:09 GMT""}]","2023-05-16"
"1911.09415","Reza Mahini Sheikhhosseini","Reza Mahini, Peng Xu, Guoliang Chen, Yansong Li, Weiyan Ding, Lei
  Zhang, Nauman Khalid Qureshi, Asoke K. Nandi, Fengyu Cong","Optimal Number of Clusters by Measuring Similarity among Topographies
  for Spatio-temporal ERP Analysis","34 Pages, 15 figures, 9 tables, under review in Brain Topography",,,,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Averaging amplitudes over consecutive time samples within a time-window is
widely used to calculate the amplitude of an event-related potential (ERP) for
cognitive neuroscience. Objective determination of the time-window is critical
for determining the ERP component. Clustering on the spatio-temporal ERP data
can obtain the time-window in which the consecutive time samples topographies
are expected to be highly similar in practice. However, there exists a
challenging problem of determining an optimal number of clusters. Here, we
develop a novel methodology to obtain the optimal number of clusters using
consensus clustering on the spatio-temporal ERP data. Various clustering
methods, namely, K-means, hierarchical clustering, fuzzy C-means,
self-organizing map, and diffusion maps spectral clustering are combined in an
ensemble clustering manner to find the most reliable clusters. When a range of
numbers of clusters is applied on the spatio-temporal ERP dataset, the optimal
number of clusters should correspond to the cluster of interest within which
the average of correlation coefficients between topographies of every two-time
sample in the time-window is the maximum for an ERP of interest. In our method,
we consider fewer cluster maps for analyzing an optimal number of clusters for
isolating the components of interest in the spatio-temporal ERP. The
statistical comparison demonstrates that the present method outperforms other
conventional approaches. This finding would be practically useful for
discovering the optimal clustering in spatio-temporal ERP, especially when the
cognitive knowledge about time-window is not clearly defined.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:16:10 GMT""}]","2019-11-22"
"1911.09416","Yoshio Koide","Yoshio Koide","Are Charged Leptons in the Simultaneous Eigenstates of Mass and Family?","9 pages, 5 figures",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Conventionally, the observed charged leptons are regarded the simultaneous
eigenstates of ""mass"" and ""family"". Against this view, we discuss a possibility
that the observed charged leptons $e_i=(e, \mu, \tau)$ are not identical with
the eigenstates of family $e^0_\alpha =(e_1^0, e_2^0, e_3^0)$. Here, we define
the eigenstates of family, $e^0_\alpha$, as the states which interact with
family gauge bosons in the mass eigenstates of the broken U(3)$_{family}$ gauge
symmetry. Although there is at present not any experimental evidence for
$e^0_1$-$e^0_2$ mixing, and we have only an upper limit for the mixing from the
present experimental data. We will conclude that the $e$-$\mu$ mixing angle
$\theta$ must be $\theta \lesssim 10^{-3}$. Thus, we can not exclude a
possibility $\theta\neq 0$. If we want more small upper limit of $\theta$, a
rare decay search $\mu \rightarrow e + \gamma$ will be useful.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:20:11 GMT""},{""version"":""v2"",""created"":""Thu, 5 Mar 2020 05:17:41 GMT""}]","2020-03-06"
"1911.09417","Benedikt Eggemeier","Benedikt Eggemeier, Javier Redondo, Klaus Dolag, Jens C. Niemeyer,
  Alejandro Vaquero","First Simulations of Axion Minicluster Halos","8 pages, 6 figures, accepted by PRL","Phys. Rev. Lett. 125, 041301 (2020)","10.1103/PhysRevLett.125.041301",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the gravitational collapse of axion dark matter fluctuations in the
post-inflationary scenario, so-called axion miniclusters, with N-body
simulations. Largely confirming theoretical expectations, overdensities begin
to collapse in the radiation-dominated epoch and form an early distribution of
miniclusters with masses up to $10^{-12}\,M_\odot$. After matter-radiation
equality, ongoing mergers give rise to a steep power-law distribution of
minicluster halo masses. The density profiles of well-resolved halos are
NFW-like to good approximation. The fraction of axion dark matter in these
bound structures is $\sim 0.75$ at redshift $z=100$.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:22:19 GMT""},{""version"":""v2"",""created"":""Tue, 21 Jul 2020 15:05:46 GMT""}]","2020-07-22"
"1911.09418","Yunteng Luan","Yunteng Luan, Hanyu Zhao, Zhi Yang, Yafei Dai","MSD: Multi-Self-Distillation Learning via Multi-classifiers within Deep
  Neural Networks",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the development of neural networks, more and more deep neural networks are
adopted in various tasks, such as image classification. However, as the huge
computational overhead, these networks could not be applied on mobile devices
or other low latency scenes. To address this dilemma, multi-classifier
convolutional network is proposed to allow faster inference via early
classifiers with the corresponding classifiers. These networks utilize
sophisticated designing to increase the early classifier accuracy. However,
naively training the multi-classifier network could hurt the performance
(accuracy) of deep neural networks as early classifiers throughout interfere
with the feature generation process.
  In this paper, we propose a general training framework named
multi-self-distillation learning (MSD), which mining knowledge of different
classifiers within the same network and increase every classifier accuracy. Our
approach can be applied not only to multi-classifier networks, but also modern
CNNs (e.g., ResNet Series) augmented with additional side branch classifiers.
We use sampling-based branch augmentation technique to transform a
single-classifier network into a multi-classifier network. This reduces the gap
of capacity between different classifiers, and improves the effectiveness of
applying MSD. Our experiments show that MSD improves the accuracy of various
networks: enhancing the accuracy of every classifier significantly for existing
multi-classifier network (MSDNet), improving vanilla single-classifier networks
with internal classifiers with high accuracy, while also improving the final
accuracy.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:35:50 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 08:52:14 GMT""},{""version"":""v3"",""created"":""Mon, 2 Dec 2019 12:04:32 GMT""}]","2019-12-03"
"1911.09419","Jie Wang","Zhanqiu Zhang, Jianyu Cai, Yongdong Zhang, and Jie Wang","Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction","Accepted to AAAI 2020",,,,"cs.LG cs.CL stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Knowledge graph embedding, which aims to represent entities and relations as
low dimensional vectors (or matrices, tensors, etc.), has been shown to be a
powerful technique for predicting missing links in knowledge graphs. Existing
knowledge graph embedding models mainly focus on modeling relation patterns
such as symmetry/antisymmetry, inversion, and composition. However, many
existing approaches fail to model semantic hierarchies, which are common in
real-world applications. To address this challenge, we propose a novel
knowledge graph embedding model -- namely, Hierarchy-Aware Knowledge Graph
Embedding (HAKE) -- which maps entities into the polar coordinate system. HAKE
is inspired by the fact that concentric circles in the polar coordinate system
can naturally reflect the hierarchy. Specifically, the radial coordinate aims
to model entities at different levels of the hierarchy, and entities with
smaller radii are expected to be at higher levels; the angular coordinate aims
to distinguish entities at the same level of the hierarchy, and these entities
are expected to have roughly the same radii but different angles. Experiments
demonstrate that HAKE can effectively model the semantic hierarchies in
knowledge graphs, and significantly outperforms existing state-of-the-art
methods on benchmark datasets for the link prediction task.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:37:18 GMT""},{""version"":""v2"",""created"":""Wed, 25 Dec 2019 12:31:40 GMT""},{""version"":""v3"",""created"":""Wed, 6 Apr 2022 03:18:14 GMT""}]","2022-04-07"
"1911.09420","Dmitry Treschev","Dmitry Treschev","Volume preserving diffeomorphisms as Poincare maps for volume preserving
  flows","6 pages",,"10.1070/RM9934",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $q:M\to M$ be a volume-preserving diffeomorphism of a smooth manifold
$M$. We study the possibility to present $q$ as the Poincar\'e map,
corresponding to a volume-preserving vector field on $\mathbb{T}\times M$,
$\mathbb{T} = \mathbb{R}/\mathbb{Z}$.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:38:00 GMT""}]","2020-06-24"
"1911.09421","Christos Psarras M.Sc.","Christos Psarras, Henrik Barthels and Paolo Bientinesi","The Linear Algebra Mapping Problem. Current state of linear algebra
  languages and libraries",,,"10.1145/3549935",,"cs.MS cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We observe a disconnect between the developers and the end users of linear
algebra libraries. On the one hand, the numerical linear algebra and the
high-performance communities invest significant effort in the development and
optimization of highly sophisticated numerical kernels and libraries, aiming at
the maximum exploitation of both the properties of the input matrices, and the
architectural features of the target computing platform. On the other hand, end
users are progressively less likely to go through the error-prone and time
consuming process of directly using said libraries by writing their code in C
or Fortran; instead, languages and libraries such as Matlab, Julia, Eigen and
Armadillo, which offer a higher level of abstraction, are becoming more and
more popular. Users are given the opportunity to code matrix computations with
a syntax that closely resembles the mathematical description; it is then a
compiler or an interpreter that internally maps the input program to lower
level kernels, as provided by libraries such as BLAS and LAPACK. Unfortunately,
our experience suggests that in terms of performance, this translation is
typically vastly suboptimal.
  In this paper, we first introduce the Linear Algebra Mapping Problem, and
then investigate how effectively a benchmark of test problems is solved by
popular high-level programming languages. Specifically, we consider Matlab,
Octave, Julia, R, Armadillo (C++), Eigen (C++), and NumPy (Python); the
benchmark is meant to test both standard compiler optimizations such as common
subexpression elimination and loop-invariant code motion, as well as linear
algebra specific optimizations such as optimal parenthesization of a matrix
product and kernel selection for matrices with properties. The aim of this
study is to give concrete guidelines for the development of languages and
libraries that support linear algebra computations.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:42:14 GMT""},{""version"":""v2"",""created"":""Sun, 5 Sep 2021 20:24:18 GMT""}]","2022-07-25"
"1911.09422","Juan Carlos Gonzalez Avella","M. G. Cosenza and M. E. Gavidia and J. C. Gonz\'alez-Avella","Against mass media trends: minority growth in cultural globalization","7 pages and 7 figures",,"10.1371/journal.pone.0230923",,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the collective behavior of a globalized society under the
influence of endogenous mass media trends. The mass media trend is a global
field corresponding to the statistical mode of the states of the agents in the
system. The interaction dynamics is based on Axelrod's rules for the
dissemination of culture. We find situations where the largest minority group,
possessing a cultural state different from that of the predominant trend
transmitted by the mass media, can grow to almost half of the size of the
population. We show that this phenomenon occurs when a critical number of
long-range connections are present in the underlying network of interactions.
We have numerically characterized four phases on the space of parameters of the
system: an ordered phase; a semi-ordered phase where almost half of the
population consists of the largest minority in a state different from that of
the mass media; a disordered phase; and a chimera-like phase where one large
domain coexists with many very small domains.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:43:52 GMT""}]","2020-07-01"
"1911.09423","Asim \""Onder","Asim \""Onder and Philip Li-Fan Liu","Stability of the solitary wave boundary layer subject to finite
  amplitude disturbances",,,"10.1017/jfm.2020.351",,"physics.flu-dyn","http://creativecommons.org/licenses/by/4.0/","  The stability and transition in the bottom boundary layer under a solitary
wave are analysed in the presence of finite amplitude disturbances. First, the
receptivity of the boundary layer is investigated using a linear input-output
analysis, in which the environment noise is modelled as distributed body
forces. The most dangerous perturbations in a time frame until flow reversal
are found to be arranged as counter-rotating streamwise-constant rollers. One
of these roller configurations is then selected and deployed to nonlinear
equations, and streaks of various amplitudes are generated via lift-up
mechanism. By means of secondary stability analysis and direct numerical
simulations, the dual role of streaks in the boundary-layer transition is
shown. When the amplitude of streaks remains moderate, these elongated features
remain stable until the adverse-pressure-gradient stage and have a dampening
effect on the instabilities developing thereafter. In contrast, when the
low-speed streaks reach high amplitudes exceeding 15% of free-stream velocity
at the respective phase, they become highly unstable to secondary sinuous modes
in the outer shear layers. Consequently, a subcritical transition to
turbulence, i.e., bypass transition, can be already initiated in the
favourable-pressure-gradient region ahead of the wave crest.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:50:21 GMT""}]","2020-07-15"
"1911.09424","Filippo Marcello Maccagni","F. M. Maccagni, M. Murgia, P. Serra, F. Govoni, K. Morokuma-Matsui, D.
  Kleiner, S. Buchner, G. I. J. J\'ozsa, P. Kamphuis, S. Makhathini, D. Cs.
  Moln\'ar, D. A. Prokhorov, A. Ramaila, M. Ramatsoku, K. Thorat, O. Smirnov","The flickering nuclear activity of Fornax A","Accepted for publication in Astronomy & Astrophysics","A&A 634, A9 (2020)","10.1051/0004-6361/201936867",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present new observations of Fornax A taken at 1 GHz with the MeerKAT
telescope and at 6 GHz with the Sardinia Radio Telescope (SRT). The sensitive
(noise ~16 micro-Jy beam$^{-1}$), high resolution ( < 10'') MeerKAT images show
that the lobes of Fornax A have a double-shell morphology, where dense
filaments are embedded in a diffuse and extended cocoon. We study the spectral
properties of these components by combining the MeerKAT and SRT observations
with archival data between 84 MHz and 217 GHz. For the first time, we show that
multiple episodes of nuclear activity must have formed the extended radio
lobes. The modelling of the radio spectrum suggests that the last episode of
injection of relativistic particles into the lobes started ~ 24 Myr ago and
stopped approximately 12 Myr ago. More recently (~ 3 Myr ago), a less powerful
and short ( < 1 Myr) phase of nuclear activity generated the central jets.
Currently, the core may be in a new active phase. It appears that Fornax A is
rapidly flickering. The dense environment in which Fornax A lives has lead to a
complex recent merger history for this galaxy, including mergers spanning a
range of gas contents and mass ratios, as shown by the analysis of the galaxy's
stellar- and cold-gas phases. This complex recent history may be the cause of
the rapid, recurrent nuclear activity of Fornax A.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:50:57 GMT""}]","2020-01-29"
"1911.09425","Pengcheng Zhang","Pengcheng Zhang (Member, IEEE), Feng Xiao, Xiapu Luo","SolidityCheck : Quickly Detecting Smart Contract Problems Through
  Regular Expressions","17 pages, 5 figures and 11 tables",,,,"cs.SE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As a blockchain platform that has developed vigorously in recent years,
Ethereum is different from Bitcoin in that it introduces smart contracts into
blockchain.Solidity is one of the most mature and widely used smart contract
programming language,which is used to write smart contracts and deploy them on
blockchain. However, once the data in the blockchain is written, it cannot be
modified. Ethereum smart contract is stored in the block chain, which makes the
smart contract can no longer repair the code problems such as re-entrancy
vulnerabilities or integer overflow problems. Currently, there still lacks of
an efficient and effective approach for detecting these problems in Solidity.
In this paper, we first classify all the possible problems in Solidity, then
propose a smart contract problem detection approach for Solidity, namely
SolidityCheck. The approach uses regular expressions to define the
characteristics of problematic statements and uses regular matching and program
instrumentation to prevent or detect problems. Finally, a large number of
experiments is performed to show that SolidityCheck is superior to existing
approaches.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:55:07 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 13:54:12 GMT""}]","2019-11-25"
"1911.09426","Peter Nejjar","Peter Nejjar","KPZ statistics of second class particles in ASEP via mixing","V3: A few minor typos corrected. Accepted for publication in
  Communications in Mathematical Physics",,"10.1007/s00220-020-03782-5",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the asymmetric simple exclusion process on $\mathbb{Z}$ with a
single second class particle initially at the origin. The first class particles
form two rarefaction fans which come together at the origin, where the large
time density jumps from $0$ to $1$. We are interested in $X(t)$, the position
of the second class particle at time $t$. We show that, under the KPZ $1/3$
scaling, $X(t)$ is asymptotically distributed as the difference of two
independent, $\mathrm{GUE}$-distributed random variables.The key part of the
proof is to show that $X(t)$ equals, up to a negligible term, the difference of
a random number of holes and particles, with the randomness built up by ASEP
itself. This provides a KPZ analogue to the 1994 result of Ferrari and Fontes
\cite{FF94b}, where this randomness comes from the initial data and leads to
Gaussian limit laws.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:56:02 GMT""},{""version"":""v2"",""created"":""Mon, 16 Dec 2019 08:50:13 GMT""},{""version"":""v3"",""created"":""Mon, 9 Mar 2020 13:18:33 GMT""}]","2020-06-24"
"1911.09427","Guy Shalev","Guy Shalev, Ran El-Yaniv, Daniel Klotz, Frederik Kratzert, Asher
  Metzger, Sella Nevo","Accurate Hydrologic Modeling Using Less Information",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Joint models are a common and important tool in the intersection of machine
learning and the physical sciences, particularly in contexts where real-world
measurements are scarce. Recent developments in rainfall-runoff modeling, one
of the prime challenges in hydrology, show the value of a joint model with
shared representation in this important context. However, current
state-of-the-art models depend on detailed and reliable attributes
characterizing each site to help the model differentiate correctly between the
behavior of different sites. This dependency can present a challenge in
data-poor regions. In this paper, we show that we can replace the need for such
location-specific attributes with a completely data-driven learned embedding,
and match previous state-of-the-art results with less information.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:01:19 GMT""}]","2019-11-22"
"1911.09428","Zhengyang Lu","Zhengyang Lu, Ying Chen","Single Image Super Resolution based on a Modified U-net with Mixed
  Gradient Loss",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Single image super-resolution (SISR) is the task of inferring a
high-resolution image from a single low-resolution image. Recent research on
super-resolution has achieved great progress due to the development of deep
convolutional neural networks in the field of computer vision. Existing
super-resolution reconstruction methods have high performances in the criterion
of Mean Square Error (MSE) but most methods fail to reconstruct an image with
shape edges. To solve this problem, the mixed gradient error, which is composed
by MSE and a weighted mean gradient error, is proposed in this work and applied
to a modified U-net network as the loss function. The modified U-net removes
all batch normalization layers and one of the convolution layers in each block.
The operation reduces the number of parameters, and therefore accelerates the
reconstruction. Compared with the existing image super-resolution algorithms,
the proposed reconstruction method has better performance and time consumption.
The experiments demonstrate that modified U-net network architecture with mixed
gradient loss yields high-level results on three image datasets: SET14, BSD300,
ICDAR2003. Code is available online.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:02:38 GMT""}]","2019-11-22"
"1911.09429","Abdel\^aali Boudjem\^aa abdou abdel aalim","Abdelaali Boudjemaa and Redaouia Keltoum","Effects of weak disorder on two-dimensional bilayered dipolar
  Bose-Einstein condensates","6 pages, 5 figures","Chaos, Solitons and Fractals 131, 109543 (2020)","10.1016/j.chaos.2019.109543",,"cond-mat.dis-nn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate properties of two-dimensional bilayered dipolar Bose condensed
gases in a weak random potential with Gaussian correlation at zero temperature.
Here the dipoles are oriented perpendicularly to the layers and in
parallel/antiparallel configurations. We calculate analytically and numerically
the condensate depletion, the one-body density-matrix, and the superfluid
fraction in the framework of the Bogoliubov theory. Our analysis not only
provides fascinating new results do not exist in the literature but also shows
that the intriguing interplay between the disorder, the interlayer coupling and
the polarization orientation may lead to localize/delocalize the condensed
particles results in the formation of glassy/superfluid phases. For a pure
short-range interaction and a vanishing correlation length and a small
interlayer distance, we reproduce the seminal results of Huang and Meng. While
for a vanishing interlayer distance, our results reduce to the those obtained
for single layer systems.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:04:14 GMT""}]","2020-09-01"
"1911.09430","Tao Zhang","Tao Zhang, Yang Cong, Gan Sun, Qianqian Wang, Zhenming Ding","Visual Tactile Fusion Object Clustering","8 pages, 5 figures",,,,"cs.LG cs.RO stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Object clustering, aiming at grouping similar objects into one cluster with
an unsupervised strategy, has been extensivelystudied among various data-driven
applications. However, most existing state-of-the-art object clustering methods
(e.g., single-view or multi-view clustering methods) only explore visual
information, while ignoring one of most important sensing modalities, i.e.,
tactile information which can help capture different object properties and
further boost the performance of object clustering task. To effectively benefit
both visual and tactile modalities for object clustering, in this paper, we
propose a deep Auto-Encoder-like Non-negative Matrix Factorization framework
for visual-tactile fusion clustering. Specifically, deep matrix factorization
constrained by an under-complete Auto-Encoder-like architecture is employed to
jointly learn hierarchical expression of visual-tactile fusion data, and
preserve the local structure of data generating distribution of visual and
tactile modalities. Meanwhile, a graph regularizer is introduced to capture the
intrinsic relations of data samples within each modality. Furthermore, we
propose a modality-level consensus regularizer to effectively align thevisual
and tactile data in a common subspace in which the gap between visual and
tactile data is mitigated. For the model optimization, we present an efficient
alternating minimization strategy to solve our proposed model. Finally, we
conduct extensive experiments on public datasets to verify the effectiveness of
our framework.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:04:17 GMT""}]","2019-11-22"
"1911.09431","Thomas Demeester","Thomas Demeester","System Identification with Time-Aware Neural Sequence Models","34th AAAI Conference on Artificial Intelligence (AAAI 2020)",,,,"cs.LG cs.SY eess.SY stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Established recurrent neural networks are well-suited to solve a wide variety
of prediction tasks involving discrete sequences. However, they do not perform
as well in the task of dynamical system identification, when dealing with
observations from continuous variables that are unevenly sampled in time, for
example due to missing observations. We show how such neural sequence models
can be adapted to deal with variable step sizes in a natural way. In
particular, we introduce a time-aware and stationary extension of existing
models (including the Gated Recurrent Unit) that allows them to deal with
unevenly sampled system observations by adapting to the observation times,
while facilitating higher-order temporal behavior. We discuss the properties
and demonstrate the validity of the proposed approach, based on samples from
two industrial input/output processes.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:09:08 GMT""}]","2019-11-22"
"1911.09432","Istv\'an Andr\'as Seres","Ferenc Beres, Istvan Andras Seres, Andras A. Benczur","A Cryptoeconomic Traffic Analysis of Bitcoin's Lightning Network","Cryptoeconomic Systems (CES) '20 Journal & Conference 7-8 March 2020,
  MIT, Cambridge, MA",,,,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lightning Network (LN) is designed to amend the scalability and privacy
issues of Bitcoin. It's a payment channel network where Bitcoin transactions
are issued off chain, onion routed through a private payment path with the aim
to settle transactions in a faster, cheaper, and private manner, as they're not
recorded in a costly-to-maintain, slow, and public ledger. In this work, we
design a traffic simulator to empirically study LN's transaction fees and
privacy provisions. The simulator relies on publicly available data of the
network structure and generates transactions under assumptions we attempt to
validate based on information spread by certain blog posts of LN node owners.
Our findings on the estimated revenue from transaction fees are in line with
widespread opinion that participation is economically irrational for the
majority of large routing nodes who currently hold the network together. Either
traffic or transaction fees must increase by orders of magnitude to make
payment routing economically viable. We give worst-case estimates for the
potential fee increase by assuming strong price competition among the routers.
We estimate how current channel structures and pricing policies respond to a
potential increase in traffic, how reduction in locked funds on channels would
affect the network, and show examples of nodes who are estimated to operate
with economically feasible revenue. Even if transactions are onion routed,
strong statistical evidence on payment source and destination can be inferred,
as many transaction paths only consist of a single intermediary by the side
effect of LN's small-world nature. Based on our simulation experiments, we
quantitatively characterize the privacy shortcomings of current LN operation,
and propose a method to inject additional hops in routing paths to demonstrate
how privacy can be strengthened with very little additional transactional cost.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:12:18 GMT""},{""version"":""v2"",""created"":""Mon, 3 Feb 2020 07:43:19 GMT""},{""version"":""v3"",""created"":""Mon, 13 Jul 2020 17:39:24 GMT""}]","2020-07-14"
"1911.09433","Jianwei Zhao","Jianwei Zhao, Qi Dong, Yanjie Zhao, Bolei Wang, and Feifei Gao","Time Varying Channel Tracking for Multi-UAV Wideband Communications with
  Beam Squint",,,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unmanned aerial vehicle (UAV) has become an appealing solution for a wide
range of commercial and civilian applications because of its high mobility and
flexible deployment. Due to the continuous UAV navigation, the channel between
UAV and base station (BS) is subject to the Doppler effect. Meanwhile, when the
BS is equipped with massive number of antennas, the non-negligible propagation
delay across the array aperture would cause beam squint effect. In this paper,
we first investigate the channel of UAV communications under both Doppler shift
effect and beam squint effect. Then, we design a gridless compressed sensing
(GCS) based channel tracking method, where the high dimension uplink channel
can be derived by estimating a few physical parameters such as the direction of
arrival (DOA), Doppler shift, and the complex gain information. Besides, with
the Doppler shift reciprocity and angular reciprocity, the downlink channel can
be derived by only one pilot symbol, which greatly decreases the downlink
channel training overhead. Various simulation results are provided to verify
the effectiveness of the proposed methods.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:13:48 GMT""}]","2019-11-22"
"1911.09434","Raul Ribeiro Prado","A. Archer, W. Benbow, R. Bird, A. Brill, R. Brose, M. Buchovecky, J.
  L. Christiansen, A. J. Chromey, W. Cui, A. Falcone, Q. Feng, J. P. Finley, L.
  Fortson, A. Furniss, A. Gent, G. H. Gillanders, C. Giuri, O. Gueta, D. Hanna,
  T. Hassan, O. Hervet, J. Holder, G. Hughes, T. B. Humensky, P. Kaaret, N.
  Kelley-Hoskins, M. Kertzman, D. Kieda, M. Krause, M. J. Lang, G. Maier, P.
  Moriarty, R. Mukherjee, D. Nieto, M. Nievas-Rosillo, S. O'Brien, R. A. Ong,
  A. N. Otte, N. Park, A. Petrashyk, K. Pfrang, M. Pohl, R. R. Prado, E.
  Pueschel, J. Quinn, K. Ragan, P. T. Reynolds, D. Ribeiro, G. T. Richards, E.
  Roache, I. Sadeh, M. Santander, S. Schlenstedt, G. H. Sembroski, I. Sushch,
  A. Weinstein, P. Wilcox, A. Wilhelm, D. A. Williams, T. J Williamson, C. J.
  Hailey, S. Mandel, K. Mori","Probing the Properties of the Pulsar Wind in the Gamma-Ray Binary HESS
  J0632+057 with NuSTAR and VERITAS Observations","Accepted for publication in The Astrophysical Journal",,"10.3847/1538-4357/ab59de",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  HESS J0632+057 is a gamma-ray binary composed of a compact object orbiting a
Be star with a period of about $315$ days. Extensive X-ray and TeV gamma-ray
observations have revealed a peculiar light curve containing two peaks,
separated by a dip. We present the results of simultaneous observations in hard
X-rays with NuSTAR and in TeV gamma-rays with VERITAS, performed in November
and December 2017. These observations correspond to the orbital phases
$\phi\approx0.22$ and $0.3$, where the fluxes are rising towards the first
light-curve peak. A significant variation of the spectral index from
1.77$\pm$0.05 to 1.56$\pm$0.05 is observed in the X-ray data. The
multi-wavelength spectral energy distributions (SED) derived from the
observations are interpreted in terms of a leptonic model, in which the compact
object is assumed to be a pulsar and non-thermal radiation is emitted by
high-energy electrons accelerated at the shock formed by the collision between
the stellar and pulsar wind. The results of the SED fitting show that our data
can be consistently described within this scenario, and allow us to estimate
the magnetization of the pulsar wind at the location of the shock formation.
The constraints on the pulsar-wind magnetization provided by our results are
shown to be consistent with those obtained from other systems.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:15:30 GMT""},{""version"":""v2"",""created"":""Wed, 27 Nov 2019 11:51:27 GMT""},{""version"":""v3"",""created"":""Thu, 12 Dec 2019 08:58:05 GMT""}]","2020-01-29"
"1911.09435","Limin Wang","Zhaoyang Liu, Donghao Luo, Yabiao Wang, Limin Wang, Ying Tai, Chengjie
  Wang, Jilin Li, Feiyue Huang, Tong Lu","TEINet: Towards an Efficient Architecture for Video Recognition","Accepted by AAAI 2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Efficiency is an important issue in designing video architectures for action
recognition. 3D CNNs have witnessed remarkable progress in action recognition
from videos. However, compared with their 2D counterparts, 3D convolutions
often introduce a large amount of parameters and cause high computational cost.
To relieve this problem, we propose an efficient temporal module, termed as
Temporal Enhancement-and-Interaction (TEI Module), which could be plugged into
the existing 2D CNNs (denoted by TEINet). The TEI module presents a different
paradigm to learn temporal features by decoupling the modeling of channel
correlation and temporal interaction. First, it contains a Motion Enhanced
Module (MEM) which is to enhance the motion-related features while suppress
irrelevant information (e.g., background). Then, it introduces a Temporal
Interaction Module (TIM) which supplements the temporal contextual information
in a channel-wise manner. This two-stage modeling scheme is not only able to
capture temporal structure flexibly and effectively, but also efficient for
model inference. We conduct extensive experiments to verify the effectiveness
of TEINet on several benchmarks (e.g., Something-Something V1&V2, Kinetics,
UCF101 and HMDB51). Our proposed TEINet can achieve a good recognition accuracy
on these datasets but still preserve a high efficiency.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:16:32 GMT""}]","2019-11-22"
"1911.09436","Galina L. Klimchitskaya","G.L. Klimchitskaya","The Casimir-Polder interaction of an atom and real graphene sheet:
  Verification of the Nernst heat theorem","8 pages; to appear in Mod. Phys. Lett. A; based on the talk presented
  at the ""10th Alexander Friedmann International Seminar on Gravitation and
  Cosmology and 4th Symposium on the Casimir Effect"" (Saint Petersburg, Russia,
  June 2019)","Mod. Phys. Lett. A, v.35, 2040004 (2020)","10.1142/S0217732320400040",,"quant-ph cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We find the low-temperature behavior of the Casimir-Polder free energy and
entropy for an atom interacting with real graphene sheet possessing nonzero
energy gap and chemical potential. Employing the formalism of the polarization
tensor, it is shown that the Casimir-Polder entropy goes to zero by the power
law with vanishing temperature, i.e., the Nernst heat theorem is satisfied.
This result is discussed in connection with the problems connected with account
of free charge carriers in the Lifshitz theory.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:23:41 GMT""}]","2020-02-06"
"1911.09437","Andrea Castro","Andrea Castro (on behalf of the ATLAS and CMS Collaborations)","Top Quark Mass Measurements in ATLAS and CMS","6 pages, 2 figures. Proceedings of the 12th International Workshop on
  Top Quark Physics - Beijing, China, September 22-27, 2019",,,"CMS CR-2019/262","hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ATLAS and CMS Collaborations have performed a variety of measurements of
the top quark mass, taking advantage of the abundant production of top quarks
at the LHC. The most recent measurements are reported here, based on data
collected at 8 and 13 TeV, with particular emphasis on the distinction between
the so-called ""direct"" measurements and the ""indirect"" evaluations obtained
from cross sections and differential cross sections.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:23:42 GMT""}]","2019-11-22"
"1911.09438","Xin-Zhen Weng","Xin-Zhen Weng, Li-Ye Xiao, Wei-Zhen Deng, Xiao-Lin Chen, and Shi-Lin
  Zhu","Three body open flavor decays of higher vector charmonium and
  bottomonium","5 pages, 1 figure; contribution to the proceedings of the XVIII
  International Conference on Hadron Spectroscopy and Structure, HADRON-2019.
  August 16-21, Guilin, China",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  With an extended quark pair creation model we systematically study the
OZI-allowed three body open flavor decays of higher vector charmonium and
bottomonium states. We obtain that the $BB^*\pi$ and $B^*B^*\pi$ partial decay
widths of $\Upsilon(10860)$ are consistent with experiment, and the
corresponding partial decay widths of $\Upsilon(11020)$ can reach up to
2$\sim$3 MeV. Meanwhile the partial widths of $DD^*\pi$ and $D^*D^*\pi$ modes
for most higher vector charmonium states can reach up to several MeV.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:31:20 GMT""}]","2019-11-22"
"1911.09439","Xue Zhang","Xue Zhang and Qing-Guo Huang","Measuring $H_0$ from low-$z$ datasets","4 pages, 1 figure",,,,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Adopting the low-redshift observational datasets, including the Pantheon
sample of Type Ia supernovae, baryon acoustic oscillation measurements, and the
tomographic Alcock-Paczynski method, we determine the Hubble constant to be
$67.95^{+0.78}_{-1.03}$ , $69.81^{+2.22}_{-2.70}$ and $66.75^{+3.42}_{-4.23}$
km s$^{-1}$ Mpc$^{-1}$ at 68\% confidence level in the $\Lambda$CDM, $w$CDM and
$w_0w_a$CDM models, respectively. Compared to the Hubble constant given by
Riess et al. in 2019, we conclude that the new physics beyond the standard
$\Lambda$CDM model is needed if all of these datasets are reliable.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:36:21 GMT""}]","2019-11-22"
"1911.09440","Anton A. Kutsenko","Anton A. Kutsenko","Classification of integro-differential $C^*$-algebras",,,,,"math.OA math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The integro-differential algebra $\mathscr{F}_{N,M}$ is the $C^*$-algebra
generated by the following operators acting on $L^2([0,1)^N\to\mathbb{C}^M)$:
1) operators of multiplication by bounded matrix-valued functions, 2) finite
differential operators, 3) integral operators. We give a complete
characterization of $\mathscr{F}_{N,M}$ in terms of its Bratteli diagram. In
particular, we show that $\mathscr{F}_{N,M}$ does not depend on $M$ but depends
on $N$. At the same time, it is known that differential algebras
$\mathscr{H}_{N,M}$, generated by the operators 1) and 2), do not depend on
both dimensions $N$ and $M$, they are all $*$-isomorphic to the universal
UHF-algebra. We explicitly compute the Glimm-Bratteli symbols (for
$\mathscr{H}_{N,M}$ it was already computed earlier) $$
  \mathfrak{n}(\mathscr{F}_{N,M})=\prod_{n=1}^{\infty}\begin{pmatrix} n & 0 \\
n-1 & 1 \end{pmatrix}^{\otimes N}\begin{pmatrix}1 \\ 1 \end{pmatrix}^{\otimes
N},\ \ \ \ \mathfrak{n}(\mathscr{H}_{N,M})=\prod_{n=1}^{\infty}n, $$ which
characterize completely the corresponding AF-algebras.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:36:51 GMT""},{""version"":""v2"",""created"":""Thu, 23 Jan 2020 13:00:38 GMT""},{""version"":""v3"",""created"":""Sun, 16 Feb 2020 16:04:11 GMT""}]","2020-02-18"
"1911.09441","Olga Rozanova","Sergey I. Nikulin, Olga S. Rozanova","Some analytically solvable problems of the mean-field games theory","13 pages, 1 figure",,,,"math.AP q-fin.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the mean field games equations, consisting of the coupled
Kolmogorov-Fokker-Planck and Hamilton-Jacobi-Bellman equations. The equations
are complemented by initial and terminal conditions. It is shown that with some
specific choice of data, this problem can be reduced to solving a quadratically
nonlinear system of ODEs. This situation occurs naturally in economic
applications. As an example, the problem of forming an investor's opinion on an
asset is considered.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:37:19 GMT""}]","2019-11-22"
"1911.09442","Uri Keich","Kristen Emery and Uri Keich","Controlling the FDR in variable selection via multiple knockoffs","Fixed minor linguistic errors in the original submission",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Barber and Candes recently introduced a feature selection method called
knockoff+ that controls the false discovery rate (FDR) among the selected
features in the classical linear regression problem. Knockoff+ uses the
competition between the original features and artificially created knockoff
features to control the FDR [1]. We generalize Barber and Candes' knockoff
construction to generate multiple knockoffs and use those in conjunction with a
recently developed general framework for multiple competition-based FDR control
[9].
  We prove that using our initial multiple-knockoff construction the combined
procedure rigorously controls the FDR in the finite sample setting. Because
this construction has a somewhat limited utility we introduce a heuristic we
call ""batching"" which significantly improves the power of our multiple-knockoff
procedures.
  Finally, we combine the batched knockoffs with a new context-dependent
resampling scheme that replaces the generic resampling scheme used in the
general multiple-competition setup. We show using simulations that the
resulting ""multi-knockoff-select"" procedure empirically controls the FDR in the
finite setting of the variable selection problem while often delivering
substantially more power than knockoff+.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:41:48 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 03:16:18 GMT""}]","2019-11-25"
"1911.09443","Roy Karasik","Roy Karasik, Osvaldo Simeone, Marco Di Renzo, Shlomo Shamai (Shitz)","Beyond Max-SNR: Joint Encoding for Reconfigurable Intelligent Surfaces","To be submitted for conference publication",,,,"cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A communication link aided by a Reconfigurable Intelligent Surface (RIS) is
studied, in which the transmitter can control the state of the RIS via a
finite-rate control link. Prior work mostly assumed a fixed RIS configuration
irrespective of the transmitted information. In contrast, this work derives
information-theoretic limits, and demonstrates that the capacity is achieved by
a scheme that jointly encodes information in the transmitted signal as well as
in the RIS configuration. In addition, a novel signaling strategy based on
layered encoding is proposed that enables practical successive
cancellation-type decoding at the receiver. Numerical experiments demonstrate
that the standard max-SNR scheme that fixes the configuration of the RIS as to
maximize the Signal-to-Noise Ratio (SNR) at the receiver is strictly
suboptimal, and is outperformed by the proposed strategies at all practical SNR
levels.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:45:55 GMT""}]","2019-11-22"
"1911.09444","Pablo Spiga","Pablo Spiga","On the equivalence between a conjecture of Babai-Godsil and a conjecture
  of Xu concerning the enumeration of Cayley graphs",,,,,"math.CO math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we show that two distinct conjectures, the first proposed by
Babai and Godsil in $1982$ and the second proposed by Xu in $1998$, concerning
the asymptotic enumeration of Cayley graphs are in fact equivalent. This result
follows from a more general theorem concerning the asymptotic enumeration of a
certain family of Cayley graphs.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:55:04 GMT""}]","2019-11-22"
"1911.09445","Guoqiang Zhang","Guoqiang Zhang, Kenta Niwa and W. B. Kleijn","Approximated Orthonormal Normalisation in Training Neural Networks",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Generalisation of a deep neural network (DNN) is one major concern when
employing the deep learning approach for solving practical problems. In this
paper we propose a new technique, named approximated orthonormal normalisation
(AON), to improve the generalisation capacity of a DNN model. Considering a
weight matrix W from a particular neural layer in the model, our objective is
to design a function h(W) such that its row vectors are approximately
orthogonal to each other while allowing the DNN model to fit the training data
sufficiently accurate. By doing so, it would avoid co-adaptation among neurons
of the same layer to be able to improve network-generalisation capacity.
Specifically, at each iteration, we first approximate (WW^T)^(-1/2) using its
Taylor expansion before multiplying the matrix W. After that, the matrix
product is then normalised by applying the spectral normalisation (SN)
technique to obtain h(W). Conceptually speaking, AON is designed to turn
orthonormal regularisation into orthonormal normalisation to avoid manual
balancing the original and penalty functions. Experimental results show that
AON yields promising validation performance compared to orthonormal
regularisation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:57:50 GMT""},{""version"":""v2"",""created"":""Tue, 14 Jan 2020 11:05:56 GMT""}]","2020-01-15"
"1911.09446","K\k{e}stutis \v{C}esnavi\v{c}ius","Kestutis Cesnavicius, Michael Neururer, Abhishek Saha","The Manin constant and the modular degree","51 pages, 1 figure; final version, to appear in Journal of the
  European Mathematical Society",,,,"math.NT math.AG math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Manin constant $c$ of an elliptic curve $E$ over $\mathbb{Q}$ is the
nonzero integer that scales the differential $\omega_f$ determined by the
normalized newform $f$ associated to $E$ into the pullback of a N\'{e}ron
differential under a minimal parametrization $\phi\colon X_0(N)_{\mathbb{Q}}
\twoheadrightarrow E$. Manin conjectured that $c = \pm 1$ for optimal
parametrizations, and we prove that in general $c \mid \mathrm{deg}(\phi)$
under a minor assumption at $2$ and $3$ that is not needed for cube-free $N$ or
for parametrizations by $X_1(N)_{\mathbb{Q}}$. Since $c$ is supported at the
additive reduction primes, which need not divide $\mathrm{deg}(\phi)$, this
improves the status of the Manin conjecture for many $E$. Our core result that
gives this divisibility is the containment $\omega_f \in H^0(X_0(N), \Omega)$,
which we establish by combining automorphic methods with techniques from
arithmetic geometry; here the modular curve $X_0(N)$ is considered over
$\mathbb{Z}$ and $\Omega$ is its relative dualizing sheaf over $\mathbb{Z}$. We
reduce this containment to $p$-adic bounds on denominators of the Fourier
expansions of $f$ at all the cusps of $X_0(N)_{\mathbb{C}}$ and then use the
recent basic identity for the $p$-adic Whittaker newform to establish stronger
bounds in the more general setup of newforms of weight $k$ on $X_0(N)$. To
overcome obstacles at $2$ and $3$, we analyze nondihedral supercuspidal
representations of $\mathrm{GL}_2(\mathbb{Q}_2)$ and exhibit new cases in which
$X_0(N)_{\mathbb{Z}}$ has rational singularities.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:59:32 GMT""},{""version"":""v2"",""created"":""Mon, 16 Dec 2019 12:14:11 GMT""},{""version"":""v3"",""created"":""Wed, 2 Nov 2022 07:19:29 GMT""}]","2022-11-03"
"1911.09447","Gregor Ulm","Gregor Ulm, Simon Smith, Adrian Nilsson, Emil Gustavsson, Mats
  Jirstrand","S-RASTER: Contraction Clustering for Evolving Data Streams","24 pages, 5 figures, 2 tables","Journal of Big Data (Springer) Vol. 7, Article number: 62 (2020)","10.1186/s40537-020-00336-3",,"cs.DS cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Contraction Clustering (RASTER) is a single-pass algorithm for density-based
clustering of 2D data. It can process arbitrary amounts of data in linear time
and in constant memory, quickly identifying approximate clusters. It also
exhibits good scalability in the presence of multiple CPU cores. RASTER
exhibits very competitive performance compared to standard clustering
algorithms, but at the cost of decreased precision. Yet, RASTER is limited to
batch processing and unable to identify clusters that only exist temporarily.
In contrast, S-RASTER is an adaptation of RASTER to the stream processing
paradigm that is able to identify clusters in evolving data streams. This
algorithm retains the main benefits of its parent algorithm, i.e. single-pass
linear time cost and constant memory requirements for each discrete time step
within a sliding window. The sliding window is efficiently pruned, and
clustering is still performed in linear time. Like RASTER, S-RASTER trades off
an often negligible amount of precision for speed. Our evaluation shows that
competing algorithms are at least 50% slower. Furthermore, S-RASTER shows good
qualitative results, based on standard metrics. It is very well suited to
real-world scenarios where clustering does not happen continually but only
periodically.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:01:43 GMT""},{""version"":""v2"",""created"":""Tue, 4 Feb 2020 12:57:20 GMT""},{""version"":""v3"",""created"":""Mon, 15 Jun 2020 22:48:06 GMT""},{""version"":""v4"",""created"":""Mon, 6 Jul 2020 19:38:21 GMT""},{""version"":""v5"",""created"":""Wed, 16 Sep 2020 12:43:59 GMT""}]","2020-09-17"
"1911.09448","Kishor Bharti Mr.","Kishor Bharti, Maharshi Ray, Antonios Varvitsiotis, Ad\'an Cabello,
  and Leong-Chuan Kwek","Local certification of programmable quantum devices of arbitrary high
  dimensionality","10 pages, 4 figures, Comments welcome",,,,"quant-ph cs.DM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The onset of the era of fully-programmable error-corrected quantum computers
will be marked by major breakthroughs in all areas of science and engineering.
These devices promise to have significant technological and societal impact,
notable examples being the analysis of big data through better machine learning
algorithms and the design of new materials. Nevertheless, the capacity of
quantum computers to faithfully implement quantum algorithms relies crucially
on their ability to prepare specific high-dimensional and high-purity quantum
states, together with suitable quantum measurements. Thus, the unambiguous
certification of these requirements without assumptions on the inner workings
of the quantum computer is critical to the development of trusted quantum
processors. One of the most important approaches for benchmarking quantum
devices is through the mechanism of self-testing that requires a pair of
entangled non-communicating quantum devices. Nevertheless, although computation
typically happens in a localized fashion, no local self-testing scheme is known
to benchmark high dimensional states and measurements. Here, we show that the
quantum self-testing paradigm can be employed to an individual quantum computer
that is modelled as a programmable black box by introducing a noise-tolerant
certification scheme. We substantiate the applicability of our scheme by
providing a family of outcome statistics whose observation certifies that the
computer is producing specific high-dimensional quantum states and implementing
specific measurements.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:03:46 GMT""}]","2019-11-22"
"1911.09449","Xingxing Wei","Zhipeng Wei, Jingjing Chen, Xingxing Wei, Linxi Jiang, Tat-Seng Chua,
  Fengfeng Zhou, Yu-Gang Jiang","Heuristic Black-box Adversarial Attacks on Video Recognition Models","AAAI-2020 Oral",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the problem of attacking video recognition models in the black-box
setting, where the model information is unknown and the adversary can only make
queries to detect the predicted top-1 class and its probability. Compared with
the black-box attack on images, attacking videos is more challenging as the
computation cost for searching the adversarial perturbations on a video is much
higher due to its high dimensionality. To overcome this challenge, we propose a
heuristic black-box attack model that generates adversarial perturbations only
on the selected frames and regions. More specifically, a heuristic-based
algorithm is proposed to measure the importance of each frame in the video
towards generating the adversarial examples. Based on the frames' importance,
the proposed algorithm heuristically searches a subset of frames where the
generated adversarial example has strong adversarial attack ability while keeps
the perturbations lower than the given bound. Besides, to further boost the
attack efficiency, we propose to generate the perturbations only on the salient
regions of the selected frames. In this way, the generated perturbations are
sparse in both temporal and spatial domains. Experimental results of attacking
two mainstream video recognition methods on the UCF-101 dataset and the HMDB-51
dataset demonstrate that the proposed heuristic black-box adversarial attack
method can significantly reduce the computation cost and lead to more than 28\%
reduction in query numbers for the untargeted attack on both datasets.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:04:33 GMT""}]","2019-11-22"
"1911.09450","Haoli Bai","Haoli Bai, Jiaxiang Wu, Irwin King, Michael Lyu","Few Shot Network Compression via Cross Distillation","AAAI 2020","The Thirty-Fourth AAAI Conference on Artificial Intelligence
  (AAAI), 2020",,,"cs.LG cs.CV stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Model compression has been widely adopted to obtain light-weighted deep
neural networks. Most prevalent methods, however, require fine-tuning with
sufficient training data to ensure accuracy, which could be challenged by
privacy and security issues. As a compromise between privacy and performance,
in this paper we investigate few shot network compression: given few samples
per class, how can we effectively compress the network with negligible
performance drop? The core challenge of few shot network compression lies in
high estimation errors from the original network during inference, since the
compressed network can easily over-fits on the few training instances. The
estimation errors could propagate and accumulate layer-wisely and finally
deteriorate the network output. To address the problem, we propose cross
distillation, a novel layer-wise knowledge distillation approach. By
interweaving hidden layers of teacher and student network, layer-wisely
accumulated estimation errors can be effectively reduced.The proposed method
offers a general framework compatible with prevalent network compression
techniques such as pruning. Extensive experiments on benchmark datasets
demonstrate that cross distillation can significantly improve the student
network's accuracy when only a few training instances are available.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:07:52 GMT""},{""version"":""v2"",""created"":""Sat, 2 May 2020 10:20:20 GMT""}]","2020-05-05"
"1911.09451","Josh Merel","Josh Merel, Diego Aldarondo, Jesse Marshall, Yuval Tassa, Greg Wayne,
  Bence \""Olveczky","Deep neuroethology of a virtual rodent",,,,,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Parallel developments in neuroscience and deep learning have led to mutually
productive exchanges, pushing our understanding of real and artificial neural
networks in sensory and cognitive systems. However, this interaction between
fields is less developed in the study of motor control. In this work, we
develop a virtual rodent as a platform for the grounded study of motor activity
in artificial models of embodied control. We then use this platform to study
motor activity across contexts by training a model to solve four complex tasks.
Using methods familiar to neuroscientists, we describe the behavioral
representations and algorithms employed by different layers of the network
using a neuroethological approach to characterize motor activity relative to
the rodent's behavior and goals. We find that the model uses two classes of
representations which respectively encode the task-specific behavioral
strategies and task-invariant behavioral kinematics. These representations are
reflected in the sequential activity and population dynamics of neural
subpopulations. Overall, the virtual rodent facilitates grounded collaborations
between deep reinforcement learning and motor neuroscience.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:08:17 GMT""}]","2019-11-22"
"1911.09452","Shamit Shrivastava","Shamit Shrivastava and Robin O. Cleveland","Photo and acoustic emissions from the non-equilibrium phase transition
  at the interface during cavitation","11 Pages 4 figures",,,,"physics.flu-dyn cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This study investigates the emission of light and sound from cavitation
caused by intense pressure pulses in water. Based on time-resolved measurements
of (a) pressure waveform at the focus, (b) light scattering upon cavitation,
(c) acoustic emission, and (d) photoemission (sonoluminescence) it is shown
that emissions occur upon the creation or expansion as well as the collapse of
the cavity. These results suggest that the thermodynamic irreversibility,
resulting from non-equilibrium phase transition and changes in surface entropy,
is a basis for photo and acoustic emissions during cavitation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:08:24 GMT""}]","2019-11-22"
"1911.09453","Shu Suzuki","Shu-Ichiro Suzuki, Masatoshi Sato, and Yukio Tanaka","Identifying possible pairing states in Sr$_2$RuO$_4$ by tunneling
  spectroscopy","9 pages, 9 figures, 1 table, accepted for publication in Physical
  Review B","Phys. Rev. B 101, 054505 (2020)","10.1103/PhysRevB.101.054505",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the tunneling spectroscopy of three-dimensional
normal-metal/Sr$_2$RuO$_4$ junctions as an experimental means to identify
pairing symmetry in Sr$_2$RuO$_4$. In particular, we consider three different
possible pairing states in Sr$_2$RuO$_4$: spin-singlet chiral $d$-wave,
spin-triplet helical $p$-wave, and spin-nematic $f$-wave ones, all of which are
consistent with recent nuclear-magnetic-resonance experiments [A. Pustogow et
al., Nature 574, 72 (2019)]. The Blonder-Tinkham-Klapwijk theory is employed to
calculate the tunneling conductance, and the cylindrical two-dimensional Fermi
surface of Sr$_2$RuO$_4$ is properly taken into account as an anisotropic
effective mass and a cutoff in the momentum integration. It is pointed out that
the chiral $d$-wave pairing state is inconsistent with previous tunneling
conductance experiments along the $c$-axis. We also find that the remaining
candidates, the spin-triplet helical $p$-wave pairing state and the
spin-nematic $f$-wave ones, can be distinguished from each other by the
in-plane tunneling spectroscopy along the $a$- and $b$-axes.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:09:06 GMT""},{""version"":""v2"",""created"":""Wed, 29 Jan 2020 13:53:28 GMT""}]","2020-02-19"
"1911.09454","Bitan Hou","Bitan Hou, Yujing Wang, Ming Zeng, Shan Jiang, Ole J. Mengshoel,
  Yunhai Tong, Jing Bai","Customized Graph Embedding: Tailoring Embedding Vectors to different
  Applications","The first three authors contributed equally to this paper",,,,"cs.LG cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Graph is a natural representation of data for a variety of real-word
applications, such as knowledge graph mining, social network analysis and
biological network comparison. For these applications, graph embedding is
crucial as it provides vector representations of the graph. One limitation of
existing graph embedding methods is that their embedding optimization
procedures are disconnected from the target application. In this paper, we
propose a novel approach, namely Customized Graph Embedding (CGE) to tackle
this problem. The CGE algorithm learns customized vector representations of
graph nodes by differentiating the importance of distinct graph paths
automatically for a specific application. Extensive experiments were carried
out on a diverse set of node classification datasets, which demonstrate strong
performances of CGE and provide deep insights into the model.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:09:26 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jan 2020 09:17:17 GMT""},{""version"":""v3"",""created"":""Thu, 23 Jan 2020 10:07:19 GMT""}]","2020-01-24"
"1911.09455","Mahmood Mahmoodian","M.M. Mahmoodian and M.V. Entin","Conductivity of a two-dimensional HgTe layer near the critical width:
  The role of developed edge states network and random mixture of $p$- and
  $n$-domains","9 pages, 7 figures","Phys. Rev. B 101, 125415 (2020)","10.1103/PhysRevB.101.125415",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The conductivity of a two-dimensional HgTe quantum well with a width
$\sim$6.3~nm, close to the transition from ordinary to topological insulating
phases, is studied. The Fermi level is supposed to get to the overall energy
gap. The consideration is based on the percolation theory. We have found that
the width fluctuations convert the system to a random mixture of domains with
positive and negative energy gaps with internal edge states formed near zero
gap lines. In the case with no potential fluctuations, the conductance of a
finite sample is provided by a random edge states network. The zero-temperature
conductivity of an infinite sample is determined by the free motion of
electrons along the zero-gap lines and tunneling between them.
  The conductance of a single $p$-$n$ junction, which is crossed by the edge
state, is found. The result is applied to the situation when potential
fluctuations transform the system to a mixture of $p$- and $n$-domains. It is
stated that the tunneling across $p$-$n$ junctions forbids the low-temperature
conductivity of a random system, but the latter is restored due to the random
edge states crossing the junctions.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:09:41 GMT""},{""version"":""v2"",""created"":""Thu, 19 Mar 2020 04:55:43 GMT""}]","2020-03-25"
"1911.09456","Bartosz Etma\'nski","B. Etma\'nski, M. R. Schmidt, R. Szczerba","Ammonia in circumstellar environment of V Cyg",,,,,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The HIFI instrument on board of the Herschel Space Observatory (HSO) has been
very successful in detecting molecular lines from circumstellar envelopes
around evolved stars, like massive red supergiants, Asymptotic Giant Branch
(AGB) and post-AGB stars, as well as planetary nebulae. Among others, ammonia
has been found in circumstellar envelopes of C-rich AGB stars in amounts that
significantly exceeded theoretical predictions for C-rich stars. Few scenarios
have been proposed to resolve this problem: formation of ammonia behind the
shock front, photochemical processes in the inner part of the envelope partly
transparent to UV background radiation due to the clumpy structure of the gas,
and formation of ammonia on dust grains. Careful analysis of observations may
help to put constraints on one or another mechanism of ammonia formation. Here,
we present results of the non-LTE radiative transfer modeling of ammonia
transitions including a crucial process of radiative pumping via v$_2$ = 1
vibrational band (at $\sim$10 $\mu$m) for V Cyg. Only ground-based ammonia
transition NH$_{3}$ J = 1$_{0}$ - 0$_{0}$ at 572.5 GHz has been observed by
HIFI. Therefore, to determine abundance of ammonia we estimate a
photodissociation radius of NH$_{3}$ using chemical model of the envelope
consistent with dust grain properties concluded from the spectral energy
distribution.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:10:45 GMT""}]","2019-11-22"
"1911.09457","Mara Ungureanu","Mara Ungureanu","Refined de Jonqui\`eres divisors and secant varieties on algebraic
  curves","Corrected statement of main result. New Section 3 dedicated to
  discussion of applications to secant varieties",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this paper is to provide another perspective on secant varieties
on algebraic curves by reformulating the problem in terms of refined de
Jonqui\`eres divisors, that is divisors on the curve with prescribed
multiplicities and dimensions of their spaces of global sections. We are able
to both recover some already known results and to obtain some new statements
concerning the dimension theory of secant varieties. We do this via the study
of the dimension theory of refined de Jonqui\`eres divisors in some relevant
cases and degeneration arguments.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:19:03 GMT""},{""version"":""v2"",""created"":""Mon, 16 Dec 2019 17:29:49 GMT""}]","2019-12-17"
"1911.09458","Jinhang Zuo","Jinhang Zuo, Xiaoxi Zhang, Carlee Joe-Wong","Observe Before Play: Multi-armed Bandit with Pre-observations",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the stochastic multi-armed bandit (MAB) problem in a setting
where a player can pay to pre-observe arm rewards before playing an arm in each
round. Apart from the usual trade-off between exploring new arms to find the
best one and exploiting the arm believed to offer the highest reward, we
encounter an additional dilemma: pre-observing more arms gives a higher chance
to play the best one, but incurs a larger cost. For the single-player setting,
we design an Observe-Before-Play Upper Confidence Bound (OBP-UCB) algorithm for
$K$ arms with Bernoulli rewards, and prove a $T$-round regret upper bound
$O(K^2\log T)$. In the multi-player setting, collisions will occur when players
select the same arm to play in the same round. We design a centralized
algorithm, C-MP-OBP, and prove its $T$-round regret relative to an offline
greedy strategy is upper bounded in $O(\frac{K^4}{M^2}\log T)$ for $K$ arms and
$M$ players. We also propose distributed versions of the C-MP-OBP policy,
called D-MP-OBP and D-MP-Adapt-OBP, achieving logarithmic regret with respect
to collision-free target policies. Experiments on synthetic data and wireless
channel traces show that C-MP-OBP and D-MP-OBP outperform random heuristics and
offline optimal policies that do not allow pre-observations.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:22:21 GMT""}]","2019-11-22"
"1911.09459","Frederic Voisin","Fr\'ed\'eric Voisin","Designing Virtual Soundscapes for Alzheimer's Disease Care",,"14th International Symposium on Computer Music Multidisciplinary
  Research, Oct 2019, Marseille, France",,,"cs.SD eess.AS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sound environment is a prime source of conscious and unconscious information
which allows listeners to place themselves, to communicate, to feel, to
remember. The author describes the process of designing a new audio interactive
apparatus for Alzheimer's care, in the context of an active multidisciplinary
research project led by the author in collaboration with a longterm care centre
(EHPAD) in Burgundy (France), a geriatrician, a gerontologist, psychologists
and caregivers. The apparatus, named Madeleines Sonores in reference to
Proust's madeleine, have provided virtual soundscapes sounding for a year for
14 elderly people hosted in the dedicated Alzheimer's unit of the care centre,
24/7. Empiric aspects of sonic interactivity are discussed in relation to
dementia and to the activity of caring. Scientific studies are initiated to
evaluate the benefits of such a disposal in Alzheimer's disease therapy and in
caring dementia.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:23:12 GMT""}]","2019-11-22"
"1911.09460","\'Eric Soccorsi","\'Eric Soccorsi","Multidimensional Borg-Levinson inverse spectral theory",,"Contemporary Mathematics 757 (2020)","10.1090/conm/757",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This text deals with multidimensional Borg-Levinson inverse theory. Its main
purpose is to establish that the Dirichlet eigenvalues and Neumann boundary
data of the Dirichlet Laplacian acting in a bounded domain of dimension 2 or
greater, uniquely determine the real-valued bounded potential. We first address
the case of incomplete spectral data, where finitely many boundary spectral
eigen-pairs remain unknown. Under suitable summability condition on the Neumann
data, we also consider the case where only the asymptotic behavior of the
eigenvalues is known. Finally, we use the multidimensional Borg-Levinson theory
for solving parabolic inverse coefficient problems.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:24:21 GMT""}]","2021-12-21"
"1911.09461","David Bergman","David Bergman, Teng Huang, Philip Brooks, Andrea Lodi, Arvind U.
  Raghunathan","JANOS: An Integrated Predictive and Prescriptive Modeling Framework","12 pages, 3 figures",,,,"cs.LG math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Business research practice is witnessing a surge in the integration of
predictive modeling and prescriptive analysis. We describe a modeling framework
JANOS that seamlessly integrates the two streams of analytics, for the first
time allowing researchers and practitioners to embed machine learning models in
an optimization framework. JANOS allows for specifying a prescriptive model
using standard optimization modeling elements such as constraints and
variables. The key novelty lies in providing modeling constructs that allow for
the specification of commonly used predictive models and their features as
constraints and variables in the optimization model. The framework considers
two sets of decision variables; regular and predicted. The relationship between
the regular and the predicted variables are specified by the user as
pre-trained predictive models. JANOS currently supports linear regression,
logistic regression, and neural network with rectified linear activation
functions, but we plan to expand on this set in the future. In this paper, we
demonstrate the flexibility of the framework through an example on scholarship
allocation in a student enrollment problem and provide a numeric performance
evaluation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:31:24 GMT""}]","2019-11-22"
"1911.09462","Etienne Grau","Geoffrey Hibert (LCPO), Etienne Grau (LCPO), Didier Pintori (ITERG),
  S\'ebastien Lecommandoux (LCPO), Henri Cramail (LCPO)","ADMET polymerization of $\alpha$,$\omega$-unsaturated glycolipids:
  synthesis and physico-chemical properties of the resulting polymers",,"Polymer Chemistry, Royal Society of Chemistry - RSC, 2017,
  pp.3731-3739","10.1039/C7PY00788D",,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Trehalose diesters exhibiting $\alpha$,$\omega$-unsaturation are glycolipids
which can be easily polymerized by ADMET (acyclic diene metathesis)
polymerization. In this paper, enzymatic esterification was performed to
selectively esterify primary hydroxyl groups of trehalose (6 and 6'-positions)
with vinyl undecenoate. The vinyl ester was beforehand obtained by
palladium-catalyzed transesterification of undecenoic acid with vinyl acetate.
The resulting trehalose diundecenoate was homopolymerized and copolymerized
with undecenyl undecenoate in order to obtain random copolymers with different
compositions. The synthesis of such copolymers was confirmed by 1 H NMR
spectroscopy and size exclusion chromatography (SEC). Their solid-state phase
separation were investigated by DSC and X-ray scattering as function of
temperature and their solution self-assembly was investigated by dynamic light
scattering (DLS) in water.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:39:19 GMT""}]","2019-11-22"
"1911.09463","Hongbo Zhao","Hongbo Zhao","On Fixed Points of a Map Defined by Alain Connes",,,,,"math.QA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study certain analogues of the map defined by Alain Connes,
which follows an idea of Atiyah in trying to simplify the proof of
Feit-Thompson theorem. It turns out that the the non-zero fixed points of the
map can be characterized explicitly as an abelian group, and we can calculate
some examples. It turns out that most fixed points are not one dimensional
representations for these examples, and much work need to be done.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:39:37 GMT""}]","2019-11-22"
"1911.09464","Xu Shen","Jiwei Yang, Xu Shen, Jun Xing, Xinmei Tian, Houqiang Li, Bing Deng,
  Jianqiang Huang, Xiansheng Hua","Quantization Networks","10 pages, CVPR2019",,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although deep neural networks are highly effective, their high computational
and memory costs severely challenge their applications on portable devices. As
a consequence, low-bit quantization, which converts a full-precision neural
network into a low-bitwidth integer version, has been an active and promising
research topic. Existing methods formulate the low-bit quantization of networks
as an approximation or optimization problem. Approximation-based methods
confront the gradient mismatch problem, while optimization-based methods are
only suitable for quantizing weights and could introduce high computational
cost in the training stage. In this paper, we propose a novel perspective of
interpreting and implementing neural network quantization by formulating
low-bit quantization as a differentiable non-linear function (termed
quantization function). The proposed quantization function can be learned in a
lossless and end-to-end manner and works for any weights and activations of
neural networks in a simple and uniform way. Extensive experiments on image
classification and object detection tasks show that our quantization networks
outperform the state-of-the-art methods. We believe that the proposed method
will shed new insights on the interpretation of neural network quantization.
Our code is available at
https://github.com/aliyun/alibabacloud-quantization-networks.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:44:03 GMT""},{""version"":""v2"",""created"":""Thu, 28 Nov 2019 02:37:31 GMT""}]","2019-12-02"
"1911.09465","Morihiko Saito","Seung-Jo Jung, In-Kyun Kim, Youngho Yoon, Morihiko Saito","Spectrum of non-degenerate functions with simplicial Newton polyhedra","17 pages",,,,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove a simple formula for the spectrum of non-degenerate functions of 3
variables with simplicial convenient Newton polyhedra (which does not hold in
the non-simplicial case) generalizing a picture of Arnold in the 2 variable
case. Combining this with Steenbrink's conjecture on a refinement of Yomdin's
formula (proved long ago), we can deduce a formula for the spectrum of certain
non-isolated surface singularities with simplicial non-degenerate Newton
boundaries.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:48:36 GMT""},{""version"":""v2"",""created"":""Sun, 26 Apr 2020 12:35:04 GMT""},{""version"":""v3"",""created"":""Thu, 23 Jul 2020 08:22:08 GMT""}]","2020-07-24"
"1911.09466","Guilaine Lagache","G. Lagache, M. Bethermin, L. Montier, P. Serra, M. Tucci","Impact of polarised extragalactic sources on the measurement of CMB
  B-mode anisotropies","A&A in press. Match published version","A&A 642, A232 (2020)","10.1051/0004-6361/201937147",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the main goals of Cosmology is to search for the imprint of primordial
gravitational waves in the CMB polarisation field, to probe inflationary
theories. One of the obstacles toward the detection of the primordial signal is
to extract the B-mode polarisation from astrophysical contaminations. We
present a complete analysis of extragalactic foreground contamination due to
polarised emission of radio and dusty star-forming galaxies. We update or use
up-to-date models that are validated using the most recent measurements. We
predict the flux limit (confusion noise) for the future CMB space or balloon
experiments (IDS, PIPER, SPIDER, LiteBIRD, PICO), as well as ground-based
experiments (C-BASS, NEXT-BASS, QUIJOTE, AdvACTPOL, BICEP3+Keck, BICEPArray,
CLASS, SO, SPT3G, S4). Telescope aperture size (and frequency) is the main
characteristic impacting the level of confusion noise. Using the flux limits
and assuming constant polarisation fractions for radio and dusty galaxies, we
compute the B-mode power spectra of the three extragalactic foregrounds (radio
source shot noise, dusty galaxy shot noise and clustering), discuss their
relative levels and compare their amplitudes to that of the primordial tensor
modes parametrized by the tensor-to-scalar ratio r. At the reionization bump
(l=5), contamination by extragalactic foregrounds is negligible. At the
recombination peak (l=80), while the contamination is much lower than the
targeted sensitivity on r for large-aperture telescopes, it is at comparable
level for some of the medium- and small-aperture telescope experiments. For
example, the contamination is at the level of the 68 per cent confidence level
uncertainty on the primordial r for the LiteBIRD and PICO space experiments.
Finally we also provide some useful unit conversion factors and give some
predictions for the SPICA B-BOP experiment. Abridged
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:50:31 GMT""},{""version"":""v2"",""created"":""Fri, 24 Jul 2020 14:58:59 GMT""},{""version"":""v3"",""created"":""Tue, 25 Aug 2020 11:33:57 GMT""}]","2020-10-28"
"1911.09467","Mohammad H. Mamduhi","Mohammad H. Mamduhi, Ehsan Hashemi, John S. Baras, Karl H. Johansson","Event-triggered Add-on Safety for Connected and Automated Vehicles Using
  Road-side Network Infrastructure","8 pages, 6 figures, preprint submitted for IFAC 2020",,,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes an event-triggered add-on safety mechanism to adjust the
control parameters for timely braking in a networked vehicular system while
maintaining maneuverability. Passenger vehicle maneuverability is significantly
affected by the combined-slip friction effect, in which larger longitudinal
tire slips result in considerable drop in lateral tire forces. This is of
higher importance when unexpected dangerous situations occur on the road and
immediate actions, such as braking, need to be taken to avoid collision. Harsh
braking can lead to high-slip and loss of maneuverability, hence, timely
braking is essential to reduce high-slip scenarios. In addition to the vehicles
own active safety systems, the proposed event-triggered add-on safety is
activated upon being informed about dangers by the road-side infrastructure.
The aim is to incorporate the add-on safety feature to adjust the automatic
control parameters for smooth and timely braking such that a collision is
avoided while vehicle's maneuverability is maintained. We study two different
wireless technologies for communication between the infrastructure and the
vehicles, the Long-Term Evolution (LTE) and the fifth generation (5G) schemes.
The framework is validated through high-fidelity software simulations and the
advantages of including the add-on feature to augment the safety margins for
each communication technology is evaluated.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:51:11 GMT""}]","2019-11-22"
"1911.09468","Sergey Filippov","S. N. Filippov, A. N. Glinov, L. Lepp\""aj\""arvi","Phase covariant qubit dynamics and divisibility","12 pages, 5 figures","Lobachevskii J. Math. 41, 617-630 (2020)","10.1134/S1995080220040095",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Phase covariant qubit dynamics describes an evolution of a two-level system
under simultaneous action of pure dephasing, energy dissipation, and energy
gain with time-dependent rates $\gamma_z(t)$, $\gamma_-(t)$, and $\gamma_+(t)$,
respectively. Non-negative rates correspond to completely positive divisible
dynamics, which can still exhibit such peculiarities as non-monotonicity of
populations for any initial state. We find a set of quantum channels attainable
in the completely positive divisible phase covariant dynamics and show that
this set coincides with the set of channels attainable in semigroup phase
covariant dynamics. We also construct new examples of eternally indivisible
dynamics with $\gamma_z(t) < 0$ for all $t > 0$ that is neither unital nor
commutative. Using the quantum Sinkhorn theorem, we for the first time derive a
restriction on the decoherence rates under which the dynamics is positive
divisible, namely, $\gamma_{\pm}(t) \geq 0$, $\sqrt{\gamma_+(t) \gamma_-(t)} +
2 \gamma_z(t) > 0$. Finally, we consider phase covariant convolution master
equations and find a class of admissible memory kernels that guarantee complete
positivity of the dynamical map.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:52:20 GMT""}]","2020-04-24"
"1911.09469","Giuseppe Fanizza","Giuseppe Fanizza, Maurizio Gasperini, Giovanni Marozzi, Gabriele
  Veneziano","Generalized covariant prescriptions for averaging cosmological
  observables","29 pages, 7 figures. Several comments added, comparison with previous
  results improved, references added. Version accepted for publication on JCAP","JCAP 02 (2020) 017","10.1088/1475-7516/2020/02/017","BA-TH/721-19, CERN-TH-2019-183","gr-qc astro-ph.CO hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present two new covariant and general prescriptions for averaging scalar
observables on spatial regions typical of the observed sources and intersecting
the past light-cone of a given observer. One of these prescriptions is adapted
to sources exactly located on a given space-like hypersurface, the other
applies instead to situations where the physical location of the sources is
characterized by the experimental ""spread"" of a given observational variable.
The geometrical and physical differences between the two procedures are
illustrated by computing the averaged energy flux received by distant sources
located on (or between) constant redshift surfaces, and by working in the
context of a perturbed $\Lambda$CDM geometry. We find significant numerical
differences (of about ten percent or more, in a large range of redshift) even
limiting our model to scalar metric perturbations, and stopping our
computations to the leading non-trivial perturbative order.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:54:31 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jan 2020 17:04:44 GMT""}]","2020-02-17"
"1911.09470","Victoria Lipinska","Victoria Lipinska, Gl\'aucia Murta, J\'er\'emy Ribeiro, Stephanie
  Wehner","Verifiable Hybrid Secret Sharing With Few Qubits","12 + 5 pages, 3 figures","Phys. Rev. A 101, 032332 (2020)","10.1103/PhysRevA.101.032332",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the task of sharing a secret quantum state in a quantum network
in a verifiable way. We propose a protocol that achieves this task, while
reducing the number of required qubits, as compared to the existing protocols.
To achieve this, we combine classical encryption of the quantum secret with an
existing verifiable quantum secret sharing scheme based on
Calderbank-Shor-Steane quantum error correcting codes. In this way we obtain a
verifiable hybrid secret sharing scheme for sharing qubits, which combines the
benefits of quantum and classical schemes. Our scheme does not reveal any
information to any group of less than half of the $n$ nodes participating in
the protocol. Moreover, for sharing a one-qubit state each node needs a quantum
memory to store $n$ single-qubit shares, and requires a workspace of at most
$3n$ qubits in total to verify the quantum secret. Importantly, in our scheme
an individual share is encoded in a single qubit, as opposed to previous
schemes requiring $\Omega(\log n)$ qubits per share. Furthermore, we define a
ramp verifiable hybrid scheme. We give explicit examples of various verifiable
hybrid schemes based on existing quantum error correcting codes.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:55:34 GMT""},{""version"":""v2"",""created"":""Mon, 23 Mar 2020 17:23:10 GMT""}]","2020-03-24"
"1911.09471","Sahan Bulathwela","Sahan Bulathwela, Maria Perez-Ortiz, Emine Yilmaz and John
  Shawe-Taylor","TrueLearn: A Family of Bayesian Algorithms to Match Lifelong Learners to
  Open Educational Resources","In Proceedings of AAAI Conference on Artificial Intelligence 2020",,,,"cs.AI cs.IR cs.LG stat.AP stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The recent advances in computer-assisted learning systems and the
availability of open educational resources today promise a pathway to providing
cost-efficient, high-quality education to large masses of learners. One of the
most ambitious use cases of computer-assisted learning is to build a lifelong
learning recommendation system. Unlike short-term courses, lifelong learning
presents unique challenges, requiring sophisticated recommendation models that
account for a wide range of factors such as background knowledge of learners or
novelty of the material while effectively maintaining knowledge states of
masses of learners for significantly longer periods of time (ideally, a
lifetime). This work presents the foundations towards building a dynamic,
scalable and transparent recommendation system for education, modelling
learner's knowledge from implicit data in the form of engagement with open
educational resources. We i) use a text ontology based on Wikipedia to
automatically extract knowledge components of educational resources and, ii)
propose a set of online Bayesian strategies inspired by the well-known areas of
item response theory and knowledge tracing. Our proposal, TrueLearn, focuses on
recommendations for which the learner has enough background knowledge (so they
are able to understand and learn from the material), and the material has
enough novelty that would help the learner improve their knowledge about the
subject and keep them engaged. We further construct a large open educational
video lectures dataset and test the performance of the proposed algorithms,
which show clear promise towards building an effective educational
recommendation system.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:56:40 GMT""}]","2019-11-22"
"1911.09472","Fabrizio Nesti","Stefano Bertolini, Alessio Maiezza, Fabrizio Nesti","Kaon CP violation and neutron EDM in the minimal left-right symmetric
  model","Version matching published version. Typos corrected and references
  added","Phys. Rev. D 101, 035036 (2020)","10.1103/PhysRevD.101.035036",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Within the minimal Left-Right (LR) symmetric model we revisit the predictions
for the kaon CP violating observables $\varepsilon$ and $\varepsilon'$ in
correlation with the neutron electric dipole moment. We perform a complete
study of the cross constraints on the model parameters, phases and the
$M_{W_R}$ scale, considering the two cases of extended parity or charge
conjugation as LR discrete symmetries, together with the possible presence of a
Peccei-Quinn symmetry. We discuss in particular two scenarios: whether the
Standard Model saturates the experimental value of $\varepsilon'/\varepsilon$
or whether new physics is needed, still an open issue after the recent lattice
results on the QCD penguin matrix elements. Within the first scenario, we find
no constraints on the LR scale in the charge-conjugation case while in the
parity case we show that $M_{W_R}$ can be as low as 13 TeV. On the other side,
the request that new physics contributes dominantly to $\varepsilon'$ implies
strong correlations among the model parameters, with an upper bound of
$M_{W_R}< 8-100$ TeV depending on $\tan\beta$ in the case of charge conjugation
and a range of $M_{W_R}\simeq 7-45$ TeV in the parity setup. Both scenarios may
be probed directly at future colliders and only indirectly at the LHC.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:01:10 GMT""},{""version"":""v2"",""created"":""Thu, 26 Dec 2019 19:10:06 GMT""},{""version"":""v3"",""created"":""Thu, 5 Mar 2020 15:21:52 GMT""}]","2020-03-09"
"1911.09473","Dmitry Shkatov","Mikhail Rybakov and Dmitry Shkatov","Recursive enumerability and elementary frame definability in predicate
  modal logic",,,"10.1093/logcom/exz028",,"math.LO cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the relationship between recursive enumerability and
elementary frame definability in first-order predicate modal logic. On the one
hand, it is well-known that every first-order predicate modal logic complete
with respect to an elementary class of Kripke frames, i.e., a class of frames
definable by a classical first-order formula, is recursively enumerable. On the
other, numerous examples are known of predicate modal logics, based on
`natural' propositional modal logics with essentially second-order Kripke
semantics, that are either not recursively enumerable or Kripke incomplete.
This raises the question of whether every Kripke complete, recursively
enumerable predicate modal logic can be characterized by an elementary class of
Kripke frames. We answer this question in the negative, by constructing a
normal predicate modal logic which is Kripke complete, recursively enumerable,
but not complete with respect to an elementary class of frames. We also present
an example of a normal predicate modal logic that is recursively enumerable,
Kripke complete, and not complete with respect to an elementary class of rooted
frames, but is complete with respect to an elementary class of frames that are
not rooted.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:02:36 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 14:44:40 GMT""},{""version"":""v3"",""created"":""Mon, 25 Nov 2019 12:55:36 GMT""},{""version"":""v4"",""created"":""Fri, 20 Dec 2019 19:35:23 GMT""}]","2019-12-24"
"1911.09474","Najib Idrissi","Ricardo Campos, Julien Ducoulombier, Najib Idrissi","Boardman-Vogt resolutions and bar/cobar constructions of (co)operadic
  (co)bimodules","Final version, to appear in Higher Structures",,,,"math.AT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop the combinatorics of leveled trees in order to construct explicit
resolutions of (co)operads and (co)operadic (co)bimodules. We build explicit
cofibrant resolutions of operads and operadic bimodules in spectra analogous to
the ordinary Boardman--Vogt resolutions and we express them as cobar
constructions of indecomposable elements. Dually, in the context of CDGAs, we
perform similar constructions, and we obtain fibrant resolutions of Hopf
cooperads and Hopf cooperadic cobimodules. We also express them as bar
constructions of primitive elements.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:03:58 GMT""},{""version"":""v2"",""created"":""Thu, 11 Feb 2021 10:05:05 GMT""},{""version"":""v3"",""created"":""Sat, 3 Jul 2021 12:08:50 GMT""}]","2021-07-06"
"1911.09475","Silvan K\""aser","Silvan K\""aser, Oliver T. Unke, Markus Meuwly","Reactive Dynamics and Spectroscopy of Hydrogen Transfer from Neural
  Network-Based Reactive Potential Energy Surfaces",,,"10.1088/1367-2630/ab81b5",,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The in silico exploration of chemical, physical and biological systems
requires accurate and efficient energy functions to follow their nuclear
dynamics at a molecular and atomistic level. Recently, machine learning tools
gained a lot of attention in the field of molecular sciences and simulations
and are increasingly used to investigate the dynamics of such systems. Among
the various approaches, artificial neural networks (NNs) are one promising tool
to learn a representation of potential energy surfaces. This is done by
formulating the problem as a mapping from a set of atomic positions
$\mathbf{x}$ and nuclear charges $Z_i$ to a potential energy $V(\mathbf{x})$.
Here, a fully-dimensional, reactive neural network representation for
malonaldehyde (MA), acetoacetaldehyde (AAA) and acetylacetone (AcAc) is
learned. It is used to run finite-temperature molecular dynamics simulations,
and to determine the infrared spectra and the hydrogen transfer rates for the
three molecules. The finite-temperature infrared spectrum for MA based on the
NN learned on MP2 reference data provides a realistic representation of the
low-frequency modes and the H-transfer band whereas the CH vibrations are
somewhat too high in frequency. For AAA it is demonstrated that the IR
spectroscopy is sensitive to the position of the transferring hydrogen at
either the OCH- or OCCH$_3$ end of the molecule. For the hydrogen transfer
rates it is demonstrated that the O-O vibration is a gating mode and largely
determines the rate at which the hydrogen is transferred between the donor and
acceptor. Finally, possibilities to further improve such NN-based potential
energy surfaces are explored. They include the transferability of an NN-learned
energy function across chemical species (here methylation) and transfer
learning from a lower level of reference data (MP2) to a higher level of theory
(pair natural orbital-LCCSD(T)).
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:04:09 GMT""}]","2020-08-26"
"1911.09476","Golnaz Habibi","Golnaz Habibi, Nikita Japuria, Jonathan P. How","Incremental Learning of Motion Primitives for Pedestrian Trajectory
  Prediction at Intersections",,,,,"cs.RO cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a novel incremental learning algorithm for pedestrian
motion prediction, with the ability to improve the learned model over time when
data is incrementally available. In this setup, trajectories are modeled as
simple segments called motion primitives. Transitions between motion primitives
are modeled as Gaussian Processes. When new data is available, the motion
primitives learned from the new data are compared with the previous ones by
measuring the inner product of the motion primitive vectors. Similar motion
primitives and transitions are fused and novel motion primitives are added to
capture newly observed behaviors. The proposed approach is tested and compared
with other baselines in intersection scenarios where the data is incrementally
available either from a single intersection or from multiple intersections with
different geometries. In both cases, our method incrementally learns motion
patterns and outperforms the offline learning approach in terms of prediction
errors. The results also show that the model size in our algorithm grows at a
much lower rate than standard incremental learning, where newly learned motion
primitives and transitions are simply accumulated over time.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:06:18 GMT""}]","2019-11-22"
"1911.09477","Wim Veldman","Wim Veldman","Equality and equivalence, intuitionistically",,,"10.13140/RG.2.2.29768.67849",,"math.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the intuitionistic first-order theory of equality has continuum
many complete extensions. We also study the Vitali equivalence relation and
show there are many intuitionistically precise versions of it.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:06:20 GMT""}]","2019-11-22"
"1911.09478","Victor Petr\'en Bach Hansen","Victor Petr\'en Bach Hansen, Anders S{\o}gaard","What Do You Mean `Why?': Resolving Sluices in Conversations","Accepted at the 34TH AAAI Conference on Artificial Intelligence
  (AAAI-2020)",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In conversation, we often ask one-word questions such as `Why?' or `Who?'.
Such questions are typically easy for humans to answer, but can be hard for
computers, because their resolution requires retrieving both the right semantic
frames and the right arguments from context. This paper introduces the novel
ellipsis resolution task of resolving such one-word questions, referred to as
sluices in linguistics. We present a crowd-sourced dataset containing
annotations of sluices from over 4,000 dialogues collected from conversational
QA datasets, as well as a series of strong baseline architectures.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:09:33 GMT""}]","2019-11-22"
"1911.09479","Janne Heittokangas","Gary G. Gundersen, Janne M. Heittokangas and Zhi-Tao Wen","Contour integral solutions of linear differential equations which
  include a generalization of the Airy integral","30 pages, 4 figures",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Airy integral is a well-known contour integral solution of Airy's
equation which has several applications and which has been used for
mathematical illustrations due to its interesting properties. We present and
derive properties of two families of contour integral solutions of linear
differential equations, where one family includes the Airy integral and Airy's
equation, such that the family generalizes known properties of the Airy
integral which include exponential decay growth in a certain sector. The second
family includes a known example and contains a subfamily with interesting
properties where a separate analysis of three pairwise linearly independent
contour integral solutions of a particular equation is given.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:12:15 GMT""},{""version"":""v2"",""created"":""Thu, 17 Sep 2020 17:47:07 GMT""}]","2020-09-18"
"1911.09480","Valentin Zagrebnov","Valentin Zagrebnov (I2M)","Notes on the Chernoff Product Formula",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We revise the strong convergent Chernoff product formula and extend it, in a
Hilbert space, to convergence in the operator-norm topology. Main results deal
with the self-adjoint Chernoff product formula. The nonself-adjoint case
concerns the quasi-sectorial contractions.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:13:09 GMT""}]","2019-11-22"
"1911.09481","Haiyan Lu","Haiyan Lu and Li Huang","Unraveling the 4f electronic structures of cerium monopnictides","8 pages, 6 figures","J. Phys.: Condens. Matter 32, 485601 (2020)","10.1088/1361-648X/abaa82",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In order to unveil the 4f electronic structures in cerium monopnictides (CeX,
where X = N, P, As, Sb, and Bi), we employed a state-of-the-art
first-principles many-body approach, namely the density functional theory in
combination with the single-site dynamical mean-field theory, to make detailed
calculations. We find that the 4f electrons in CeN are highly itinerant and
mixed-valence, showing a prominent quasi-particle peak near the Fermi level. On
the contrary, they become well localized and display weak valence fluctuation
in CeBi. It means that a 4f itinerant-localized crossover could emerge upon
changing the X atom from N to Bi. Moreover, according to the low-energy
behaviors of 4f self-energy functions, we could conclude that the 4f electrons
in CeX also demonstrate interesting orbital-selective electronic correlations,
which are similar to the other cerium-based heavy fermion compounds.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:15:20 GMT""}]","2020-09-18"
"1911.09482","Mathieu Lewin","Soeren Fournais, Mathieu Lewin, Arnaud Triay","The Scott correction in Dirac-Fock theory",,,"10.1007/s00220-020-03781-6",,"math-ph math.MP math.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We give the first derivation of the Scott correction in the large-$Z$
expansion of the energy of an atom in Dirac-Fock theory without projections.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:19:36 GMT""}]","2020-07-15"
"1911.09484","Christoph Gote","Christoph Gote, Ingo Scholtes, Frank Schweitzer","Analysing Time-Stamped Co-Editing Networks in Software Development Teams
  using git2net","44 pages, 24 figures, 16 tables, extended version of arXiv:1903.10180",,,,"cs.SE cs.MA cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Data from software repositories have become an important foundation for the
empirical study of software engineering processes. A recurring theme in the
repository mining literature is the inference of developer networks capturing
e.g. collaboration, coordination, or communication from the commit history of
projects. Most of the studied networks are based on the co-authorship of
software artefacts. Because this neglects detailed information on code changes
and code ownership we introduce git2net, a scalable python software that
facilitates the extraction of fine-grained co-editing networks in large git
repositories. It uses text mining techniques to analyse the detailed history of
textual modifications within files. We apply our tool in two case studies using
GitHub repositories of multiple Open Source as well as a commercial software
project. Specifically, we use data on more than 1.2 million commits and more
than 25'000 developers to test a hypothesis on the relation between developer
productivity and co-editing patterns in software teams. We argue that git2net
opens up a massive new source of high-resolution data on human collaboration
patterns that can be used to advance theory in empirical software engineering,
computational social science, and organisational studies.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:23:54 GMT""}]","2019-11-22"
"1911.09485","Di Zhu","Di Zhu, Marco Colangelo, Changchen Chen, Boris A. Korzh, Franco N. C.
  Wong, Matthew D. Shaw, and Karl K. Berggren","Resolving photon numbers using a superconducting tapered nanowire
  detector",,"Nano Lett. 20(5), 3858-3863 (2020)","10.1021/acs.nanolett.0c00985",,"physics.ins-det physics.optics quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Time- and number-resolved photon detection is crucial for photonic quantum
information processing. Existing photon-number-resolving (PNR) detectors
usually have limited timing and dark-count performance or require complex
fabrication and operation. Here we demonstrate a PNR detector at
telecommunication wavelengths based on a single superconducting nanowire with
an integrated impedance-matching taper. The prototyping device was able to
resolve up to five absorbed photons and had 16.1 ps timing jitter, <2 c.p.s.
device dark count rate, $\sim$86 ns reset time, and 5.6% system detection
efficiency (without cavity) at 1550 nm. Its exceptional distinction between
single- and two-photon responses is ideal for coincidence counting and allowed
us to directly observe bunching of photon pairs from a single output port of a
Hong-Ou-Mandel interferometer. This detector architecture may provide a
practical solution to applications that require high timing resolution and
few-photon discrimination.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:27:41 GMT""}]","2020-06-23"
"1911.09486","Daniel Vargas-Montoya","Daniel Vargas Montoya","Alg\'ebricit\'e modulo p, s\'eries hyperg\'eom\'etriques et structures
  de Frobenius forte","in French",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This work is devoted to study of algebraicty modulo p of Siegel's
G-functions. Our goal is to emphasize the relevance of the notion of strong
Frobenius structure, clasically studied in the theory of the p-adic
diffenrential equations, for the study of a Adamczewski-Delaygue's conjecture
concerning of the degree of algebraicity modulo p of G-functions. For this, we
first make a Christol's result explicit by showing that if $f$ is a G-function
that is solution of a differential operator $L$ in $ \mathbb{Q}(z)[d/dz]$ of
order $n$ endowed of a strong Frobenius structure of period $h$ for the prime
number $p$ and that $f(z)$ belongs to $\mathbb{Z}_{(p)}[[z]]$, then the
reduction of $f$ modulo $ p $ is algebraic over $\mathbb F_p(z)$ and its
algebraicity degree is bounded by $p^{n^2h}$. By generalizing an approach
introduced by Salinier, we show that if $L$ is a Fuchsian operator with
coefficients in $\mathbb{Q}(z)$, whose monodromy group is rigid and whose
exponents are rational numbers, then $L$ has for almost every prime number $p$
a strong Frobenius structure of period $h$, where $h$ is explicitly bounded and
does not depend on $p$. A slightly different version of this result has been
recently demonstrated by Crew following a different approach based on the $p$
-adic cohomology. We use these two results to solve the mentioned conjecture in
the case of generalized hypergeometric series.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:27:44 GMT""},{""version"":""v2"",""created"":""Tue, 22 Sep 2020 16:35:00 GMT""},{""version"":""v3"",""created"":""Tue, 4 May 2021 15:52:16 GMT""}]","2021-05-05"
"1911.09487","Cong Sun","Cong Sun, Zhihao Yang, Leilei Su, Lei Wang, Yin Zhang, Hongfei Lin and
  Jian Wang","Chemical-protein Interaction Extraction via Gaussian Probability
  Distribution and External Biomedical Knowledge","8 pages, 4 figures, Bioinformatics manuscript",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivation: The biomedical literature contains a wealth of chemical-protein
interactions (CPIs). Automatically extracting CPIs described in biomedical
literature is essential for drug discovery, precision medicine, as well as
basic biomedical research. Most existing methods focus only on the sentence
sequence to identify these CPIs. However, the local structure of sentences and
external biomedical knowledge also contain valuable information. Effective use
of such information may improve the performance of CPI extraction. Results: In
this paper, we propose a novel neural network-based approach to improve CPI
extraction. Specifically, the approach first employs BERT to generate
high-quality contextual representations of the title sequence, instance
sequence, and knowledge sequence. Then, the Gaussian probability distribution
is introduced to capture the local structure of the instance. Meanwhile, the
attention mechanism is applied to fuse the title information and biomedical
knowledge, respectively. Finally, the related representations are concatenated
and fed into the softmax function to extract CPIs. We evaluate our proposed
model on the CHEMPROT corpus. Our proposed model is superior in performance as
compared with other state-of-the-art models. The experimental results show that
the Gaussian probability distribution and external knowledge are complementary
to each other. Integrating them can effectively improve the CPI extraction
performance. Furthermore, the Gaussian probability distribution can effectively
improve the extraction performance of sentences with overlapping relations in
biomedical relation extraction tasks. Availability: Data and code are available
at https://github.com/CongSun-dlut/CPI_extraction. Contact: yangzh@dlut.edu.cn,
wangleibihami@gmail.com Supplementary information: Supplementary data are
available at Bioinformatics online.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:29:42 GMT""},{""version"":""v2"",""created"":""Fri, 24 Apr 2020 02:47:49 GMT""}]","2020-04-27"
"1911.09488","Toby Walsh","Martin Aleksandrov and Toby Walsh","Online Fair Division: A Survey","Accepted by the 34th AAAI Conference on Artificial Intelligence (AAAI
  2020)",,,,"cs.AI cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We survey a burgeoning and promising new research area that considers the
online nature of many practical fair division problems. We identify wide
variety of such online fair division problems, as well as discuss new
mechanisms and normative properties that apply to this online setting. The
online nature of such fair division problems provides both opportunities and
challenges such as the possibility to develop new online mechanisms as well as
the difficulty of dealing with an uncertain future.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:30:34 GMT""}]","2019-11-22"
"1911.09490","Michiya Mori","Michiya Mori, Peter \v{S}emrl","Continuous coexistency preservers on effect algebras","18 pages",,,,"math-ph math.FA math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $H$ be a finite-dimensional Hilbert space, $\dim H \ge 2$. We prove that
every continuous coexistency preserving map on the effect algebra $E(H)$ is
either a standard automorphism of $E(H)$, or a standard automorphism of $E(H)$
composed with the orthocomplementation. We present examples showing the
optimality of the result.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:34:09 GMT""}]","2019-11-22"
"1911.09491","Arielle Leitner","Nir Lazarovich and Arielle Leitner","Local Limits of Connected Subgroups of $SL_3(\mathbb{R})$",,,,,"math.GT math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we describe the local limits under conjugation of all closed
connected subgroups of $SL_3(\mathbb{R})$ in the Chabauty topology.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:35:26 GMT""},{""version"":""v2"",""created"":""Thu, 26 Nov 2020 09:23:16 GMT""}]","2020-11-30"
"1911.09492","Thomas Sauvaget","Thomas Sauvaget","Remarks on an interpolation between Wilson's theorem and Giuga's
  conjecture","Section 3 reformulated in terms of unsigned Stirling numbers of the
  first kind",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A family of congruences interpolating between those of Wilson and Giuga is
constructed. Several elementary results are established, in order to present a
possible approach to establishing Giuga's conjecture.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:35:28 GMT""},{""version"":""v2"",""created"":""Thu, 30 Jan 2020 07:32:06 GMT""},{""version"":""v3"",""created"":""Thu, 19 Mar 2020 07:52:21 GMT""}]","2020-03-20"
"1911.09493","Tobias Gabler","Tobias Gabler (1), Karsten Backhaus (1), Steffen Gro{\ss}mann (1) and
  Ronny Fritsche (2) ((1) Technische Universit\""at Dresden - Institute of
  Electrical Power Systems and High Voltage Engineering, (2) SIEMENS AG -
  Transformers)","Dielectric Modeling of Oil-paper Insulation Systems at High DC Voltage
  Stress Using a Charge-carrier-based Approach","This accepted version of the contribution was published in IEEE
  Transactions on Dielectrics and Electrical Insulation Vol. 26, No. 5; October
  2019 with DOI 10.1109/TDEI.2019.008175, see
  https://doi.org/10.1109/TDEI.2019.008175","IEEE Trans. Dielectr. Electr. Insul. 26-5 (2019) 1549-1557","10.1109/TDEI.2019.008175",,"physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is state-of-the-art to describe the dielectric behavior of an insulation
material by its permittivity and its specific electric conductivity in order to
estimate the dielectric stress of an insulation system. Thus, the electric
field at DC voltage stress is determined according to the stationary electrical
conduction field with the electric conductivity of the insulation materials.
However, at oil-insulated arrangements a higher field strength in front of bare
metal electrodes at high DC voltage stress occurs, which is not explainable
with this model.
  Therefore, a charge carrier-based approach is presented to describe the
dielectric behavior of the oil-paper insulation. It describes the movement of
charge carriers and their effect on the electric field strength. Their drift
leads to an accumulation of charge carriers in front of electrodes which
results in a higher field strength in these areas, which can be calculated
numerically using the Poisson-Nernst-Planck equation system.
  Compared to the conductivity-based model fundamental differences can be
shown. Breakdown experiments qualitatively confirm the expectations according
to the charge carrier-based approach.
  The results show that the charge carrier-based field distribution has to be
considered for modelling the electrical field strength distribution at high DC
voltage stress. They also show, that the dielectric behavior of these
arrangements cannot be explained according to the state-of-the-art model.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:35:35 GMT""}]","2019-11-22"
"1911.09497","Chen Wang","Chen Wang","Symbolic summation methods and hypergeometric supercongruences","11 pages","J. Math. Anal. Appl. 488 (2020), Art. 124068","10.1016/j.jmaa.2020.124068",,"math.NT math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we establish the following two congruences: \begin{gather*}
\sum_{k=0}^{(p+1)/2}(3k-1)\frac{\left(-\frac{1}{2}\right)_k^2\left(\frac{1}{2}\right)_k4^k}{k!^3}\equiv
p-6p^3\left(\frac{-1}{p}\right)+2p^3\left(\frac{-1}{p}\right)E_{p-3}\pmod{p^4},\\
\sum_{k=0}^{p-1}(3k-1)\frac{\left(-\frac{1}{2}\right)_k^2\left(\frac{1}{2}\right)_k4^k}{k!^3}\equiv
p-2p^3\pmod{p^4}, \end{gather*} where $p>3$ is a prime, $E_{p-3}$ is the
$(p-3)$-th Euler number and $\left(-\right)$ is the Legendre symbol. The first
congruence modulo $p^3$ was conjectured by Guo and Schlosser recently.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:41:17 GMT""},{""version"":""v2"",""created"":""Sat, 25 Apr 2020 04:14:46 GMT""}]","2020-06-30"
"1911.09498","Jos\'e Fuentes","Jos\'e Fuentes-Sep\'ulveda and Gonzalo Navarro and Diego Seco","Navigating Planar Topologies in Near-Optimal Space and Time","This research has received funding from the European Union's Horizon
  2020 research and innovation programme under the Marie Sklodowska-Curie
  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941. Conference version
  presented at SPIRE 2019",,"10.1007/978-3-030-32686-9_35",,"cs.DS cs.CG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that any embedding of a planar graph can be encoded succinctly while
efficiently answering a number of topological queries near-optimally. More
precisely, we build on a succinct representation that encodes an embedding of
$m$ edges within $4m$ bits, which is close to the information-theoretic lower
bound of about $3.58m$. With $4m+o(m)$ bits of space, we show how to answer a
number of topological queries relating nodes, edges, and faces, most of them in
any time in $\omega(1)$. Further, we show that with $O(m)$ bits of space we can
solve all those operations in $O(1)$ time.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:42:08 GMT""},{""version"":""v2"",""created"":""Fri, 10 Dec 2021 20:40:37 GMT""}]","2021-12-14"
"1911.09499","Antonio Celani","Mihir Durve, Lorenzo Piro, Massimo Cencini, Luca Biferale, Antonio
  Celani","Collective olfactory search in a turbulent environment",,"Phys. Rev. E 102, 012402 (2020)","10.1103/PhysRevE.102.012402",,"physics.bio-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Finding the distant source of an odor dispersed by a turbulent flow is a
vital task for many organisms, either for foraging or for mating purposes. At
the level of individual search, animals like moths have developed effective
strategies to solve this very difficult navigation problem based on the noisy
detection of odor concentration and wind velocity alone.
  When many individuals concurrently perform the same olfactory search task,
without any centralized control, sharing information about the decisions made
by the members of the group can potentially increase the performance. But how
much of this information is actually valuable and exploitable for the
collective task ? Here we show that, in a model of a swarm of agents inspired
by moth behavior, there is an optimal way to blend the private information
about odor and wind detections with the publicly available information about
other agents' heading direction. At optimality, the time required for the first
agent to reach the source is essentially the shortest flight time from the
departure point to the target. Conversely, agents who discard public
information are several fold slower and groups that do not put enough weight on
private information perform even worse. Our results then suggest an efficient
multi-agent olfactory search algorithm that could prove useful in robotics, for
instance in the identification of sources of harmful volatile compounds.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:44:00 GMT""}]","2020-07-15"
"1911.09500","Matteo Tacchi","Didier Henrion (LAAS-MAC), Matteo Tacchi (LAAS-MAC), Carmen Cardozo,
  Jean Lasserre (LAAS-MAC)","Approximating regions of attraction of a sparse polynomial differential
  system *",,,,,"eess.SY cs.SY math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by stability analysis of large scale power systems, we describe how
the Lasserre (moment-sums of squares, SOS) hierarchy can be used to generate
outer approximations of the region of attraction (ROA) of sparse polynomial
differential systems, at the price of solving linear matrix inequalities (LMI)
of increasing size. We identify specific sparsity structures for which we can
provide numerically certified outer approximations of the region of attraction
in high dimension. For this purpose, we combine previous results on non-sparse
ROA approximations with sparse semi-algebraic set volume computation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:44:39 GMT""},{""version"":""v2"",""created"":""Mon, 16 Mar 2020 16:49:38 GMT""}]","2020-03-17"
"1911.09501","Kia Khezeli","Kia Khezeli and Eilyan Bitar","Safe Linear Stochastic Bandits",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the safe linear stochastic bandit framework---a generalization
of linear stochastic bandits---where, in each stage, the learner is required to
select an arm with an expected reward that is no less than a predetermined
(safe) threshold with high probability. We assume that the learner initially
has knowledge of an arm that is known to be safe, but not necessarily optimal.
Leveraging on this assumption, we introduce a learning algorithm that
systematically combines known safe arms with exploratory arms to safely expand
the set of safe arms over time, while facilitating safe greedy exploitation in
subsequent stages. In addition to ensuring the satisfaction of the safety
constraint at every stage of play, the proposed algorithm is shown to exhibit
an expected regret that is no more than $O(\sqrt{T}\log (T))$ after $T$ stages
of play.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:45:43 GMT""}]","2019-11-22"
"1911.09504","Han Zhang","H. Zhang, L. Hao, J. Yang, J. Mutch, Z. Liu, Q. Huang, K. Noordhoek,
  A. F. May, J.-H. Chu, J. W. Kim, P. J. Ryan, H. D. Zhou and Jian Liu","Comprehensive Control of Metamagnetic Transition of Antiferromagnetic
  Mott Insulator Sr2IrO4 by in-situ Anisotropic Strain",,"Adv. Mater. (2020) 02451","10.1002/adma.202002451",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metamagnetism in antiferromagnets exhibits distinct critical behaviors and
dynamics when invoking spin reversal and rotation. Here we show a 0.05%
anisotropic strain suffices to in-situ modulate the metamagnetic critical field
of the Mott insulator Sr2IrO4 by over 50%, enabling electrical switching of the
transition. Resonant x-ray scattering and model simulation reveal that the
transition is completely tuned from the spin-flop to spin-flip type as the
strain introduces C4-symmetry-breaking magnetic anisotropy. Simultaneous
transport study indicates the metamagnetic responses are reflected in the large
elasto- and magnetoconductance, highlighting the active charge degree of
freedom in the spin-orbit-coupled Mott state and its potential for
spin-electronics.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:47:39 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jul 2020 21:14:22 GMT""}]","2020-07-24"
"1911.09509","Luiz Zanlorensi","Luiz A. Zanlorensi, Diego R. Lucio, Alceu S. Britto Jr., Hugo
  Proen\c{c}a, David Menotti","Deep Representations for Cross-spectral Ocular Biometrics","This paper is a postprint of a paper submitted to and accepted for
  publication inIET Biometrics and is subject to Institution of Engineering and
  Technology Copyright. The copy of the record is available at the IET Digital
  Library",,"10.1049/iet-bmt.2019.0116",,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  One of the major challenges in ocular biometrics is the cross-spectral
scenario, i.e., how to match images acquired in different wavelengths
(typically visible (VIS) against near-infrared (NIR)). This article designs and
extensively evaluates cross-spectral ocular verification methods, for both the
closed and open-world settings, using well known deep learning representations
based on the iris and periocular regions. Using as inputs the bounding boxes of
non-normalized iris/periocular regions, we fine-tune Convolutional Neural
Network(CNN) models (based either on VGG16 or ResNet-50 architectures),
originally trained for face recognition. Based on the experiments carried out
in two publicly available cross-spectral ocular databases, we report results
for intra-spectral and cross-spectral scenarios, with the best performance
being observed when fusing ResNet-50 deep representations from both the
periocular and iris regions. When compared to the state-of-the-art, we observed
that the proposed solution consistently reduces the Equal Error Rate(EER)
values by 90% / 93% / 96% and 61% / 77% / 83% on the cross-spectral scenario
and in the PolyU Bi-spectral and Cross-eye-cross-spectral datasets. Lastly, we
evaluate the effect that the ""deepness"" factor of feature representations has
in recognition effectiveness, and - based on a subjective analysis of the most
problematic pairwise comparisons - we point out further directions for this
field of research.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:54:46 GMT""}]","2019-11-22"
"1911.09510","Nicolas Chevalier","Nicolas Chevalier (CEA-LETI)","The first digestive movements in the embryo are mediated by
  mechanosensitive smooth muscle calcium waves",,"Philosophical Transactions of the Royal Society B: Biological
  Sciences, Royal Society, The, 2018, 373 (1759), pp.20170322","10.1098/rstb.2017.0322",,"physics.bio-ph q-bio.TO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Peristalsis enables transport of the food bolus in the gut. Here, I show by
dynamic ex-vivo intra-cellular calcium imaging on living embryonic gut
transverse sections that the most primitive form of peristalsis that occurs in
the embryo is the result of inter-cellular, gap-junction dependent calcium
waves that propagate in the circular smooth muscle layer. I show that the
embryonic gut is an intrinsically mechanosensitive organ, as the slightest
externally applied mechanical stimulus triggers contractile waves. This dynamic
response is an embryonic precursor of the ""law of the intestine (peristaltic
reflex). I show how characteristic features of early peristalsis such as
counter-propagating wave annihilation, mechanosensitivity and nucleation after
wounding all result from known properties of calcium waves. I finally
demonstrate that inter-cellular mechanical tension does not play a role in the
propagation mechanism of gut contractile waves, unlike what has been recently
shown for the embryonic heartbeat. Calcium waves are an ubiquitous dynamic
signaling mechanism in biology: here I show that they are the foundation of
digestive movements in the developing embryo.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:56:30 GMT""}]","2019-11-22"
"1911.09511","Matias Cattaneo","Matias D. Cattaneo, Nicolas Idrobo, Rocio Titiunik","A Practical Introduction to Regression Discontinuity Designs:
  Foundations",,,"10.1017/9781108684606",,"stat.ME econ.EM stat.AP stat.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this Element and its accompanying Element, Matias D. Cattaneo, Nicolas
Idrobo, and Rocio Titiunik provide an accessible and practical guide for the
analysis and interpretation of Regression Discontinuity (RD) designs that
encourages the use of a common set of practices and facilitates the
accumulation of RD-based empirical evidence. In this Element, the authors
discuss the foundations of the canonical Sharp RD design, which has the
following features: (i) the score is continuously distributed and has only one
dimension, (ii) there is only one cutoff, and (iii) compliance with the
treatment assignment is perfect. In the accompanying Element, the authors
discuss practical and conceptual extensions to the basic RD setup.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:58:18 GMT""}]","2019-11-22"
"1911.09512","Akbar Siami Namin","Sima Siami-Namini and Neda Tavakoli and Akbar Siami Namin","A Comparative Analysis of Forecasting Financial Time Series Using ARIMA,
  LSTM, and BiLSTM","8 pages, 3 figures, 3 tables, 1 listing, IEEE BigData 2019",,,,"cs.LG cs.CE cs.PF stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Machine and deep learning-based algorithms are the emerging approaches in
addressing prediction problems in time series. These techniques have been shown
to produce more accurate results than conventional regression-based modeling.
It has been reported that artificial Recurrent Neural Networks (RNN) with
memory, such as Long Short-Term Memory (LSTM), are superior compared to
Autoregressive Integrated Moving Average (ARIMA) with a large margin. The
LSTM-based models incorporate additional ""gates"" for the purpose of memorizing
longer sequences of input data. The major question is that whether the gates
incorporated in the LSTM architecture already offers a good prediction and
whether additional training of data would be necessary to further improve the
prediction.
  Bidirectional LSTMs (BiLSTMs) enable additional training by traversing the
input data twice (i.e., 1) left-to-right, and 2) right-to-left). The research
question of interest is then whether BiLSTM, with additional training
capability, outperforms regular unidirectional LSTM. This paper reports a
behavioral analysis and comparison of BiLSTM and LSTM models. The objective is
to explore to what extend additional layers of training of data would be
beneficial to tune the involved parameters. The results show that additional
training of data and thus BiLSTM-based modeling offers better predictions than
regular LSTM-based models. More specifically, it was observed that BiLSTM
models provide better predictions compared to ARIMA and LSTM models. It was
also observed that BiLSTM models reach the equilibrium much slower than
LSTM-based models.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:58:52 GMT""}]","2019-11-22"
"1911.09513","Andrea L. Benfenati","Andrea Benfenati and Andrea Maiani and Filipp N. Rybakov and Egor
  Babaev","Vortex nucleation barrier in superconductors beyond the Bean-Livingston
  approximation: A numerical approach for the sphaleron problem in a gauge
  theory","12 pages, 14 figures","Phys. Rev. B 101, 220505 (2020)","10.1103/PhysRevB.101.220505",,"cond-mat.supr-con","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The knowledge of vortex nucleation barriers is crucial for applications of
superconductors, such as single-photon detectors and superconductor-based
qubits. Contrarily to the problem of finding energy minima and critical fields,
there are no controllable methods to explore the energy landscape, identify
saddle points, and compute associated barriers. Similar problems exist in
high-energy physics where the saddle-point configurations are called
sphalerons. Here, we present a generalization of the string method to gauge
field theories, which allows the calculation of energy barriers in
superconductors. We solve the problem of vortex nucleation, assessing the
effects of the nonlinearity of the model, complicated geometry, surface
roughness, and pinning.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:59:18 GMT""},{""version"":""v2"",""created"":""Tue, 9 Jun 2020 16:21:52 GMT""},{""version"":""v3"",""created"":""Sat, 2 Apr 2022 09:38:05 GMT""}]","2022-04-05"
"1911.09514","Tameem Adel","Tameem Adel, Han Zhao, Richard E. Turner","Continual Learning with Adaptive Weights (CLAW)","ICLR 2020",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Approaches to continual learning aim to successfully learn a set of related
tasks that arrive in an online manner. Recently, several frameworks have been
developed which enable deep learning to be deployed in this learning scenario.
A key modelling decision is to what extent the architecture should be shared
across tasks. On the one hand, separately modelling each task avoids
catastrophic forgetting but it does not support transfer learning and leads to
large models. On the other hand, rigidly specifying a shared component and a
task-specific part enables task transfer and limits the model size, but it is
vulnerable to catastrophic forgetting and restricts the form of task-transfer
that can occur. Ideally, the network should adaptively identify which parts of
the network to share in a data driven way. Here we introduce such an approach
called Continual Learning with Adaptive Weights (CLAW), which is based on
probabilistic modelling and variational inference. Experiments show that CLAW
achieves state-of-the-art performance on six benchmarks in terms of overall
continual learning performance, as measured by classification accuracy, and in
terms of addressing catastrophic forgetting.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:59:58 GMT""},{""version"":""v2"",""created"":""Tue, 16 Jun 2020 01:00:11 GMT""}]","2020-06-17"
"1911.09515","Sandeep Nallan Chakravarthula","Sandeep Nallan Chakravarthula, Brian Baucom, Shrikanth Narayanan,
  Panayiotis Georgiou","An analysis of observation length requirements for machine understanding
  of human behaviors from spoken language","converted to CSL format, restructured presentation of analysis and
  methodology, moved finer details to Appendix, enlarged figures and text,
  fixed typos and notational inconsistency",,,,"cs.CL","http://creativecommons.org/licenses/by/4.0/","  The task of quantifying human behavior by observing interaction cues is an
important and useful one across a range of domains in psychological research
and practice. Machine learning-based approaches typically perform this task by
first estimating behavior based on cues within an observation window, such as a
fixed number of words, and then aggregating the behavior over all the windows
in that interaction. The length of this window directly impacts the accuracy of
estimation by controlling the amount of information being used. The exact link
between window length and accuracy, however, has not been well studied,
especially in spoken language. In this paper, we investigate this link and
present an analysis framework that determines appropriate window lengths for
the task of behavior estimation. Our proposed framework utilizes a two-pronged
evaluation approach: (a) extrinsic similarity between machine predictions and
human expert annotations, and (b) intrinsic consistency between intra-machine
and intra-human behavior relations. We apply our analysis to real-life
conversations that are annotated for a large and diverse set of behavior codes
and examine the relation between the nature of a behavior and how long it
should be observed. We find that behaviors describing negative and positive
affect can be accurately estimated from short to medium-length expressions
whereas behaviors related to problem-solving and dysphoria require much longer
observations and are difficult to quantify from language alone. These findings
are found to be generally consistent across different behavior modeling
approaches.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:05:10 GMT""},{""version"":""v2"",""created"":""Fri, 29 Nov 2019 03:39:11 GMT""},{""version"":""v3"",""created"":""Wed, 26 Aug 2020 23:47:36 GMT""}]","2020-08-28"
"1911.09516","Songtao Liu","Songtao Liu, Di Huang, Yunhong Wang","Learning Spatial Fusion for Single-Shot Object Detection",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Pyramidal feature representation is the common practice to address the
challenge of scale variation in object detection. However, the inconsistency
across different feature scales is a primary limitation for the single-shot
detectors based on feature pyramid. In this work, we propose a novel and data
driven strategy for pyramidal feature fusion, referred to as adaptively spatial
feature fusion (ASFF). It learns the way to spatially filter conflictive
information to suppress the inconsistency, thus improving the scale-invariance
of features, and introduces nearly free inference overhead. With the ASFF
strategy and a solid baseline of YOLOv3, we achieve the best speed-accuracy
trade-off on the MS COCO dataset, reporting 38.1% AP at 60 FPS, 42.4% AP at 45
FPS and 43.9% AP at 29 FPS. The code is available at
https://github.com/ruinmessi/ASFF
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:05:28 GMT""},{""version"":""v2"",""created"":""Mon, 25 Nov 2019 01:59:05 GMT""}]","2019-11-26"
"1911.09517","Janne Heittokangas","Janne Heittokangas, Hui Yu and M. Amine Zemirni","On the number of linearly independent rapid solutions to linear
  differential and linear difference equations","30 pages",,,,"math.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Assuming that $A_0,\ldots,A_{n-1}$ are entire functions and that $p\in
\{0,\ldots,n-1\}$ is the smallest index such that $A_p$ is transcendental,
then, by a classical theorem of Frei, each solution base of the differential
equation $f^{(n)}+A_{n-1}f^{(n-1)}+\cdots +A_{1}f'+A_{0}f=0$ contains at least
$n-p$ entire functions of infinite order. Here, the transcendental coefficient
$A_p$ dominates the growth of the polynomial coefficients
$A_{p+1},\ldots,A_{n-1}$. By expressing the dominance of $A_p$ in different
ways, and allowing the coefficients $A_{p+1},\ldots,A_{n-1}$ to be
transcendental, we show that the conclusion of Frei's theorem still holds along
with an additional estimation on the asymptotic lower bound for the growth of
solutions. At times these new refined results give a larger number of linearly
independent solutions of infinite order than the original theorem of Frei. For
such solutions, we show that $0$ is the only possible finite deficient value.
Previously this property has been known to hold for so-called admissible
solutions and is commonly cited as Wittich's theorem. Analogous results are
discussed for linear differential equations in the unit disc, as well as for
complex difference and complex $q$-difference equations.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:05:42 GMT""}]","2019-11-22"
"1911.09519","Iver Brevik","I. Brevik and A. V. Timoshkin","Viscous Fluid Holographic Bounce","10 pages; to appear in International Journal of Geometric Methods in
  Modern Physics","Int. J. Geometric Methods in Mod. Phys. 2050023 (2020)","10.1142/S0219887820500231",,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate bounce cosmological models in the presence of a viscous fluid,
making use of generalized holographic cutoffs introduced by Nojiri and Odintsov
(2017). We consider both an exponential, a power-law, and a double exponential
form for the scale factor. By use of these models we calculate expressions for
infrared cutoffs analytically, such that they correspond to the particle
horizon at the bounce. Finally we derive the energy conservation equation, from
the holographic point of view. In that way the relationship between the viscous
fluid bounce and the holographic bounce is demonstrated.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:06:09 GMT""}]","2019-12-25"
"1911.09521","Line Jelver","Line Jelver, Daniele Stradi, Kurt Stokbro, and Karsten Wedel Jacobsen","Schottky barrier lowering due to interface states in 2D heterophase
  devices","6 figures",,"10.1039/D0NA00795A",,"cond-mat.mes-hall cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Schottky barrier of a metal-semiconductor junction is one of the key
quantities affecting the charge transport in a transistor. The Schottky barrier
height depends on several factors, such as work function difference, local
atomic configuration in the interface, and impurity doping. We show that also
the presence of interface states at 2D metal-semiconductor junctions can give
rise to a large renormalization of the effective Schottky barrier determined
from the temperature dependence of the current. We investigate the charge
transport in n- and p-doped monolayer MoTe$_2$ 1T'-1H junctions using ab-initio
quantum transport calculations. The Schottky barriers are extracted both from
the projected density of states and the transmission spectrum, and by
simulating the IT-characteristic and applying the thermionic emission model. We
find interface states originating from the metallic 1T' phase rather than the
semiconducting 1H phase in contrast to the phenomenon of Fermi level pinning.
Furthermore, we find that these interface states mediate large tunneling
currents which dominates the charge transport and can lower the effective
barrier to a value of only 55 meV.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:06:29 GMT""},{""version"":""v2"",""created"":""Fri, 6 Mar 2020 09:08:17 GMT""},{""version"":""v3"",""created"":""Tue, 19 May 2020 18:46:48 GMT""},{""version"":""v4"",""created"":""Mon, 12 Oct 2020 12:40:09 GMT""}]","2020-12-09"
"1911.09523","Rafa{\l} O{\l}dziejewski","Micha{\l} Kowalski, Rafa{\l} O{\l}dziejewski and Kazimierz
  Rz\k{a}\.zewski","Breakdown of the mean field for dark solitons of dipolar bosons in a
  one-dimensional harmonic trap","6 pages, 3 figures, any comments welcome","Phys. Rev. Research 2, 023386 (2020)","10.1103/PhysRevResearch.2.023386",,"cond-mat.quant-gas","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We directly compare the mean-field and the many-body approach in a
one-dimensional Bose system in a harmonic trap. Both contact and dipolar
interactions are considered. We propose a multi-atom version of the phase
imprinting method to generate dark solitons in the system. We begin with a
general analysis of system dynamics and observe the emergence of a dark soliton
and a shock wave. Center of mass and soliton motion become decoupled because
the shock wave oscillates with the trap frequency and soliton does not. A
detailed investigation of frequencies reveals significant differences between
results obtained in the mean-field and the many-body pictures.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:07:23 GMT""}]","2020-07-01"
"1911.09524","Raphael Wittkowski","Alexander R. Sprenger, Miguel Angel Fernandez-Rodriguez, Laura
  Alvarez, Lucio Isa, Raphael Wittkowski, Hartmut L\""owen","Active Brownian motion with orientation-dependent motility: theory and
  experiments","34 pages, 6 figures, 2 movies","Langmuir 36, 7066-7073 (2020)","10.1021/acs.langmuir.9b03617",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Combining experiments on active colloids, whose propulsion velocity can be
controlled via a feedback loop, and theory of active Brownian motion, we
explore the dynamics of an overdamped active particle with a motility that
depends explicitly on the particle orientation. In this case, the active
particle moves faster when oriented along one direction and slower when
oriented along another, leading to an anisotropic translational dynamics which
is coupled to the particle's rotational diffusion. We propose a basic model of
active Brownian motion for orientation-dependent motility. Based on this model,
we obtain analytic results for the mean trajectories, averaged over the
Brownian noise for various initial configurations, and for the mean-square
displacements including their anisotropic non-Gaussian behavior. The
theoretical results are found to be in good agreement with the experimental
data. Our findings establish a methodology to engineer complex anisotropic
motilities of active Brownian particles, with potential impact in the study of
the swimming behavior of microorganisms subjected to anisotropic driving
fields.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:07:47 GMT""}]","2020-09-01"
"1911.09527","Stefan Nemirovski","Stefan Nemirovski","Instability of rational and polynomial convexity","V.1 - 4 pages, 1 figure; V.2 - details and comments added, 5 pages, 2
  figures; V.3 - minor edits","Proc. Amer. Math. Soc. 149 (2021), 3795-3800","10.1090/proc/15535",,"math.CV math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that rational and polynomial convexity of totally real
submanifolds is in general unstable under perturbations that are
$C^\alpha$-small for any H\""older exponent $\alpha<1$. This complements the
result of L{\o}w and Wold that these properties are $C^1$-stable.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:09:25 GMT""},{""version"":""v2"",""created"":""Tue, 3 Nov 2020 10:11:48 GMT""},{""version"":""v3"",""created"":""Wed, 27 Jan 2021 11:24:15 GMT""}]","2021-07-12"
"1911.09528","Igor Ivanov","Igor P. Ivanov, Nikolai Korchagin, Alexandr Pimikov, Pengming Zhang","Kinematic surprises in twisted particle collisions","14 pages, 8 figures","Phys. Rev. D 101, 016007 (2020)","10.1103/PhysRevD.101.016007","CFTP/19-031","hep-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  ""Twisted particles"" refer to non-plane-wave states of photons, electrons,
hadrons, or any other particle which carry non-zero, adjustable orbital angular
momentum with respect to their average propagation direction. Twisted photons
and electrons have already been experimentally demonstrated, and one can expect
creation of twisted states of other particles in future. Such states can be
brought in collisions, offering a completely new degree of freedom in collider
experiments and, especially, a novel tool for hadronic physics. We recently
showed that $2 \to 1$ processes with two twisted particles such as resonance
production in twisted $e^+e^-$ annihilation give access to observables which
are difficult or impossible to probe in the usual plane-wave collisions. In
this paper, we discuss in detail surprising kinematic features of this process,
focusing on spinless particle annihilation. They include (1) a new dimension in
the final momentum space available in twisted annihilation, (2) interference
fringes emerging in the cross section as a function of the total energy, and
(3) the built-in mass spectrometric capability of this process, that is,
simultaneous production and automatic angular separation of several resonances
with different masses in monochromatic twisted particle annihilation experiment
running at fixed energy. All these features cannot be obtained in the usual
plane wave collision setting.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:09:26 GMT""}]","2020-01-15"
"1911.09529","Amirul Islam","Amirul Islam","Convolutional Neural Network-based Optical Camera Communication System
  for Internet of Vehicles","MSc Thesis",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The evolution of internet of vehicles (IoV) and the growing use of mobile
devices with the development of the Internet of Things, demand has grown for
alternative wireless communication technologies. As a promising alternative,
optical-camera communication (OCC) has emerged that uses light-emitting diode
(LED) and camera as transmitter and receiver respectively. Since LEDs and
cameras are exploring in traffic lights, vehicles, and public lightings, OCC
has the potential to handle the transport systems intelligently. Though some
technologies have been proposed or developed, these are not mature enough to
uphold the huge requirements of IoV. However, most of the OCC applications are
limited to single vehicle and there has been limited focus on the use of
multiple vehicles detection (spatial) or fast processing (temporal) systems.
Also, there has no system to challenge with the bad weather condition. In this
research, a vision camera and high-speed camera has been proposed to provide
multiple vehicle detection and fast data processing. Here, a convolutional
neural network (CNN) based vehicular OCC system has been introduced to
guarantee communication to maintain communication at the adverse condition and
near-infrared is proposed in addition to visible lights to provide long range
and secure communication. To support IoV communication, software-defined
networking (SDN) has been proposed. Finally, the results represent the required
conditions for vehicular OCC system analysis and improved performance
demonstration using the proposed intelligent system.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:16:50 GMT""}]","2019-11-22"
"1911.09532","Juntao Yu","Juntao Yu, Alexandra Uma, Massimo Poesio","A Cluster Ranking Model for Full Anaphora Resolution","LREC 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Anaphora resolution (coreference) systems designed for the CONLL 2012 dataset
typically cannot handle key aspects of the full anaphora resolution task such
as the identification of singletons and of certain types of non-referring
expressions (e.g., expletives), as these aspects are not annotated in that
corpus. However, the recently released dataset for the CRAC 2018 Shared Task
can now be used for that purpose. In this paper, we introduce an architecture
to simultaneously identify non-referring expressions (including expletives,
predicative s, and other types) and build coreference chains, including
singletons. Our cluster-ranking system uses an attention mechanism to determine
the relative importance of the mentions in the same cluster. Additional
classifiers are used to identify singletons and non-referring markables. Our
contributions are as follows. First all, we report the first result on the CRAC
data using system mentions; our result is 5.8% better than the shared task
baseline system, which used gold mentions. Second, we demonstrate that the
availability of singleton clusters and non-referring expressions can lead to
substantially improved performance on non-singleton clusters as well. Third, we
show that despite our model not being designed specifically for the CONLL data,
it achieves a score equivalent to that of the state-of-the-art system by Kantor
and Globerson (2019) on that dataset.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:14:39 GMT""},{""version"":""v2"",""created"":""Mon, 22 Jun 2020 13:27:09 GMT""}]","2020-06-23"
"1911.09533","Adam Zsolt Wagner","Benny Sudakov, Istvan Tomon, Adam Zsolt Wagner","Uniform chain decompositions and applications","22 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Boolean lattice $2^{[n]}$ is the family of all subsets of
$[n]=\{1,\dots,n\}$ ordered by inclusion, and a chain is a family of pairwise
comparable elements of $2^{[n]}$. Let $s=2^{n}/\binom{n}{\lfloor n/2\rfloor}$,
which is the average size of a chain in a minimal chain decomposition of
$2^{[n]}$. We prove that $2^{[n]}$ can be partitioned into $\binom{n}{\lfloor
n/2\rfloor}$ chains such that all but at most $o(1)$ proportion of the chains
have size $s(1+o(1))$. This asymptotically proves a conjecture of F\""uredi from
1985. Our proof is based on probabilistic arguments. To analyze our random
partition we develop a weighted variant of the graph container method. Using
this result, we also answer a Kalai-type question raised recently by Das,
Lamaison and Tran. What is the minimum number of forbidden comparable pairs
forcing that the largest subfamily of $2^{[n]}$ not containing any of them has
size at most $\binom{n}{\lfloor n/2\rfloor}$? We show that the answer is
$(\sqrt{\frac{\pi}{8}}+o(1))2^{n}\sqrt{n}$. Finally, we discuss how these
uniform chain decompositions can be used to optimize and simplify various
results in extremal set theory.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:15:05 GMT""}]","2019-11-22"
"1911.09534","Yunior Ram\'irez-Cruz","Xihui Chen, Ema K\""epuska, Sjouke Mauw, Yunior Ram\'irez-Cruz","Active Re-identification Attacks on Periodically Released Dynamic Social
  Graphs",,"Computer Security - ESORICS 2020. Springer, Lecture Notes in
  Computer Science 12309, pp. 185-205, 2020","10.1007/978-3-030-59013-0_10",,"cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Active re-identification attacks pose a serious threat to privacy-preserving
social graph publication. Active attackers create fake accounts to build
structural patterns in social graphs which can be used to re-identify
legitimate users on published anonymised graphs, even without additional
background knowledge. So far, this type of attacks has only been studied in the
scenario where the inherently dynamic social graph is published once. In this
paper, we present the first active re-identification attack in the more
realistic scenario where a dynamic social graph is periodically published. The
new attack leverages tempo-structural patterns for strengthening the adversary.
Through a comprehensive set of experiments on real-life and synthetic dynamic
social graphs, we show that our new attack substantially outperforms the most
effective static active attack in the literature by increasing the success
probability of re-identification by more than two times and efficiency by
almost 10 times. Moreover, unlike the static attack, our new attack is able to
remain at the same level of effectiveness and efficiency as the publication
process advances. We conduct a study on the factors that may thwart our new
attack, which can help design graph anonymising methods with a better balance
between privacy and utility.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:20:09 GMT""}]","2020-09-15"
"1911.09535","Oluwafemi Azeez","Siddharth Ghiya, Oluwafemi Azeez, Brendan Miller","Agent Probing Interaction Policies",,,,,"cs.MA cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reinforcement learning in a multi agent system is difficult because these
systems are inherently non-stationary in nature. In such a case, identifying
the type of the opposite agent is crucial and can help us address this
non-stationary environment. We have investigated if we can employ some probing
policies which help us better identify the type of the other agent in the
environment. We've made a simplifying assumption that the other agent has a
stationary policy that our probing policy is trying to approximate. Our work
extends Environmental Probing Interaction Policy framework to handle multi
agent environments.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:20:43 GMT""},{""version"":""v2"",""created"":""Tue, 26 Nov 2019 17:56:37 GMT""},{""version"":""v3"",""created"":""Fri, 13 Dec 2019 16:10:42 GMT""}]","2019-12-16"
"1911.09536","Abeer ElBahrawy","Abeer ElBahrawy, Laura Alessandretti, Leonid Rusnac, Daniel Goldsmith,
  Alexander Teytelboym, Andrea Baronchelli","Collective Dynamics of Dark Web Marketplaces",,"Sci Rep 10, 18827 (2020)","10.1038/s41598-020-74416-y",,"cs.CY physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dark markets are commercial websites that use Bitcoin to sell or broker
transactions involving drugs, weapons, and other illicit goods. Being illegal,
they do not offer any user protection, and several police raids and scams have
caused large losses to both customers and vendors over the past years. However,
this uncertainty has not prevented a steady growth of the dark market
phenomenon and a proliferation of new markets. The origin of this resilience
have remained unclear so far, also due to the difficulty of identifying
relevant Bitcoin transaction data. Here, we investigate how the dark market
ecosystem re-organises following the disappearance of a market, due to factors
including raids and scams. To do so, we analyse 24 episodes of unexpected
market closure through a novel datasets of 133 million Bitcoin transactions
involving 31 dark markets and their users, totalling 4 billion USD. We show
that coordinated user migration from the closed market to coexisting markets
guarantees overall systemic resilience beyond the intrinsic fragility of
individual markets. The migration is swift, efficient and common to all market
closures. We find that migrants are on average more active users in comparison
to non-migrants and move preferentially towards the coexisting market with the
highest trading volume. Our findings shed light on the resilience of the dark
market ecosystem and we anticipate that they may inform future research on the
self-organisation of emerging online markets.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:21:54 GMT""},{""version"":""v2"",""created"":""Tue, 12 Jan 2021 18:27:12 GMT""}]","2021-01-13"
"1911.09537","Jindong Gu","Jindong Gu and Volker Tresp","Neural Network Memorization Dissection","Workshop on Machine Learning with Guarantees, NeurIPS 2019",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep neural networks (DNNs) can easily fit a random labeling of the training
data with zero training error. What is the difference between DNNs trained with
random labels and the ones trained with true labels? Our paper answers this
question with two contributions. First, we study the memorization properties of
DNNs. Our empirical experiments shed light on how DNNs prioritize the learning
of simple input patterns. In the second part, we propose to measure the
similarity between what different DNNs have learned and memorized. With the
proposed approach, we analyze and compare DNNs trained on data with true labels
and random labels. The analysis shows that DNNs have \textit{One way to Learn}
and \textit{N ways to Memorize}. We also use gradient information to gain an
understanding of the analysis results.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:24:55 GMT""}]","2019-11-22"
"1911.09538","Tomasz Trze\'sniewski","Jerzy Kowalski-Glikman, Jerzy Lukierski and Tomasz Trze\'sniewski","Quantum $D = 3$ Euclidean and Poincar\'{e} symmetries from contraction
  limits","28 pages, v2 analysis of applicability of r-matrices in 3D gravity
  with $\Lambda \neq 0$ in Subsec. VI.C, generalization of procedure of quantum
  IW contractions in Subsec. IV.E, some conventions changed, redundant formulae
  removed, references added","J. High Energy Phys. 2020, 96 (2020)","10.1007/JHEP09(2020)096",,"hep-th gr-qc math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Following the recently obtained complete classification of quantum-deformed
$\mathfrak{o}(4)$, $\mathfrak{o}(3,1)$ and $\mathfrak{o}(2,2)$ algebras,
characterized by classical $r$-matrices, we study their inhomogeneous $D = 3$
quantum IW contractions (i.e. the limit of vanishing cosmological constant),
with Euclidean or Lorentzian signature. Subsequently, we compare our results
with the complete list of $D = 3$ inhomogeneous Euclidean and $D = 3$
Poincar\'{e} quantum deformations obtained by P.~Stachura. It turns out that
the IW contractions allow us to recover all Stachura deformations. We further
discuss the applicability of our results in the models of 3D quantum gravity in
the Chern-Simons formulation (both with and without the cosmological constant),
where it is known that the relevant quantum deformations should satisfy the
Fock-Rosly conditions. The latter deformations in part of the cases are
associated with the Drinfeld double structures, which also have been recently
investigated in detail.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:25:21 GMT""},{""version"":""v2"",""created"":""Tue, 3 Mar 2020 17:04:56 GMT""}]","2020-09-17"
"1911.09539","Andr\'e Hottung","Andr\'e Hottung and Kevin Tierney","Neural Large Neighborhood Search for the Capacitated Vehicle Routing
  Problem",,"ECAI 2020: 443-450","10.3233/FAIA200124",,"cs.AI stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Learning how to automatically solve optimization problems has the potential
to provide the next big leap in optimization technology. The performance of
automatically learned heuristics on routing problems has been steadily
improving in recent years, but approaches based purely on machine learning are
still outperformed by state-of-the-art optimization methods. To close this
performance gap, we propose a novel large neighborhood search (LNS) framework
for vehicle routing that integrates learned heuristics for generating new
solutions. The learning mechanism is based on a deep neural network with an
attention mechanism and has been especially designed to be integrated into an
LNS search setting. We evaluate our approach on the capacitated vehicle routing
problem (CVRP) and the split delivery vehicle routing problem (SDVRP). On CVRP
instances with up to 297 customers, our approach significantly outperforms an
LNS that uses only handcrafted heuristics and a well-known heuristic from the
literature. Furthermore, we show for the CVRP and the SDVRP that our approach
surpasses the performance of existing machine learning approaches and comes
close to the performance of state-of-the-art optimization approaches.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:29:41 GMT""},{""version"":""v2"",""created"":""Mon, 30 Nov 2020 16:45:39 GMT""}]","2020-12-01"
"1911.09540","Ling Lu","Xiaomei Gao, Lechen Yang, Hao Lin, Lang Zhang, Jiafang Li, Fang Bo,
  Zhong Wang, Ling Lu","Dirac-vortex topological cavity","7 pages, 5 figures. Published version at
  https://www.nature.com/articles/s41565-020-0773-7","Nature Nanotechnology 15, 1012 (2020)","10.1038/s41565-020-0773-7",,"physics.optics cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cavity design is crucial for single-mode semiconductor lasers such as the
distributed feedback (DFB) and vertical-cavity surface-emitting lasers (VCSEL).
By recognizing that both optical resonators feature a single mid-gap mode
localized at the topological defect in a one-dimensional (1D) lattice, we
generalize the topological cavity design into 2D using a honeycomb photonic
crystal with a vortex Dirac mass -- the analog of Jackiw-Rossi zero modes. We
theoretically predict and experimentally demonstrate that such a Dirac-vortex
cavity can have a tunable mode area across a few orders of magnitudes,
arbitrary mode degeneracy, robustly large free-spectral-range, vector-beam
output of low divergence, and compatibility with high-index substrates. This
topological cavity could enable photonic crystal surface-emitting lasers
(PCSEL) with stabler single-mode operation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:29:47 GMT""}]","2021-04-26"
"1911.09541","Thierry Dauxois","T. Dauxois, T. Peacock, P. Bauer, C.P. Caulfield, C. Cenedese, C.
  Gorl\'e, G. Haller, G.N. Ivey, P.F. Linden, E. Meiburg, N. Pinardi, N.M.
  Vriend, A. Woods","Confronting Grand Challenges in Environmental Fluid Mechanics",,"Phys. Rev. Fluids 6, 020501 (2021)","10.1103/PhysRevFluids.6.020501",,"physics.ao-ph physics.flu-dyn physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Environmental fluid mechanics underlies a wealth of natural, industrial and,
by extension, societal challenges. In the coming decades, as we strive towards
a more sustainable planet, there are a wide range of grand challenge problems
that need to be tackled, ranging from fundamental advances in understanding and
modeling of stratified turbulence and consequent mixing, to applied studies of
pollution transport in the ocean, atmosphere and urban environments. A workshop
was organized in the Les Houches School of Physics in France in January 2019
with the objective of gathering leading figures in the field to produce a road
map for the scientific community. Five subject areas were addressed: multiphase
flow, stratified flow, ocean transport, atmospheric and urban transport, and
weather and climate prediction. This article summarizes the discussions and
outcomes of the meeting, with the intent of providing a resource for the
community going forward.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:29:53 GMT""},{""version"":""v2"",""created"":""Tue, 28 Jul 2020 14:55:56 GMT""},{""version"":""v3"",""created"":""Wed, 23 Dec 2020 18:43:04 GMT""},{""version"":""v4"",""created"":""Thu, 24 Dec 2020 07:11:40 GMT""}]","2021-02-17"
"1911.09542","Samuel Reeve","Saaketh Desai, Samuel Temple Reeve, Karthik Guda Vishnu, Alejandro
  Strachan","Tuning martensitic transformations via coherent second phases in
  nanolaminates using free energy landscape engineering",,"Journal of Applied Physics, 127, 125112 (2020)","10.1063/1.5145008",,"cond-mat.mtrl-sci physics.app-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We explore the possibilities and limitations of using a coherent second phase
to engineer the thermo-mechanical properties of a martensitic alloy by
modifying the underlying free energy landscape that controls the
transformation. We use molecular dynamics simulations of a model atomistic
system where the properties of a coherent, nanoscale second phase can be varied
systematically. With a base martensitic material that undergoes a
temperature-induced transformation from a cubic austenite to a monoclinic
martensite, the simulations show a significant ability to engineer the
transformation temperatures, from a ~50% reduction to a ~200% increase, with 50
at. % of the cubic second phase. We establish correlations between the
properties of the second phase and the transformation characteristics and
microstructure, via the free energy landscape of the two-phase systems.
Coherency stresses have a strong influence on the martensitic variants observed
and can even cause the non-martensitic second phase to undergo a
transformation. Reducing the stiffness of second phase increases the
transformation strain and modifies the martensitic microstructure, increasing
the volume fraction of the transformed material. This increase in
transformation strain is accompanied by a significant increase in the Af and
thermal hysteresis, while the Ms remains unaltered. Our findings on the
tunability of martensitic transformations can be used for informed searches of
second phases to achieve desired material properties, such as achieving room
temperature, lightweight shape memory alloys.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:31:12 GMT""},{""version"":""v2"",""created"":""Tue, 21 Apr 2020 19:39:05 GMT""},{""version"":""v3"",""created"":""Tue, 26 May 2020 21:43:35 GMT""}]","2020-05-28"
"1911.09543","Meng Cai","Meng Cai, Siqing Gan, Xiaojie Wang","Weak convergence rates for an explicit full-discretization of stochastic
  Allen-Cahn equation with additive noise","28 pages","J. Sci. Comput. (2021)","10.1007/s10915-020-01378-8",,"math.NA cs.NA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discretize the stochastic Allen-Cahn equation with additive noise by means
of a spectral Galerkin method in space and a tamed version of the exponential
Euler method in time. The resulting error bounds are analyzed for the
spatio-temporal full discretization in both strong and weak senses. Different
from existing works, we develop a new and direct approach for the weak error
analysis, which does not rely on the use of the associated Kolmogorov equation
or It\^{o}'s formula and is therefore non-Markovian in nature. Such an approach
thus has a potential to be applied to non-Markovian equations such as
stochastic Volterra equations or other types of fractional SPDEs, which suffer
from the lack of Kolmogorov equations. It turns out that the obtained weak
convergence rates are, in both spatial and temporal direction, essentially
twice as high as the strong convergence rates. Also, it is revealed how the
weak convergence rates depend on the regularity of the noise. Numerical
experiments are finally reported to confirm the theoretical conclusion.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:32:04 GMT""},{""version"":""v2"",""created"":""Tue, 19 Jan 2021 08:19:10 GMT""}]","2021-01-20"
"1911.09544","Calum Milloy","Calum Milloy, Giulio Falcioni and Einan Gardi","Wilson-line geometries and the relation between IR singularities of form
  factors and the large-x limit of DGLAP splitting functions","12 pages, talk presented at RADCOR 2019, 9-13 September 2019",,,,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We discuss the relation between the infrared singularities of on-shell
partonic form factors and parton distribution functions (PDFs) near the elastic
limit, through their factorisation in terms of Wilson-line correlators.
Ultimately we identify the difference between the anomalous dimensions
controlling single poles of these two quantities to all loops in terms of the
closed parallelogram Wilson loop. To arrive at this result we first use the
common hard-collinear behaviour of the two to derive a relation between their
respective soft singularities, and then show that the latter is manifested in
terms of differing Wilson-line geometries. We perform explicit diagrammatic
calculations in configuration space through two loops to verify the relation.
More generally, the emerging picture allows us to classify collinear
singularities in eikonal quantities depending on whether they are associated
with finite (closed) Wilson-line segments or infinite (open) ones.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:33:21 GMT""}]","2019-11-22"
"1911.09545","Luca Zanotto","Luca Zanotto, Riccardo Piccoli, Junliang Dong, Diego Caraffini,
  Roberto Morandotti and Luca Razzari","Time-domain terahertz compressive imaging",,,"10.1364/OE.384134",,"eess.IV physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an implementation of the single-pixel imaging approach into a
terahertz (THz) time-domain spectroscopy (TDS) system. We demonstrate the
indirect coherent reconstruction of THz temporal waveforms at each spatial
position of an object, without the need of mechanical raster-scanning. First,
we exploit such temporal information to realize (far-field) time-of-flight
images. In addition, as a proof of concept, we apply a typical compressive
sensing algorithm to demonstrate image reconstruction with less than 50% of the
total required measurements. Finally, the access to frequency domain is also
demonstrated by reconstructing spectral images of an object featuring an
absorption line in the THz range. The combination of single-pixel imaging with
compressive sensing algorithms allows to reduce both complexity and acquisition
time of current THz-TDS imaging systems.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:39:48 GMT""},{""version"":""v2"",""created"":""Mon, 25 Nov 2019 22:27:32 GMT""}]","2020-02-19"
"1911.09547","Johanna Wiehe","Winfried Hochst\""attler and Johanna Wiehe","The Chromatic Polynomial of a Digraph",,"Graphs and Combinatorial Optimization: from Theory to
  Applications, CTW2020 Proceedings, 2021, pp. 1-14",,"feU-dmo063.19","math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An acyclic coloring of a digraph as defined by Neumann-Lara is a
vertex-coloring such that no monochromatic directed cycles occur. Counting the
number of such colorings with $k$ colors can be done by counting so-called
Neumann-Lara-coflows (NL-coflows), which build a polynomial in $k$. We will
present a representation of this polynomial using totally cyclic subdigraphs,
which form a graded poset $Q$. Furthermore we will decompose our NL-coflow
polynomial, which becomes the chromatic polynomial of a digraph by
multiplication with the number of colors to the number of components, examining
the special structure of the poset of totally cyclic subdigraphs with fixed
underlying undirected graph. This decomposition will confirm the equality of
our chromatic polynomial of a digraph and the chromatic polynomial of the
underlying undirected graph in the case of symmetric digraphs.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:41:51 GMT""},{""version"":""v2"",""created"":""Wed, 3 Nov 2021 12:23:22 GMT""},{""version"":""v3"",""created"":""Thu, 28 Apr 2022 09:08:42 GMT""}]","2022-04-29"
"1911.09548","Martin Schwalsberger","Martin Neum\""uller, Martin Schwalsberger","A parallel space-time multigrid method for the eddy-current equation",,,,,"cs.CE cs.NA math.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We expand the applicabilities and capabilities of an already existing
space-time parallel method based on a block Jacobi smoother. First we formulate
a more detailed criterion for spatial coarsening, which enables the method to
deal with unstructured meshes and varying material parameters. Further we
investigate the application to the eddy-current equation, where the non-trivial
kernel of the curl operator causes severe problems. This is remedied with a new
nodal auxiliary space correction. We proceed to identify convergence rates by
local Fourier analysis and numerical experiments. Finally, we present a
numerical experiment which demonstrates its excellent scaling properties.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:43:40 GMT""}]","2019-11-22"
"1911.09549","Christopher Zerafa","Christopher Zerafa, Pauline Galea, Cristiana Sebu","Learning to Invert Pseudo-Spectral Data for Seismic Waveform Inversion","review paper",,"10.7423/XJENZA.2019.1.01",,"physics.geo-ph eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Full-waveform inversion (FWI) is a widely used technique in seismic
processing to produce high resolution Earth models that fully explain the
recorded seismic data. FWI is a local optimisation problem which aims to
minimise in a least-squares sense the misfit between recorded and modelled
data. The inversion process begins with a best-guess initial model which is
iteratively improved using a sequence of linearised local inversions to solve a
fully non-linear problem. Deep learning has gained widespread popularity in the
new millennium. At the core of these tools are Neural Networks (NN), in
particular Deep Neural Networks (DNN) are variants of these original NN
algorithms with significantly more hidden layers, resulting in efficient
learning of a non-linear functional between input and output pairs. The
learning process within DNN involves iteratively updating network neuron
weights to best approximate input-to-output mappings. There is clearly
similarity between FWI and DNN. Both approaches attempt to solve for a
non-linear mapping in an iterative sense, however they are fundamentally
different in that the former is knowledge-driven whereas the latter is
data-driven. This article proposes a novel approach which learns
pseudo-spectral data-driven FWI. We test this methodology by training a DNN on
1D multi-layer, horizontally-isotropic data and then apply this to previously
unseen data to infer the surface velocity. Results are compared against a
synthetic model and successfulness and failures of this approach are hence
identified.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:44:47 GMT""}]","2019-11-22"
"1911.09550","Hao Wang","Hao Wang, Pu Lu, Hui Zhang, Mingkun Yang, Xiang Bai, Yongchao Xu,
  Mengchao He, Yongpan Wang, Wenyu Liu","All You Need Is Boundary: Toward Arbitrary-Shaped Text Spotting","Accepted to AAAI2020",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, end-to-end text spotting that aims to detect and recognize text
from cluttered images simultaneously has received particularly growing interest
in computer vision. Different from the existing approaches that formulate text
detection as bounding box extraction or instance segmentation, we localize a
set of points on the boundary of each text instance. With the representation of
such boundary points, we establish a simple yet effective scheme for end-to-end
text spotting, which can read the text of arbitrary shapes. Experiments on
three challenging datasets, including ICDAR2015, TotalText and COCO-Text
demonstrate that the proposed method consistently surpasses the
state-of-the-art in both scene text detection and end-to-end text recognition
tasks.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:45:56 GMT""}]","2019-11-22"
"1911.09551","Junle Pei","Tianjun Li, Junle Pei, Fangzhou Xu, Wenxing Zhang","$SU(3)_C\times SU(3)_L\times U(1)_X$ model from $SU(6)$",,"Phys. Rev. D 102, 016004 (2020)","10.1103/PhysRevD.102.016004",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose the $SU(3)_C\times SU(3)_L\times U(1)_X$ model arising from
$SU(6)$ breaking. One family of the Standard Model (SM) fermions arises from
two $\bar{6}$ representations and one $15$ representation of $SU(6)$ gauge
symmetry. To break the $SU(3)_C\times SU(3)_L\times U(1)_X$ gauge symmetry down
to the SM, we introduce three $SU(3)_L$ triplet Higgs fields, where two of them
come from the $\bar{6}$ representation while the other one from the $15$
representation. We study the gauge boson masses and Higgs boson mass in detail,
and find that the vacuum expectation value (VEV) of the Higgs field for
$SU(3)_L\times U(1)_X$ gauge symmetry breaking is around 10 TeV. The neutrino
masses and mixing can be generated via the littlest inverse seesaw mechanism.
In particular, we have normal hierarchy for neutrino masses and the lightest
active neutrino is massless. Also, we consider constraints from the charged
lepton flavor changing decays as well. Furthermore, introducing two $SU(3)_L$
adjoint fermions, one $SU(3)_C$ adjoint scalar, and one $SU(3)_L$ triplet
scalar, we can achieve gauge coupling unification within 1\%. These extra
particles can provide a dark matter candidate as well.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:46:07 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jul 2020 10:41:57 GMT""},{""version"":""v3"",""created"":""Fri, 20 Nov 2020 14:50:13 GMT""}]","2020-11-23"
"1911.09552","Philippe Mendels","P. Khuntia, M. Velazquez, Q. Barth\'elemy, F. Bert, E. Kermarrec, A.
  Legros, B. Bernu, L. Messio, A. Zorko, P. Mendels","Gapless ground state in the archetypal quantum kagome antiferromagnet
  ZnCu$_3$(OH)$_6$Cl$_2$","8 pages main text, 4 figures, 21 pages supplementary information","Nature Physics 16, 469-474 (2020)","10.1038/s41567-020-0792-1",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Spin liquids are exotic phases of quantum matter challenging Landau's
paradigm of symmetry-breaking phase transitions. Despite strong exchange
interactions, spins do not order or freeze down to zero temperature. While
well-established for 1D quantum antiferromagnets, in higher dimension where
quantum fluctuations are less acute, realizing and understanding such states
represent major issues, both theoretical and experimental. In this respect the
simplest nearest-neighbor Heisenberg antiferromagnet Hamiltonian on the highly
frustrated kagome lattice has proven to be a fascinating and inspiring model.
The exact nature of its ground state remains elusive and the existence of a
spin-gap is the first key-issue to be addressed to discriminate between the
various classes of proposed spin liquids. Here, through low-temperature Nuclear
Magnetic Resonance (NMR) contrast experiments on high quality single crystals,
we single out the kagome susceptibility and the corresponding dynamics in the
kagome archetype, the mineral herbertsmithite, ZnCu$_3$(OH)$_6$Cl$_2$. We
firmly conclude that this material does not harbor any spin-gap, which restores
a convergence with recent numerical results promoting a gapless Dirac spin
liquid as the ground state of the Heisenberg kagome antiferromagnet.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:47:48 GMT""}]","2020-04-22"
"1911.09553","David Visontai","D\'avid Visontai, J\'ozsef St\'eger, J\'anos M\'ark Szalai-Gindl,
  L\'aszl\'o Dobos, L\'aszl\'o Oroszl\'any, Istv\'an Ervin Csabai","Kooplex: collaborative data analytics portal for advancing sciences","22 pages, 4 figures, 6 tables",,,,"cs.SE","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Research collaborations are continuously emerging catalyzed by online
platforms, where people can share their codes, calculations, data and results.
These virtual research platforms are innovative, community oriented, flexible
and secure as required by modern scientific approaches. A wide range of open
source and commercial solutions are available in this field emphasizing the
relevant aspects of such a platform differently. In this paper we present our
open source and modular platform, KOOPLEX, which combines the key concepts of
dynamic collaboration, customizable research environment, data sharing, access
to datahubs, reproducible research and reporting. It is easily deployable and
scalable to serve more users or access large computational resources.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:47:51 GMT""}]","2019-11-22"
"1911.09554","Pedro Henrique da Costa Avelar","Pedro H. C. Avelar, Anderson R. Tavares, Marco Gori, Luis C. Lamb","Discrete and Continuous Deep Residual Learning Over Graphs",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we propose the use of continuous residual modules for graph
kernels in Graph Neural Networks. We show how both discrete and continuous
residual layers allow for more robust training, being that continuous residual
layers are those which are applied by integrating through an Ordinary
Differential Equation (ODE) solver to produce their output. We experimentally
show that these residuals achieve better results than the ones with
non-residual modules when multiple layers are used, mitigating the low-pass
filtering effect of GCN-based models. Finally, we apply and analyse the
behaviour of these techniques and give pointers to how this technique can be
useful in other domains by allowing more predictable behaviour under dynamic
times of computation.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:48:15 GMT""},{""version"":""v2"",""created"":""Tue, 26 Nov 2019 11:15:03 GMT""}]","2019-11-27"
"1911.09555","Albino Carbognani","A. Carbognani, D. Barghini, D. Gardiol, M. di Martino, G. B.
  Valsecchi, P. Trivero, A. Buzzoni, S. Rasetti, D. Selvestrel, C. Knapic, E.
  Londero, S. Zorba, C. A. Volpicelli, M. Di Carlo, J. Vaubaillon, C. Marmo, F.
  Colas, D. Valeri, F. Zanotti, M. Morini, P. Demaria, B. Zanda, S. Bouley, P.
  Vernazza, J. Gattacceca, J.-L. Rault, L. Maquet, M. Birlan","A Case Study of the May 30th, 2017 Italian Fireball","19 pages, 17 figures. Accepted for publication in The European
  Physical Journal PLUS",,,,"astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On May 30th, 2017 at about 21h 09m 17s UTC a green bright fireball crossed
the sky of north-eastern Italy. The fireball path was observed from some
all-sky cameras starting from a mean altitude of $81.1 \pm 0.2$ km (Lat.
$44.369^{\circ} \pm 0.002^{\circ}$ N; Long. $11.859^{\circ} \pm 0.002^{\circ}$
E) and extinct at $23.3 \pm 0.2$ km (Lat. $45.246^{\circ} \pm 0.002^{\circ}$ N;
Long. $12.046^{\circ} \pm 0.002^{\circ}$ E), between the Italian cities of
Venice and Padua. In this paper, on the basis of simple physical models, we
will compute the atmospheric trajectory, analize the meteoroid atmospheric
dynamics, the dark flight phase (with the strewn field) and compute the best
heliocentric orbit of the progenitor body. Search for meteorites on the ground
has not produced any results so far.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:49:44 GMT""},{""version"":""v2"",""created"":""Sun, 2 Feb 2020 16:57:31 GMT""}]","2020-02-04"
"1911.09556","Yang Wan","Mohammad Masiur Rahaman, Wenqiang Fang, Alice Lux Fawzi, Yang Wan,
  Haneesh Kesari","An accelerometer-only algorithm for determining the acceleration field
  of a rigid body, with application in studying the mechanics of mild Traumatic
  Brain Injury","35 pages, 7 figures",,,,"physics.med-ph physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present an algorithm for determining the acceleration field of a rigid
body using measurements from four tri-axial accelerometers. The acceleration
field is an important quantity in bio-mechanics problems, especially in the
study of mild Traumatic Brain Injury (mTBI). The in vivo strains in the brain,
which are hypothesized to closely correlate with brain injury, are generally
not directly accessible outside of a laboratory setting. However, they can be
estimated on knowing the head's acceleration field. In contrast to other
techniques, the proposed algorithm uses data exclusively from accelerometers,
rather than from a combination of accelerometers and gyroscopes. For that
reason, the proposed accelerometer only (AO) algorithm does not involve any
numerical differentiation of data, which is known to greatly amplify
measurement noise. For applications where only the magnitude of the
acceleration vector is of interest, the algorithm is straightforward,
computationally efficient and does not require computation of angular velocity
or orientation. When both the magnitude and direction of acceleration are of
interest, the proposed algorithm involves the calculation of the angular
velocity and orientation as intermediate steps. In addition to helping
understand the mechanics of mTBI, the AO-algorithm may find widespread use in
several bio-mechanical applications, gyroscope-free inertial navigation units,
ballistic platform guidance, and platform control.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:50:25 GMT""}]","2019-11-22"
"1911.09557","Gilles Ev\'equoz","Huyuan Chen, Gilles Ev\'equoz, Tobias Weth","Complex solutions and stationary scattering for the nonlinear Helmholtz
  equation",,"SIAM J. Math. Anal. 53(2) (2021) 2349-2372","10.1137/19M1302314",,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study a stationary scattering problem related to the nonlinear Helmholtz
equation $-\Delta u - k^2 u = f(x,u) \ \ \text{in $\mathbb{R}^N$,}$ where $N
\ge 3$ and $k>0$. For a given incident free wave $\varphi \in
L^\infty(\mathbb{R}^N)$, we prove the existence of complex-valued solutions of
the form $u=\varphi+u_{\text{sc}}$, where $u_{\text{sc}}$ satisfies the
Sommerfeld outgoing radiation condition. Since neither a variational framework
nor maximum principles are available for this problem, we use topological fixed
point theory and global bifurcation theory to solve an associated integral
equation involving the Helmholtz resolvent operator. The key step of this
approach is the proof of suitable a priori bounds.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:51:37 GMT""},{""version"":""v2"",""created"":""Tue, 16 Mar 2021 21:30:36 GMT""}]","2021-08-10"
"1911.09558","Mar\'ia Claudia Ram\'irez-Tannus","M.C. Ram\'irez-Tannus, J. Poorta, A. Bik, L. Kaper, A. de Koter, J. De
  Ridder, H. Beuther, W. Brandner, B. Davies, M. Gennaro, D. Guo, T. Henning,
  H. Linz, T. Naylor, A. Pasquali, O.H. Ram\'irez-Agudelo, and H. Sana","The young stellar content of the giant HII regions M8, G333.6-0.2, and
  NGC6357 with VLT/KMOS","Accepted for publication in A&A. The arXiv version includes appendix
  C, which is an online only figure in A&A","A&A 633, A155 (2020)","10.1051/0004-6361/201935941",,"astro-ph.SR astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Context: The identification and characterisation of populations of young
massive stars in (giant) HII regions provides important constraints on i) the
formation process of massive stars and their early feedback on the environment,
and ii) the initial conditions for population synthesis models predicting the
evolution of ensembles of stars. Aims: We identify and characterise the stellar
populations of the following young giant HII regions: M8, G333.6-0.2, and
NGC6357. Methods: We acquired H- and K-band spectra of around 200 stars using
The K-band KMOS on the ESO Very Large Telescope. The targets for M8 and NGC6357
were selected from the MYStIX project, which combines X-ray observations with
near-infrared and mid-infrared data. For G333.6-0.2, the sample selection is
based on the near-infrared colours combined with X-ray data. We introduce an
automatic spectral classification method in order to obtain temperatures and
luminosities for the observed stars. We analyse the stellar populations using
their photometric, astrometric, and spectroscopic properties and compared the
position of the stars in the Hertzprung-Russell diagram with stellar evolution
models to constrain their ages and mass ranges. Results: We confirm the
presence of candidate ionising sources in the three regions and report new
ones, including the first spectroscopically identified O stars in G333.6-0.2.
In M8 and NGC6357, two populations are identified: i) OB main-sequence stars
($M > 5~\rm{M_{\odot}}$) and ii) pre-main sequence stars
($M\approx0.5-5~\rm{M_{\odot}}$). The ages of the clusters are $\sim$1-3~Myr,
$< 3$~Myr, and $\sim$0.5-3~Myr for M8, G333.6-0.2, and NGC6357, respectively.
We show that MYStIX selected targets have $>$ 90\% probability of being members
of the HII region, whereas a selection based on near infrared (NIR) colours
leads to a membership probability of only $\sim$70\%.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:53:07 GMT""}]","2020-01-29"
"1911.09559","Jed Duersch","Jed A. Duersch and Thomas A. Catanach","Generalizing Information to the Evolution of Rational Belief",,,"10.3390/e22010108",,"cs.IT math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Information theory provides a mathematical foundation to measure uncertainty
in belief. Belief is represented by a probability distribution that captures
our understanding of an outcome's plausibility. Information measures based on
Shannon's concept of entropy include realization information, Kullback-Leibler
divergence, Lindley's information in experiment, cross entropy, and mutual
information.
  We derive a general theory of information from first principles that accounts
for evolving belief and recovers all of these measures. Rather than simply
gauging uncertainty, information is understood in this theory to measure change
in belief. We may then regard entropy as the information we expect to gain upon
realization of a discrete latent random variable.
  This theory of information is compatible with the Bayesian paradigm in which
rational belief is updated as evidence becomes available. Furthermore, this
theory admits novel measures of information with well-defined properties, which
we explore in both analysis and experiment. This view of information
illuminates the study of machine learning by allowing us to quantify
information captured by a predictive model and distinguish it from residual
information contained in training data. We gain related insights regarding
feature selection, anomaly detection, and novel Bayesian approaches.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:54:43 GMT""},{""version"":""v2"",""created"":""Sun, 12 Jan 2020 23:30:31 GMT""}]","2020-01-17"
"1911.09560","Kai Arulkumaran","Andrea Agostinelli, Kai Arulkumaran, Marta Sarrico, Pierre Richemond,
  Anil Anthony Bharath","Memory-Efficient Episodic Control Reinforcement Learning with Dynamic
  Online k-means","Workshop on Biological and Artificial Reinforcement Learning, NeurIPS
  2019",,,,"cs.LG cs.NE stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, neuro-inspired episodic control (EC) methods have been developed to
overcome the data-inefficiency of standard deep reinforcement learning
approaches. Using non-/semi-parametric models to estimate the value function,
they learn rapidly, retrieving cached values from similar past states. In
realistic scenarios, with limited resources and noisy data, maintaining
meaningful representations in memory is essential to speed up the learning and
avoid catastrophic forgetting. Unfortunately, EC methods have a large space and
time complexity. We investigate different solutions to these problems based on
prioritising and ranking stored states, as well as online clustering
techniques. We also propose a new dynamic online k-means algorithm that is both
computationally-efficient and yields significantly better performance at
smaller memory sizes; we validate this approach on classic reinforcement
learning environments and Atari games.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:54:49 GMT""}]","2019-11-22"
"1911.09561","Oliviero Riganelli","Leonardo Mariani, Mauro Pezz\`e, Oliviero Riganelli, Rui Xin","Predicting Failures in Multi-Tier Distributed Systems","Accepted for publication in Journal of Systems and Software",,,,"cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many applications are implemented as multi-tier software systems, and are
executed on distributed infrastructures, like cloud infrastructures, to benefit
from the cost reduction that derives from dynamically allocating resources
on-demand. In these systems, failures are becoming the norm rather than the
exception, and predicting their occurrence, as well as locating the responsible
faults, are essential enablers of preventive and corrective actions that can
mitigate the impact of failures, and significantly improve the dependability of
the systems. Current failure prediction approaches suffer either from false
positives or limited accuracy, and do not produce enough information to
effectively locate the responsible faults. In this paper, we present PreMiSE, a
lightweight and precise approach to predict failures and locate the
corresponding faults in multi-tier distributed systems. PreMiSE blends
anomaly-based and signature-based techniques to identify multi-tier failures
that impact on performance indicators, with high precision and low false
positive rate. The experimental results that we obtained on a Cloud-based IP
Multimedia Subsystem indicate that PreMiSE can indeed predict and locate
possible failure occurrences with high precision and low overhead.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:55:09 GMT""}]","2019-11-25"
"1911.09562","Andr\'eas Sundstr\""om","Andr\'eas Sundstr\""om and Laurent Gremillet and Evangelos Siminos and
  Istv\'an Pusztai","Fast collisional electron heating and relaxation in thin foils driven by
  a circularly polarized ultraintense short-pulse laser","Published in Journal of Plasma Physics","J. Plasma Phys. (2020) vol. 86, 755860201","10.1017/S0022377820000264",,"physics.plasm-ph","http://creativecommons.org/licenses/by/4.0/","  The creation of well-thermalized, hot and dense plasmas is attractive for
warm dense matter studies. We investigate collisionally induced energy
absorption of an ultraintense and ultrashort laser pulse in a solid copper
target using particle-in-cell simulations. We find that, upon irradiation by a
$2\times10^{20}{\rm\,W\,cm^{-2}}$ intensity, $60{\rm\,fs}$ duration, circularly
polarized laser pulse, the electrons in the collisional simulation rapidly
reach a well-thermalized distribution with ${\sim}3.5{\rm\,keV}$ temperature,
while in the collisionless simulation the absorption is several orders of
magnitude weaker. Circular polarization inhibits the generation of suprathermal
electrons, while ensuring efficient bulk heating through inverse
bremsstrahlung, a mechanism usually overlooked at relativistic laser intensity.
An additional simulation, taking account of both collisional and field
ionization, yields similar results: the bulk electrons are heated to
${\sim}2.5{\rm\,keV}$, but with a somewhat lower degree of thermalization than
in the pre-set, fixed-ionization case. The collisional absorption mechanism is
found to be robust against variations in the laser parameters. At fixed laser
pulse energy, increasing the pulse duration rather than the intensity leads to
a higher electron temperature.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:55:30 GMT""},{""version"":""v2"",""created"":""Tue, 18 Feb 2020 12:25:48 GMT""},{""version"":""v3"",""created"":""Tue, 28 Apr 2020 15:26:19 GMT""}]","2020-04-29"
"1911.09563","Achillefs Tzioufas","Achillefs Tzioufas","Monotonicity of escape probabilities for branching random walks on
  \Z^{d}","Added Remark 9",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study nearest-neighbors branching random walks started from a point at the
interior of a hypercube. We show that the probability that the process escapes
the hypercube is monotonically decreasing with respect to the distance of its
starting point from the boundary. We derive as a consequence that at all times
the number of particles at a site is monotonically decreasing with respect to
its distance from the starting point.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:57:34 GMT""},{""version"":""v2"",""created"":""Thu, 27 Feb 2020 15:49:29 GMT""}]","2020-02-28"
"1911.09564","Kwang-Sung Jun","Kwang-Sung Jun, Francesco Orabona","Parameter-Free Locally Differentially Private Stochastic Subgradient
  Descent","to appear at Privacy in Machine Learning (PriML) workshop, NeurIPS'19",,,,"cs.LG cs.CR math.OC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the problem of minimizing a convex risk with stochastic
subgradients guaranteeing $\epsilon$-locally differentially private
($\epsilon$-LDP). While it has been shown that stochastic optimization is
possible with $\epsilon$-LDP via the standard SGD (Song et al., 2013), its
convergence rate largely depends on the learning rate, which must be tuned via
repeated runs. Further, tuning is detrimental to privacy loss since it
significantly increases the number of gradient requests. In this work, we
propose BANCO (Betting Algorithm for Noisy COins), the first $\epsilon$-LDP SGD
algorithm that essentially matches the convergence rate of the tuned SGD
without any learning rate parameter, reducing privacy loss and saving privacy
budget.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:58:17 GMT""}]","2019-11-22"
"1911.09565","Cassie Meeker","Cassie Meeker, Maximilian Haas-Heger, Matei Ciocarlie","A Continuous Teleoperation Subspace with Empirical and Algorithmic
  Mapping Algorithms for Non-Anthropomorphic Hands","14 pages, 6 tables, 8 figures, accepted October 2020 IEEE T-ASE",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Teleoperation is a valuable tool for robotic manipulators in highly
unstructured environments. However, finding an intuitive mapping between a
human hand and a non-anthropomorphic robot hand can be difficult, due to the
hands' dissimilar kinematics. In this paper, we seek to create a mapping
between the human hand and a fully actuated, non-anthropomorphic robot hand
that is intuitive enough to enable effective real-time teleoperation, even for
novice users. To accomplish this, we propose a low-dimensional teleoperation
subspace which can be used as an intermediary for mapping between hand pose
spaces. We present two different methods to define the teleoperation subspace:
an empirical definition, which requires a person to define hand motions in an
intuitive, hand-specific way, and an algorithmic definition, which is
kinematically independent, and uses objects to define the subspace. We use each
of these definitions to create a teleoperation mapping for different hands. One
of the main contributions of this paper is the validation of both the empirical
and algorithmic mappings with teleoperation experiments controlled by ten
novices and performed on two kinematically distinct hands. The experiments show
that the proposed subspace is relevant to teleoperation, intuitive enough to
enable control by novices, and can generalize to non-anthropomorphic hands with
different kinematics.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:58:26 GMT""},{""version"":""v2"",""created"":""Wed, 1 Apr 2020 19:45:52 GMT""},{""version"":""v3"",""created"":""Fri, 10 Jul 2020 19:36:37 GMT""},{""version"":""v4"",""created"":""Thu, 17 Sep 2020 15:02:15 GMT""},{""version"":""v5"",""created"":""Thu, 29 Oct 2020 03:53:54 GMT""}]","2020-10-30"
"1911.09566","Guangcun Lu","Kun Shi and Guangcun Lu","Combinatorial formulas for some generalized Ekeland-Hofer-Zehnder
  capacities of convex polytopes","18 pages, published version","J. Fixed Point Theory Appl. (2021)23:67","10.1007/s11784-021-00903-y",,"math.SG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by Pazit Haim-Kislev's combinatorial formula for the
Ekeland-Hofer-Zehnder capacities of convex polytopes, we give corresponding
formulas for $\Psi$-Ekeland-Hofer-Zehnder and coisotropic Ekeland-Hofer-Zehnder
capacities of convex polytopes introduced by the second named author and others
recently. Contrary to Pazit Haim-Kislev's subadditivity result for the
Ekeland-Hofer-Zehnder capacities of convex domains, we show that the
coisotropic Hofer-Zehnder capacities satisfy the subadditivity for suitable
hyperplane cuts of two-dimensional convex domains in the reverse direction.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:58:36 GMT""},{""version"":""v2"",""created"":""Tue, 12 Oct 2021 09:04:50 GMT""}]","2021-10-13"
"1911.09647","David Kofler","Lukas Gonon, Philipp Grohs, Arnulf Jentzen, David Kofler, and David
  \v{S}i\v{s}ka","Uniform error estimates for artificial neural network approximations for
  heat equations",,"IMA J. Numer. Anal. (2021), 1-64","10.1093/imanum/drab027",,"math.NA cs.LG cs.NA math.PR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recently, artificial neural networks (ANNs) in conjunction with stochastic
gradient descent optimization methods have been employed to approximately
compute solutions of possibly rather high-dimensional partial differential
equations (PDEs). Very recently, there have also been a number of rigorous
mathematical results in the scientific literature which examine the
approximation capabilities of such deep learning based approximation algorithms
for PDEs. These mathematical results from the scientific literature prove in
part that algorithms based on ANNs are capable of overcoming the curse of
dimensionality in the numerical approximation of high-dimensional PDEs. In
these mathematical results from the scientific literature usually the error
between the solution of the PDE and the approximating ANN is measured in the
$L^p$-sense with respect to some $p \in [1,\infty)$ and some probability
measure. In many applications it is, however, also important to control the
error in a uniform $L^\infty$-sense. The key contribution of the main result of
this article is to develop the techniques to obtain error estimates between
solutions of PDEs and approximating ANNs in the uniform $L^\infty$-sense. In
particular, we prove that the number of parameters of an ANN to uniformly
approximate the classical solution of the heat equation in a region $ [a,b]^d $
for a fixed time point $ T \in (0,\infty) $ grows at most polynomially in the
dimension $ d \in \mathbb{N} $ and the reciprocal of the approximation
precision $ \varepsilon > 0 $. This shows that ANNs can overcome the curse of
dimensionality in the numerical approximation of the heat equation when the
error is measured in the uniform $L^\infty$-norm.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:29:17 GMT""},{""version"":""v2"",""created"":""Mon, 17 Feb 2020 08:00:25 GMT""},{""version"":""v3"",""created"":""Mon, 15 Jun 2020 05:53:30 GMT""}]","2021-10-12"
"1911.09679","Santiago Benavides Mr.","Santiago J. Benavides, Glenn R. Flierl","Two-dimensional partially ionized magnetohydrodynamic turbulence","Updated manuscript (v2) published in JFM. 22 pages, 6 figures",,"10.1017/jfm.2020.500",,"physics.flu-dyn astro-ph.EP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ionization occurs in the upper atmospheres of hot Jupiters and in the
interiors of Gas Giant Planets, leading to magnetohydrodynamic (MHD) effects
which couple the momentum and the magnetic field, thereby significantly
altering the dynamics. In regions of moderate temperatures the gas is only
partially ionized, which also leads to interactions with neutral molecules. To
explore the turbulent dynamics of these regions we utilize Partially-Ionized
MHD (PIMHD), a two-fluid model -- one neutral and one ionized -- coupled by a
collision term proportional to the difference in velocities. Motivated by
planetary settings where rotation constrains the large-scale motions to be
mostly two-dimensional, we perform a suite of simulations to examine the
parameter space of 2D PIMHD turbulence and pay particular attention to
collisions and their role in the dynamics, dissipation, and energy exchange
between the two species. We arrive at, and numerically confirm, an expression
for the energy loss due to collisions in both the weakly and strongly
collisional limits, and show that, in the latter limit, the neutral fluid
couples to the ions and behaves as an MHD fluid. Finally, we discuss some
implications of our findings to current understanding of gas giant planet
atmospheres.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:51 GMT""},{""version"":""v2"",""created"":""Tue, 11 Aug 2020 15:57:26 GMT""}]","2020-08-12"
"1911.09680","Chandanie Navaratna","Richard A. Lockhart and Chandanie W. Navaratna","On comparison of estimators for proportional error nonlinear regression
  models in the limit of small measurement error","15 pages",,,,"math.ST stat.TH","http://creativecommons.org/licenses/by/4.0/","  In this paper, we compare maximum likelihood (ML), quasi likelihood (QL) and
weighted least squares (WLS) estimators for proportional error nonlinear
regression models. Literature on thermoluminescence sedimentary dating revealed
another estimator similar to weighted least squares but observed responses used
as weights. This estimator that we refer to as data weighted least squares
(DWLS) is also included in the comparison. We show that on the order $\sigma, $
all four estimators behave similar to ordinary least squares estimators for
standard linear regression models. On the order of $\sigma^2, $ the estimators
have biases. Formulae that are valid in the limit of small measurement error
are derived for the biases and the variances of the four estimators. The
maximum likelihood estimator has less bias compared to the quasi likelihood
estimator. Conditions are derived under which weighted least squares and
maximum likelihood estimators have similar biases. On the order of $\sigma^ {2}
$, all estimators have similar standard errors. On higher order of $\sigma$,
maximum likelihood estimator has smaller variance compared to quasi likelihood
estimator, provided that the random errors have the same first four moments as
the normal distribution. The maximum likelihood and quasi-likelihood estimating
equations are unbiased. In large samples, these two estimators are distributed
as multivariate normal. The estimating equations for weighted least squares and
data weighted least squares are biased. However, in the limit of $\sigma \to 0$
and $n \to \infty, $ if $ n^ {1/2} \sigma$ remains bounded, these two
estimators are also distributed as multivariate normal. A simulation study
justified the applicability of the derived formulae in the presence of
measurement errors typical in sedimentary data. Results are illustrated with a
data set from thermoluminescence sedimentary dating.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 01:43:44 GMT""}]","2019-11-25"
"1911.09681","Jean-Paul Tsasa K","Matata Ponyo Mapon and Jean-Paul K. Tsasa","The artefact of the Natural Resources Curse","in French",,,,"econ.GN q-fin.EC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper reexamines the validity of the natural resource curse hypothesis,
using the database of mineral exporting countries. Our findings are as follows:
(i) Resource-rich countries (RRCs) do not necessarily exhibit poor political,
economic and social performance; (ii) RRCs that perform poorly have a low
diversified exports portfolio; (iii) In contrast, RRCs with a low diversified
exports portfolio do not necessarily perform poorly. Then, we develop a model
of strategic interaction from a Bayesian game setup to study the role of
leadership and governance in the management of natural resources. We show that
an improvement in the leadership-governance binomial helps to discipline the
behavior of lobby groups (theorem 1) and generate a Pareto improvement in the
management of natural resources (theorem 2). Evidence from the World Bank
Group's CPIA data confirms the later finding. Our results remain valid after
some robustness checks.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 05:36:57 GMT""}]","2019-11-25"
"1911.09682","Artur Garcia-Saez","Artur Garcia-Saez and Jordi Riu","Quantum Observables for continuous control of the Quantum Approximate
  Optimization Algorithm via Reinforcement Learning","6 pages, 4 figures",,,,"quant-ph cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a classical control mechanism for Quantum devices using
Reinforcement Learning. Our strategy is applied to the Quantum Approximate
Optimization Algorithm (QAOA) in order to optimize an objective function that
encodes a solution to a hard combinatorial problem. This method provides
optimal control of the Quantum device following a reformulation of QAOA as an
environment where an autonomous classical agent interacts and performs actions
to achieve higher rewards. This formulation allows a hybrid classical-Quantum
device to train itself from previous executions using a continuous formulation
of deep Q-learning to control the continuous degrees of freedom of QAOA. Our
approach makes a selective use of Quantum measurements to complete the
observations of the Quantum state available to the agent. We run tests of this
approach on MAXCUT instances of size up to N = 21 obtaining optimal results. We
show how this formulation can be used to transfer the knowledge from shorter
training episodes to reach a regime of longer executions where QAOA delivers
higher results.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:45:52 GMT""}]","2019-11-25"
"1911.09683","Benoit Lavraud","E. Sanchez-Diaz (IRAP), A. Rouillard, B. Lavraud (IRAP), E. Kilpua
  (FMI), J. Davies","In situ measurements of the variable slow solar wind near sector
  boundaries",,"The Astrophysical Journal, American Astronomical Society, 2019","10.3847/1538-4357/ab341c",,"astro-ph.SR astro-ph.EP physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The release of density structures at the tip of the coronal helmet streamers,
likely as a consequence of magnetic reconnection, contributes to the mass flux
of the slow solar wind. In situ measurements in the vicinity of the
heliospheric plasma sheet of the magnetic field, protons and suprathermal
electrons reveal details of the processes at play during the formation of
density structures near the Sun. In a previous article, we exploited
remote-sensing observations to derive a 3-D picture of the dynamic evolution of
a streamer. We found evidence of the recurrent and continual release of dense
blobs from the tip of the streamers. In the present paper, we interpret in situ
measurements of the slow solar wind during solar maximum. Through both case and
statistical analysis, we show that in situ signatures (magnetic field
magnitude, smoothness and rotation, proton density and suprathermal electrons,
in the first place) are consistent with the helmet streamers producing, in
alternation, high-density regions (mostly disconnected) separated by magnetic
flux ropes (mostly connected to the Sun). This sequence of emission of dense
blobs and flux ropes also seems repeated at smaller scales inside each of the
high-density regions. These properties are further confirmed with in situ
measurements much closer to the Sun using Helios observations. We conclude on a
model for the formation of dense blobs and flux ropes that explains both the in
situ measurements and the remote-sensing observations presented in our previous
studies.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:57:12 GMT""}]","2020-01-08"
"1911.10040","Arindam Mishra","Arnob Ray, Arindam Mishra, Dibakar Ghosh, Tomasz Kapitaniak, Syamal K.
  Dana and Chittaranjan Hens","Extreme events in a network of heterogeneous Josephson junctions",,"Phys. Rev. E 101, 032209 (2020)","10.1103/PhysRevE.101.032209",,"nlin.AO nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report rare and recurrent large spiking events in a heterogeneous network
of superconducting Josephson junctions (JJ) connected through a resistive load
and driven by a radio-frequency (rf) current in addition to a constant bias.
The intermittent large spiking events show characteristic features of extreme
events (EE) since they are larger than a statistically defined significant
height. Under the influence of repulsive interactions and an impact of
heterogeneity of damping parameters, the network splits into three sub-groups
of junctions, one in incoherent rotational, another in coherent librational
motion and a third sub-group originating EE. We are able to scan the whole
population of junctions with their distinctive individual dynamical features
either in EE mode or non-EE mode in parameter space. EE migrates spatially from
one to another sub-group of junctions depending upon the repulsive strength and
the damping parameter. For a weak repulsive coupling, all the junctions
originate frequent large spiking events, in rotational motion when the average
inter-spike-interval (ISI) is small, but it increases exponentially with
repulsive interaction; it largely deviates from its exponential growth at a
break point where EE triggers in a sub-group of junctions. The probability
density of inter-event-intervals (IEI) in the subgroup exhibits a Poisson
distribution. EE originates via bubbling instability of in-phase
synchronization.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 21:09:26 GMT""}]","2020-03-18"
"1911.10260","Truong Tran","Truong X. Tran and Xuan N. Nguyen","Jackiw-Rebbi states and trivial states in interfaced binary waveguide
  arrays with cubic-quintic nonlinearity","arXiv admin note: text overlap with arXiv:1909.03222",,"10.1063/5.0004073",,"physics.optics physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We systematically investigate two types of localized states - one is the
optical analogue of the quantum relativistic Jackiw-Rebbi states, and the other
is the trivial localized state - in interfaced binary waveguide arrays in the
presence of cubic-quintic nonlinearity. By using the shooting method we can
exactly calculate the profiles of these nonlinear localized states. Like in the
case with Kerr nonlinearity, we demonstrate that these nonlinear localized
states in the case with cubic-quintic nonlinearity also have a distinguishing
feature which is completely different from all other well-known nonlinear
localized structures in other media. Namely, the profiles of nonlinear
localized states with higher peak amplitudes in interfaced binary waveguide
arrays can totally envelope those with lower peak amplitudes. We show that high
values of the saturation nonlinearity parameter can help to generate and
stabilize these intense localized states during propagation, especially in the
case with negative coefficient for the cubic nonlinearity term.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 10:59:58 GMT""}]","2020-07-15"
"1911.10261","Tian-You Fan","Tian-You Fan and Zhi-Yi Tang","Study on stability of the first kind of soft-matter quasicrystals","arXiv admin note: text overlap with arXiv:1909.00312",,,,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on extended free energy of soft-matter quasicrystals and the variation
principle on thermodynamic stability, this study reports the results on
stability of the first kind of soft-matter quasicrystals. They are dependent
only upon the material constants, and quite simple and intuitive, the material
constants can be measured by experiments. The results are significant in
studying thermodynamics of the matter.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:36:07 GMT""}]","2019-11-26"
"1911.10266","Guido Cantelmo Dr","Guido Cantelmo, Kucharski Rafal, Constantinos Antoniou","A low dimensional model for bike sharing demand forecasting","2019 IEEE. Personal use of this material is permitted. Permission
  from IEEE must be obtained for all other uses, in any current or future
  media, including reprinting/republishing this material for advertising or
  promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works","2019 6th International Conference on Models and Technologies for
  Intelligent Transportation Systems (MT-ITS) - IEEE Explore Proceedings","10.1109/MTITS.2019.8883283",,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Big, transport-related datasets are nowadays publicly available, which makes
data-driven mobility analysis possible. Trips with their origins, destinations
and travel times are collected in publicly available big databases, which
allows for a deeper and richer understanding of mobility patterns. This paper
proposes a low dimensional approach to combine these data sources with weather
data in order to forecast the daily demand for Bike Sharing Systems (BSS). The
core of this approach lies in the proposed clustering technique, which reduces
the dimension of the problem and, differently from other machine learning
techniques, requires limited assumptions on the model or its parameters. The
proposed clustering technique synthesizes mobility data quantitatively (number
of trips) and spatially (mean trip origin and destination). This allows
identifying recursive mobility patterns that - when combined with weather data
- provide accurate predictions of the demand. The method is tested with
real-world data from New York City. We synthesize more than four million trips
into vectors of movement, which are then combined with weather data to forecast
the daily demand at a city-level. Results show that, already with a
one-parameters model, the proposed approach provides accurate predictions.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 16:14:52 GMT""}]","2019-11-26"
"1911.10571","Paulin Jacquot Dr","Paulin Jacquot (TROPICAL), Cheng Wan (EDF R&D OSIRIS), Olivier Beaude
  (EDF R&D OSIRIS), Nadia Oudjane (EDF R&D OSIRIS)","Efficient Estimation of Equilibria in Large Aggregative Games with
  Coupling Constraints","arXiv admin note: substantial text overlap with arXiv:1810.01436",,,,"cs.GT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Aggregative games have many industrial applications, and computing an
equilibrium in those games is challenging when the number of players is large.
In the framework of atomic aggregative games with coupling constraints, we show
that variational Nash equilibria of a large aggregative game can be
approximated by a Wardrop equilibrium of an auxiliary population game of
smaller dimension. Each population of this auxiliary game corresponds to a
group of atomic players of the initial large game. This approach enables an
efficient computation of an approximated equilibrium, as the variational
inequality characterizing the Wardrop equilibrium is of smaller dimension than
the initial one. This is illustrated on an example in the smart grid context.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 08:49:14 GMT""},{""version"":""v2"",""created"":""Thu, 26 Mar 2020 16:24:38 GMT""}]","2020-03-27"
"1911.10892","Chaitra","Chaitra, Sara Bertocco, Marco Molinaro, Sergio Molinari, Antonio
  Ragagnin, and Giuliano Taffoni","Exposing SED Models And Snapshots Via VO Simulation Artefacts","4 pages, 2 figures The 29th annual international Astronomical Data
  Analysis Software & Systems ( ADASS) conference held at Groningen from
  October 6-10, 2019 This is a proceedings submission",,,,"cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Virtual Observatory (VO) simulation standards, Simulation Data Model
(SimDM) and Simulation Data Access Layer (SimDAL), establish a framework for
the discoverability and dissemination of data created in simulation projects.
These standards address the complexity of having a standard access and facade
for data which is expected to be multifaceted and, of a diverse range. In this
paper, we detail the realisation of an application exposing the theoretical
products of one such scientific project via the simulation facades proposed by
the VO. The scientific project in question, is a study of the evolution of
young clusters in dense molecular clumps. The theoretical products arising from
this study include a grid of 20 million SED (Spectral Energy Distribution)
models for synthetic young clusters and related data products. Details on the
implementation of SimDAL components in the application as well as the ways in
which the data structures of SimDM are incorporated onto the existing data
products are provided.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 09:39:45 GMT""}]","2019-11-26"
"1911.10899","Godwill Mbiti Kanyolo PhD","Godwill Mbiti Kanyolo and Hiroshi Shimada","Rescaling of Applied Oscillating Voltages in Small Josephson Junctions","24 pages, 7 figures, 2 tables","J. Phys. Commun. 4 (2020) 105007","10.1088/2399-6528/abbba5",,"cond-mat.mes-hall cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The standard theory of dynamical Coulomb blockade [$P(E)$ theory] in
ultra-small tunnel junctions has been formulated on the basis of phase-phase
correlations by several authors. It was recently extended by several
experimental and theoretical works to account for novel features such as
electromagnetic environment-based renormalization effects. Despite this
progress, aspects of the theory remain elusive especially in the case of linear
arrays. Here, we apply path integral formalism to re-derive the Cooper-pair
current and the BCS quasi-particle current in single small Josephson junctions
and extend it to include long Josephson junction arrays as effective single
junctions. We consider renormalization effects of applied oscillating voltages
due to the impedance environment of a single junction as well as its
implication to the array. As is the case in the single junction, we find that
the amplitude of applied oscillating electromagnetic fields is renormalized by
the same complex-valued weight $\Xi(\omega) = |\Xi(\omega)|\exp i\eta(\omega)$
that rescales the environmental impedance in the $P(E)$ function. This weight
acts as a linear response function for applied oscillating electromagnetic
fields driving the quantum circuit, leading to a mass gap in the thermal
spectrum of the electromagnetic field. The mass gap can be modeled as a pair of
exotic `particle' excitation with quantum statistics determined by the argument
$\eta(\omega)$. In the case of the array, this pair corresponds to a bosonic
charge soliton/anti-soliton pair injected into the array by the electromagnetic
field. Possible application of these results is in dynamical Coulomb blockade
experiments where long arrays are used as electromagnetic power detectors.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 14:30:37 GMT""},{""version"":""v2"",""created"":""Sat, 14 Mar 2020 02:34:33 GMT""},{""version"":""v3"",""created"":""Sun, 20 Sep 2020 19:31:45 GMT""},{""version"":""v4"",""created"":""Sat, 19 Dec 2020 12:03:49 GMT""}]","2020-12-22"
"1911.10903","Marek Czachor","Marek Czachor","Non-Newtonian mathematics instead of non-Newtonian physics: Dark matter
  and dark energy from a mismatch of arithmetics","in v2 an arithmetic that exactly reconstructs the observable
  acceleration of the Universe is derived","Found. Sci. 26, 75-95 (2021)","10.1007/s10699-020-09687-9",,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Newtonian physics is based on Newtonian calculus applied to Newtonian
dynamics. New paradigms such as MOND change the dynamics, but do not alter the
calculus. Calculus is dependent on arithmetic, e.g. in special relativity we
add and subtract velocities by means of addition $\beta_1\oplus
\beta_2=\tanh\big(\tanh^{-1}(\beta_1)+\tanh^{-1}(\beta_2)\big)$, although
multiplication $\beta_1\odot
\beta_2=\tanh\big(\tanh^{-1}(\beta_1)\cdot\tanh^{-1}(\beta_2)\big)$ does not
seem to appear in the literature. The map
$f_\mathbb{X}(\beta)=\tanh^{-1}(\beta)$ defines an isomorphism of the
arithmetic in $\mathbb{X}=(-1,1)$ with the standard one in $\mathbb{R}$. The
new arithmetic is non-Diophantine in the sense of Burgin. Velocity of light
plays a role of non-Diophantine infinity. The new arithmetic allows us to
define the corresponding derivative and integral, and thus a new calculus which
is non-Newtonian in the sense of Grossman and Katz. Treating he above example
as a paradigm, we ask what can be said about the set $\mathbb{X}$ and the
isomorphism $f_{\mathbb{X}}:\mathbb{X}\to \mathbb{R}$, if we assume the
standard form of Newtonian mechanics and general relativity (formulated by
means of the new calculus) but demand agreement with astrophysical
observations. It turns out that for $f_\mathbb{X}(t/t_H)\approx 0.8\sinh
(t-t_1)/(0.8\, t_H)$ the resulting non-Newtonian Friedman equation with
$\Omega_\Lambda=0$ is exactly quivalent to the standard Newtonian one with
$\Omega_\Lambda=0.7$, $\Omega_M=0.3$. Asymptotically flat rotation curves are
obtained if `zero', the neutral element of addition, is nonzero from the point
of view of the standard arithmetic of $\mathbb{R}$. We do not yet know if the
proposed generalization ultimately removes any need of dark matter, but it will
certainly change estimates of its parameters.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:42:43 GMT""},{""version"":""v2"",""created"":""Mon, 2 Dec 2019 13:43:21 GMT""},{""version"":""v3"",""created"":""Thu, 26 Dec 2019 07:58:29 GMT""}]","2021-08-10"
"1911.10942","Dragan Hajdukovic","Dragan Hajdukovic","Antimatter gravity and the Universe",,"Modern Physics Letters A, 2030001 (2019)","10.1142/S0217732320300013",,"physics.gen-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The aim of this brief review is twofold. First, we give an overview of the
unprecedented experimental efforts to measure the gravitational acceleration of
antimatter; with antihydrogen in three competing experiments at CERN (AEGIS,
ALPHA and GBAR, and with muonium and positronium in other laboratories in the
world. Second, we present the 21st Century's attempts to develop a new model of
the Universe with the assumed gravitational repulsion between matter and
antimatter; so far, three radically different and incompatible theoretical
paradigms have been proposed. Two of these 3 models, Dirac-Milne Cosmology
(that incorporates CPT violation) and the Lattice Universe (based on CPT
symmetry) assume a symmetric Universe composed of equal amounts of matter and
antimatter, with antimatter somehow ""hidden"" in cosmic voids; this hypothesis
produced encouraging preliminary results. The hearth of the third model is the
hypothesis that quantum vacuum fluctuations are virtual gravitational dipoles;
for the first time, this hypothesis makes possible and inevitable to include
the quantum vacuum as a source of gravity. Standard Model matter is considered
as the only content of the Universe, while phenomena usually attributed to dark
matter and dark energy are explained as the local and global effects of the
gravitational polarization of the quantum vacuum by the immersed baryonic
matter. An additional feature is that we might live in a cyclic Universe
alternatively dominated by matter and antimatter. In about three years, we will
know if there is gravitational repulsion between matter and antimatter; a
discovery that can forever change our understanding of the Universe.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:28:10 GMT""}]","2019-11-26"
"1911.10944","Issam Lakkis","Ramy Tanios, Samah El Mohtar, Omar Knio, Issam Lakkis","Green's function of the screened Poisson's equation on the sphere",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In geophysical fluid dynamics, the screened Poisson equation appears in the
shallow-water, quasi geostrophic equations. Recently, many attempts have been
made to solve those equations on the sphere using different numerical methods.
These include vortex methods, which solve a Poisson equation to compute the
stream-function from the (relative) vorticity. Alternatively, the
stream-function can be computed directly from potential vorticity (PV), which
would offer the possibility of constructing more attractive vortex methods
because PV is conserved along material trajectories in the inviscid case. On
the spherical shell, however, the screened Poisson equation does not admit a
known Green's function, which limits the extension of such approaches to the
case of a sphere. In this paper, we derive an expression of Green's function
for the screened Poisson equation on the spherical shell in series form and in
integral form. A proof of convergence of the series representation is then
given. As the series is slowly convergent, a robust and efficient approximation
is obtained using a split form which isolates the singular behavior. The
solutions are illustrated and analyzed for different values of the screening
constant.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 13:14:06 GMT""}]","2019-11-26"
"1911.10966","Matteo Parsani","Diego Rojas, Radouan Boukharfane, Lisandro Dalcin, David C. Del Rey
  Fernandez, Hendrik Ranocha, David E. Keyes and Matteo Parsani","On the robustness and performance of entropy stable discontinuous
  collocation methods for the compressible Navier-Stokes equations","39 pages. arXiv admin note: substantial text overlap with
  arXiv:1911.03682 and text overlap with arXiv:1905.03007 by other authors","Journal of Computational Physics, 2020","10.1016/j.jcp.2020.109891",,"math.NA cs.NA physics.flu-dyn","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In computational fluid dynamics, the demand for increasingly
multidisciplinary reliable simulations, for both analysis and design
optimization purposes, requires transformational advances in individual
components of future solvers. At the algorithmic level, hardware compatibility
and efficiency are of paramount importance in determining viability at exascale
and beyond. However, equally important (if not more so) is algorithmic
robustness with minimal user intervention, which becomes progressively more
challenging to achieve as problem size and physics complexity increase. We
numerically show that low and high order entropy stable discontinuous spatial
discretizations based on summation-by-part operators and
simultaneous-approximation-terms technique provides an essential step toward a
truly enabling technology in terms of reliability and robustness for both
under-resolved turbulent flow simulations and flows with discontinuities.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:12:30 GMT""},{""version"":""v2"",""created"":""Wed, 27 Nov 2019 15:11:55 GMT""},{""version"":""v3"",""created"":""Wed, 11 Dec 2019 14:03:58 GMT""}]","2020-11-26"
"1911.11621","Angelo Carollo","Angelo Carollo, Bernardo Spagnolo, Alexander A. Dubkov, and Davide
  Valenti","On quantumness in multi-parameter quantum estimation","21 pages, 2 Figures. arXiv admin note: text overlap with
  arXiv:1911.10196","J. Stat. Mech. Theory Exp. 2019, 094010 (2019)","10.1088/1742-5468/ab3ccb",,"quant-ph cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we derive a measure of quantumness in quantum multi-parameter
estimation problems. We can show that the ratio between the mean Uhlmann
Curvature and the Fisher Information provides a figure of merit which estimates
the amount of incompatibility arising from the quantum nature of the underlying
physical system. This ratio accounts for the discrepancy between the attainable
precision in the simultaneous estimation of multiple parameters and the
precision predicted by the Cram\'er-Rao bound. As a testbed for this concept,
we consider a quantum many-body system in thermal equilibrium, and explore the
quantum compatibility of the model across its phase diagram.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:00:00 GMT""},{""version"":""v2"",""created"":""Fri, 27 Dec 2019 19:02:25 GMT""}]","2020-01-01"
"1911.11855","Badong Chen","Badong Chen, Yuqing Xie, Zhuang Li, Yingsong Li, Pengju Ren","Asymmetric Correntropy for Robust Adaptive Filtering",,,,,"eess.SP cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, correntropy has been seccessfully applied to robust adaptive
filtering to eliminate adverse effects of impulsive noises or outliers.
Correntropy is generally defined as the expectation of a Gaussian kernel
between two random variables. This definition is reasonable when the error
between the two random variables is symmetrically distributed around zero. For
the case of asymmetric error distribution, the symmetric Gaussian kernel is
however inappropriate and cannot adapt to the error distribution well. To
address this problem, in this brief we propose a new variant of correntropy,
named asymmetric correntropy, which uses an asymmetric Gaussian model as the
kernel function. In addition, a robust adaptive filtering algorithm based on
asymmetric correntropy is developed and its steady-state convergence
performance is analyzed. Simulations are provided to confirm the theoretical
results and good performance of the proposed algorithm.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:02:40 GMT""},{""version"":""v2"",""created"":""Mon, 1 Nov 2021 08:50:40 GMT""}]","2021-11-02"
"1912.01708","Bruce Knuteson","Bruce Knuteson","Celebrating Three Decades of Worldwide Stock Market Manipulation","8 pages",,,,"q-fin.GN econ.GN q-fin.EC q-fin.TR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  As the decade turns, we reflect on nearly thirty years of successful
manipulation of the world's public equity markets. This reflection highlights a
few of the key enabling ingredients and lessons learned along the way. A
quantitative understanding of market impact and its decay, which we cover
briefly, lets you move long-term market prices to your advantage at acceptable
cost. Hiding your footprints turns out to be less important than moving prices
in the direction most people want them to move. Widespread (if misplaced) trust
of market prices -- buttressed by overestimates of the cost of manipulation and
underestimates of the benefits to certain market participants -- makes price
manipulation a particularly valuable and profitable tool. Of the many recent
stories heralding the dawn of the present golden age of misinformation, the
manipulation leading to the remarkable increase in the market capitalization of
the world's publicly traded companies over the past three decades is among the
best.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 23:32:59 GMT""}]","2019-12-05"
"1912.01709","Abhishek Kesarwani","Abhishek Kesarwani and Pabitra Mohan Khilar","Development of trust based access control models using fuzzy logic in
  cloud computing",,,"10.1016/j.jksuci.2019.11.001",,"cs.CR","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Cloud computing is the technology that provides different types of services
as a useful resource on the Internet. Resource trust value will help the cloud
users to select the services of a cloud provider for processing and storing
their essential information. Also, service providers can give access to users
based on trust value to secure cloud resources from malicious users. In this
paper, trust models are proposed, which comes under the subjective trust model
based on the behavior of user and service provider to calculate the trust
values. The trust is fuzzy, which motivated us to apply fuzzy logic for
calculating the trust values of the cloud users and service providers in the
cloud environment. We use a Mamdani fuzzy method with gauss membership function
for fuzzification and triangular membership function for defuzzification.
Parameters such as performance and elasticity are taken for trust evaluation of
the resource. The attributes for calculating performance are workload and
response time. And for calculating elasticity, we have taken scalability,
availability, security, and usability. The fuzzy C-means clustering is applied
to parameters for evaluating the trust value of users such as bad requests,
bogus requests, unauthorized requests, and total requests.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:10:53 GMT""}]","2019-12-05"
"1912.02743","Azim Ahmadzadeh","Azim Ahmadzadeh, Sushant S. Mahajan, Dustin J. Kempton, Rafal A.
  Angryk, and Shihao Ji","Toward Filament Segmentation Using Deep Neural Networks","10 pages, 10 figures, 1 table, accepted in IEEE BigData 2019",,,,"astro-ph.SR cs.CV cs.LG","http://creativecommons.org/licenses/by/4.0/","  We use a well-known deep neural network framework, called Mask R-CNN, for
identification of solar filaments in full-disk H-alpha images from Big Bear
Solar Observatory (BBSO). The image data, collected from BBSO's archive, are
integrated with the spatiotemporal metadata of filaments retrieved from the
Heliophysics Events Knowledgebase (HEK) system. This integrated data is then
treated as the ground-truth in the training process of the model. The available
spatial metadata are the output of a currently running filament-detection
module developed and maintained by the Feature Finding Team; an international
consortium selected by NASA. Despite the known challenges in the identification
and characterization of filaments by the existing module, which in turn are
inherited into any other module that intends to learn from such outputs, Mask
R-CNN shows promising results. Trained and validated on two years worth of BBSO
data, this model is then tested on the three following years. Our case-by-case
and overall analyses show that Mask R-CNN can clearly compete with the existing
module and in some cases even perform better. Several cases of false positives
and false negatives, that are correctly segmented by this model are also shown.
The overall advantages of using the proposed model are two-fold: First, deep
neural networks' performance generally improves as more annotated data, or
better annotations are provided. Second, such a model can be scaled up to
detect other solar events, as well as a single multi-purpose module. The
results presented in this study introduce a proof of concept in benefits of
employing deep neural networks for detection of solar events, and in
particular, filaments.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 17:45:41 GMT""}]","2019-12-06"
"1912.04823","Ata Ak{\i}n","Ipek Ustun, Ege Ozer, Erim Habib, Burcin Tatliesme, Ata Akin","Vigilance Overload Measured by Computerized Mackworth Clock Test","4 pages, 4 figures",,,,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper studied the change of vigilance based on stimulus coming
consecutively using the computerized version of the Mackworth Clock Test run
from PsyToolkit website. 7 participants (16.57 +/-1 years old, 2 males),
performed 10 consecutive trials in order to measure whether or not it is a
realistic goal for high school students to display the level of vigilance
expected from them in class. Success percentages were calculated by dividing
the number of correct jumps to the total number of jumps. The results indicated
that while the average success percentage for all subjects remained relatively
stable over the 10 trials (79% +/-7%), success percentages drop relatively as
the number of jumps increase. Success rate dropped from 90% (2 jumps) to 70% (7
jumps). We conclude that there is an upper limit of vigilance that should be
expected from students when they are exposed to more than 4 randomly occurring
attention requiring task within a minute.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 12:33:25 GMT""}]","2019-12-11"
"1912.05006","Zhenyu Weng","Zhenyu Weng, Yuesheng Zhu","Efficient Querying from Weighted Binary Codes","13 pages, accepted by AAAI2020",,,,"cs.CV cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Binary codes are widely used to represent the data due to their small storage
and efficient computation. However, there exists an ambiguity problem that lots
of binary codes share the same Hamming distance to a query. To alleviate the
ambiguity problem, weighted binary codes assign different weights to each bit
of binary codes and compare the binary codes by the weighted Hamming distance.
Till now, performing the querying from the weighted binary codes efficiently is
still an open issue. In this paper, we propose a new method to rank the
weighted binary codes and return the nearest weighted binary codes of the query
efficiently. In our method, based on the multi-index hash tables, two
algorithms, the table bucket finding algorithm and the table merging algorithm,
are proposed to select the nearest weighted binary codes of the query in a
non-exhaustive and accurate way. The proposed algorithms are justified by
proving their theoretic properties. The experiments on three large-scale
datasets validate both the search efficiency and the search accuracy of our
method. Especially for the number of weighted binary codes up to one billion,
our method shows a great improvement of more than 1000 times faster than the
linear scan.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:48:29 GMT""},{""version"":""v2"",""created"":""Thu, 11 Jun 2020 02:41:13 GMT""}]","2020-06-12"
"1912.05295","Priyank Pathak","Priyank Pathak, Amir Erfan Eshratifar, Michael Gormish","Video Person Re-ID: Fantastic Techniques and Where to Find Them","2 Page (Student Abstract) accepted in AAAI-20",,,"AAAI-20 SA-572","cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to identify the same person from multiple camera views without
the explicit use of facial recognition is receiving commercial and academic
interest. The current status-quo solutions are based on attention neural
models. In this paper, we propose Attention and CL loss, which is a hybrid of
center and Online Soft Mining (OSM) loss added to the attention loss on top of
a temporal attention-based neural network. The proposed loss function applied
with bag-of-tricks for training surpasses the state of the art on the common
person Re-ID datasets, MARS and PRID 2011. Our source code is publicly
available on github.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 03:52:41 GMT""}]","2019-12-18"
"1912.05471","Svitlana Alkhimova","Svitlana Alkhimova","Impact of perfusion ROI detection to the quality of CBV perfusion map",,"Technology Audit and Production Reserves. - 2019. - V. 5, N. 2
  (49). - P.4-7","10.15587/2312-8372.2019.182789",,"physics.med-ph cs.CV eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The object of research in this study is quality of CBV perfusion map,
considering detection of perfusion ROI as a key component in processing of
dynamic susceptibility contrast magnetic resonance images of a human head. CBV
map is generally accepted to be the best among others to evaluate location and
size of stroke lesions and angiogenesis of brain tumors. Its poor accuracy can
cause failed results for both quantitative measurements and visual assessment
of cerebral blood volume. The impact of perfusion ROI detection on the quality
of maps was analyzed through comparison of maps produced from threshold and
reference images of the same datasets from 12 patients with cerebrovascular
disease. Brain perfusion ROI was placed to exclude low intensity (air and
non-brain tissues regions) and high intensity (cerebrospinal fluid regions)
pixels. Maps were produced using area under the curve and deconvolution
methods. For both methods compared maps were primarily correlational according
to Pearson correlation analysis: r=0.8752 and r=0.8706 for area under the curve
and deconvolution, respectively, p<2.2*10^-16. In spite of this, for both
methods scatter plots had data points associated with missed blood regions and
regression lines indicated presence of scale and offset errors for maps
produced from threshold images. Obtained results indicate that thresholding is
an ineffective way to detect brain perfusion ROI, which usage can cause
degradation of CBV map quality. Perfusion ROI detection should be standardized
and accepted into validation protocols of new systems for perfusion data
analysis.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:46:43 GMT""}]","2019-12-12"
"1912.05913","Alireza Abdoli","Alireza Abdoli, Amy C. Murillo, Alec C. Gerry, Eamonn J. Keogh","Time Series Classification: Lessons Learned in the (Literal) Field while
  Studying Chicken Behavior","arXiv admin note: text overlap with arXiv:1811.03149",,"10.1109/BigData47090.2019.9005596",,"cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Poultry farms are a major contributor to the human food chain. However,
around the world, there have been growing concerns about the quality of life
for the livestock in poultry farms; and increasingly vocal demands for improved
standards of animal welfare. Recent advances in sensing technologies and
machine learning allow the possibility of monitoring birds, and employing the
lessons learned to improve the welfare for all birds. This task superficially
appears to be easy, yet, studying behavioral patterns involves collecting
enormous amounts of data, justifying the term Big Data. Before the big data can
be used for analytical purposes to tease out meaningful, well-conserved
behavioral patterns, the collected data needs to be pre-processed. The
pre-processing refers to processes for cleansing and preparing data so that it
is in the format ready to be analyzed by downstream algorithms, such as
classification and clustering algorithms. However, as we shall demonstrate,
efficient pre-processing of chicken big data is both non-trivial and crucial
towards success of further analytics.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 06:57:47 GMT""},{""version"":""v2"",""created"":""Fri, 20 Dec 2019 19:48:04 GMT""}]","2020-06-02"
"1912.08791","Firuz Kamalov","Firuz Kamalov","Forecasting significant stock price changes using neural networks",,"Neural Computing and Applications (2020)","10.1007/s00521-020-04942-3",,"q-fin.TR cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Stock price prediction is a rich research topic that has attracted interest
from various areas of science. The recent success of machine learning in speech
and image recognition has prompted researchers to apply these methods to asset
price prediction. The majority of literature has been devoted to predicting
either the actual asset price or the direction of price movement. In this
paper, we study a hitherto little explored question of predicting significant
changes in stock price based on previous changes using machine learning
algorithms. We are particularly interested in the performance of neural network
classifiers in the given context. To this end, we construct and test three
neural network models including multi-layer perceptron, convolutional net, and
long short term memory net. As benchmark models we use random forest and
relative strength index methods. The models are tested using 10-year daily
stock price data of four major US public companies. Test results show that
predicting significant changes in stock price can be accomplished with a high
degree of accuracy. In particular, we obtain substantially better results than
similar studies that forecast the direction of price change.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 11:48:48 GMT""}]","2020-09-22"
"1912.08928","Angelo Salatino","Angelo Antonio Salatino","Early Detection of Research Trends","This dissertation is submitted for the Degree of Doctor of Philosophy",,,,"cs.SI cs.DL cs.IR physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Being able to rapidly recognise new research trends is strategic for many
stakeholders, including universities, institutional funding bodies, academic
publishers and companies. The literature presents several approaches to
identifying the emergence of new research topics, which rely on the assumption
that the topic is already exhibiting a certain degree of popularity and
consistently referred to by a community of researchers. However, detecting the
emergence of a new research area at an embryonic stage, i.e., before the topic
has been consistently labelled by a community of researchers and associated
with a number of publications, is still an open challenge. In this
dissertation, we begin to address this challenge by performing a study of the
dynamics preceding the creation of new topics. This study indicates that the
emergence of a new topic is anticipated by a significant increase in the pace
of collaboration between relevant research areas, which can be seen as the
'ancestors' of the new topic. Based on this understanding, we developed Augur,
a novel approach to effectively detecting the emergence of new research topics.
Augur analyses the diachronic relationships between research areas and is able
to detect clusters of topics that exhibit dynamics correlated with the
emergence of new research topics. Here we also present the Advanced Clique
Percolation Method (ACPM), a new community detection algorithm developed
specifically for supporting this task. Augur was evaluated on a gold standard
of 1,408 debutant topics in the 2000-2011 timeframe and outperformed four
alternative approaches in terms of both precision and recall.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 20:20:20 GMT""}]","2019-12-21"
"1912.09211","Jorge Fandinno","Jorge Fandinno and Johannes Fichte","Proceedings of the twelfth Workshop on Answer Set Programming and Other
  Computing Paradigms 2019",,,,,"cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This is the Proceedings of the twelfth Workshop on Answer Set Programming and
Other Computing Paradigms (ASPOCP) 2019, which was held in Philadelphia, USA,
June 3rd , 2019.
","[{""version"":""v1"",""created"":""Thu, 21 Nov 2019 15:47:40 GMT""}]","2019-12-20"
"1912.09212","Ulrich Jentschura","U. D. Jentschura","Equivalence Principle for Antiparticles and its Limitations","19 pages; LaTeX article style","Int. J. Mod. Phys. A 34 (2019) 1950180","10.1142/S0217751X1950180X",,"physics.gen-ph hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate the particle-antiparticle symmetry of the gravitationally
coupled Dirac equation, both on the basis of the gravitational central-field
problem and in general curved space-time backgrounds. First, we investigate the
central-field problem with the help of a Foldy-Wouthuysen transformation. This
disentangles the particle from the antiparticle solutions, and leads to a
""matching relation"" of the inertial and the gravitational mass, which is valid
for both particles as well as antiparticles. Second, we supplement this
derivation by a general investigation of the behavior of the gravitationally
coupled Dirac equation under the discrete symmetry of charge conjugation, which
is tantamount to a particle -> antiparticle transformation. Limitations of the
Einstein equivalence principle due to quantum fluctuations are discussed. In
quantum mechanics, the question of where and when in the Universe an experiment
is being performed, can only be answered up to the limitations implied by
Heisenberg's Uncertainty Principle, questioning an assumption made in the
original formulation of the Einstein equivalence principle. Furthermore, at
some level of accuracy, it becomes impossible to separate non-gravitational
from gravitational experiments, leading to further limitations.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 18:06:15 GMT""}]","2019-12-20"
"2001.10081","Aramis Rivera","D. Hernandez, L. Quinones, C. Charnay, M. Velazquez and A. Rivera","Stability of a natural palygorskite after a cycle of
  adsorption-desorption of an emerging pollutant","4 pages, 2 figures",,,,"physics.app-ph cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we evaluate the structural stability of a natural Cuban clay
(an adsorbent of organic pollutants) after an adsorption-desorption process.
The clay under study was palygorskite, and sulfamethoxazole was the emerging
contaminant. The materials were characterized by X-ray diffraction, attenuated
total reflection infrared spectroscopy and zeta potential before and after the
sulfamethoxazole adsorption-desorption processes. Based on the material
integrity, the potentiality of Pal as pollutant adsorbent and its possible
reuse in adsorption-desorption cycles was demonstrated.
","[{""version"":""v1"",""created"":""Wed, 20 Nov 2019 19:42:06 GMT""}]","2020-01-29"

"1908.08885","Richard Evans","Daniel Meilak, Sarah Jenkins, Rory Pond, and Richard F. L. Evans","Massively parallel atomistic simulation of ultrafast thermal spin
  dynamics of a permalloy vortex",,,,,"cond-mat.mtrl-sci cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Ultrafast magnetization dynamics probes the most fundamental properties of
magnetic materials, exploring questions about the fundamental interactions
responsible for magnetic phenomena. Thermal effects are known to be extremely
important for laser-induced dynamics in metallic systems, but the dynamics of
topological magnetic structures are little understood. Here we apply a
massively parallel atomistic spin dynamics simulation to study the response of
a permalloy vortex to a 50 fs laser pulse. We find that macroscopically the
short timescale dynamics are indistinguishable from the bulk, but that strong
edge spin waves lead to a complex time evolution of the magnetic structure and
long-lived oscillations on the nanosecond timescale. In the near future such
simulations will provide unprecedented insight into the dynamics of magnetic
materials and devices beyond the approximations of continuum micromagnetics.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:06:55 GMT""}]","2019-08-26"
"1908.08886","Jesse Lansdown","Jesse Lansdown, Alice C. Niemeyer","A family of hemisystems on the parabolic quadrics",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We constuct a family of hemisystems of the parabolic quadric $\mathcal{Q}(2d,
q)$, for all ranks $d \ge 2$ and all odd prime powers $q$, that admit
$\Omega_3(q) \cong \mathrm{PSL}_2(q)$. This yields the first known construction
for $d \ge 4$.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:09:41 GMT""}]","2019-08-26"
"1908.08887","Hisato Komatsu","Hisato Komatsu","A model of magnetic friction obeying the Dieterich--Ruina law in the
  steady state","6 pages, 8 figures; accepted for publication in Phys. Rev. E","Phys. Rev. E 100, 052130 (2019)","10.1103/PhysRevE.100.052130",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a model of magnetic friction and investigate the relation between
the frictional force and the relative velocity of surfaces in the steady state.
The model comprises two square lattices adjacent to each other, the upper of
which is subjected to an external force, and the magnetic interaction acts as a
kind of ""potential barrier"" that prevents the upper lattice from moving. We
consider two surface types for the upper lattice: smooth and rough. The
behavior of this model is classified into two domains, which we refer to as
domains I and II. In domain II, the external force is dominant compared with
other forces, whereas in the domain I, the the velocity of the lattice is
suppressed by the magnetic interaction and obeys the Dieterich--Ruina law. This
characteristic property can be observed regardless of whether the surface is
smooth or rough.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:10:01 GMT""},{""version"":""v2"",""created"":""Fri, 22 Nov 2019 00:28:16 GMT""}]","2019-11-27"
"1908.08888","Joaquim Martin","Joaquim Martin, Walter A. Ortiz","Symmetrization Inequalities for Probability metric spaces with Convex
  Isoperimetric profile",,,,,"math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We obtain symmetrization inequalities on probability metric spaces with
convex isoperimetric profile which incorporate in their formulation the
isoperimetric estimator and that can be applied to provide a unified treatment
of sharp Sobolev-Poincar\'{e} and Nash inequalities.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:14:16 GMT""}]","2019-08-26"
"1908.08889","Roy Radian","Roy Radian and Or Sattath","Semi-Quantum Money","81 pages LaTeX; new discussions and figures",,"10.1145/3318041.3355462",,"quant-ph cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum money allows a bank to mint quantum money states that can later be
verified and cannot be forged. Usually, this requires a quantum communication
infrastructure to transfer quantum states between the user and the bank.
Gavinsky (CCC 2012) introduced the notion of classically verifiable quantum
money, which allows verification through classical communication. In this work
we introduce the notion of classical minting, and combine it with classical
verification to introduce semi-quantum money. Semi-quantum money is the first
type of quantum money to allow transactions with completely classical
communication and an entirely classical bank. This work features constructions
for both a public memory-dependent semi-quantum money scheme and a private
memoryless semi-quantum money scheme. The public construction is based on the
works of Zhandry and Coladangelo, and the private construction is based on the
notion of Noisy Trapdoor Claw Free Functions (NTCF) introduced by Brakerski et
al. (FOCS 2018).
  In terms of technique, our main contribution is a perfect parallel repetition
theorem for NTCF.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:15:11 GMT""},{""version"":""v2"",""created"":""Thu, 12 Sep 2019 18:42:31 GMT""},{""version"":""v3"",""created"":""Thu, 27 Feb 2020 21:14:36 GMT""},{""version"":""v4"",""created"":""Mon, 23 Mar 2020 17:15:23 GMT""},{""version"":""v5"",""created"":""Sun, 12 Apr 2020 16:50:10 GMT""},{""version"":""v6"",""created"":""Tue, 20 Oct 2020 17:32:58 GMT""}]","2020-10-21"
"1908.08890","Pablo de Castro","Pablo de Castro and Peter Sollich","Phase separation of mixtures after a second quench: composition
  heterogeneities","13 pages, 17 figures","Soft Matter, 2019, 15, 9287 - 9299","10.1039/c9sm01706b",,"cond-mat.soft cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate binary mixtures undergoing phase separation after a second
(deeper) temperature quench into two- and three-phase coexistence regions. The
analysis is based on a lattice theory previously developed for gas-liquid
separation in generic mixtures. Our previous results, which considered an
arbitrary number of species and a single quench, showed that, due to slow
changes in composition, dense colloidal mixtures can phase-separate in two
stages. Moreover, the denser phase contains long-lived composition
heterogeneities that originate as the interfaces of shrunk domains. Here we
predict several new effects that arise after a second quench, mostly associated
with the extent to which crowding can slow down 'fractionation', i.e.
equilibration of compositions. They include long-lived regular arrangements of
secondary domains; wetting of fractionated interfaces by oppositely
fractionated layers; 'surface'-directed spinodal 'waves' propagating from
primary interfaces; a 'dead zone' where no phase separation occurs; and, in the
case of three-phase coexistence, filamentous morphologies arising out of
secondary domains.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:17:47 GMT""}]","2019-11-22"
"1908.08891","Timo Hinzmann","Timo Hinzmann, Cesar Cadena, Juan Nieto, and Roland Siegwart","Flexible Trinocular: Non-rigid Multi-Camera-IMU Dense Reconstruction for
  UAV Navigation and Mapping","Preprint of a paper presented at the IEEE International Conference on
  Intelligent Robots and Systems (IROS) 2019",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a visual-inertial framework able to efficiently
estimate the camera poses of a non-rigid trinocular baseline for long-range
depth estimation on-board a fast moving aerial platform. The estimation of the
time-varying baseline is based on relative inertial measurements, a photometric
relative pose optimizer, and a probabilistic wing model fused in an efficient
Extended Kalman Filter (EKF) formulation. The estimated depth measurements can
be integrated into a geo-referenced global map to render a reconstruction of
the environment useful for local replanning algorithms. Based on extensive
real-world experiments we describe the challenges and solutions for obtaining
the probabilistic wing model, reliable relative inertial measurements, and
vision-based relative pose updates and demonstrate the computational efficiency
and robustness of the overall system under challenging conditions.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:20:41 GMT""}]","2019-08-26"
"1908.08892","Md. Tanvir Hossan","Md Tanvir Hossan","Localization using Optical Camera Communication and Photogrammetry for
  Wireless Networking Applications","100 pages, 46 figures, MSc thesis paper",,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Localization defines a term to describe the identifying process of a location
within the space of two-dimensional (2D) space or three-dimensional (3D). A
localization scheme is an important concern for connecting sensor nodes in
remote locations. The demand of localization in wireless networking is
increased due to the availability of mobile devices as well as scope for
billion-dollar market in e-commence sector. Moreover, a new era has written
with internet-of-things, which boost this demand 100 times than ever before.
Importance of localization applications is considered in both indoor and
outdoor environments. Due to several advantages, LED and camera based
positioning is more demanding over radio frequency based localization. Using
the existing light-emitting diodes (LEDs) based illumination infrastructure it
is possible to compute the coordinates of the camera, whereas cameras are
embedded/installed in mobile objects, such as smartphone, vehicle. Optical
camera communication (OCC) and photogrammetry are two important technologies to
measure the position of these mobile objects. These technologies based
localization scheme for both smartphone and vehicle should be cost effective
and can be deployed with little modification of the existing infrastructures. I
proposed two different schemes (i.e., indoor and outdoor environments) to
localize these objects with OCC and photogrammetry techniques.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:21:07 GMT""}]","2019-08-26"
"1908.08893","Paul Rosen","Ghulam Jilani Quadri and Paul Rosen","You Can't Publish Replication Studies (and How to Anyways)",,,,,"cs.HC cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Reproducibility has been increasingly encouraged by communities of science in
order to validate experimental conclusions, and replication studies represent a
significant opportunity to vision scientists wishing contribute new perceptual
models, methods, or insights to the visualization community. Unfortunately, the
notion of replication of previous studies does not lend itself to how we
communicate research findings. Simple put, studies that re-conduct and confirm
earlier results do not hold any novelty, a key element to the modern research
publication system. Nevertheless, savvy researchers have discovered ways to
produce replication studies by embedding them into other sufficiently novel
studies. In this position paper, we define three methods -- re-evaluation,
expansion, and specialization -- for embedding a replication study into a novel
published work. Within this context, we provide a non-exhaustive case study on
replications of Cleveland and McGill's seminal work on graphical perception. As
it turns out, numerous replication studies have been carried out based on that
work, which have both confirmed prior findings and shined new light on our
understanding of human perception. Finally, we discuss how publishing a true
replication study should be avoided, while providing suggestions for how vision
scientists and others can still use replication studies as a vehicle to
producing visualization research publications.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:21:28 GMT""}]","2019-08-26"
"1908.08894","Pablo Roura-Bas Dr.","P. Roura-Bas, F. G\""uller, L. Tosi, and A. A. Aligia","Destructive quantum interference in transport through molecules with
  electron-electron and electron-vibration interactions","11 pages, 7 figures","J. Phys.: Condens. Matter 31 465602 (2019)","10.1088/1361-648X/ab3684",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the transport through a molecular junction exhibiting interference
effects. We show that these effects can still be observed in the presence of
molecular vibrations if Coulomb repulsion is taken into account. In the Kondo
regime, the conductance of the junction can be changed by several orders of
magnitude by tuning the levels of the molecule, or displacing a contact between
two atoms, from nearly perfect destructive interference to values of the order
of 2e 2 /h expected in Kondo systems. We also show that this large conductance
change is robust for reasonable temperatures and voltages for symmetric and
asymmetric tunnel couplings between the source-drain electrodes and the
molecular orbitals. This is relevant for the development of quantum
interference effect transistors based on molecular junctions.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:29:32 GMT""}]","2019-09-04"
"1908.08895","Wassilij Gnedin","Wassilij Gnedin","Calabi-Yau properties of ribbon graph orders","23 pages",,,,"math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We pursue the order-theoretic approach to ribbon graphs initiated by Kauer
and Roggenkamp. We show that any ribbon graph order is twisted $1$-Calabi-Yau
in general and $1$-Calabi-Yau if the ribbon graph is bipartite. We derive
analogous results for anti-commutative versions of Brauer graph algebras.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:32:03 GMT""}]","2019-08-26"
"1908.08896","Zach Teitler","Mats Boij and Zach Teitler","A bound for the Waring rank of the determinant via syzygies","17 pages. v2: clarifications and additional references. To appear in
  Linear Algebra Appl",,,"BCSim-2018-s09","math.AG math.AC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We show that the Waring rank of the $3 \times 3$ determinant, previously
known to be between $14$ and $18$, is at least $15$. We use syzygies of the
apolar ideal, which have not been used in this way before. Additionally, we
show that the cactus rank of the $3 \times 3$ permanent is at least $14$.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:34:07 GMT""},{""version"":""v2"",""created"":""Fri, 8 Nov 2019 17:06:23 GMT""}]","2019-11-11"
"1908.08897","Albrecht Seelmann","Albrecht Seelmann, Matthias T\""aufer, Kre\v{s}imir Veseli\'c","Protecting points from operator pencils","6 pages; a counterexample for sign-indefinite perturbations and some
  references have been added, some editorial changes","J. Operator Theory 85 (2021), 383--389","10.7900/jot.2019aug23.2248",,"math.SP math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify all sets of the form
$\bigcup_{t\in\mathbb{R}}\mathrm{spec}(A+tB)$ where $A$ and $B$ are
self-adjoint operators and $B$ is bounded, non-negative, and non-zero. We show
that these sets are exactly the complements of discrete subsets of
$\mathbb{R}$, that is, of at most countable subsets of $\mathbb{R}$ that
contain none of their accumulation points.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:37:48 GMT""},{""version"":""v2"",""created"":""Mon, 11 May 2020 13:25:36 GMT""}]","2021-06-02"
"1908.08898","Sunwoo Kim","Sunwoo Kim, Mrinmoy Maity, Minje Kim","Incremental Binarization On Recurrent Neural Networks For Single-Channel
  Source Separation","5 pages, 1 figure, 2019 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP 2019)",,"10.1109/ICASSP.2019.8682595",,"eess.AS cs.LG cs.SD eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes a Bitwise Gated Recurrent Unit (BGRU) network for the
single-channel source separation task. Recurrent Neural Networks (RNN) require
several sets of weights within its cells, which significantly increases the
computational cost compared to the fully-connected networks. To mitigate this
increased computation, we focus on the GRU cells and quantize the feedforward
procedure with binarized values and bitwise operations. The BGRU network is
trained in two stages. The real-valued weights are pretrained and transferred
to the bitwise network, which are then incrementally binarized to minimize the
potential loss that can occur from a sudden introduction of quantization. As
the proposed binarization technique turns only a few randomly chosen parameters
into their binary versions, it gives the network training procedure a chance to
gently adapt to the partly quantized version of the network. It eventually
achieves the full binarization by incrementally increasing the amount of
binarization over the iterations. Our experiments show that the proposed BGRU
method produces source separation results greater than that of a real-valued
fully connected network, with 11-12 dB mean Signal-to-Distortion Ratio (SDR). A
fully binarized BGRU still outperforms a Bitwise Neural Network (BNN) by 1-2 dB
even with less number of layers.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:38:02 GMT""}]","2019-08-26"
"1908.08899","Thomas Zentgraf","Qunshuo Wei, Basudeb Sain, Yongtian Wang, Bernhard Reineke, Xiaowei
  Li, Lingling Huang, Thomas Zentgraf","Simultaneous spectral and spatial modulation for color printing and
  holography using all-dielectric metasurfaces",,,"10.1021/acs.nanolett.9b03957",,"physics.app-ph cond-mat.mes-hall physics.optics","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Metasurfaces possess the outstanding ability to tailor phase, amplitude and
even spectral responses of light with an unprecedented ultrahigh resolution,
thus have attracted significant interests. Here, we propose and experimentally
demonstrate a novel meta-device that integrates color printing and
computer-generated holograms within a single-layer dielectric metasurface by
modulating spectral and spatial responses at subwavelength scale,
simultaneously. In our design, such metasurface appears as a microscopic color
image under white light illumination, while encrypting two different
holographic images that can be projected at the far-field when illuminated with
red and green laser beams. We choose amorphous silicon dimers and nanofins as
building components and use a modified parallel Gerchberg-Saxton algorithm to
obtain multiple sub-holograms with arbitrary spatial shapes for image-indexed
arrangements. Such a method can further extend the design freedom of
metasurfaces. By exploiting spectral and spatial control at the level of
individual pixels, multiple sets of independent information can be introduced
into a single-layer device, the additional complexity and enlarged information
capacity are promising for novel applications such as information security and
anti-counterfeiting.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:46:04 GMT""}]","2020-01-08"
"1908.08900","Grzegorz Cisek","Grzegorz Cisek and Tomasz P. Zieli\'nski","Frequency-Domain Modeling of OFDM Transmission with Insufficient Cyclic
  Prefix using Toeplitz Matrices","Conference: IEEE VTC-Fall 2018, 5 pages, 3 figures","In proc. IEEE 88th Vehicular Technology Conference (VTC-Fall),
  Chicago, USA, 27-30 August 2018","10.1109/VTCFall.2018.8690835",,"eess.SP cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A novel mathematical framework is proposed to model Intersymbol Interference
(ISI) phenomenon in wireless communication systems based on Orthogonal
Frequency Division Multiplexing (OFDM) with or without cyclic prefix. The
framework is based on a new formula to calculate the Fast Fourier Transform
(FFT) of a triangular Toeplitz matrix, which is derived and proven in this
paper. It is shown that distortion inducted by the ISI from a given subcarrier
is the most significant for the closest subcarriers and the contribution decays
as the distance between subcarriers grows. According to numerical experiments,
knowledge of ISI coefficients concentrated around the diagonal of Channel
Frequency Response (CFR) matrix improves the receiver's error floor
significantly. The potential use of the framework for real-time frequency
domain channel simulation was also investigated and demonstrated to be more
efficient than conventional time domain Tapped Delay Line (TDL) model when a
number of simulated users is high.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:49:36 GMT""}]","2019-08-26"
"1908.08901","Raphael Kruse","Raphael Kruse, Nick Polydorides and Yue Wu","Application of Randomized Quadrature Formulas to the Finite Element
  Method for Elliptic Equations","36 pages, 7 figures, 1 table",,,,"math.NA cs.NA math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The implementation of the finite element method for linear elliptic equations
requires to assemble the stiffness matrix and the load vector. In general, the
entries of this matrix-vector system are not known explicitly but need to be
approximated by quadrature rules. If the coefficient functions of the
differential operator or the forcing term are irregular, then standard
quadrature formulas, such as the barycentric quadrature rule, may not be
reliable. In this paper we investigate the application of two randomized
quadrature formulas to the finite element method for such elliptic boundary
value problems with irregular coefficient functions. We give a detailed error
analysis of these methods, discuss their implementation, and demonstrate their
capabilities in several numerical experiments.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:55:11 GMT""}]","2019-08-26"
"1908.08902","Federico Marocco","Peter R. M. Eisenhardt (1), Federico Marocco (1,2), John W. Fowler
  (3), Aaron M. Meisner (4), J. Davy Kirkpatrick (2), Nelson Garcia (2), Thomas
  H. Jarrett (5), Renata Koontz (6), Elijah J. Marchese (6), S. Adam Stanford
  (7), Dan Caselden (8), Michael C. Cushing (9), Roc M. Cutri (2), Jacqueline
  K. Faherty (10), Christopher R. Gelino (2), Anthony H. Gonzalez (11), Amanda
  Mainzer (1), Bahram Mobasher (12), David J. Schlegel (13), Daniel Stern (1),
  Harry I. Teplitz (2), Edward L. Wright (14) ((1) Jet Propulsion Laboratory,
  Caltech, USA, (2) IPAC, Caltech, USA, (3) 230 Pacific St., Apt. 205, Santa
  Monica, CA, USA, (4) National Optical Astronomy Observatory, USA, (5)
  University of Cape Town, South Africa, (6) UC Riverside, USA, (7) UC Davis,
  USA, (8) Gigamon ATR, USA, (9) University of Toledo, USA, (10) American
  Museum of Natural History, USA, (11) University of Florida, USA, (12) UC
  Riverside, USA, (13) Lawrence Berkeley National Laboratory, USA, (14) UCLA,
  USA)","The CatWISE Preliminary Catalog: Motions from ${\it WISE}$ and ${\it
  NEOWISE}$ Data","53 pages, 20 figures, 5 tables. Accepted by ApJS",,"10.3847/1538-4365/ab7f2a",,"astro-ph.IM","http://creativecommons.org/licenses/by/4.0/","  CatWISE is a program to catalog sources selected from combined ${\it WISE}$
and ${\it NEOWISE}$ all-sky survey data at 3.4 and 4.6 $\mu$m (W1 and W2). The
CatWISE Preliminary Catalog consists of 900,849,014 sources measured in data
collected from 2010 to 2016. This dataset represents four times as many
exposures and spans over ten times as large a time baseline as that used for
the AllWISE Catalog. CatWISE adapts AllWISE software to measure the sources in
coadded images created from six-month subsets of these data, each representing
one coverage of the inertial sky, or epoch. The catalog includes the measured
motion of sources in 8 epochs over the 6.5 year span of the data. From
comparison to ${\it Spitzer}$, the SNR=5 limits in magnitudes in the Vega
system are W1=17.67 and W2=16.47, compared to W1=16.96 and W2=16.02 for
AllWISE. From comparison to ${\it Gaia}$, CatWISE positions have typical
accuracies of 50 mas for stars at W1=10 mag and 275 mas for stars at W1=15.5
mag. Proper motions have typical accuracies of 10 mas yr$^{-1}$ and 30 mas
yr$^{-1}$ for stars with these brightnesses, an order of magnitude better than
from AllWISE. The catalog is available in the WISE/NEOWISE Enhanced and
Contributed Products area of the NASA/IPAC Infrared Science Archive.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:59:16 GMT""},{""version"":""v2"",""created"":""Wed, 11 Mar 2020 00:21:24 GMT""}]","2020-04-22"
"1908.08903","Gavin Macauley","Gavin M. Macauley, Gary W. Paterson, Yue Li, Rair Mac\^edo, Stephen
  McVitie, Robert L. Stamps","Ice-rule made manifold: phase transitions, topological defects and
  manifold restoration in two-dimensional artificial spin systems","18 pages, 5 figures","Phys. Rev. B 101, 144403 (2020)","10.1103/PhysRevB.101.144403",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Artificial spin ices are arrays of correlated nano-scale magnetic islands
that prove an excellent playground in which to study the role of topology in
critical phenomena. Here, we investigate a continuum of spin ice geometries,
parameterised by rotation of the islands. In doing so, we morph from the
classic square ice to the recently studied pinwheel geometry, with the rotation
angle acting as a proxy for controlling inter-island interactions. We
experimentally observe a change in ground state magnetic order from
antiferromagnetic to ferromagnetic across this class of geometries using
Lorentz transmission electron microscopy on thermally annealed cobalt arrays.
The change in ordering leads to an apparent change in the nature of the defects
supported: from one-dimensional strings in the antiferromagnetic phase to
two-dimensional vortex-like structures in the ferromagnetic one, consistent
with the scaling predicted by the Kibble-Zurek mechanism. Our results show how
magnetic order in artificial spin ices can be tuned by changes in geometry so
that a truly frustrated ice-rule phase is possible in two-dimensional systems.
Furthermore, we demonstrate this system as a testbed to investigate
out-of-equilibrium dynamics across phases.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:03:05 GMT""}]","2020-04-08"
"1908.08904","Balint Koczor","B\'alint Koczor, Suguru Endo, Tyson Jones, Yuichiro Matsuzaki, Simon
  C. Benjamin","Variational-State Quantum Metrology","31 pages, 10 figures -- added more discussion about, e.g., the
  optimisation and the ansatz structure","New J. Phys. 22 083038 (2020)","10.1088/1367-2630/ab965e",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Quantum technologies exploit entanglement to enhance various tasks beyond
their classical limits including computation, communication and measurements.
Quantum metrology aims to increase the precision of a measured quantity that is
estimated in the presence of statistical errors using entangled quantum states.
We present a novel approach for finding (near) optimal states for metrology in
the presence of noise, using variational techniques as a tool for efficiently
searching the classically intractable high-dimensional space of quantum states.
We comprehensively explore systems consisting of up to 9 qubits and find new
highly entangled states that are not symmetric under permutations and
non-trivially outperform previously known states up to a constant factor 2. We
consider a range of environmental noise models; while passive quantum states
cannot achieve a fundamentally superior scaling (as established by prior
asymptotic results) we do observe a significant absolute quantum advantage. We
finally outline a possible experimental setup for variational quantum metrology
which can be implemented in near-term hardware.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:03:35 GMT""},{""version"":""v2"",""created"":""Mon, 23 Sep 2019 12:49:04 GMT""},{""version"":""v3"",""created"":""Thu, 16 Apr 2020 09:38:16 GMT""}]","2020-08-25"
"1908.08905","Martin N\""ollenburg","Matthias Hummel, Fabian Klute, Soeren Nickel, Martin N\""ollenburg","Maximizing Ink in Partial Edge Drawings of k-plane Graphs","Appears in the Proceedings of the 27th International Symposium on
  Graph Drawing and Network Visualization (GD 2019)",,,,"cs.CG cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Partial edge drawing (PED) is a drawing style for non-planar graphs, in which
edges are drawn only partially as pairs of opposing stubs on the respective
end-vertices. In a PED, by erasing the central parts of edges, all edge
crossings and the resulting visual clutter are hidden in the undrawn parts of
the edges. In symmetric partial edge drawings (SPEDs), the two stubs of each
edge are required to have the same length. It is known that maximizing the ink
(or the total stub length) when transforming a straight-line graph drawing with
crossings into a SPED is tractable for 2-plane input drawings, but NP-hard for
unrestricted inputs. We show that the problem remains NP-hard even for 3-plane
input drawings and establish NP-hardness of ink maximization for PEDs of
4-plane graphs. Yet, for k-plane input drawings whose edge intersection graph
forms a collection of trees or, more generally, whose intersection graph has
bounded treewidth, we present efficient algorithms for computing maximum-ink
PEDs and SPEDs. We implemented the treewidth-based algorithms and show a brief
experimental evaluation.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:08:43 GMT""},{""version"":""v2"",""created"":""Mon, 26 Aug 2019 12:55:51 GMT""}]","2019-08-27"
"1908.08906","Dong Liu","Dong Liu, Nima N. Moghadam, Lars K. Rasmussen, Jinliang Huang, Saikat
  Chatterjee","$\alpha$ Belief Propagation as Fully Factorized Approximation","GlobalSIP 2019",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Belief propagation (BP) can do exact inference in loop-free graphs, but its
performance could be poor in graphs with loops, and the understanding of its
solution is limited. This work gives an interpretable belief propagation rule
that is actually minimization of a localized $\alpha$-divergence. We term this
algorithm as $\alpha$ belief propagation ($\alpha$-BP). The performance of
$\alpha$-BP is tested in MAP (maximum a posterior) inference problems, where
$\alpha$-BP can outperform (loopy) BP by a significant margin even in
fully-connected graphs.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:18:29 GMT""}]","2019-08-26"
"1908.08907","Sylvain Prolhac","Sylvain Prolhac","Riemann surfaces for KPZ with periodic boundaries","81 pages, 23 figures","SciPost Phys. 8, 008 (2020)","10.21468/SciPostPhys.8.1.008",,"cond-mat.stat-mech math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Riemann surface for polylogarithms of half-integer index, which has the
topology of an infinite dimensional hypercube, is studied in relation to
one-dimensional KPZ universality in finite volume. Known exact results for
fluctuations of the KPZ height with periodic boundaries are expressed in terms
of meromorphic functions on this Riemann surface, summed over all the sheets of
a covering map to an infinite cylinder. Connections to stationary large
deviations, particle-hole excitations and KdV solitons are discussed.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:27:07 GMT""},{""version"":""v2"",""created"":""Thu, 14 Nov 2019 16:36:46 GMT""}]","2020-02-03"
"1908.08908","Huynh Manh","Manh Huynh and Gita Alaghband","Trajectory Prediction by Coupling Scene-LSTM with Human Movement LSTM","To appear in ISVC 2019",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a novel human trajectory prediction system that incorporates the
scene information (Scene-LSTM) as well as individual pedestrian movement
(Pedestrian-LSTM) trained simultaneously within static crowded scenes. We
superimpose a two-level grid structure (grid cells and subgrids) on the scene
to encode spatial granularity plus common human movements. The Scene-LSTM
captures the commonly traveled paths that can be used to significantly
influence the accuracy of human trajectory prediction in local areas (i.e. grid
cells). We further design scene data filters, consisting of a hard filter and a
soft filter, to select the relevant scene information in a local region when
necessary and combine it with Pedestrian-LSTM for forecasting a pedestrian's
future locations. The experimental results on several publicly available
datasets demonstrate that our method outperforms related works and can produce
more accurate predicted trajectories in different scene contexts.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:31:59 GMT""}]","2019-08-26"
"1908.08909","Hsin-Yuan Huang","Hsin-Yuan Huang and Richard Kueng","Predicting Features of Quantum Systems from Very Few Measurements","8 pages, 6 figures + 10 page appendix and one reference to Norse
  mythology",,,,"quant-ph cs.CL cs.IT cs.LG math.IT math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Predicting features of complex, large-scale quantum systems is essential to
the characterization and engineering of quantum architectures. We present an
efficient approach for constructing an approximate classical description,
called the classical shadow, of a quantum system from very few quantum
measurements that can later be used to predict a large collection of features.
This approach is guaranteed to accurately predict M linear functions with
bounded Hilbert-Schmidt norm from only order of log(M) measurements. This is
completely independent of the system size and saturates fundamental lower
bounds from information theory. We support our theoretical findings with
numerical experiments over a wide range of problem sizes (2 to 162 qubits).
These highlight advantages compared to existing machine learning approaches.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:32:39 GMT""},{""version"":""v2"",""created"":""Sun, 24 Nov 2019 19:20:43 GMT""}]","2019-11-26"
"1908.08910","Jay Pantone","Anders Claesson and Bjarki \'Ag\'ust Gu{\dh}mundsson and Jay Pantone","Counting pop-stacked permutations in polynomial time",,,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Permutations in the image of the pop-stack operator are said to be
pop-stacked. We give a polynomial-time algorithm to count pop-stacked
permutations up to a fixed length and we use it to compute the first 1000 terms
of the corresponding counting sequence. Only the first 16 terms had previously
been computed. With the 1000 terms we prove some negative results concerning
the nature of the generating function for pop-stacked permutations. We also
predict the asymptotic behavior of the counting sequence using differential
approximation.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:34:12 GMT""}]","2019-08-26"
"1908.08911","Martin N\""ollenburg","Sujoy Bhore, Robert Ganian, Fabrizio Montecchiani, Martin N\""ollenburg","Parameterized Algorithms for Book Embedding Problems","Appears in the Proceedings of the 27th International Symposium on
  Graph Drawing and Network Visualization (GD 2019)",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A k-page book embedding of a graph G draws the vertices of G on a line and
the edges on k half-planes (called pages) bounded by this line, such that no
two edges on the same page cross. We study the problem of determining whether G
admits a k-page book embedding both when the linear order of the vertices is
fixed, called Fixed-Order Book Thickness, or not fixed, called Book Thickness.
Both problems are known to be NP-complete in general. We show that Fixed-Order
Book Thickness and Book Thickness are fixed-parameter tractable parameterized
by the vertex cover number of the graph and that Fixed-Order Book Thickness is
fixed-parameter tractable parameterized by the pathwidth of the vertex order.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:36:13 GMT""}]","2019-08-26"
"1908.08912","Salem Said","Salem Said","On the Riemannian barycentre of a Markov chain","not yet submitted for publication ; I have found a mistake in this
  work",,,,"math.PR math.DG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Riemannian barycentre is one of the most widely used statistical
descriptors for probability distributions on Riemannian manifolds. At present,
existing algorithms are able to compute the Riemannian barycentre of a
probability distribution, only if i.i.d. samples of this distribution are
readily available. However, there are many cases where i.i.d. samples are quite
difficult to obtain, and have to be replaced with non-independent samples,
generated by a Markov chain Monte Carlo method. To overcome this difficulty,
the present paper proposes a new Markov chain Monte Carlo algorithm for
computing the Riemannian barycentre of a probability distribution on a Hadamard
manifold (a simply connected, complete Riemannian manifold with non-positive
curvature). This algorithm relies on two original propositions, proved in the
paper. The first proposition states that the recursive barycentre of samples
generated from a geometrically ergodic Markov chain converges in the
mean-square to the Riemannian barycentre of the stationary distribution of this
chain. The second proposition provides verifiable conditions which ensure a
Metropolis-Hastings Markov chain, with its values in a symmetric Hadamard
manifold, is geometrically ergodic. This latter result yields a partial
solution, in the context of Riemannian manifolds, to the problem of geometric
ergodicity of Metropolis-Hastings chains, which has previously attracted
extensive attention when considered in Euclidean space. In addition to these
two propositions, the new Markov chain Monte Carlo algorithm, proposed in this
paper, is applied to a problem of Bayesian inference, arising from computer
vision.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:36:37 GMT""},{""version"":""v2"",""created"":""Tue, 25 Feb 2020 08:00:56 GMT""}]","2020-02-26"
"1908.08913","Sebastian Gomez","S. Gomez, G. Hosseinzadeh, P. S. Cowperthwaite, V. A. Villar, E.
  Berger, T. Gardner, K. D. Alexander, R. Chornock, M. R. Drout, T. Eftekhari,
  W. Fong, K. Gill, R. Margutti, M. Nicholl, K. Paterson, P. K. G. Williams","A Galaxy-Targeted Search for the Optical Counterpart of the Candidate
  NS-BH Merger S190814bv with Magellan","10 pages, 1 table, 4 figures, accepted to ApJL",,"10.3847/2041-8213/ab4ad5",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  On 2019 August 14 the Laser Interferometer Gravitational Wave Observatory
(LIGO) and the Virgo gravitational wave interferometer announced the detection
of a binary merger, S190814bv, with a low false alarm rate (FAR) of about 1 in
$1.6\times 10^{25}$ years, a distance of $267\pm 52$ Mpc, a 90\% (50\%)
localization region of about 23 (5) deg$^2$, and a probability of being a
neutron star--black hole (NS-BH) merger of $>99\%$. The LIGO/Virgo
Collaboration (LVC) defines NS-BH such that the lighter binary member has a
mass of $<3$ M$_\odot$ and the more massive one has $>5$ M$_\odot$, and this
classification is in principle consistent with a BH-BH merger depending on the
actual upper mass cut-off for neutron stars. Additionally, the LVC designated a
probability that the merger led to matter outside the final BH remnant of
$<1\%$, suggesting that an electromagnetic (EM) counterpart is unlikely. Here
we report our optical follow-up observations of S190814bv using the Magellan
Baade 6.5 m telescope to target all 96 galaxies in the GLADE catalog within the
50\% localization volume (representing about 70\% of the integrated luminosity
within this region). No counterpart was identified to a median $3\sigma$
limiting magnitude of $i=22.2$ ($M_i\approx -14.9$ mag), comparable to the
brightness of the optical counterpart of the binary neutron star merger
GW170817 at the distance of S190814bv; similarly, we can rule out an on-axis
jet typical of short GRBs. However, we cannot rule out other realistic models,
such as a kilonova with only $\sim 0.01$ M$_\odot$ of lanthanide-rich material,
or an off-axis jet with a viewing angle of $\theta_{\rm obs}\gtrsim 15^\circ$.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:37:38 GMT""},{""version"":""v2"",""created"":""Sat, 11 Apr 2020 14:21:39 GMT""}]","2020-04-14"
"1908.08914","Matthew Kowal","Matthew Kowal, Gillian Sandison, Len Yabuki-Soh, Raner la Bastide","Region Tracking in an Image Sequence: Preventing Driver Inattention",,,,,"cs.CV","http://creativecommons.org/publicdomain/zero/1.0/","  Driver inattention is a large problem on the roads around the world. The
objective of this project was to develop an eye tracking algorithm with
sufficient computational efficiency and accuracy, to successfully realize when
the driver was looking away from the road for an extended period. The method of
tracking involved the minimization of a functional, using the gradient descent
and level set methods. The algorithm was then discretized and implemented using
C and MATLAB. Multiple synthetic images, grey-scale and colour images were
tested using the final design, with a desired region coverage of 82%. Further
work is needed to decrease the computation time, increase the robustness of the
algorithm, develop a small device capable of running the algorithm, as well as
physically implement this device into various vehicles.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:38:27 GMT""}]","2019-08-26"
"1908.08915","Agnieszka Kalamajska","Agnieszka Ka{\l}amajska, Anna Kosiorek","On maximum principles for radial solutions to nonlinear elliptic PDE's
  via Opial-type inequalities",,,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider degenerated nonlinear PDE of elliptic type: $$
  - \mathrm{div}(a(|x|)|\nabla w(x)|^{p-2} \nabla w(x)) +
h(|x|,w(x),\langle\nabla w(x),\frac{x}{|x|}\rangle)=\phi(w(x)), $$ where $x$
belongs to the ball in $\bf{R}^n$. Using the argument based on Opial-type
inequalities, we investigate qualitative properties of their radial solutions,
like e.g. maximum principles, monotonicity, as well as nonexistence of the
nontrivial solutions.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:38:58 GMT""}]","2019-08-26"
"1908.08923","Gudrun Heinrich","Matteo Capozi, Gudrun Heinrich","Exploring anomalous couplings in Higgs boson pair production through
  shape analysis","34 pages, 19 figures, benchmark points added, replaced by published
  version","J. High Energ. Phys. 2020, 91 (2020)","10.1007/JHEP03(2020)091","MPP-2019-183","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We classify shapes of Higgs boson pair invariant mass distributions $m_{hh}$,
calculated at NLO with full top quark mass dependence, and visualise how
distinct classes of shapes relate to the underlying coupling parameter space.
Our study is based on a five-dimensional parameter space relevant for Higgs
boson pair production in a non-linear Effective Field Theory framework. We use
two approaches: an analysis based on predefined shape types and a
classification into shape clusters based on unsupervised learning. We find that
our method based on unsupervised learning is able to capture shape features
very well and therefore allows a more detailed study of the impact of anomalous
couplings on the $m_{hh}$ shape compared to more conventional approaches to a
shape analysis.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:45:27 GMT""},{""version"":""v2"",""created"":""Fri, 20 Mar 2020 07:12:35 GMT""}]","2020-03-23"
"1908.08924","Klaus Frahm","Klaus M. Frahm and Dima L. Shepelyansky","Linear response theory for Google matrix","11 pages, 8 pdf figures; additional material available at:
  http://www.quantware.ups-tlse.fr/QWLIB/lirgomax",,,,"cs.SI physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop the linear response theory for the Google matrix PageRank
algorithm with respect to a general weak perturbation and a numerical efficient
and accurate algorithm, called LIRGOMAX algorithm, to compute the linear
response of the PageRank with respect to this perturbation. We illustrate its
efficiency on the example of the English Wikipedia network with more than 5
millions of articles (nodes). For a group of initial nodes (or simply a pair of
nodes) this algorithm allows to identify the effective pathway between initial
nodes thus selecting a particular subset of nodes which are most sensitive to
the weak perturbation applied to them (injection or pumping at one node and
absorption of probability at another node). The further application of the
reduced Google matrix algorithm (REGOMAX) allows to determine the effective
interactions between the nodes of this subset. General linear response theory
already found numerous applications in various areas of science including
statistical and mesoscopic physics. Based on these grounds we argue that the
developed LIRGOMAX algorithm will find broad applications in the analysis of
complex directed networks.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:48:54 GMT""}]","2019-08-26"
"1908.08932","Yawei Li","Yawei Li, Shuhang Gu, Luc Van Gool, Radu Timofte","Learning Filter Basis for Convolutional Neural Network Compression","Code is available at
  https://github.com/ofsoundof/learning_filter_basis. ICCV 2019",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Convolutional neural networks (CNNs) based solutions have achieved
state-of-the-art performances for many computer vision tasks, including
classification and super-resolution of images. Usually the success of these
methods comes with a cost of millions of parameters due to stacking deep
convolutional layers. Moreover, quite a large number of filters are also used
for a single convolutional layer, which exaggerates the parameter burden of
current methods. Thus, in this paper, we try to reduce the number of parameters
of CNNs by learning a basis of the filters in convolutional layers. For the
forward pass, the learned basis is used to approximate the original filters and
then used as parameters for the convolutional layers. We validate our proposed
solution for multiple CNN architectures on image classification and image
super-resolution benchmarks and compare favorably to the existing
state-of-the-art in terms of reduction of parameters and preservation of
accuracy.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:55:26 GMT""},{""version"":""v2"",""created"":""Mon, 23 Dec 2019 18:55:28 GMT""}]","2019-12-24"
"1908.08933","Francisco Santos","\'Oscar Iglesias Vali\~no and Francisco Santos","The complete classification of empty lattice $4$-simplices","31 pages, 3 figures, 8 tables. Apart of minor edits the main change
  in v3 is the inclusion of a supplementary *.txt file with the data for the
  2461 sporadic simplices","Rev. Mat. Iberoam. 37:6 (2021), 2399-2432","10.4171/rmi/1268",,"math.CO math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  An empty simplex is a lattice simplex with only its vertices as lattice
points. Their classification in dimension three was completed by White in 1964.
In dimension four, the same task was started in 1988 by Mori, Morrison, and
Morrison, with their motivation coming from the close relationship between
empty simplices and terminal quotient singularities. They conjectured a
classification of empty simplices of prime volume, modulo finitely many
exceptions. Their conjecture was proved by Sankaran (1990) with a simplified
proof by Bober (2009). The same classification was claimed by Barile et al. in
2011 for simplices of non-prime volume, but this statement was proved wrong by
Blanco et al. (2016+).
  In this article we complete the classification of $4$-dimensional empty
simplices. In doing so we correct and complete the classification claimed by
Barile et al., and we also compute all the finitely many exceptions, by first
proving an upper bound for their volume. The whole classification has:
  - One $3$-parameter family, consisting of simplices of width equal to one.
  - Two $2$-parameter families (the one in Mori et al., plus a second new one).
  - Forty-six $1$-parameter families (the 29 in Mori et al., plus 17 new ones).
  - $2461$ individual simplices not belonging to the above families, with
volumes ranging between 29 and 419.
  We characterize the infinite families of empty simplices in terms of lower
dimensional point configurations that they project to, with techniques that can
be applied to higher dimensions and larger classes of lattice polytopes.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:56:57 GMT""},{""version"":""v2"",""created"":""Tue, 8 Oct 2019 11:55:31 GMT""},{""version"":""v3"",""created"":""Sat, 11 Apr 2020 11:24:16 GMT""}]","2021-11-05"
"1908.08934","Cornelis Storm","Elizaveta A. Novikova and Cornelis Storm","Evolving roles and dynamics for catch and slip bonds during adhesion
  cluster maturation","8 pages, 7 figures","Phys. Rev. E 103, 032402 (2021)","10.1103/PhysRevE.103.032402",,"physics.bio-ph cond-mat.soft q-bio.SC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Focal adhesions are the loci of cellular adhesion to the extracellular
matrix. At these sites, various integrins forge connections between the
intracellular cytoskeleton and the outside world: large patches of multiple
types of integrins together grip hold of collagen, fibronectin and other
extracellular matrix components. The mixture of integrins composing the FA
will, in general, contain both slip bond integrins and catch bond
integrins---bonds whose lifetime increases with applied load and bonds for whom
it decreases when forced. Prior work suggests that catch bonds are essential
for proper FA stability and mechanosensory functionality. In the present work,
we investigate, numerically, the interplay between the two distinct types of
bonds and ask how the presence, in the same FA cluster, of slip bonds augments
the behavior of the catch bonds. We show, that mixing the two components m
low-force mechanical integrity, lacking in purely catch systems, while
preserving the potential to strengthen the FA bond by force as well as the
mechanosensory qualities of the catch bonds. We investigate the spatial
distribution in mixed-integrin FA's and show that the differential response to
loading leads, via an excluded volume interaction, to a dependence of the
individual integrin diffusivities on the applied load, an effect that has been
reported in experiments.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:57:49 GMT""}]","2021-03-10"
"1908.08935","John Y. Yoritomo","John Y. Yoritomo and Richard L. Weaver","Slow dynamic nonlinearity in unconsolidated glass bead packs","19 pages, 8 figures","Phys. Rev. E 101, 012901 (2020)","10.1103/PhysRevE.101.012901",,"cond-mat.soft cond-mat.other physics.class-ph physics.geo-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Slow dynamic nonlinearity describes a poorly understood, creep-like phenomena
that occurs in brittle composite materials such as rocks and cement. It is
characterized by a drop in stiffness induced by a mechanical conditioning,
followed by a log(time) recovery. A consensus theoretical understanding of the
behavior has not been developed. Here we introduce an alternative experimental
venue with which to inform theory. Unconsolidated glass bead packs are studied
rather than rocks or cement because the structure and internal contacts of bead
packs are less complex and better understood. Slow dynamics has been observed
in such systems previously. However, the measurements to date tend to be
irregular. Particular care is used here in the experimental design to overcome
the difficulties inherent in bead pack studies. This includes the design of the
bead pack support, the use of low frequency conditioning, and the use of
ultrasonic waves as a probe with coda wave interferometry to assess changes.
Slow dynamics is observed in our system after three different methods for
low-frequency conditioning, one of which has not been reported in the
literature previously.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:58:17 GMT""},{""version"":""v2"",""created"":""Mon, 26 Aug 2019 19:55:42 GMT""},{""version"":""v3"",""created"":""Fri, 13 Sep 2019 19:24:32 GMT""},{""version"":""v4"",""created"":""Tue, 29 Oct 2019 21:27:28 GMT""}]","2020-01-15"
"1908.08938","Martin N\""ollenburg","Philipp de Col, Fabian Klute, Martin N\""ollenburg","Mixed Linear Layouts: Complexity, Heuristics, and Experiments","Appears in the Proceedings of the 27th International Symposium on
  Graph Drawing and Network Visualization (GD 2019)",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A $k$-page linear graph layout of a graph $G = (V,E)$ draws all vertices
along a line $\ell$ and each edge in one of $k$ disjoint halfplanes called
pages, which are bounded by $\ell$. We consider two types of pages. In a stack
page no two edges should cross and in a queue page no edge should be nested by
another edge. A crossing (nesting) in a stack (queue) page is called a
conflict. The algorithmic problem is twofold and requires to compute (i) a
vertex ordering and (ii) a page assignment of the edges such that the resulting
layout is either conflict-free or conflict-minimal. While linear layouts with
only stack or only queue pages are well-studied, mixed $s$-stack $q$-queue
layouts for $s,q \ge 1$ have received less attention. We show NP-completeness
results on the recognition problem of certain mixed linear layouts and present
a new heuristic for minimizing conflicts. In a computational experiment for the
case $s, q = 1$ we show that the new heuristic is an improvement over previous
heuristics for linear layouts.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:59:39 GMT""}]","2019-08-26"
"1908.08946","Nicola de Divitiis","Nicola de Divitiis","von K\'arm\'an--Howarth and Corrsin equations closures through Liouville
  theorem","30 pages, revised. Journal title: Results in Physics. arXiv admin
  note: text overlap with arXiv:1902.03509","Results in Physics, 2020","10.1016/j.rinp.2020.102979",,"physics.flu-dyn physics.ao-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this communication, the closure formulas of von K\'arm\'an--Howarth and
Corrsin equations are obtained through the Liouville theorem and the hypothesis
of homogeneous isotropic incompressible turbulence. Such closures, based on the
concept that, in fully developed turbulence, contiguous fluid particles
trajectories continuously diverge, are of non--diffusive nature, and express a
correlations spatial propagation phenomenon between the several scales which
occurs with a propagation speed depending on length scale and velocity standard
deviation. These closure formulas coincide with those just obtained in previous
works through the finite scale Lyapunov analysis of the fluid act of motion.
Here, unlike the other articles, the present study does not use the Lyapunov
theory, and provides the closures showing first an exact relationship between
the pair spatial correlations calculated with the velocity distribution
function and those obtained using the material separation line distribution
function. As this analysis does not adopt the Lyapunov theory, this does not
need the definition and/or the existence of the Lyapunov exponents.
Accordingly, the present proof of the closures results to be more general and
rigorous than that presented in the other works, corroborating the previous
results. Finally, the conditions of existence of invariants in isotropic
turbulence are studied by means of the proposed closures. In the presence of
such invariants and self--similarity, the sole evolution of velocity and
temperature standard deviations and of the correlation scales is shown to be
adequate to fairly describe the isotropic turbulence.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:55:50 GMT""},{""version"":""v2"",""created"":""Mon, 21 Oct 2019 19:12:52 GMT""},{""version"":""v3"",""created"":""Fri, 7 Feb 2020 12:08:58 GMT""}]","2020-02-11"
"1908.08947","Sahar Yousefi","Sahar Yousefi, Lydiane Hirschler, Merlijn van der Plas, Mohamed S.
  Elmahdy, Hessam Sokooti, Matthias Van Osch, Marius Staring","Fast Dynamic Perfusion and Angiography Reconstruction using an
  end-to-end 3D Convolutional Neural Network","11 pages, 4 figures, 1 table, conference paper, accepted in MLMIR2019",,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Hadamard time-encoded pseudo-continuous arterial spin labeling (te-pCASL) is
a signal-to-noise ratio (SNR)-efficient MRI technique for acquiring dynamic
pCASL signals that encodes the temporal information into the labeling according
to a Hadamard matrix. In the decoding step, the contribution of each sub-bolus
can be isolated resulting in dynamic perfusion scans. When acquiring te-ASL
both with and without flow-crushing, the ASL-signal in the arteries can be
isolated resulting in 4D-angiographic information. However, obtaining
multi-timepoint perfusion and angiographic data requires two acquisitions. In
this study, we propose a 3D Dense-Unet convolutional neural network with a
multi-level loss function for reconstructing multi-timepoint perfusion and
angiographic information from an interleaved $50\%$-sampled crushed and
$50\%$-sampled non-crushed data, thereby negating the additional scan time. We
present a framework to generate dynamic pCASL training and validation data,
based on models of the intravascular and extravascular te-pCASL signals. The
proposed network achieved SSIM values of $97.3 \pm 1.1$ and $96.2 \pm 11.1$
respectively for 4D perfusion and angiographic data reconstruction for 313 test
data-sets.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:51:20 GMT""},{""version"":""v2"",""created"":""Wed, 4 Sep 2019 08:16:39 GMT""}]","2019-09-05"
"1908.08948","Jurij Vol\v{c}i\v{c}","Jurij Vol\v{c}i\v{c}","Free Bertini's theorem and applications",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The simplest version of Bertini's irreducibility theorem states that the
generic fiber of a non-composite polynomial function is an irreducible
hypersurface. The main result of this paper is its analog for a free algebra:
if $f$ is a noncommutative polynomial such that $f-\lambda$ factors for
infinitely many scalars $\lambda$, then there exist a noncommutative polynomial
$h$ and a nonconstant univariate polynomial $p$ such that $f=p\circ h$. Two
applications of free Bertini's theorem for matrix evaluations of noncommutative
polynomials are given. An eigenlevel set of $f$ is the set of all matrix tuples
$X$ where $f(X)$ attains some given eigenvalue. It is shown that eigenlevel
sets of $f$ and $g$ coincide if and only if $fa=ag$ for some nonzero
noncommutative polynomial $a$. The second application pertains quasiconvexity
and describes polynomials $f$ such that the connected component of $\{X \text{
tuple of symmetric $n\times n$ matrices}: \lambda I\succ f(X) \}$ about the
origin is convex for all natural $n$ and $\lambda>0$. It is shown that such a
polynomial is either everywhere negative semidefinite or the composition of a
univariate and a convex quadratic polynomial.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:00 GMT""}]","2019-08-27"
"1908.08949","Jesse Thaler","Annie Y. Wei, Preksha Naik, Aram W. Harrow, Jesse Thaler","Quantum Algorithms for Jet Clustering","21 pages, 1 table, 6 figures. v2: correction to doubling trick and
  additional discussion of resource requirements; approximate version to appear
  in PRD","Phys. Rev. D 101, 094015 (2020)","10.1103/PhysRevD.101.094015","MIT-CTP 5137","hep-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifying jets formed in high-energy particle collisions requires solving
optimization problems over potentially large numbers of final-state particles.
In this work, we consider the possibility of using quantum computers to speed
up jet clustering algorithms. Focusing on the case of electron-positron
collisions, we consider a well-known event shape called thrust whose optimum
corresponds to the most jet-like separating plane among a set of particles,
thereby defining two hemisphere jets. We show how to formulate thrust both as a
quantum annealing problem and as a Grover search problem. A key component of
our analysis is the consideration of realistic models for interfacing classical
data with a quantum algorithm. With a sequential computing model, we show how
to speed up the well-known O(N^3) classical algorithm to an O(N^2) quantum
algorithm, including the O(N) overhead of loading classical data from N
final-state particles. Along the way, we also identify a way to speed up the
classical algorithm to O(N^2 log N) using a sorting strategy inspired by the
SISCone jet algorithm, which has no natural quantum counterpart. With a
parallel computing model, we achieve O(N log N) scaling in both the classical
and quantum cases. Finally, we consider the generalization of these quantum
methods to other jet algorithms more closely related to those used for
proton-proton collisions at the Large Hadron Collider.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:00 GMT""},{""version"":""v2"",""created"":""Tue, 5 May 2020 23:06:05 GMT""}]","2020-05-20"
"1908.08950","Suvodip Mukherjee","Suvodip Mukherjee, Benjamin D. Wandelt, Joseph Silk","Multi-messenger tests of gravity with weakly lensed gravitational waves","7 pages, 3 figures. Matches the published version","Phys. Rev. D 101, 103509 (2020)","10.1103/PhysRevD.101.103509",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  General relativity (GR) predicts concordant trajectories for photons and
gravitational waves (GW). We propose a new multi-messenger avenue (GW-CMB-CMB)
to prove this aspect of fundamental physics by cross-correlating the GW signal
of astrophysical origin with the lensing field derived from the cosmic
microwave background (CMB). This new window will allow robust measurement of
the prediction from GR with high signal-to-noise and will be able to unveil the
true nature of gravity using the GW sources detected by missions such as the
Laser Interferometer Space Antenna (LISA), Einstein Telescope and Cosmic
Explorer.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:01 GMT""},{""version"":""v2"",""created"":""Fri, 22 May 2020 08:54:18 GMT""}]","2020-05-25"
"1908.08951","Suvodip Mukherjee","Suvodip Mukherjee, Benjamin D. Wandelt, Joseph Silk","Probing the theory of gravity with gravitational lensing of
  gravitational waves and galaxy surveys","16 pages, 7 figures. Minor changes in the text and added new
  references. Matches the version accepted for publication in MNRAS",,"10.1093/mnras/staa827",,"astro-ph.CO astro-ph.GA gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The cross-correlation of gravitational wave strain with upcoming galaxy
surveys probe theories of gravity in a new way. This method enables testing the
theory of gravity by combining the effects from both gravitational lensing of
gravitational waves and the propagation of gravitational waves in spacetime. We
find that within 10 years, the combination of the Advanced-LIGO and VIRGO
detector networks with planned galaxy surveys should detect weak gravitational
lensing of gravitational waves in the low redshift Universe ($z<0.5$). With the
next generation gravitational wave experiments such as Voyager, LISA,
Cosmic-Explorer and Einstein Telescope, we can extend this test of the theory
of gravity to larger redshifts by exploiting the synergies between
electromagnetic wave and gravitational wave probes.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:03 GMT""},{""version"":""v2"",""created"":""Fri, 20 Mar 2020 16:29:02 GMT""}]","2020-04-01"
"1908.08952","Daniel D. Kelson","Daniel D. Kelson, Louis E. Abramson, Andrew J. Benson, Shannon G.
  Patel, Stephen A. Shectman, Alan Dressler, Patrick J. McCarthy, John S.
  Mulchaey, and Rik J. Williams","Gravity and the Nonlinear Growth of Structure in the
  Carnegie-Spitzer-IMACS Redshift Survey","13 pages, 12 figures, submitted to Monthly Notices of the Royal
  Astronomical Society, 23 August 2019, and accepted for publication, 9 January
  2020. Some more typo(s) fixed",,"10.1093/mnras/staa100",,"astro-ph.CO astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A key obstacle to developing a satisfying theory of galaxy evolution is the
difficulty in extending analytic descriptions of early structure formation into
full nonlinearity, the regime in which galaxy growth occurs. Extant techniques,
though powerful, are based on approximate numerical methods whose Monte
Carlo-like nature hinders intuition building. Here, we develop a new solution
to this problem and its empirical validation. We first derive closed-form
analytic expectations for the evolution of fixed percentiles in the real-space
cosmic density distribution, {\it averaged over representative volumes
observers can track cross-sectionally\}. Using the Lagrangian forms of the
fluid equations, we show that percentiles in $\delta$---the density relative to
the median---should grow as $\delta(t)\propto\delta_{0}^{\alpha}\,t^{\beta}$,
where $\alpha\equiv2$ and $\beta\equiv2$ for Newtonian gravity at epochs after
the overdensities transitioned to nonlinear growth. We then use 9.5 sq. deg. of
Carnegie-Spitzer-IMACS Redshift Survey data to map {\it galaxy\} environmental
densities over $0.2<z<1.5$ ($\sim$7 Gyr) and infer $\alpha=1.98\pm0.04$ and
$\beta=2.01\pm0.11$---consistent with our analytic prediction. These
findings---enabled by swapping the Eulerian domain of most work on density
growth for a Lagrangian approach to real-space volumetric averages---provide
some of the strongest evidence that a lognormal distribution of early density
fluctuations indeed decoupled from cosmic expansion to grow through
gravitational accretion. They also comprise the first exact, analytic
description of the nonlinear growth of structure extensible to (arbitrarily)
low redshift. We hope these results open the door to new modeling of, and
insight-building into, the galaxy growth and its diversity in cosmological
contexts.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:03 GMT""},{""version"":""v2"",""created"":""Mon, 13 Jan 2020 23:43:30 GMT""},{""version"":""v3"",""created"":""Tue, 21 Jan 2020 21:24:46 GMT""}]","2020-05-06"
"1908.08953","Selim Hotinli","Selim C. Hotinli, James B. Mertens, Matthew C. Johnson, Marc
  Kamionkowski","Probing correlated compensated isocurvature perturbations using
  scale-dependent galaxy bias","7 pages, 3 figures, comments welcome","Phys. Rev. D 100, 103528 (2019)","10.1103/PhysRevD.100.103528",,"astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Compensated isocurvature perturbations (CIPs) are modulations of the relative
baryon and dark matter density that leave the total matter density constant.
The best current constraints from the primary cosmic microwave background (CMB)
are consistent with CIPs some two orders of magnitude larger in amplitude than
adiabatic perturbations, suggesting that there may be a huge gap in our
knowledge of the early Universe. However, it was recently suggested by
Barreira~et.~al. that CIPs which are correlated with the primordial curvature
perturbation, as arises in some versions of the curvaton model, lead to a new
observable: scale dependent galaxy bias. Combining a galaxy survey with an
unbiased tracer of the density field facilitates a measurement of the amplitude
of correlated CIPs that is free from cosmic variance, the main limitation on
constraints from the primary CMB. Among the most promising tracers to use for
this purpose is the remote dipole field, reconstructed using the technique of
kinetic Sunyaev Zel'dovich (kSZ) tomography. In this paper, we evaluate the
detection significance on the amplitude of correlated CIPs possible with
next-generation CMB and galaxy surveys using kSZ tomography. Our analysis
includes all relativistic contributions to the observed galaxy number counts
and allows for both CIPs and primordial non-Gaussianity, which also gives rise
to a scale dependent galaxy bias. We find that kSZ tomography can probe CIPs of
comparable amplitude to the adiabatic fluctuations, representing an improvement
of over two orders of magnitude upon current constraints, and an order of
magnitude over what will be possible using future CMB or galaxy surveys alone.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:03 GMT""}]","2019-12-04"
"1908.08954","Xi Kleisinger-Yu","Xi Kleisinger-Yu, Vlatka Komaric, Martin Larsson, Markus Regez","A multi-factor polynomial framework for long-term electricity forwards
  with delivery period","Forthcoming in SIAM Journal on Financial Mathematics",,,,"q-fin.MF","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a multi-factor polynomial framework to model and hedge long-term
electricity contracts with delivery period. This framework has several
advantages: the computation of forwards, risk premium and correlation between
different forwards are fully explicit, and the model can be calibrated to
observed electricity forward curves easily and well. Electricity markets suffer
from non-storability and poor medium- to long-term liquidity. Therefore, we
suggest a rolling hedge which only uses liquid forward contracts and is
risk-minimizing in the sense of F\""ollmer and Schweizer. We calibrate the model
to over eight years of German power calendar year forward curves and
investigate the quality of the risk-minimizing hedge over various time
horizons.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:04 GMT""},{""version"":""v2"",""created"":""Tue, 9 Jun 2020 11:27:02 GMT""}]","2020-06-11"
"1908.08955","K\'evin Nguyen","Vijay Balasubramanian, Ben Craps, Marine De Clerck and K\'evin Nguyen","Superluminal chaos after a quantum quench","42 pages, 8 figures, corrected typos, matches published version","JHEP 1912 (2019) 132","10.1007/JHEP12(2019)132",,"hep-th cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Thermal states holographically dual to black holes in Einstein gravity
display maximal Lyapunov growth as well as ""butterfly effect cones"". We study
these effects in highly non-equilibrium states, obtained from an initial
thermal state by the sudden injection of energy. We do this by computing
out-of-time-order correlators (OTOCs) in BTZ-Vaidya spacetimes, which describe
transitions between black holes at different temperatures. If both pairs of
boundary operators appearing in the OTOC are inserted before the energy
injection, we recover standard results, with butterfly effect cones displaying
a light-cone structure. But when one pair of operators is inserted before and
the other pair after the energy injection, the Lyapunov growth saturates the
chaos bounds set by the local temperatures and the butterfly effect cones ""open
up"", becoming superluminal, albeit in a way that does not violate causality. In
the limiting case, in which the initial state is the vacuum, Lyapunov growth
only starts after the energy injection. Our computations of the OTOCs are
phrased in terms of gravitationally interacting particles, where fields are
treated in a geodesic approximation and the eikonal phase shift is expressed in
terms of stress tensors and shock waves associated to geodesics.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:04 GMT""},{""version"":""v2"",""created"":""Fri, 3 Jan 2020 10:54:31 GMT""}]","2020-01-06"
"1908.08956","James Trayford Dr","James W. Trayford, Claudia del P. Lagos, Aaron S. G. Robotham, Danail
  Obreschkow","Fade to grey: systematic variation of the galaxy attenuation curves with
  galaxy properties in EAGLE","16 pages (incl. 4 appendix pages), 8 Figures. Submitted to MNRAS.
  Comments welcome!",,"10.1093/mnras/stz3234",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a simple model for galaxy attenuation by distilling SKIRT
radiative transfer calculations for ~100,000 EAGLE galaxies at redshifts z=2-0.
Our model adapts the two component screen model of Charlot & Fall (2000),
parametrising the optical depth and slope of the ISM screen using the average
dust surface density, $\Sigma_{\rm dust}$. We recover relatively tight
relations between these parameters for the EAGLE sample, but also provide the
scatter in these parameter owing to the morphological variation and orientation
of galaxies. We also find that these relations are nearly independent of
redshift in the EAGLE model. By pairing our model with an empirical
prescription for birth clouds below the resolution scale of the simulation, we
reproduce the observed relation between attenuation slope and optical depth for
the first time in a cosmological simulation. We demonstrate that this result is
remarkably independent of the attenuation properties assumed for birth cloud
screen, merely requiring a boosted attenuation for infant stars. We present
this model with a view to interpreting observations, as well as processing
semi-analytic models and other hydrodynamic simulations.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:05 GMT""}]","2020-01-08"
"1908.08957","Donovan Buterakos","Donovan Buterakos and Sankar Das Sarma","Coupled electron-impurity and electron-phonon systems as trivial
  non-Fermi liquids","13 pages","Phys. Rev. B 100, 235149 (2019)","10.1103/PhysRevB.100.235149",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider an electron gas, both in two (2D) and three (3D) dimensions,
interacting with quenched impurities and phonons within leading order
finite-temperature many body perturbation theories, calculating the electron
self-energies, spectral functions, and momentum distribution functions at
finite temperatures. The resultant spectral function is in general highly
non-Lorentzian, indicating that the system is not a Fermi liquid in the usual
sense. The calculated momentum distribution function cannot be approximated by
a Fermi function at any temperature, providing a rather simple example of a
non-Fermi liquid with well-understood properties.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:10 GMT""}]","2020-01-08"
"1908.08958","Max A. Metlitski","Max A. Metlitski","A 1d lattice model for the boundary of the quantum spin-Hall insulator",,,,,"cond-mat.str-el hep-th quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present a 1d lattice model that mimics the boundary of the conventional 2d
quantum spin-Hall insulator (QSHI) with $U(1)$ symmetry and time-reversal $T$,
satisfying $T^2 = (-1)^F$. Our construction utilizes a local tensor product
Hilbert space of finite site dimension with a non-onsite symmetry action. We
discuss how several signature properties of the QSHI, such as the fractional
charge on $T$-domain walls and Kramers parity switching upon $\pi$-flux
threading, are manifested in our treatment. We also present a 1d Hamiltonian
whose ground state realizes the conventional Luttinger-liquid phase of the QSHI
edge.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:11 GMT""}]","2019-08-27"
"1908.08959","Bryan Ostdiek","Layne Bradshaw, Rashmish K. Mishra, Andrea Mitridate, Bryan Ostdiek","Mass Agnostic Jet Taggers","25 pages, 15 figures, plus appendices. Prepared for submission to
  SciPost Physics",,"10.21468/SciPostPhys.8.1.011",,"hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Searching for new physics in large data sets needs a balance between two
competing effects---signal identification vs background distortion. In this
work, we perform a systematic study of both single variable and multivariate
jet tagging methods that aim for this balance. The methods preserve the shape
of the background distribution by either augmenting the training procedure or
the data itself. Multiple quantitative metrics to compare the methods are
considered, for tagging 2-, 3-, or 4-prong jets from the QCD background. This
is the first study to show that the data augmentation techniques of Planing and
PCA based scaling deliver similar performance as the augmented training
techniques of Adversarial NN and uBoost, but are both easier to implement and
computationally cheaper.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:19 GMT""},{""version"":""v2"",""created"":""Wed, 27 Nov 2019 00:27:26 GMT""}]","2020-02-25"
"1908.08960","Wojciech Kryscinski","Wojciech Kry\'sci\'nski, Nitish Shirish Keskar, Bryan McCann, Caiming
  Xiong, Richard Socher","Neural Text Summarization: A Critical Evaluation","To appear in EMNLP 2019, 13 pages, 2 figures, 6 tables",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Text summarization aims at compressing long documents into a shorter form
that conveys the most important parts of the original document. Despite
increased interest in the community and notable research effort, progress on
benchmark datasets has stagnated. We critically evaluate key ingredients of the
current research setup: datasets, evaluation metrics, and models, and highlight
three primary shortcomings: 1) automatically collected datasets leave the task
underconstrained and may contain noise detrimental to training and evaluation,
2) current evaluation protocol is weakly correlated with human judgment and
does not account for important characteristics such as factual correctness, 3)
models overfit to layout biases of current datasets and offer limited diversity
in their outputs.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:38 GMT""}]","2019-08-27"
"1908.08961","Max Tegmark","Max Tegmark (MIT), Tailin Wu (MIT)","Pareto-optimal data compression for binary classification tasks","Replaced to match version published in Entropy. 17 pages, 9 figs;
  improved discussion, comparison with Blahut-Arimoto method","Entropy (2020), 22, 7","10.3390/e22010007",,"cs.LG cs.CV cs.IT math.IT stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The goal of lossy data compression is to reduce the storage cost of a data
set $X$ while retaining as much information as possible about something ($Y$)
that you care about. For example, what aspects of an image $X$ contain the most
information about whether it depicts a cat? Mathematically, this corresponds to
finding a mapping $X\to Z\equiv f(X)$ that maximizes the mutual information
$I(Z,Y)$ while the entropy $H(Z)$ is kept below some fixed threshold. We
present a method for mapping out the Pareto frontier for classification tasks,
reflecting the tradeoff between retained entropy and class information. We
first show how a random variable $X$ (an image, say) drawn from a class
$Y\in\{1,...,n\}$ can be distilled into a vector $W=f(X)\in \mathbb{R}^{n-1}$
losslessly, so that $I(W,Y)=I(X,Y)$; for example, for a binary classification
task of cats and dogs, each image $X$ is mapped into a single real number $W$
retaining all information that helps distinguish cats from dogs. For the $n=2$
case of binary classification, we then show how $W$ can be further compressed
into a discrete variable $Z=g_\beta(W)\in\{1,...,m_\beta\}$ by binning $W$ into
$m_\beta$ bins, in such a way that varying the parameter $\beta$ sweeps out the
full Pareto frontier, solving a generalization of the Discrete Information
Bottleneck (DIB) problem. We argue that the most interesting points on this
frontier are ""corners"" maximizing $I(Z,Y)$ for a fixed number of bins
$m=2,3...$ which can be conveniently be found without multiobjective
optimization. We apply this method to the CIFAR-10, MNIST and Fashion-MNIST
datasets, illustrating how it can be interpreted as an
information-theoretically optimal image clustering algorithm.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:00:40 GMT""},{""version"":""v2"",""created"":""Wed, 15 Jan 2020 18:43:57 GMT""}]","2020-01-16"
"1908.08962","Iulia Turc","Iulia Turc, Ming-Wei Chang, Kenton Lee, Kristina Toutanova","Well-Read Students Learn Better: On the Importance of Pre-training
  Compact Models","Added comparison to concurrent work",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recent developments in natural language representations have been accompanied
by large and expensive models that leverage vast amounts of general-domain text
through self-supervised pre-training. Due to the cost of applying such models
to down-stream tasks, several model compression techniques on pre-trained
language representations have been proposed (Sun et al., 2019; Sanh, 2019).
However, surprisingly, the simple baseline of just pre-training and fine-tuning
compact models has been overlooked. In this paper, we first show that
pre-training remains important in the context of smaller architectures, and
fine-tuning pre-trained compact models can be competitive to more elaborate
methods proposed in concurrent work. Starting with pre-trained compact models,
we then explore transferring task knowledge from large fine-tuned models
through standard knowledge distillation. The resulting simple, yet effective
and general algorithm, Pre-trained Distillation, brings further improvements.
Through extensive experiments, we more generally explore the interaction
between pre-training and distillation under two variables that have been
under-studied: model size and properties of unlabeled task data. One surprising
observation is that they have a compound effect even when sequentially applied
on the same data. To accelerate future research, we will make our 24
pre-trained miniature BERT models publicly available.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:02:05 GMT""},{""version"":""v2"",""created"":""Wed, 25 Sep 2019 22:55:20 GMT""}]","2019-09-27"
"1908.08963","Yunong Shi","Yunong Shi, Runzhou Tao, Xupeng Li, Ali Javadi-Abhari, Andrew W.
  Cross, Frederic T. Chong, Ronghui Gu","CertiQ: A Mostly-automated Verification of a Realistic Quantum Compiler",,,,,"quant-ph cs.ET cs.PL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present CertiQ, a verification framework for writing and verifying
compiler passes of Qiskit, the most widely-used quantum compiler. To our
knowledge, CertiQ is the first effort enabling the verification of real-world
quantum compiler passes in a mostly-automated manner. Compiler passes written
in the CertiQ interface with annotations can be used to generate verification
conditions, as well as the executable code that can be integrated into Qiskit.
CertiQ introduces the quantum circuit calculus to enable the efficient checking
of equivalence of quantum circuits by encoding such a checking procedure into
an SMT problem. CertiQ also provides a verified library of widely-used data
structures, transformation functions for circuits, and conversion functions for
different quantum data representations. This verified library not only enables
modular verification but also sheds light on future quantum compiler design. We
have re-implemented and verified 26 (out of 30) Qiskit compiler passes in
CertiQ, during which three bugs are detected in the Qiskit implementation. Our
verified compiler pass implementations passed all of Qiskit's regression tests
without showing noticeable performance loss.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:02:17 GMT""},{""version"":""v2"",""created"":""Thu, 29 Aug 2019 02:59:04 GMT""},{""version"":""v3"",""created"":""Wed, 27 Nov 2019 19:38:44 GMT""},{""version"":""v4"",""created"":""Tue, 24 Nov 2020 04:26:32 GMT""},{""version"":""v5"",""created"":""Thu, 26 Nov 2020 14:09:35 GMT""}]","2020-11-30"
"1908.08964","Juan Carlos Criado","Juan Carlos Criado, Manuel Perez-Victoria","Vector-like quarks with non-renormalizable interactions","51 pages",,"10.1007/JHEP01(2020)057",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the impact of the leading non-renormalizable terms in the effective
field theory that describes general extensions of the Standard Model with
vector-like quarks. Dropping the usual assumption of renormalizability has
several phenomenological consequences for the production and decay of the heavy
quarks and also for Higgs physics. The most dramatic effects, including those
associated with a long lifetime, occur for vector-like quarks with non-standard
quantum numbers.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:06:22 GMT""}]","2020-01-29"
"1908.08966","Syed Hashim Ali Shah","Syed Hashim Ali Shah, Sundar Aditya, Sourjya Dutta, Christopher Slezak
  and Sundeep Rangan","Power Efficient Discontinuous Reception in THz and mmWave Wireless
  Systems","The paper has been accepted and presented at IEEE SPAWC 2019. It is
  yet to be published on IEEE Xplore",,,,"eess.SP","http://creativecommons.org/licenses/by/4.0/","  Discontinuous reception (DRX), where a user equip-ment (UE) temporarily
disables its receiver, is a critical power saving feature in modern cellular
systems. DRX is likely tobe particularly aggressively used in the mmWave and
THzfrequencies due to the high front end power consumption. A keychallenge of
DRX in these frequencies is that individual links are directional and highly
susceptible to blockage. MmWave and THz UEs will therefore likely need to
monitor multiple cells in multiple directions to ensure continuous reliable
connectivity.This work proposes a novel, heuristic algorithm to dynamically
select the cells to monitor to attempt to optimally trade-off link reliability
and power consumption. The paper provides preliminary estimates of connected
mode DRX mode consumption using detailed and realistic statistical models of
blockers at both 28 and 140 GHz. It is found that although blockage dynamics
are faster at 140 GHz, reliable connectivity at low power can be maintained
with sufficient macro-diversity and link prediction
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:15:47 GMT""}]","2019-08-27"
"1908.08967","Lianrong Dai","L. R. Dai and E. Oset","Helicity amplitudes in the $\bar{B} \to D^{*} \bar{\nu}_\tau \tau$ decay
  with $V-A$ breaking in the quark sector","9 pages, 5 figures, 1 table",,"10.1140/epja/s10050-020-00160-6",,"hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In view of the recent measurement of the $F_L^{D^*}$ magnitude in the
$\bar{B} \to D^{*} \bar{\nu}_\tau \tau$ reaction we evaluate this magnitude
within the standard model and for a family of models with the $\gamma^\mu
-\alpha\gamma^\mu \gamma_5$ current structure for the quarks for different
values of $\alpha$. At the same time we evaluate also the transverse
contributions, $M=-1$, $M=+1$, and find that the difference between the $M=-1$
and $M=+1$ contributions is far more sensitive to changes in $\alpha$ than the
longitudinal component.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:20:43 GMT""},{""version"":""v2"",""created"":""Thu, 29 Aug 2019 21:03:18 GMT""}]","2020-06-24"
"1908.08968","Carlos Ivan Henao Osorio","Ivan Henao, Raam Uzdin and Nadav Katz","Experimental detection of microscopic environments using thermodynamic
  observables","In the new version we show efficient (polynomial) scalability of the
  tests with respect to the size of the system",,,,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Modern thermodynamic theories can be used to study highly complex quantum
dynamics. Here, we experimentally demonstrate that the violation of
thermodynamic constraints allows to detect the coupling of a quantum system to
a hidden environment. By using the IBM quantum superconducting processors, we
perform thermodynamic tests to detect a qubit environment interacting with a
system composed of up to four qubits. The experiments are complemented by
theoretical findings that show efficient scalability of the tests with respect
to system size. Hence, they may be useful to detect an open system dynamics in
situations where other methods (e.g. quantum state tomography) are practically
infeasible.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:26:27 GMT""},{""version"":""v2"",""created"":""Wed, 19 Aug 2020 21:13:27 GMT""},{""version"":""v3"",""created"":""Tue, 9 Mar 2021 12:20:41 GMT""}]","2021-03-10"
"1908.08969","John Zhang H","John Hongguang Zhang","Studies of Bi-layers Growth Mechanism of Silver Bromide Molecular
  Clusters Prepared Via Electroporation of Vesicles and Quantum Confinement
  Effects Applications of Molecular Clusters","32 pages, 11 figures, 2 tables",,,,"physics.chem-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Our previous work show that in the molecular cluster regime, the band blue
shift associated with cluster growth can be understood by a model that assume
electrons are confined to a spherical potential well and the clusters are made
of some basic units. A formula is given for the lowest excited electronic state
energy. This expression contains an electron-hole-pair (EHP) delocalization
constant as an adjustable parameter which, however, can be anchored to a
definite value through the known transition energy at the spectra turn-around
point. We also proposed symmetry and probability principles in molecular
cluster growth range to explain the molecular cluster electron absorption
spectra turn-around phenomena and unusual isotopic properties of small silver
bromide clusters. In this paper, based on systematical review of Quasi-Elastic
Light Scattering (QELS), Fourier-transform infrared spectroscopy (FTIR) and
Direct Laser Desorption Mass Spectra (DLD-MS) experiments of silver bromide
clusters prepared via the electroporation of vesicles, we show how the symmetry
and probability principles in molecular cluster growth range can be used to
explain the lager silver bromide molecular cluster formation in a bilayer
formation mechanism. The turn round curve of energy gap vs confine sphere size
had been proved to be a right curve to describe the molecular cluster quantum
confinement behavior. We also defined Electron Delocalized Status (EDS),
Electron Localized Status (ELS), and EDS/ELS switch or quantum confinement
switch (QCS) in the quantum confine system. These studies pave the theoretical
and technical ways for advanced device technology continue shrink and new
concept device generation in the atomic and molecular cluster size range.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:27:36 GMT""}]","2019-08-27"
"1908.08970","Bruce Cox","Zachary T. Hornberger, Bruce A. Cox, and Brian J. Lunday","Optimal Heterogeneous Asset Location Modeling for Expected
  Spatiotemporal Search and Rescue Demands using Historic Event Data","Preprint version, submitted to IISE Transactions on 17 April 2019",,,,"math.OC stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The United States Coast Guard is charged with the coordination of all search
and rescue missions in maritime regions within the United States purview. Given
the size of the Pacific Ocean and the limited resources available to respond to
search and rescue missions in this region, the service seeks to posture its
aligned fleet of maritime and aeronautical assets to reduce the expected
response time for such missions. Leveraging historic event records for the
region of interest, we propose and demonstrate a two-stage solution approach.
In the first stage, we develop and apply a stochastic zonal distribution model
to evaluate spatiotemporal trends for emergency event rates and corresponding
response strategies to inform the probabilistic modeling of future rescue
events respective locations, frequencies, and demands for support. In the
second stage, the results from the aforementioned analysis enable the
parameterization and solution of a integer linear programming formulation to
identify the best locations at which to station limited heterogeneous search
and rescue assets. Considering both the 50th and 75th percentile levels of
forecast event and asset demand distributions using 7.5 years of historical
event data, our models identify asset location strategies that respectively
yield a 9.6 percent and 17.6 percent increase in coverage over current asset
basing when allowing locations among current homeports and airports, as well as
respective 67.3 percent and 57.4 percent increases in coverage when considering
a larger set of feasible basing locations.
  Keywords: search and rescue, spatiotemporal forecasting, location-allocation
modeling, p-median location problem, multi-objective optimization
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:31:31 GMT""}]","2019-08-27"
"1908.08971","Hilaria Cruz","Hilaria Cruz, Joseph Waring","Deploying Technology to Save Endangered Languages",,,,,"cs.CL","http://creativecommons.org/licenses/by-sa/4.0/","  Computer scientists working on natural language processing, native speakers
of endangered languages, and field linguists to discuss ways to harness
Automatic Speech Recognition, especially neural networks, to automate
annotation, speech tagging, and text parsing on endangered languages.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:31:35 GMT""},{""version"":""v2"",""created"":""Sun, 1 Sep 2019 02:39:09 GMT""}]","2019-09-04"
"1908.08972","Juan Maro\~nas","Juan Maro\~nas and Roberto Paredes and Daniel Ramos","Calibration of Deep Probabilistic Models with Decoupled Bayesian Neural
  Networks","Submit to Neurocomputing",,"10.1016/j.neucom.2020.04.103",,"cs.LG stat.ML","http://creativecommons.org/publicdomain/zero/1.0/","  Deep Neural Networks (DNNs) have achieved state-of-the-art accuracy
performance in many tasks. However, recent works have pointed out that the
outputs provided by these models are not well-calibrated, seriously limiting
their use in critical decision scenarios. In this work, we propose to use a
decoupled Bayesian stage, implemented with a Bayesian Neural Network (BNN), to
map the uncalibrated probabilities provided by a DNN to calibrated ones,
consistently improving calibration. Our results evidence that incorporating
uncertainty provides more reliable probabilistic models, a critical condition
for achieving good calibration. We report a generous collection of experimental
results using high-accuracy DNNs in standardized image classification
benchmarks, showing the good performance, flexibility and robust behavior of
our approach with respect to several state-of-the-art calibration methods. Code
for reproducibility is provided.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:35:48 GMT""},{""version"":""v2"",""created"":""Wed, 25 Sep 2019 13:18:52 GMT""},{""version"":""v3"",""created"":""Fri, 28 Feb 2020 15:18:08 GMT""}]","2020-07-16"
"1908.08973","Klaus Lehnertz","Theresa Wilkat and Thorsten Rings and Klaus Lehnertz","No evidence for critical slowing down prior to human epileptic seizures","6 pages, 3 figures","Chaos 29, 033115, 2019","10.1063/1.5122759",,"physics.med-ph physics.bio-ph q-bio.NC","http://creativecommons.org/licenses/by/4.0/","  There is a ongoing debate whether generic early warning signals for critical
transitions exist that can be applied across diverse systems. The human
epileptic brain is often considered as a prototypical system, given the
devastating and, at times, even life-threatening nature of the extreme event
epileptic seizure. More than three decades of international effort has
successfully identified predictors of imminent seizures. However, the
suitability of typically applied early warning indicators for critical slowing
down, namely variance and lag-1 autocorrelation, for indexing seizure
susceptibility is still controversially discussed. Here, we investigated
long-term, multichannel recordings of brain dynamics from 28 subjects with
epilepsy. Using a surrogate-based evaluation procedure of sensitivity and
specificity of time-resolved estimates of early warning indicators, we found no
evidence for critical slowing down prior to 105 epileptic seizures.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:37:03 GMT""}]","2019-10-23"
"1908.08974","Michael Bartram","F. Michael Bartram, Sopheak Sorn, Zhuolu Li, Kyle Hwangbo, Shengchun
  Shen, Felix Frontini, Liqun He, Pu Yu, Arun Paramekanti, Luyi Yang","Anomalous Kerr Effect in SrRuO$_3$ Thin Films",,"Phys. Rev. B 102, 140408 (2020)","10.1103/PhysRevB.102.140408",,"cond-mat.str-el cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the magneto-optical Kerr effect (MOKE) in SrRuO$_3$ thin films,
uncovering wide regimes of wavelength, temperature, and magnetic field where
the Kerr rotation is not simply proportional to the magnetization but instead
displays two-component behavior. One component of the MOKE signal tracks the
average magnetization, while the second ""anomalous"" component bears a
resemblance to anomalies in the Hall resistivity which have been previously
reported in skyrmion materials. We present a theory showing that the MOKE
anomalies arise from the non-monotonic relation between the Kerr angle and the
magnetization, when we average over magnetic domains which proliferate near the
coercive field. Our results suggest that inhomogeneous domain formation, rather
than skyrmions, may provide a common origin for the observed MOKE and Hall
resistivity anomalies.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:49:12 GMT""},{""version"":""v2"",""created"":""Sat, 10 Oct 2020 05:52:05 GMT""}]","2020-11-04"
"1908.08975","Sergei Parkhomenko","S.E. Parkhomenko","Generalized K$\ddot{a}$hler Geometry in Kazama-Suzuki coset models","LaTex, 11 pages, minor changes, misprints corrected",,"10.1016/j.physletb.2020.135346",,"hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is shown that Kazama-Suzuki conditions for the denominator subgroup of N=2
superconformal $G/H$ coset model determine Generalized K$\ddot{a}$hler geometry
on the target space of the corresponding N=2 supersymmetric $\sigma$-model.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:56:20 GMT""},{""version"":""v2"",""created"":""Sat, 31 Aug 2019 09:02:18 GMT""},{""version"":""v3"",""created"":""Wed, 4 Dec 2019 22:38:59 GMT""},{""version"":""v4"",""created"":""Thu, 27 Feb 2020 18:49:00 GMT""},{""version"":""v5"",""created"":""Mon, 30 Mar 2020 17:31:29 GMT""}]","2020-03-31"
"1908.08976","Udit Gupta","Udit Gupta, Brandon Reagen, Lillian Pentecost, Marco Donato, Thierry
  Tambe, Alexander M. Rush, Gu-Yeon Wei, David Brooks","MASR: A Modular Accelerator for Sparse RNNs",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Recurrent neural networks (RNNs) are becoming the de facto solution for
speech recognition. RNNs exploit long-term temporal relationships in data by
applying repeated, learned transformations. Unlike fully-connected (FC) layers
with single vector matrix operations, RNN layers consist of hundreds of such
operations chained over time. This poses challenges unique to RNNs that are not
found in convolutional neural networks (CNNs) or FC models, namely large
dynamic activation. In this paper we present MASR, a principled and modular
architecture that accelerates bidirectional RNNs for on-chip ASR. MASR is
designed to exploit sparsity in both dynamic activations and static weights.
The architecture is enhanced by a series of dynamic activation optimizations
that enable compact storage, ensure no energy is wasted computing null
operations, and maintain high MAC utilization for highly parallel accelerator
designs. In comparison to current state-of-the-art sparse neural network
accelerators (e.g., EIE), MASR provides 2x area 3x energy, and 1.6x performance
benefits. The modular nature of MASR enables designs that efficiently scale
from resource-constrained low-power IoT applications to large-scale, highly
parallel datacenter deployments.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:58:07 GMT""}]","2019-08-27"
"1908.08977","Piero Triverio","Piero Triverio","Vector Fitting","This work is a draft of the book chapter P. Triverio, ""Vector
  Fitting"" that will be part of the ""Handbook on Model Order Reduction"" edited
  by P. Benner, S. Grivet-Talocia, A. Quarteroni, G. Rozza, W. H. A. Schilders,
  L. M. Silveira, to appear for De Gruyter",,,,"physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce the Vector Fitting algorithm for the creation of reduced-order
models from the sampled response of a linear time-invariant system. This
data-driven approach to reduction is particularly useful when the system under
modeling is known only through experimental measurements. The theory behind
Vector Fitting is presented for single- and multiple-input systems, together
with numerical details, pseudocodes, and an open-source implementation. We
discuss how the reduced model can be made stable and converted to a variety of
forms for use in virtually any modeling context. Finally, we survey recent
extensions of the Vector Fitting algorithm geared towards time-domain,
parametric and distributed systems modeling.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:58:45 GMT""}]","2019-08-27"
"1908.08978","Dan Rutherford","Justin Murray and Dan Rutherford","Legendrian DGA Representations and the Colored Kauffman Polynomial",,"SIGMA 16 (2020), 017, 33 pages","10.3842/SIGMA.2020.017",,"math.SG math.GT math.QA","http://creativecommons.org/licenses/by-sa/4.0/","  For any Legendrian knot $K$ in standard contact ${\mathbb R}^3$ we relate
counts of ungraded ($1$-graded) representations of the Legendrian contact
homology DG-algebra $(\mathcal{A}(K),\partial)$ with the $n$-colored Kauffman
polynomial. To do this, we introduce an ungraded $n$-colored ruling polynomial,
$R^1_{n,K}(q)$, as a linear combination of reduced ruling polynomials of
positive permutation braids and show that (i) $R^1_{n,K}(q)$ arises as a
specialization $F_{n,K}(a,q)\big|_{a^{-1}=0}$ of the $n$-colored Kauffman
polynomial and (ii) when $q$ is a power of two $R^1_{n,K}(q)$ agrees with the
total ungraded representation number, $\operatorname{Rep}_1\big(K,
\mathbb{F}_q^n\big)$, which is a normalized count of $n$-dimensional
representations of $(\mathcal{A}(K),\partial)$ over the finite field
$\mathbb{F}_q$. This complements results from [Leverson C., Rutherford D.,
Quantum Topol. 11 (2020), 55-118, arXiv:1802.10531] concerning the colored
HOMFLY-PT polynomial, $m$-graded representation numbers, and $m$-graded ruling
polynomials with $m \neq 1$.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:59:54 GMT""},{""version"":""v2"",""created"":""Sun, 22 Mar 2020 07:04:30 GMT""}]","2020-03-24"
"1908.08979","Mimansa Jaiswal","Mimansa Jaiswal, Zakaria Aldeneh, Emily Mower Provost","Controlling for Confounders in Multimodal Emotion Classification via
  Adversarial Learning","10 pages, ICMI 2019",,"10.1145/3340555.3353731",,"cs.LG cs.CL cs.SD eess.AS stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Various psychological factors affect how individuals express emotions. Yet,
when we collect data intended for use in building emotion recognition systems,
we often try to do so by creating paradigms that are designed just with a focus
on eliciting emotional behavior. Algorithms trained with these types of data
are unlikely to function outside of controlled environments because our
emotions naturally change as a function of these other factors. In this work,
we study how the multimodal expressions of emotion change when an individual is
under varying levels of stress. We hypothesize that stress produces modulations
that can hide the true underlying emotions of individuals and that we can make
emotion recognition algorithms more generalizable by controlling for variations
in stress. To this end, we use adversarial networks to decorrelate stress
modulations from emotion representations. We study how stress alters acoustic
and lexical emotional predictions, paying special attention to how modulations
due to stress affect the transferability of learned emotion recognition models
across domains. Our results show that stress is indeed encoded in trained
emotion classifiers and that this encoding varies across levels of emotions and
across the lexical and acoustic modalities. Our results also show that emotion
recognition models that control for stress during training have better
generalizability when applied to new domains, compared to models that do not
control for stress during training. We conclude that is is necessary to
consider the effect of extraneous psychological factors when building and
testing emotion recognition models.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:00:18 GMT""}]","2019-08-27"
"1908.08980","Edward Wheatcroft","Edward Wheatcroft","Evaluating probabilistic forecasts of football matches: The case against
  the Ranked Probability Score",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A scoring rule is a function of a probabilistic forecast and a corresponding
outcome that is used to evaluate forecast performance. A wide range of scoring
rules have been defined over time and there is some debate as to which are the
most appropriate for evaluating the performance of forecasts of sporting
events. This paper focuses on forecasts of the outcomes of football matches.
The ranked probability score (RPS) is often recommended since it is `sensitive
to distance', that is it takes into account the ordering in the outcomes (a
home win is `closer' to a draw than it is to an away win, for example). In this
paper, this reasoning is disputed on the basis that it adds nothing in terms of
the actual aims of using scoring rules. A related property of scoring rules is
locality. A scoring rule is local if it only takes the probability placed on
the outcome into consideration. Two simulation experiments are carried out in
the context of football matches to compare the performance of the RPS, which is
non-local and sensitive to distance, the Brier score, which is non-local and
insensitive to distance, and the ignorance score, which is local and
insensitive to distance. The ignorance score is found to outperform both the
RPS and the Brier score, casting doubt on the value of non-locality and
sensitivity to distance as properties of scoring rules in this context.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:04:03 GMT""}]","2019-08-27"
"1908.08981","Thomas F\""uhrer","Thomas F\""uhrer","Ultraweak formulation of linear PDEs in nondivergence form and DPG
  approximation",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop and analyze an ultraweak formulation of linear PDEs in
nondivergence form where the coefficients satisfy the Cordes condition. Based
on the ultraweak formulation we propose discontinuous Petrov--Galerkin (DPG)
methods. We investigate Fortin operators for the fully discrete schemes and
provide a posteriori estimators for the methods under consideration. Numerical
experiments are presented in the case of uniform and adaptive mesh-refinement.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:07:24 GMT""}]","2019-08-27"
"1908.08982","Ilyes Naidji","Ilyes Naidji, Moncef Ben Smida, Mohamed Khalgui, Abdelmalik Bachir","Non Cooperative Game Theoretic Approach for Residential Energy
  Management in Smart Grid","The 32nd Annual European Simulation and Modelling Conference","in Proc. ESM conference 32 (2018) 164-170",,,"eess.SY cs.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Demand side management (DSM) is one of the main functionalities of the smart
grid as it allows the consumer to adjust its energy consumption for an
efficient energy management. Most of the existing DSM techniques aim at
minimizing the energy cost while not considering the comfort of consumers.
Therefore, maintaining a trade-off between these two conflicting objectives is
still a challenging task. This paper proposes a novel DSM approach for
residential consumers based on a non-cooperative game theoretic approach, where
each player is encouraged to reshape its electricity consumption pattern
through the dynamic pricing policy applied by the smart grid operator. The
players are guided to select the best strategy that consists of scheduling
their electric appliances in order to minimize the daily energy cost and their
discomfort level. The Nash Equilibrium of the energy management game is
achieved using Non-Sorting Genetic Algorithm NSGA-II. Simulation results show
the effectiveness of the distributed non cooperative game approach for the
residential energy management problem where an appreciable energy cost
reduction is reached while maintaining the discomfort in an acceptable level.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:09:05 GMT""}]","2019-09-04"
"1908.08983","Aditi Chaudhary","Aditi Chaudhary, Jiateng Xie, Zaid Sheikh, Graham Neubig, Jaime G.
  Carbonell","A Little Annotation does a Lot of Good: A Study in Bootstrapping
  Low-resource Named Entity Recognizers","Accepted at EMNLP 2019",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Most state-of-the-art models for named entity recognition (NER) rely on the
availability of large amounts of labeled data, making them challenging to
extend to new, lower-resourced languages. However, there are now several
proposed approaches involving either cross-lingual transfer learning, which
learns from other highly resourced languages, or active learning, which
efficiently selects effective training data based on model predictions. This
paper poses the question: given this recent progress, and limited human
annotation, what is the most effective method for efficiently creating
high-quality entity recognizers in under-resourced languages? Based on
extensive experimentation using both simulated and real human annotation, we
find a dual-strategy approach best, starting with a cross-lingual transferred
model, then performing targeted annotation of only uncertain entity spans in
the target language, minimizing annotator effort. Results demonstrate that
cross-lingual transfer is a powerful tool when very little data can be
annotated, but an entity-targeted annotation strategy can achieve competitive
accuracy quickly, with just one-tenth of training data.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:15:07 GMT""}]","2019-08-27"
"1908.08991","Taha Yasseri","Victor Martins Maimone and Taha Yasseri","Football is becoming more predictable; Network analysis of 88 thousands
  matches in 11 major leagues","revised version - before publication in Royal Society Open Sciecne","Royal Society Open Science, 8(12), 210617 (2021)","10.1098/rsos.210617",,"physics.soc-ph cs.SI stat.OT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years excessive monetization of football and professionalism among
the players has been argued to have affected the quality of the match in
different ways. On the one hand, playing football has become a high-income
profession and the players are highly motivated; on the other hand, stronger
teams have higher incomes and therefore afford better players leading to an
even stronger appearance in tournaments that can make the game more imbalanced
and hence predictable. To quantify and document this observation, in this work
we take a minimalist network science approach to measure the predictability of
football over 26 years in major European leagues. We show that over time, the
games in major leagues have indeed become more predictable. We provide further
support for this observation by showing that inequality between teams has
increased and the home-field advantage has been vanishing ubiquitously. We do
not include any direct analysis on the effects of monetization on football's
predictability or therefore, lack of excitement, however, we propose several
hypotheses which could be tested in future analyses.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:25:02 GMT""},{""version"":""v2"",""created"":""Wed, 6 Jul 2022 14:22:49 GMT""}]","2023-01-05"
"1908.08999","Tomas Jenicek","Tomas Jenicek and Ond\v{r}ej Chum","No Fear of the Dark: Image Retrieval under Varying Illumination
  Conditions",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image retrieval under varying illumination conditions, such as day and night
images, is addressed by image preprocessing, both hand-crafted and learned.
Prior to extracting image descriptors by a convolutional neural network, images
are photometrically normalised in order to reduce the descriptor sensitivity to
illumination changes. We propose a learnable normalisation based on the U-Net
architecture, which is trained on a combination of single-camera multi-exposure
images and a newly constructed collection of similar views of landmarks during
day and night. We experimentally show that both hand-crafted normalisation
based on local histogram equalisation and the learnable normalisation
outperform standard approaches in varying illumination conditions, while
staying on par with the state-of-the-art methods on daylight illumination
benchmarks, such as Oxford or Paris datasets.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:30:37 GMT""}]","2019-08-27"
"1908.09004","Angela Capel","Ivan Bardet, Angela Capel, Angelo Lucia, David P\'erez-Garc\'ia and
  Cambyse Rouz\'e","On the modified logarithmic Sobolev inequality for the heat-bath
  dynamics for 1D systems","28 pages, 4 figures. Included some additional comments and updated
  results in light of recent advances in the literature","Journal of Mathematical Physics 62 (6), 061901 (2021)","10.1063/1.5142186",,"quant-ph cond-mat.stat-mech math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The mixing time of Markovian dissipative evolutions of open quantum many-body
systems can be bounded using optimal constants of certain quantum functional
inequalities, such as the modified logarithmic Sobolev constant. For classical
spin systems, the positivity of such constants follows from a mixing condition
for the Gibbs measure, via quasi-factorization results for the entropy.
  Inspired by the classical case, we present a strategy to derive the
positivity of the modified logarithmic Sobolev constant associated to the
dynamics of certain quantum systems from some clustering conditions on the
Gibbs state of a local, commuting Hamiltonian. In particular we show that for
the heat-bath dynamics for 1D systems, the modified logarithmic Sobolev
constant is positive under the assumptions of a mixing condition on the Gibbs
state and a strong quasi-factorization of the relative entropy.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:32:09 GMT""},{""version"":""v2"",""created"":""Tue, 15 Jun 2021 14:51:57 GMT""}]","2021-08-03"
"1908.09008","Apratim Bhattacharyya","Apratim Bhattacharyya, Michael Hanselmann, Mario Fritz, Bernt Schiele,
  Christoph-Nikolas Straehle","Conditional Flow Variational Autoencoders for Structured Sequence
  Prediction","To appear at Bayesian Deep Learning and Machine Learning for
  Autonomous Driving @NeurIPS 2019",,,,"cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Prediction of future states of the environment and interacting agents is a
key competence required for autonomous agents to operate successfully in the
real world. Prior work for structured sequence prediction based on latent
variable models imposes a uni-modal standard Gaussian prior on the latent
variables. This induces a strong model bias which makes it challenging to fully
capture the multi-modality of the distribution of the future states. In this
work, we introduce Conditional Flow Variational Autoencoders (CF-VAE) using our
novel conditional normalizing flow based prior to capture complex multi-modal
conditional distributions for effective structured sequence prediction.
Moreover, we propose two novel regularization schemes which stabilizes training
and deals with posterior collapse for stable training and better fit to the
target data distribution. Our experiments on three multi-modal structured
sequence prediction datasets -- MNIST Sequences, Stanford Drone and HighD --
show that the proposed method obtains state of art results across different
evaluation metrics.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 08:02:34 GMT""},{""version"":""v2"",""created"":""Tue, 8 Oct 2019 10:44:50 GMT""},{""version"":""v3"",""created"":""Tue, 18 Aug 2020 09:55:31 GMT""}]","2020-08-19"
"1908.09011","Merlin von Soosten","Merlin von Soosten, Dennis Valbj{\o}rn Christensen, Chang-Beom Eom,
  Thomas Sand Jespersen, Yunzhong Chen, Nini Pryds","On the emergence of conductivity at SrTiO3-based oxide interfaces -- an
  in-situ study",,,,,"cond-mat.mtrl-sci","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Heterostructures and crystal interfaces play a major role in state-of-the-art
semiconductor devices and play a central role in the field of oxide
electronics. In oxides the link between the microscopic properties of the
interfaces and bulk properties of the resulting heterostructures challenge our
fundamental understanding. Insights on the early growth stage of interfaces and
its influence on resulting physical properties are scarce -- typically the
information is inferred from post growth characterization. Here, we report on
real time measurements of the transport properties of SrTiO3-based
heterostructures while the crystal heterostructure is forming. Surprisingly, we
detect a conducting interface already at the initial growth stage, much earlier
than the well-established critical thickness limit for observing conductivity
ex-situ after sample growth. We investigate how the conductivity depends on
various physical processes occurring during pulsed laser depositions, including
light illumination, particle bombardment by the plasma plume, interactions with
the atmosphere and oxygen migration from SrTiO3 to the thin films of varying
compositions. Using this approach, we propose a new design tool to control the
electrical properties of interfaces in real time during their formation.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:39:51 GMT""}]","2019-08-27"
"1908.09012","Bruce Watson","Wen-Chi Kuo, David F. Rodda and Bruce A. Watson","The H\'ajek-R\'enyi-Chow maximal inequality and a strong law of large
  numbers in Riesz spaces",,,,,"math.FA math.PR math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we generalize the H\'ajek-R\'enyi-Chow maximal inequality for
submartingales to $L^p$ type Riesz spaces with conditional expectation
operators. As applications we obtain a submartingale convergence theorem and a
strong law of large numbers in Riesz spaces. Along the way we develop a Riesz
space variant of the Clarkson's inequality for $1\le p\le 2$.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:41:18 GMT""}]","2019-08-27"
"1908.09013","Meng-Qiang Zhao","Srinivas V. Mandyam, Meng Qiang Zhao, Paul Masih Das, Qicheng Zhang,
  Christopher C. Price, Zhaoli Gao, Vivek B. Shenoy, Marija Drndic, Alan T.
  Charlie Johnson","Controlled Growth of Large-Area Bilayer Tungsten Diselenides with
  Lateral P-N Junctions",,,"10.1021/acsnano.9b04453",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Bilayer two-dimensional (2D) van der Waals (vdW) materials are attracting
increasing attention due to their predicted high quality electronic and optical
properties. Here we demonstrate dense, selective growth of WSe2 bilayer flakes
by chemical vapor deposition with the use of a 1:10 molar mixture of sodium
cholate and sodium chloride as the growth promoter to control the local
diffusion of W-containing species. A large fraction of the bilayer WSe2 flakes
showed a 0 and 60o twist between the two layers, while moire 15 and 30o-twist
angles were also observed. Well-defined monolayer-bilayer junctions were formed
in the as-grown bilayer WSe2 flakes, and these interfaces exhibited p-n diode
rectification and an ambipolar transport characteristic. This work provides an
efficient method for the layer-controlled growth of 2D materials, in
particular, 2D transition metal dichalcogenides and promotes their applications
in next-generation electronic and optoelectronic devices.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:45:06 GMT""}]","2019-08-27"
"1908.09014","Brenda Rubenstein","Rong Cong, Ravindra Nanguneri, Brenda M. Rubenstein, and V. F.
  Mitrovic","First Principles calculations of the EFG tensors of Ba$_2$NaOsO$_6$, a
  Mott insulator with strong spin orbit coupling","11 pages, Submitted to Physical Review B",,"10.1103/PhysRevB.100.245141",,"cond-mat.str-el cond-mat.mtrl-sci cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We present first principles calculations of the electrostatic properties of
Ba$_2$NaOsO$_6$ (BNOO), a 5$d^1$ Mott insulator with strong spin orbit coupling
(SOC) in its low temperature quantum phases. In light of recent NMR experiments
showing that BNOO develops a local octahedral distortion that is accompanied by
the emergence of an electric field gradient (EFG) and precedes the formation of
long range magnetic order [Lu et al., Nature Comm. 8, 14407 (2017), Liu et al.,
Phys. Rev. B. 97, 224103 (2018), Liu et al., Physica B. 536, 863 (2018)], we
calculated BNOO's EFG tensor for several different model distortions. The local
orthorhombic distortion that we identified as mostly strongly agreeing with
experiment corresponds to a Q2 distortion mode of the Na-O octahedra, in
agreement with conclusions given in [Liu et al., Phys. Rev. B. 97, 224103
(2018)]. Furthermore, we found that the EFG is insensitive to the type of
underlying magnetic order. By combining NMR results with first principles
modeling, we have thus forged a more complete understanding of BNOO's
structural and magnetic properties, which could not be achieved based upon
experiment or theory alone.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:50:37 GMT""}]","2020-01-29"
"1908.09015","Hien Truong","Hien Thi Thu Truong, Miguel Almeida, Ghassan Karame, Claudio Soriente","Towards Secure and Decentralized Sharing of IoT Data",,,,,"cs.DC cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Internet of Things (IoT) bears unprecedented security and scalability
challenges due to the magnitude of data produced and exchanged by IoT devices
and platforms. Some of those challenges are currently being addressed by
coupling IoT applications with blockchains. However, current blockchain-backed
IoT systems simply use the blockchain to store access control policies, thereby
underutilizing the power of blockchain technology. In this paper, we propose a
new framework named Sash that couples IoT platforms with blockchain that
provides a number of advantages compared to state of the art. In Sash, the
blockchain is used to store access control policies and take access control
decisions. Therefore, both changes to policies and access requests are
correctly enforced and publicly auditable. Further, we devise a ``data
marketplace'' by leveraging the ability of blockchains to handle financial
transaction and providing ``by design'' remuneration to data producers.
Finally, we exploit a special flavor of identity-based encryption to cater for
cryptography-enforced access control while minimizing the overhead to
distribute decryption keys. We prototype Sash by using the FIWARE open source
IoT platform and the Hyperledger Fabric framework as the blockchain back-end.
We also evaluate the performance of our prototype and show that it incurs
tolerable overhead in realistic deployment settings.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:50:40 GMT""}]","2019-08-27"
"1908.09016","Alena Nechaeva","I.V. Zimovets (1), A.B. Nechaeva (1 and 2), I.N. Sharykin (1), W.Q.
  Gan (3) ((1) Space Research Institute of the Russian Academy of Sciences, (2)
  Moscow Institute of Physics and Technology, (3) Purple Mountain Observatory
  of the Chinese Academy of Sciences)","Density distribution of photospheric vertical electric currents in flare
  active regions of the Sun","14 pages, 7 figures",,,,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solar active regions contain electric currents. Information on the
distribution of currents is important for understanding the processes of energy
release on the surface of the Sun and in the overlying layers. The paper
presents an analysis of the probability density function (PDF) of the absolute
value of the photospheric vertical electric current density ($|j_z|$) in 48
active regions before and after flares in 2010--2017. Calculation of $|j_z|$ is
performed by applying the differential form of Ampere's circuital law to
photospheric vector magnetograms obtained from observations of the Helioseismic
and Magnetic Imager (HMI) instrument onboard the Solar Dynamics Observatory
(SDO). It has been established that for the studied active regions PDF($|j_z|$)
is described by the Gauss function in the low-$|j_z|$ region ($|j_z| < 10110
\pm 1321$ statampere/cm$^2$) and the decaying power-law function in the region
of higher $|j_z|$ values. Also, for some active regions PDF($|j_z|$) can be
described by the special kappa-function. The distributions of the parameters of
the approximating functions are obtained using the least squares method. The
average absolute value of the power-law function index is $3.69 \pm 0.51$, and
$3.99 \pm 0.51$ of the kappa-function. No systematic changes in parameters
during the flares are detected. An explicit connection between the parameters
and the flare X-ray class, as well as with the Hale magnetic class of the
active regions, is not found. Arguments are presented in favor of the
suggestion that the Gaussian distribution in the low-value region of
PDF($|j_z|$) represents noise in the data, while the power-law ""tail"" reflects
the nature of electric currents in the solar active regions.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:55:03 GMT""}]","2019-08-27"
"1908.09017","Laurie Rousseau-Nepton","L. Rousseau-Nepton, R. P. Martin, C. Robert, L. Drissen, P. Amram, S.
  Prunet, T. Martin, I. Moumen, A. Adamo, A. Alarie, P. Barmby, A. Boselli, F.
  Bresolin, M. Bureau, L. Chemin, R. C. Fernandes, F. Combes, C. Crowder, L.
  Della Bruna, F. Egusa, B. Epinat, V. F. Ksoll, M. Girard, V. G\'omez Llanos,
  D. Gouliermis, K. Grasha, C. Higgs, J. Hlavacek-Larrondo, I.-T. Ho, J.
  Iglesias-P\'aramo, G. Joncas, Z. S. Kam, P. Karera, R. C. Kennicutt, R. S.
  Klessen, S. Lianou, L. Liu, Q. Liu, A. Luiz de Amorim, J. D. Lyman, H.
  Martel, B. Mazzilli-Ciraulo, A. F. McLeod, A-L. Melchior, I. Millan, M.
  Moll\'a, R. Momose, C. Morisset, H.-A. Pan, A. K. Pati, A. Pellerin, E.
  Pellegrini, I. P\'erez, A. Petric, H. Plana, D. Rahner, T. Ruiz Lara, L.
  S\'anchez-Menguiano, K. Spekkens, G. Stasi\'nska, M. Takamiya, N. Vale Asari,
  and J. M. V\'ilchez","SIGNALS: I. Survey Description","19 pages, 14 figures, submitted to MNRAS",,"10.1093/mnras/stz2455",,"astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  SIGNALS, the Star formation, Ionized Gas, and Nebular Abundances Legacy
Survey, is a large observing program designed to investigate massive star
formation and HII regions in a sample of local extended galaxies. The program
will use the imaging Fourier transform spectrograph SITELLE at the
Canada-France-Hawaii Telescope. Over 355 hours (54.7 nights) have been
allocated beginning in fall 2018 for eight consecutive semesters. Once
completed, SIGNALS will provide a statistically reliable laboratory to
investigate massive star formation, including over 50 000 resolved HII regions
: the largest, most complete, and homogeneous database of spectroscopically and
spatially resolved extragalactic HII regions ever assembled. For each field
observed, three datacubes covering the spectral bands of the filters SN1 (363
-386 nm), SN2 (482 - 513 nm), and SN3 (647 - 685 nm) are gathered. The spectral
resolution selected for each spectral band is 1000, 1000, and 5000,
respectively. As defined, the project sample will facilitate the study of
small-scale nebular physics and many other phenomena linked to star formation
at a mean spatial resolution of 20 pc. This survey also has considerable legacy
value for additional topics including planetary nebulae, diffuse ionized gas,
andsupernova remnants. The purpose of this paper is to present a general
outlook of the survey, notably the observing strategy, galaxy sample, and
science requirements.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:57:27 GMT""}]","2019-10-02"
"1908.09018","Joseph Chapman","Joseph C. Chapman, Charles C. W. Lim, Paul G. Kwiat","Hyperentangled Time-bin and Polarization Quantum Key Distribution","30 pages, 11 figures, and 4 tables","Phys. Rev. Applied 18, 044027 (2022)","10.1103/PhysRevApplied.18.044027",,"quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fiber-based quantum communication networks are currently limited without
quantum repeaters. Satellite-based quantum links have been proposed to extend
the network domain. We have developed a quantum communication system, suitable
for realistic satellite-to-ground communication. With this system, we have
executed an entanglement-based quantum key distribution (QKD) protocol
developed by Bennett, Brassard, and Mermin in 1992 (BBM92), achieving quantum
bit error rates (QBER) below 2$\%$ in all bases. More importantly, we
demonstrate low QBER execution of a higher dimensional hyperentanglement-based
QKD protocol, using photons simultaneously entangled in polarization and
time-bin, leading to significantly higher secure key rates, at the cost of
increased technical complexity and system size. We show that our protocol is
suitable for a space-to-ground link, after incorporating Doppler shift
compensation, and verify its security using a rigorous finite-key analysis.
Additionally, We discuss system engineering considerations relevant to those
and other quantum communication protocols, and their dependence on what
photonic degrees of freedom are utilized.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:57:39 GMT""},{""version"":""v2"",""created"":""Thu, 5 Sep 2019 15:31:11 GMT""},{""version"":""v3"",""created"":""Tue, 3 Mar 2020 15:12:42 GMT""},{""version"":""v4"",""created"":""Fri, 10 Dec 2021 17:26:34 GMT""},{""version"":""v5"",""created"":""Wed, 1 Jun 2022 16:11:02 GMT""},{""version"":""v6"",""created"":""Tue, 13 Sep 2022 21:33:52 GMT""}]","2022-10-27"
"1908.09019","Seyyedeh Azar Oliaei Motlagh","S. Azar Oliaei Motlagh, Fatemeh Nematollahi, Aranyo Mitra, Ahmal Jawad
  Zafar, Vadym Apalkov, and Mark I. Stockman","Ultrafast optical currents in gapped graphene",,,,,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study theoretically the interaction of ultrashort optical pulses with
gapped graphene. Such strong pulse results in finite conduction band population
and corresponding electric current both during and after the pulse. Since
gapped graphene has broken inversion symmetry, it has an axial symmetry about
the $y$-axis but not about the $x$-axis. We show that, in this case, if the
linear pulse is polarized along the $x$-axis, the rectified electric current is
generated in the $y$ direction. At the same time, the conduction band
population distribution in the reciprocal space is symmetric about the
$x$-axis. Thus, the rectified current in gapped graphene has inter-band origin,
while the intra-band contribution to the rectified current is zero.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 19:59:31 GMT""}]","2019-08-27"
"1908.09020","Julian Sahasrabudhe","Marcus Michelen and Julian Sahasrabudhe","Central limit theorems and the geometry of polynomials","44 pages. Typo in abstract fixed",,,,"math.PR math.CA math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $X \in \{0,\ldots,n \}$ be a random variable, with mean $\mu$ and
standard deviation $\sigma$ and let \[f_X(z) = \sum_{k} \mathbb{P}(X = k) z^k,
\] be its probability generating function. Pemantle conjectured that if
$\sigma$ is large and $f_X$ has no roots close to $1\in \mathbb{C}$ then $X$
must be approximately normal. We completely resolve this conjecture in the
following strong quantitative form, obtaining sharp bounds. If $\delta =
\min_{\zeta}|\zeta-1|$ over the complex roots $\zeta$ of $f_X$, and $X^{\ast}
:= (X-\mu)/\sigma$, then \[ \sup_{t \in \mathbb{R}} \left|\mathbb{P}(X^{\ast}
\leq t) - \mathbb{P}( Z \leq t) \, \right| = O\left(\frac{\log n}{\delta\sigma}
\right) \] where $Z \sim \mathcal{N}(0,1)$ is a standard normal. This gives the
best possible version of a result of Lebowitz, Pittel, Ruelle and Speer. We
also show that if $f_X$ has no roots with small argument, then $X$ must be
approximately normal, again in a sharp quantitative form: if we set $\delta =
\min_{\zeta}|\arg(\zeta)|$ then \[ \sup_{t \in \mathbb{R}}
\left|\mathbb{P}(X^{\ast} \leq t) - \mathbb{P}( Z \leq t) \, \right| =
O\left(\frac{1}{\delta\sigma} \right). \] Using this result, we answer a
question of Ghosh, Liggett and Pemantle by proving a sharp multivariate central
limit theorem for random variables with real-stable probability generating
functions.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:08:05 GMT""},{""version"":""v2"",""created"":""Tue, 27 Aug 2019 20:12:50 GMT""}]","2019-08-29"
"1908.09022","Thiago Castro Ferreira","Thiago Castro Ferreira, Chris van der Lee, Emiel van Miltenburg, Emiel
  Krahmer","Neural data-to-text generation: A comparison between pipeline and
  end-to-end architectures","Preprint version of the EMNLP 2019 article",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Traditionally, most data-to-text applications have been designed using a
modular pipeline architecture, in which non-linguistic input data is converted
into natural language through several intermediate transformations. In
contrast, recent neural models for data-to-text generation have been proposed
as end-to-end approaches, where the non-linguistic input is rendered in natural
language with much less explicit intermediate representations in-between. This
study introduces a systematic comparison between neural pipeline and end-to-end
data-to-text approaches for the generation of text from RDF triples. Both
architectures were implemented making use of state-of-the art deep learning
methods as the encoder-decoder Gated-Recurrent Units (GRU) and Transformer.
Automatic and human evaluations together with a qualitative analysis suggest
that having explicit intermediate steps in the generation process results in
better texts than the ones generated by end-to-end approaches. Moreover, the
pipeline models generalize better to unseen inputs. Data and code are publicly
available.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:10:36 GMT""},{""version"":""v2"",""created"":""Wed, 27 Nov 2019 13:06:04 GMT""}]","2019-11-28"
"1908.09023","Peter Grabner","Peter J. Grabner","Purity results for some arithmetically defined measures",,"Indagationes Mathematicae 2022",,,"math.DS math.NT","http://creativecommons.org/licenses/by/4.0/","  We study measures that are obtained as push-forwards of measures of maximal
entropy on sofic shifts under digital maps
  $(x_k)_{k\in\mathbb{N}}\mapsto\sum_{k\in\mathbb{N}}x_k\beta^{-k}$, where
$\beta>1$ is a Pisot number. We characterise the continuity of such measures in
terms of the underlying automaton and show a purity result.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:11:50 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 13:10:59 GMT""},{""version"":""v3"",""created"":""Fri, 8 Apr 2022 14:18:11 GMT""}]","2022-05-16"
"1908.09024","Seyyedeh Azar Oliaei Motlagh","S. Azar Oliaei Motlagh, Vadym Apalkov, and Mark I. Stockman","Laser pulse waveform control of Dirac fermions in graphene",,,"10.1117/12.2529325",,"cond-mat.mes-hall cond-mat.other","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We theoretically study the Dirac fermion dynamics in a graphene monolayer in
the presence of an applied ultrafast laser pulse. The pulse has the duration of
a few femtoseconds and the amplitude of ~ 0.1 - 0.5 $\mathrm{V/\AA}$. The
waveform of the pulse is described by Hermit Gaussian polynomials with varying
carrier-envelope phase. We show that the ultrafast dynamics of Dirac fermions
strongly depends on the carrier-envelope phase and the frequency of the applied
pulse. The ultrafast pulse generates an electric current which results in a
finite transferred charge. The ultrafast field-driven current and the
corresponding net transferred charge depend on the waveform of the applied
pulse. Our results pave the way for the development of ultrafast information
processing in the terahertz domain.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:12:51 GMT""}]","2019-09-12"
"1908.09025","Binita Hona","Binita Hona, Henrike Fleischhack and Petra Huentemeyer (for the HAWC
  Collaboration)","Testing the Limits of Particle Acceleration in Cygnus OB2 with HAWC","Presented at the 36th International Cosmic Ray Conference (ICRC 2019)",,,,"astro-ph.HE astro-ph.GA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Star forming regions (SFRs) have been postulated as possible sources of
cosmic rays (CRs) in our galaxy. One example of a gamma-ray source associated
with an SFR is the Fermi-LAT cocoon, an extended region of gamma-ray emission
in the Cygnus X region and attributed to a possible superbubble with freshly
accelerated CRs. Because the emission region is surrounded by ionization
fronts, it has been named the ""Cygnus cocoon"". CRs in the cocoon could have
originated in the OB2 association and been accelerated at the interaction sites
of stellar winds of massive O type stars. So far, there is no clear association
at TeV energies. Spectral and morphological studies of TeV gamma-ray emission
detected by the High Altitude Water Cherenkov (HAWC) observatory at the 2HWC
J2031+415 region reveal that the spectral energy distribution of the cocoon
extends from GeV to at least tens of TeV. Using HAWC data, we are able to study
the acceleration of particles to highest energies in the Cygnus OB2 SFR.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:17:48 GMT""}]","2019-08-27"
"1908.09026","Michael Assaf","Ohad Vilk and Michael Assaf","Extinction risk of a Metapopulation under the Allee Effect","5 pages, 3 figures + Supplemental Material","Phys. Rev. E 101, 012135 (2020)","10.1103/PhysRevE.101.012135",,"q-bio.PE cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the extinction risk of a fragmented population residing on a network
of patches coupled by migration, where the local patch dynamics include the
Allee effect. We show that mixing between patches dramatically influences the
population's viability. Slow migration is shown to always increase the
population's global extinction risk compared to the isolated case. At fast
migration, we demonstrate that synchrony between patches minimizes the
population's extinction risk. Moreover, we discover a critical migration rate
that maximizes the extinction risk of the population, and identify an
early-warning signal when approaching this state. Our theoretical results are
confirmed via the highly-efficient weighted ensemble method. Notably, our
analysis can also be applied to studying switching in gene regulatory networks
with multiple transcriptional states.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:19:21 GMT""}]","2020-02-05"
"1908.09027","You-Cheng Chou","You-Cheng Chou, Yuan-Pin Lee","Virasoro constraints for moduli of weighted pointed stable curves","22 pages. Corrected some typos. Initial condition for KdV hierarchy
  added in section 4",,,,"math.AG math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We formulate Virasoro constraints for the generating functions of the
intersection numbers on Hassett's moduli of weighted pointed curves and show
that they are governed by the KdV integrable hierarchy.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:22:52 GMT""},{""version"":""v2"",""created"":""Tue, 25 Aug 2020 06:20:07 GMT""}]","2020-08-26"
"1908.09028","Michael Assaf","Tom Israeli and Michael Assaf","Population switching under a time-varying environment","9 pages, 8 figures","Phys. Rev. E 101, 022109 (2020)","10.1103/PhysRevE.101.022109",,"cond-mat.stat-mech","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the switching dynamics of a stochastic population subjected to a
deterministically time-varying environment. Our approach is demonstrated in the
realm of ecology on a problem of population establishment. Here, by assuming a
constant immigration pressure along with a strong Allee effect, at the
deterministic level one obtains a critical population size beyond which the
system experiences establishment. Notably the latter has been shown to be
strongly influenced by the interplay between demographic and environmental
noise. We consider two prototypical examples for environmental variations: a
temporary environmental change, and a periodically-varying environment. By
employing a semi-classical approximation we compute, within exponential
accuracy, the change in the establishment probability and mean establishment
time of the population, due to the environmental variability. Our analytical
results are verified by using a modified Gillespie algorithm which accounts for
explicitly time-dependent reaction rates. Finally, our theoretical approach can
also be useful in studying switching dynamics in gene regulatory networks under
extrinsic variations.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:23:04 GMT""}]","2020-02-19"
"1908.09029","Bryan Graham","Bryan S. Graham","Dyadic Regression","20 pages, 1 table",,,,"econ.EM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Dyadic data, where outcomes reflecting pairwise interaction among sampled
units are of primary interest, arise frequently in social science research.
Regression analyses with such data feature prominently in many research
literatures (e.g., gravity models of trade). The dependence structure
associated with dyadic data raises special estimation and, especially,
inference issues. This chapter reviews currently available methods for
(parametric) dyadic regression analysis and presents guidelines for empirical
researchers.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:31:25 GMT""}]","2019-08-27"
"1908.09030","Joseph E. Bonin","Joseph E. Bonin and Carolyn Chun","Decomposable polymatroids and connections with graph coloring","21 pages",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce ideas that complement the many known connections between
polymatroids and graph coloring. Given a hypergraph that satisfies certain
conditions, we construct polymatroids, given as rank functions, that can be
written as sums of rank functions of matroids, and for which the minimum number
of matroids required in such sums is the chromatic number of the line graph of
the hypergraph. This result motivates introducing chromatic numbers and
chromatic polynomials for polymatroids. We show that the chromatic polynomial
of any 2-polymatroid is a rational multiple of the chromatic polynomial of some
graph. We also find the excluded minors for the minor-closed class of
polymatroids that can be written as sums of rank functions of matroids that
form a chain of quotients.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:31:47 GMT""}]","2019-08-27"
"1908.09031","Jiachen Li","Jiachen Li and Wei Zhan and Yeping Hu and Masayoshi Tomizuka","Generic Tracking and Probabilistic Prediction Framework and Its
  Application in Autonomous Driving","IEEE Transactions on Intelligent Transportation Systems",,"10.1109/TITS.2019.2930310",,"cs.RO cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurately tracking and predicting behaviors of surrounding objects are key
prerequisites for intelligent systems such as autonomous vehicles to achieve
safe and high-quality decision making and motion planning. However, there still
remain challenges for multi-target tracking due to object number fluctuation
and occlusion. To overcome these challenges, we propose a constrained mixture
sequential Monte Carlo (CMSMC) method in which a mixture representation is
incorporated in the estimated posterior distribution to maintain
multi-modality. Multiple targets can be tracked simultaneously within a unified
framework without explicit data association between observations and tracking
targets. The framework can incorporate an arbitrary prediction model as the
implicit proposal distribution of the CMSMC method. An example in this paper is
a learning-based model for hierarchical time-series prediction, which consists
of a behavior recognition module and a state evolution module. Both modules in
the proposed model are generic and flexible so as to be applied to a class of
time-series prediction problems where behaviors can be separated into different
levels. Finally, the proposed framework is applied to a numerical case study as
well as a task of on-road vehicle tracking, behavior recognition, and
prediction in highway scenarios. Instead of only focusing on forecasting
trajectory of a single entity, we jointly predict continuous motions for
interactive entities simultaneously. The proposed approaches are evaluated from
multiple aspects, which demonstrate great potential for intelligent vehicular
systems and traffic surveillance systems.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:34:53 GMT""}]","2020-03-31"
"1908.09032","Vipin Singh Sehrawat","Vipin Singh Sehrawat and Yvo Desmedt","Bi-Homomorphic Lattice-Based PRFs and Unidirectional Updatable
  Encryption","This is the full version of the paper that appears in Cryptology and
  Network Security 2019, LNCS, Springer, Volume 11829, pp. 3-23","Cryptology and Network Security 2019, LNCS, Springer, Volume
  11829, pp. 3-23","10.1007/978-3-030-31578-8_1",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We define a pseudorandom function (PRF) $F: \mathcal{K} \times \mathcal{X}
\rightarrow \mathcal{Y}$ to be bi-homomorphic when it is fully Key homomorphic
and partially Input Homomorphic (KIH), i.e., given $F(k_1, x_1)$ and $F(k_2,
x_2)$, there is an efficient algorithm to compute $F(k_1 \oplus k_2, x_1
\ominus x_2)$, where $\oplus$ and $\ominus$ are (binary) group operations. The
homomorphism on the input is restricted to a fixed subset of the input bits,
i.e., $\ominus$ operates on some pre-decided $m$-out-of-$n$ bits, where $|x_1|
= |x_2| = n$, and the remaining $n-m$ bits are identical in both inputs. In
addition, the output length, $\ell$, of the operator $\ominus$ is not fixed and
is defined as $n \leq \ell \leq 2n$, hence leading to Homomorphically induced
Variable input Length (HVL) as $n \leq |x_1 \ominus x_2| \leq 2n$. We present a
learning with errors (LWE) based construction for a HVL-KIH-PRF family. Our
construction is inspired by the key homomorphic PRF construction due to
Banerjee and Peikert (Crypto 2014).
  An updatable encryption scheme allows rotations of the encryption key, i.e.,
moving existing ciphertexts from old to new key. These updates are carried out
via \emph{update tokens}, which can be used by an untrusted party since the
update procedure does not involve decryption of the ciphertext. We use our
novel PRF family to construct an updatable encryption scheme, named QPC-UE-UU,
which is quantum-safe, post-compromise secure and supports unidirectional
ciphertext updates, i.e., the update tokens can be used to perform ciphertext
updates but they cannot be used to undo already completed updates. Our PRF
family also leads to the first left/right key homomorphic constrained-PRF
family with HVL.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:37:10 GMT""},{""version"":""v2"",""created"":""Tue, 29 Oct 2019 01:13:10 GMT""},{""version"":""v3"",""created"":""Thu, 20 Aug 2020 02:10:22 GMT""},{""version"":""v4"",""created"":""Fri, 21 Aug 2020 13:32:35 GMT""}]","2020-08-24"
"1908.09033","Weite Zhang","Weite Zhang, Hipolito Gomez-Sousa, Juan Heredia-Juesas, and Jose A.
  Martinez-Lorenzo","Single-Frequency Imaging and Material Characterization using
  Reconfigurable Reflectarrays",,,,,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, a physical and geometrical optics based single-frequency
imaging scheme is proposed for personal screening systems using multiple
reconfigurable reflectarrays. This scheme is able to not only reconstruct
profiles of potential threat objects on human body, but also identify their
materials in terms of their complex relative permittivities. Both simulation
and experiment are carried out to detect dielectric objects at a microwave
frequency of 24.16 GHz. The object profiles and complex relative permittivities
are obtained with both high accuracy and computational efficiency, which show
great potentials for security imaging where inspection of human body for threat
materials, such as narcotics, explosives, and other types of contraband, is
very common.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:38:09 GMT""}]","2019-08-27"
"1908.09034","Yi Guo","Yi Guo and Mario Rotea and Tyler Summers","Stochastic Dynamic Programming for Wind Farm Power Maximization",,,,,"math.OC cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wind farms can increase annual energy production (AEP) with advanced control
algorithms by coordinating the set points of individual turbine controllers
across the farm. However, it remains a significant challenge to achieve
performance improvements in practice because of the difficulty of utilizing
models that capture pertinent complex aerodynamic phenomena while remaining
amenable to control design. We formulate a multi-stage stochastic optimal
control problem for wind farm power maximization and show that it can be solved
analytically via dynamic programming. In particular, our model incorporates
state- and input-dependent multiplicative noise whose distributions capture
stochastic wind fluctuations. The optimal control policies and value functions
explicitly incorporate the moments of these distributions, establishing a
connection between wind flow data and optimal feedback control. We illustrate
the results with numerical experiments that demonstrate the advantages of our
approach over existing methods based on deterministic models.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:44:03 GMT""},{""version"":""v2"",""created"":""Tue, 17 Mar 2020 02:16:16 GMT""}]","2020-03-18"
"1908.09035","Livia Corsi","Livia Corsi, Giuseppe Genovese","Long time behaviour of a local perturbation in the isotropic XY chain
  under periodic forcing","21 pages",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the isotropic XY quantum spin chain with a time-periodic transverse
magnetic field acting on a single site. The asymptotic problem can be mapped
into a highly resonant Floquet-Schr\""odinger equation, for which, under a
diophantine-like assumption on the frequency, we show the existence of a
periodic solution. The proof is based on a KAM-type renormalisation. This in
turn implies the state of the quantum spin chain to be asymptotically a
periodic function synchronised with the forcing also at low frequencies.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:44:54 GMT""},{""version"":""v2"",""created"":""Sun, 13 Dec 2020 09:30:07 GMT""}]","2020-12-15"
"1908.09036","John Bergdall","John Bergdall and Brandon Levin","Reductions of some two-dimensional crystalline representations via Kisin
  modules","Minor revision. Updated references",,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We determine rational Kisin modules associated with two-dimensional,
irreducible, crystalline representations of
$\mathrm{Gal}(\overline{\mathbb{Q}}_p/\mathbb{Q}_p)$ of Hodge-Tate weights $0,
k-1$. If the slope is larger than $\lfloor \frac{k-1}{p} \rfloor$, we further
identify an integral Kisin module, which we use to calculate the semisimple
reduction of the Galois representation. In that range, we find that the
reduction is constant, thereby improving on a theorem of Berger, Li, and Zhu.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:55:11 GMT""},{""version"":""v2"",""created"":""Mon, 1 Jun 2020 14:58:48 GMT""},{""version"":""v3"",""created"":""Thu, 30 Jul 2020 13:26:59 GMT""}]","2020-07-31"
"1908.09037","Brandon Roach","Brandon M. Roach, Kenny C. Y. Ng, Kerstin Perez, John F. Beacom,
  Shunsaku Horiuchi, Roman Krivonos, Daniel R. Wik","NuSTAR Tests of Sterile-Neutrino Dark Matter: New Galactic Bulge
  Observations and Combined Impact","16 pages, 5 figures. Text updated to match published version in PRD.
  Conclusions unchanged","Phys. Rev. D 101, 103011 (2020)","10.1103/PhysRevD.101.103011",,"astro-ph.HE astro-ph.CO hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We analyze two dedicated NuSTAR observations with exposure ${\sim}190$ ks
located ${\sim}10^\circ$ from the Galactic plane, one above and the other
below, to search for x-ray lines from the radiative decay of sterile-neutrino
dark matter. These fields were chosen to minimize astrophysical x-ray
backgrounds while remaining near the densest region of the dark matter halo. We
find no evidence of anomalous x-ray lines in the energy range 5--20 keV,
corresponding to sterile neutrino masses 10--40 keV. Interpreted in the context
of sterile neutrinos produced via neutrino mixing, these observations provide
the leading constraints in the mass range 10--12 keV, improving upon previous
constraints in this range by a factor ${\sim}2$. We also compare our results to
Monte Carlo simulations, showing that the fluctuations in our derived limit are
not dominated by systematic effects. An updated model of the instrumental
background, which is currently under development, will improve NuSTAR's
sensitivity to anomalous x-ray lines, particularly for energies 3--5 keV.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:59:41 GMT""},{""version"":""v2"",""created"":""Wed, 25 Sep 2019 16:19:22 GMT""},{""version"":""v3"",""created"":""Fri, 8 May 2020 16:07:41 GMT""}]","2020-05-11"
"1908.09038","Tom Velez PhD","Tom Velez, Tony Wang, Ioannis Koutroulis, James Chamberlain, Amit
  Uppal, Seife Yohannes, Tim Tschampel, Emilia Apostolova","Identification of Pediatric Sepsis Subphenotypes for Enhanced Machine
  Learning Predictive Performance: A Latent Profile Analysis","Keywords: Pediatric Sepsis, Mortality, Latent Profile Analysis,
  Machine Learning, Subphenotypes 15 pages including Appendix",,,,"stat.ML cs.LG q-bio.QM stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Background: While machine learning (ML) models are rapidly emerging as
promising screening tools in critical care medicine, the identification of
homogeneous subphenotypes within populations with heterogeneous conditions such
as pediatric sepsis may facilitate attainment of high-predictive performance of
these prognostic algorithms. This study is aimed to identify subphenotypes of
pediatric sepsis and demonstrate the potential value of partitioned
data/subtyping-based training. Methods: This was a retrospective study of
clinical data extracted from medical records of 6,446 pediatric patients that
were admitted at a major hospital system in the DC area. Vitals and labs
associated with patients meeting the diagnostic criteria for sepsis were used
to perform latent profile analysis. Modern ML algorithms were used to explore
the predictive performance benefits of reduced training data heterogeneity via
label profiling. Results: In total 134 (2.1%) patients met the diagnostic
criteria for sepsis in this cohort and latent profile analysis identified four
profiles/subphenotypes of pediatric sepsis. Profiles 1 and 3 had the lowest
mortality and included pediatric patients from different age groups. Profile 2
were characterized by respiratory dysfunction; profile 4 by neurological
dysfunction and highest mortality rate (22.2%). Machine learning experiments
comparing the predictive performance of models derived without training data
profiling against profile targeted models suggest statistically significant
improved performance of prediction can be obtained. For example, area under ROC
curve (AUC) obtained to predict profile 4 with 24-hour data (AUC = .998, p <
.0001) compared favorably with the AUC obtained from the model considering all
profiles as a single homogeneous group (AUC = .918) with 24-hour data.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:59:42 GMT""}]","2019-08-27"
"1908.09039","Ma. Isabel Hern\'andez","Mar\'ia Alejandra Alvarez and Ma Isabel Hern\'andez","Varieties of Nilpotent Lie Superalgebras of dimension $\leq 5$",,,,,"math.RA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper we study the varieties of nilpotent Lie superalgebras of
dimension $\leq 5$. We provide the algebraic classification of these
superalgebras and obtain the irreducible components in every variety. As a by
product we construct rigid nilpotent Lie superalgebras of arbitrary dimension.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 21:37:38 GMT""}]","2019-08-27"
"1908.09040","Firas Rassoul-Agha","Christopher Janjigian, Firas Rassoul-Agha, and Timo Sepp\""al\""ainen","Geometry of geodesics through Busemann measures in directed last-passage
  percolation","Fixed a few typos. Page layout changed. 59 pages, 13 figures",,,,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider planar directed last-passage percolation on the square lattice
with general i.i.d. weights and study the geometry of the full set of
semi-infinite geodesics in a typical realization of the random environment. The
structure of the geodesics is studied through the properties of the Busemann
functions viewed as a stochastic process indexed by the asymptotic direction.
Our results are further connected to the ergodic program for and stability
properties of random Hamilton-Jacobi equations. In the exactly solvable
exponential model, our results specialize to give the first complete
characterization of the uniqueness and coalescence structure of the entire
family of semi-infinite geodesics for any model of this type. Furthermore, we
compute statistics of locations of instability, where we discover an unexpected
connection to simple symmetric random walk.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 21:39:53 GMT""},{""version"":""v2"",""created"":""Mon, 10 Feb 2020 22:38:28 GMT""},{""version"":""v3"",""created"":""Fri, 3 Sep 2021 17:03:47 GMT""}]","2021-09-06"
"1908.09041","Neil Lutz","Christopher Jung, Sampath Kannan, Neil Lutz","A Center in Your Neighborhood: Fairness in Facility Location",,,,,"cs.DS cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When selecting locations for a set of facilities, standard clustering
algorithms may place unfair burden on some individuals and neighborhoods. We
formulate a fairness concept that takes local population densities into
account. In particular, given $k$ facilities to locate and a population of size
$n$, we define the ""neighborhood radius"" of an individual $i$ as the minimum
radius of a ball centered at $i$ that contains at least $n/k$ individuals. Our
objective is to ensure that each individual has a facility within at most a
small constant factor of her neighborhood radius. We present several
theoretical results:
  We show that optimizing this factor is NP-hard; we give an approximation
algorithm that guarantees a factor of at most 2 in all metric spaces; and we
prove matching lower bounds in some metric spaces. We apply a variant of this
algorithm to real-world address data, showing that it is quite different from
standard clustering algorithms and outperforms them on our objective function
and balances the load between facilities more evenly.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 22:04:57 GMT""},{""version"":""v2"",""created"":""Fri, 30 Aug 2019 15:42:36 GMT""}]","2019-09-02"
"1908.09042","Hamed Rahimi","Parsa Rajabzadeh, Amin Pishevar and Hamed Rahimi","SIDLE: Semantically Intelligent Distributed Leader Election Algorithm
  for Wireless Sensor Networks","not agreed anymore",,,,"cs.NI cs.DC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper introduces the deployment of a group of Wireless Sensor and
Actuator Network (WSAN) for Internet of Thing (IoT) systems in rural regions
deployed by a drone dropping sensors and actuators at a certain position as a
mesh of a hexagonal form. Nodes are heterogeneous in hardware and functionality
thus not all nodes are able to transfer data directly to the base station.
Primitive ones are only capable of collecting local data. However, ones that
are more sophisticated are equipped with long-range radio telemetry and more
computational power. Power optimization is one of the crucial factors in
designing WSANs. Total power consumption must be minimized, as sensors are
self-managed. It is not feasible to collect sensors on time bases and recharge
the batteries. Therefore, energy consumption optimization and harvesting green
energy are other factors that are considered. In this regard, protocols are
designed in a way to support such requirements. The preprocessed data are first
collected and combined by the leaders at each hexagonal cell. Then, the
information packets are sent to the head clusters. Consequently, head clusters
reprocess the received information and depict a better global view of the zone,
using a variety of the received information. Finally, the processed information
is sent to the nearest base station or a mobile drone.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 22:19:15 GMT""},{""version"":""v2"",""created"":""Wed, 19 May 2021 21:06:30 GMT""},{""version"":""v3"",""created"":""Tue, 14 Jun 2022 23:52:38 GMT""}]","2022-06-16"
"1908.09043","Mihailo Jovanovic","Sepideh Hassan-Moghaddam and Mihailo R. Jovanovi\'c","Proximal gradient flow and Douglas-Rachford splitting dynamics: global
  exponential stability via integral quadratic constraints","8 pages; 1 figure",,,,"math.OC cs.LG cs.SY eess.SY math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Many large-scale and distributed optimization problems can be brought into a
composite form in which the objective function is given by the sum of a smooth
term and a nonsmooth regularizer. Such problems can be solved via a proximal
gradient method and its variants, thereby generalizing gradient descent to a
nonsmooth setup. In this paper, we view proximal algorithms as dynamical
systems and leverage techniques from control theory to study their global
properties. In particular, for problems with strongly convex objective
functions, we utilize the theory of integral quadratic constraints to prove the
global exponential stability of the equilibrium points of the differential
equations that govern the evolution of proximal gradient and Douglas-Rachford
splitting flows. In our analysis, we use the fact that these algorithms can be
interpreted as variable-metric gradient methods on the suitable envelopes and
exploit structural properties of the nonlinear terms that arise from the
gradient of the smooth part of the objective function and the proximal operator
associated with the nonsmooth regularizer. We also demonstrate that these
envelopes can be obtained from the augmented Lagrangian associated with the
original nonsmooth problem and establish conditions for global exponential
convergence even in the absence of strong convexity.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 22:21:48 GMT""},{""version"":""v2"",""created"":""Thu, 25 Jun 2020 04:47:06 GMT""}]","2020-06-26"
"1908.09044","Alexander Balsomo","Alexander J. Balsomo and Job A. Nable","Moyal Star-Product and Unitary Representations of the Euclidean Motion
  Group","17 pages",,,,"math-ph math.MP math.RT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, the Moyal star-product quantization is used to construct the
unitary irreducible representations of the Euclidean motion group on
3-dimensions. These unitary representations will come from the representation
of its Lie algebra whose operators are defined by the left Moyal star-product
multiplication. In fact, these representations of the Lie algebra is the
infinitisimal representation. Hence, the exponentiation of these operators
gives rise to unitary operators that defines the desired unitary
representations.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 22:28:29 GMT""}]","2019-08-27"
"1908.09045","Francisco Rubilar A.","E. Gasparim, F. Rubilar","Deformations of noncompact Calabi--Yau manifolds, families and diamonds","Written for a Proceedings of the workshops Geometry at the Frontier
  2016-2018","Contemporary Mathematics. Year:2021, Vol. 766","10.1090/conm/766",,"math.AG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We introduce a new notion of deformation of complex structure, which we use
as an adaptation of Kodaira's theory of deformations, but that is better suited
to the study of noncompact manifolds. We present several families of
deformations illustrating this new approach. Our examples include toric
Calabi--Yau threefolds, cotangent bundles of flag manifolds, and semisimple
adjoint orbits, and we describe their Hodge theoretical invariants, depicting
Hodge diamonds and KKP diamonds.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 22:32:40 GMT""},{""version"":""v2"",""created"":""Thu, 24 Jun 2021 17:43:46 GMT""}]","2021-06-25"
"1908.09046","Ivan Levcovitz","Pallavi Dani and Ivan Levcovitz","Subgroups of right-angled Coxeter groups via Stallings-like techniques","44 pages, 7 figures. Incorporated referee's comments, added
  references and new examples. To appear in Journal of Combinatorial Algebra",,,,"math.GT math.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We associate cube complexes called completions to each subgroup of a
right-angled Coxeter group (RACG). A completion characterizes many properties
of the subgroup such as whether it is quasiconvex, normal, finite-index or
torsion-free. We use completions to show that reflection subgroups are
quasiconvex, as are one-ended Coxeter subgroups of a 2-dimensional RACG. We
provide an algorithm that determines whether a given one-ended, 2-dimensional
RACG is isomorphic to some finite-index subgroup of another given RACG. In
addition, we answer several algorithmic questions regarding quasiconvex
subgroups. Finally, we give a new proof of Haglund's result that quasiconvex
subgroups of RACGs are separable.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 22:37:41 GMT""},{""version"":""v2"",""created"":""Fri, 19 Jun 2020 15:50:47 GMT""},{""version"":""v3"",""created"":""Tue, 13 Apr 2021 15:34:27 GMT""}]","2021-04-14"
"1908.09047","Rohit Singh Mr","Rohit Singh and Douglas Sicker","Parameter Modeling for Small-Scale Mobility in Indoor THz Communication","To appear in IEEE GLOBECOM 2019. The document has 6 pages, 16
  figures, 2 tables",,,,"cs.NI eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Despite such challenges as high path loss and equipment cost, THz
communication is becoming one of the potentially viable means through which
ultra-high data rate can be achieved. To compensate for the high path loss, we
present parameter modeling for indoor THz communication. To maximize efficient
and opportunistic use of resources, we analyze the potential workarounds for a
single access point to satisfy most of the mobile terminals by varying such
parameters as humidity, distance, frequency windows, beamwidths, antenna
placement, and user mobility type. One promising parameter is antenna
beamwidth, where narrower beams results in higher antenna gain. However, this
can lead to ""\textit{beamwidth dilemma}"" scenario, where narrower beamwidth can
result in significant outages due to device mobility and orientation. In this
paper, we address this challenge by presenting a mobility model that performs
an extensive analysis of different human mobility scenarios, where each
scenario has different data rate demands and movement patterns. We observe that
for mobile users, there are optimal beamwidths that are affected by the
mobility type (high mobility, constrained mobility, and low mobility) and AP
placement.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 22:46:12 GMT""}]","2019-08-27"
"1908.09048","Subramaniam Venkatraman Krishnan","Liqun Shao, Yiwen Zhu, Abhiram Eswaran, Kristin Lieber, Janhavi
  Mahajan, Minsoo Thigpen, Sudhir Darbha, Siqi Liu, Subru Krishnan, Soundar
  Srinivasan, Carlo Curino and Konstantinos Karanasos","Griffon: Reasoning about Job Anomalies with Unlabeled Data in
  Cloud-based Platforms",,,"10.1145/3357223.3362716",,"cs.LG cs.DC stat.ML","http://creativecommons.org/licenses/by-nc-sa/4.0/","  Microsoft's internal big data analytics platform is comprised of hundreds of
thousands of machines, serving over half a million jobs daily, from thousands
of users. The majority of these jobs are recurring and are crucial for the
company's operation. Although administrators spend significant effort tuning
system performance, some jobs inevitably experience slowdowns, i.e., their
execution time degrades over previous runs. Currently, the investigation of
such slowdowns is a labor-intensive and error-prone process, which costs
Microsoft significant human and machine resources, and negatively impacts
several lines of businesses. In this work, we present Griffin, a system we
built and have deployed in production last year to automatically discover the
root cause of job slowdowns. Existing solutions either rely on labeled data
(i.e., resolved incidents with labeled reasons for job slowdowns), which is in
most cases non-existent or non-trivial to acquire, or on time-series analysis
of individual metrics that do not target specific jobs holistically. In
contrast, in Griffin we cast the problem to a corresponding regression one that
predicts the runtime of a job, and show how the relative contributions of the
features used to train our interpretable model can be exploited to rank the
potential causes of job slowdowns. Evaluated over historical incidents, we show
that Griffin discovers slowdown causes that are consistent with the ones
validated by domain-expert engineers, in a fraction of the time required by
them.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 22:57:50 GMT""}]","2020-04-02"
"1908.09049","Sangwoo Park","Sangwoo Park, Hyeryung Jang, Osvaldo Simeone, and Joonhyuk Kang","Learning to Demodulate from Few Pilots via Offline and Online
  Meta-Learning","journal paper to appear in IEEE Transactions on Signal Processing,
  subsumes (arXiv:1903.02184)","IEEE Transactions on Signal Processing, vol. 69, pp. 226-239, 2020","10.1109/TSP.2020.3043879",,"eess.SP cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers an Internet-of-Things (IoT) scenario in which devices
sporadically transmit short packets with few pilot symbols over a fading
channel. Devices are characterized by unique transmission non-idealities, such
as I/Q imbalance. The number of pilots is generally insufficient to obtain an
accurate estimate of the end-to-end channel, which includes the effects of
fading and of the transmission-side distortion. This paper proposes to tackle
this problem by using meta-learning. Accordingly, pilots from previous IoT
transmissions are used as meta-training data in order to train a demodulator
that is able to quickly adapt to new end-to-end channel conditions from few
pilots. Various state-of-the-art meta-learning schemes are adapted to the
problem at hand and evaluated, including Model-Agnostic Meta-Learning (MAML),
First-Order MAML (FOMAML), REPTILE, and fast Context Adaptation VIA
meta-learning (CAVIA). Both offline and online solutions are developed. In the
latter case, an integrated online meta-learning and adaptive pilot number
selection scheme is proposed. Numerical results validate the advantages of
meta-learning as compared to training schemes that either do not leverage prior
transmissions or apply a standard joint learning algorithms on previously
received data.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 23:27:16 GMT""},{""version"":""v2"",""created"":""Tue, 24 Mar 2020 14:17:38 GMT""},{""version"":""v3"",""created"":""Fri, 4 Dec 2020 03:28:31 GMT""}]","2021-10-22"
"1908.09050","Brian Lawrence","Brian Lawrence and Umberto Zannier","On the $p$-adic distribution of torsion values for a section of an
  abelian scheme",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Let $A \rightarrow S$ be an abelian scheme over a $p$-adic field, and let $s
\colon S \rightarrow A$ be a section. We study the torsion locus $\bigcup
\limits_{n \geq 1} s^{-1}(A[n])$ on $S$, and we show that torsion points on $S$
of different orders stay away from each other.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 23:57:06 GMT""}]","2019-08-27"
"1908.09051","Etsuo Segawa","Sennosuke Watanabe, Akiko Fukuda, Etsuo Segawa, Iwao Sato","A walk on max-plus algebra","17 pages, 1 figures",,,,"math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Max-plus algebra is a kind of idempotent semiring over
$\mathbb{R}_{\max}:=\mathbb{R}\cup\{-\infty\}$ with two operations $\oplus :=
\max$ and $\otimes := +$.In this paper, we introduce a new model of a walk on
one dimensional lattice on $\mathbb{Z}$, as an analogue of the quantum walk,
over the max-plus algebra and we call it max-plus walk. In the conventional
quantum walk, the summation of the $\ell^2$-norm of the states over all the
positions is a conserved quantity. In contrast, the summation of eigenvalues of
state decision matrices is a conserved quantity in the max-plus walk.Moreover,
spectral analysis on the total time evolution operator is also given.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 23:57:30 GMT""},{""version"":""v2"",""created"":""Thu, 29 Aug 2019 21:20:33 GMT""}]","2019-09-02"
"1908.09052","Thomas Carroll","Vincent C. Gregoric, Jason J. Bennett, Bianca R. Gualtieri, Hannah P.
  Hastings, Ankitha Kannad, Zhimin Cheryl Liu, Maia R. Rabinowitz, Zoe A.
  Rowley, Miao Wang, Lauren Yoast, Thomas J. Carroll, Michael W. Noel","Perturbed Field Ionization for Improved State Selectivity",,"V. C. Gregoric, et al., ""Perturbed field ionization for improved
  state selectivity,"" J. Phys. B: At. Mol. Opt. Phys. 53, 084003 (2020)","10.1088/1361-6455/ab707a",,"physics.atom-ph quant-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Selective field ionization is used to determine the state or distribution of
states to which a Rydberg atom is excited. By evolving a small perturbation to
the ramped electric field using a genetic algorithm, the shape of the
time-resolved ionization signal can be controlled. This allows for separation
of signals from pairs of states that would be indistinguishable with
unperturbed selective field ionization. Measurements and calculations are
presented that demonstrate this technique and shed light on how the
perturbation directs the pathway of the electron to ionization. Pseudocode for
the genetic algorithm is provided. Using the improved resolution afforded by
this technique, quantitative measurements of the
$36p_{3/2}+36p_{3/2}\rightarrow 36s_{1/2}+37s_{1/2}$ dipole-dipole interaction
are made.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:00:23 GMT""},{""version"":""v2"",""created"":""Thu, 21 Nov 2019 01:59:45 GMT""}]","2020-03-17"
"1908.09053","James P. Crutchfield","Ariadna E. Venegas-Li and Alexandra M. Jurgens and James P.
  Crutchfield","Measurement-Induced Randomness and Structure in Controlled Qubit
  Processes","6 pages, 3 figures; supplemental material, 5 pages, 1 figure;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/qdic_prl.htm","Phys. Rev. E 102, 040102 (2020)","10.1103/PhysRevE.102.040102",,"quant-ph cond-mat.stat-mech math.DS nlin.CD","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  When an experimentalist measures a time series of qubits, the outcomes
generate a classical stochastic process. We show that measurement induces high
complexity in these processes in two specific senses: they are inherently
unpredictable (positive Shannon entropy rate) and they require an infinite
number of features for optimal prediction (divergent statistical complexity).
We identify nonunifilarity as the mechanism underlying the resulting
complexities and examine the influence that measurement choice has on the
randomness and structure of measured qubit processes. We introduce new
quantitative measures of this complexity and provide efficient algorithms for
their estimation.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:03:19 GMT""}]","2020-10-14"
"1908.09054","James Madsen","Faisal Abdu'Allah, Mark-David Hosale, Maryam Ladoni, Jim Madsen (for
  the IceCube Collaboration)","Capturing Cosmic Ray Research and Researchers with Art","Presented at the 36th International Cosmic Ray Conference (ICRC
  2019). See arXiv:1907.11699 for all IceCube contributions",,,"PoS-ICRC2019-951","astro-ph.IM physics.ed-ph physics.pop-ph","http://creativecommons.org/publicdomain/zero/1.0/","  We describe our experiment with an alternate approach to presenting cosmic
ray research. The goal was to more widely promote cosmic ray research and
attract diverse audiences, especially those from groups that are
underrepresented in science or that do not have experience attending science
outreach events. The IceCube Neutrino Observatory education and outreach team
brought together local teenagers, internationally accomplished artists, science
communicators, and scientists to produce an interactive gallery exhibit,
Messages, that explores the cosmic ray community and science. The artists
collaborated with the scientists and students to create two original
installations that will be displayed at the UW-Madison Memorial Union Gallery
for six weeks, from mid-June, 2019, through the end of the International Cosmic
Ray Conference 2019. Event Horizon by Abdu'Allah with Ladoni features portraits
of cosmic ray researchers and high school students who are learning more about
the field. This installation will examine the science community as it is and as
it could be. Messages from the Horizon by Hosale with Madsen is inspired by
previous immersive works. It combines sound and light to explore what we know
and how we know it.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:08:57 GMT""}]","2019-08-27"
"1908.09055","Bangti Jin","Manh Hong Duong, Bangti Jin","Wasserstein Gradient Flow Formulation of the Time-Fractional
  Fokker-Planck Equation","24 pages, 2 figures",,,,"math.NA cs.NA math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, we investigate a variational formulation for a time-fractional
Fokker-Planck equation which arises in the study of complex physical systems
involving anomalously slow diffusion. The model involves a fractional-order
Caputo derivative in time, and thus inherently nonlocal. The study follows the
Wasserstein gradient flow approach pioneered by [26]. We propose a JKO type
scheme for discretizing the model, using the L1 scheme for the Caputo
fractional derivative in time, and establish the convergence of the scheme as
the time step size tends to zero. Illustrative numerical results in one- and
two-dimensional problems are also presented to show the approach.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:19:22 GMT""},{""version"":""v2"",""created"":""Thu, 4 Jun 2020 12:51:56 GMT""}]","2020-06-05"
"1908.09056","Gourab Ray","Gourab Ray and Yinon Spinka","Finitary codings for gradient models and a new graphical representation
  for the six-vertex model","39 pages, 8 figures","Random Structures and Algorithms, 2021","10.1002/rsa.21032",,"math.PR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that the Ising model on $\mathbb {Z}^d$ at a given temperature is
a finitary factor of an i.i.d. process if and only if the temperature is at
least the critical temperature. Below the critical temperature, the plus and
minus states of the Ising model are distinct and differ from one another by a
global flip of the spins. We show that it is only this global information which
poses an obstruction for being finitary by showing that the gradient of the
Ising model is a finitary factor of i.i.d. at all temperatures. As a
consequence, we deduce a volume-order large deviation estimate for the energy.
A similar result is shown for the Potts model.
  A result in the same spirit is also shown for the six-vertex model, which is
itself the gradient of a height function, with parameter $c \gtrapprox 6.4$. We
show that the gradient of the height function is not a finitary factor of an
i.i.d. process, but that its ""Laplacian"" is. For this, we introduce a coupling
between the six-vertex model with $c\ge 2$ and a new graphical representation
of it, reminiscent of the Edwards--Sokal coupling between the Potts and
random-cluster models. We believe that this graphical representation may be of
independent interest and could serve as a tool in further understanding of the
six-vertex model.
  To provide further support for the ubiquity of this type of phenomenon, we
also prove an analogous result for the so-called beach model.
  The tools and techniques used in this paper are probabilistic in nature. The
heart of the argument is to devise a suitable tree structure on the clusters of
the underlying percolation process (associated to the graphical representation
of the given model), which can be revealed piece-by-piece via exploration.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:26:53 GMT""},{""version"":""v2"",""created"":""Mon, 31 Jan 2022 18:46:23 GMT""}]","2022-02-01"
"1908.09057","Oluwasanmi Koyejo","Xiaoyan Wang, Ran Li, Bowei Yan, Oluwasanmi Koyejo","Consistent Classification with Generalized Metrics",,,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose a framework for constructing and analyzing multiclass and
multioutput classification metrics, i.e., involving multiple, possibly
correlated multiclass labels. Our analysis reveals novel insights on the
geometry of feasible confusion tensors -- including necessary and sufficient
conditions for the equivalence between optimizing an arbitrary non-decomposable
metric and learning a weighted classifier. Further, we analyze averaging
methodologies commonly used to compute multioutput metrics and characterize the
corresponding Bayes optimal classifiers. We show that the plug-in estimator
based on this characterization is consistent and is easily implemented as a
post-processing rule. Empirical results on synthetic and benchmark datasets
support the theoretical findings.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:31:15 GMT""}]","2019-08-27"
"1908.09058","Dinh Nguyen","Dinh C Nguyen, Pubudu N Pathirana, Ming Ding, Aruna Seneviratne","Integration of Blockchain and Cloud of Things: Architecture,
  Applications and Challenges","Accepted by IEEE Communications Surveys & Tutorials, 29 pages",,"10.1109/COMST.2020.3020092",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The blockchain technology is taking the world by storm. Blockchain with its
decentralized, transparent and secure nature has emerged as a disruptive
technology for the next generation of numerous industrial applications. One of
them is Cloud of Things enabled by the combination of cloud computing and
Internet of Things. In this context, blockchain provides innovative solutions
to address challenges in Cloud of Things in terms of decentralization, data
privacy and network security, while Cloud of Things offer elasticity and
scalability functionalities to improve the efficiency of blockchain operations.
Therefore, a novel paradigm of blockchain and Cloud of Things integration,
called BCoT, has been widely regarded as a promising enabler for a wide range
of application scenarios. In this paper, we present a state-of-the-art review
on the BCoT integration to provide general readers with an overview of the BCoT
in various aspects, including background knowledge, motivation, and integrated
architecture. Particularly, we also provide an in-depth survey of BCoT
applications in different use-case domains such as smart healthcare, smart
city, smart transportation and smart industry. Then, we review the recent BCoT
developments with the emerging blockchain and cloud platforms, services, and
research projects. Finally, some important research challenges and future
directions are highlighted to spur further research in this promising area.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:31:42 GMT""},{""version"":""v2"",""created"":""Fri, 28 Aug 2020 04:41:33 GMT""}]","2020-08-31"
"1908.09059","Yiqun Chen","Yiqun Chen, Wenjing Zheng, Lillian B. Brown, Gabriel Chamie, Dalsone
  Kwarisiima, Jane Kabami, Tamara D. Clark, Norton Sang, James Ayieko, Edwin D.
  Charlebois, Vivek Jain, Laura Balzer, Moses R Kamya, Diane Havlir, Maya
  Petersen, and the SEARCH Collaboration","Semi-Supervised Record Linkage for Construction of Large-Scale
  Sociocentric Networks in Resource-limited Settings: An application to the
  SEARCH Study in Rural Uganda and Kenya",,,,,"stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper presents a novel semi-supervised algorithmic approach to creating
large scale sociocentric networks in rural East Africa. We describe the
construction of 32 large-scale sociocentric social networks in rural
Sub-Saharan Africa. Networks were constructed by applying a semi-supervised
record-linkage algorithm to data from census-enumerated residents of the 32
communities included in the SEARCH study (NCT01864603), a community-cluster
randomized HIV prevention trial in Uganda and Kenya. Contacts were solicited
using a five question name generator in the domains of emotional support, food
sharing, free time, health issues and money issues. The fully constructed
networks include 170; 028 nodes and 362; 965 edges aggregated across
communities (ranging from 4449 to 6829 nodes and from 2349 to 31,779 edges per
community). Our algorithm matched on average 30% of named contacts in Kenyan
communities and 50% of named contacts in Ugandan communities to residents named
in census enumeration. Assortative mixing measures for eight different
covariates reveal that residents in the network have a very strong tendency to
associate with others who are similar to them in age, sex, and especially
village. The networks in the SEARCH Study will provide a platform for improved
understanding of health outcomes in rural East Africa. The network construction
algorithm we present may facilitate future social network research in
resource-limited settings.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:39:08 GMT""}]","2019-08-27"
"1908.09060","Zhengyang Wu","Zhengyang Wu, Srivignesh Rajendran, Tarrence van As, Joelle
  Zimmermann, Vijay Badrinarayanan, Andrew Rabinovich","EyeNet: A Multi-Task Network for Off-Axis Eye Gaze Estimation and User
  Understanding",,,,,"cs.CV cs.LG eess.IV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Eye gaze estimation and simultaneous semantic understanding of a user through
eye images is a crucial component in Virtual and Mixed Reality; enabling energy
efficient rendering, multi-focal displays and effective interaction with 3D
content. In head-mounted VR/MR devices the eyes are imaged off-axis to avoid
blocking the user's gaze, this view-point makes drawing eye related inferences
very challenging. In this work, we present EyeNet, the first single deep neural
network which solves multiple heterogeneous tasks related to eye gaze
estimation and semantic user understanding for an off-axis camera setting. The
tasks include eye segmentation, blink detection, emotive expression
classification, IR LED glints detection, pupil and cornea center estimation. To
train EyeNet end-to-end we employ both hand labelled supervision and model
based supervision. We benchmark all tasks on MagicEyes, a large and new dataset
of 587 subjects with varying morphology, gender, skin-color, make-up and
imaging conditions.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:47:39 GMT""}]","2019-08-27"
"1908.09061","Amr El-Zant","Amr El-Zant, Jonathan Freundlich, Francoise Combes and Anaelle Halle","The effect of fluctuating fuzzy axion haloes on stellar dynamics: a
  stochastic model","Additional comments on the conditions for the description in terms of
  effective quasi-particle mass, and the 'Jeans-Chandrasekhar swindle'.
  References added. To appear in Monthly Notices",,"10.1093/mnras/stz3478",,"astro-ph.GA astro-ph.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Fuzzy dark matter of ultra-light axions has gained attention, largely in
light of the galactic scale problems associated with cold dark matter. But the
large de Broglie wavelength, believed to possibly alleviate these problems,
also leads to fluctuations that place constraints on ultra-light axions. We
adapt and extend a method, previously devised to describe the effect of gaseous
fluctuations on cold dark matter cusps, in order to determine the imprints of
ultra-light axion haloes on the motion of classical test particles. We first
evaluate the effect of fluctuations in a statistically homogeneous medium of
classical particles, then in a similar system of ultra light axions. In the
first case, one recovers the classical two body relaxation time (and diffusion
coefficients) from white noise density fluctuations. In the second situation,
the fluctuations are not born of discreteness noise but from the finite de
Broglie wavelength; correlation therefore exists over this scale, while white
noise is retained on larger scales, elucidating the correspondence with
classical relaxation. The resulting density power spectra and correlation
functions are compared with those inferred from numerical simulations, and the
relaxation time arising from the associated potential fluctuations is
evaluated. We then apply our results to estimate the heating of disks embedded
in axion dark haloes. We find that this implies an axion mass $m \ga 2 \times
10^{-22} {\rm eV}$. We finally apply our model to the case of the central
cluster of Eridanus II, confirming that far stronger constraints on $m$ may in
principle be obtained, and discussing the limitations associated with the
assumptions leading to these.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:55:04 GMT""},{""version"":""v2"",""created"":""Sun, 8 Dec 2019 18:40:12 GMT""}]","2020-01-08"
"1908.09062","Yuqiao Shen","Yuqiao Shen, Hong Xiao, Hengmei Li, Sai Qin, Zheng Wang, Changying
  Wang, Desheng Zhang, Manqi Ruan","Photon Reconstruction Performance at the CEPC baseline detector",,,,,"physics.ins-det hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Circular Electron Positron Collider (CEPC) is a proposed Higgs/Z factory.
The photon reconstruction is critical to its physics program. We study the
photon reconstruction at the CEPC baseline detector, a Particle Flow oriented
detector. We characterized the objective performance at both single-photon and
di-photon samples. At the single-photon sample, we quantify the photon
conversion rate, the differential reconstruction efficiency and energy
resolution, and the identification performance. Using di-photon samples, our
analysis shows that the CEPC baseline detector reaches a relative mass
resolution of 1.7 - 2.2% of the Higgs boson at the $H\to\gamma\gamma$ sample,
and can reconstruct the $\pi^0$ with energy as high as 20 - 30 GeV. We also
investigate the impact of geometry defects on photon energy resolution and
discuss the possible corrections according to the reconstructed photon
position.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 01:05:19 GMT""},{""version"":""v2"",""created"":""Fri, 21 Feb 2020 13:47:54 GMT""}]","2020-02-24"
"1908.09063","Tomoya Naito","Tomoya Naito, Daisuke Ohashi, and Haozhao Liang","How to Improve Functionals in Density Functional Theory? ---Formalism
  and Benchmark Calculation---","International Nuclear Physics Conference 2019 (INPC2019)","J. Phys.: Conf. Ser. 1643 012149 (2020)","10.1088/1742-6596/1643/1/012149","RIKEN-QHP-424, RIKEN-iTHEMS-Report-19","physics.chem-ph cond-mat.str-el nucl-th physics.atom-ph physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We proposed in Ref. [arXiv:1812.09285v2] a way to improve energy density
functionals in the density functional theory based on the combination of the
inverse Kohn-Sham method and the density functional perturbation theory. In
this proceeding, we mainly focus on the results for the $ \mathrm{Ar} $ and $
\mathrm{Kr} $ atoms.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 01:07:38 GMT""}]","2020-12-24"
"1908.09064","Morteza Banagar","Morteza Banagar and Harpreet S. Dhillon","Fundamentals of Drone Cellular Network Analysis under Random Waypoint
  Mobility Model","Journal submission based on this work is available at
  arXiv:1908.05243",,"10.1109/GLOBECOM38437.2019.9013341",,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we present the first stochastic geometry-based performance
analysis of a drone cellular network in which drone base stations (DBSs) are
initially distributed based on a Poisson point process (PPP) and move according
to a random waypoint (RWP) mobility model. The serving DBS for a typical user
equipment (UE) on the ground is selected based on the nearest neighbor
association policy. We further assume two service models for the serving DBS:
(i) UE independent model (UIM), and (ii) UE dependent model (UDM). All the
other DBSs are considered as interfering DBSs for the typical UE. We introduce
a simplified RWP (SRWP) mobility model to describe the movement of interfering
DBSs and characterize its key distributional properties that are required for
our analysis. Building on these results, we analyze the interference field as
seen by the typical UE for both the UIM and the UDM using displacement theorem,
which forms the basis for characterizing the average rate at the typical UE as
a function of time. To the best of our knowledge, this is the first work that
analyzes the performance of a mobile drone network in which the drones follow
an RWP mobility model on an infinite plane.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 01:11:29 GMT""}]","2021-01-26"
"1908.09065","O-Joung Kwon","Minjeong Kang, O-joung Kwon, Myounghwan Lee","Graphs without two vertex-disjoint $S$-cycles","25 pages, 9 figures",,,,"math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Lov\'asz (1965) characterized graphs without two vertex-disjoint cycles,
which implies that such graphs have at most three vertices hitting all cycles.
In this paper, we ask whether such a small hitting set exists for $S$-cycles,
when a graph has no two vertex-disjoint $S$-cycles. For a graph $G$ and a
vertex set $S$ of $G$, an $S$-cycle is a cycle containing a vertex of $S$.
  We provide an example $G$ on $21$ vertices where $G$ has no two
vertex-disjoint $S$-cycles, but three vertices are not sufficient to hit all
$S$-cycles. On the other hand, we show that four vertices are enough to hit all
$S$-cycles whenever a graph has no two vertex-disjoint $S$-cycles.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 01:22:50 GMT""},{""version"":""v2"",""created"":""Tue, 11 Feb 2020 06:59:27 GMT""}]","2020-02-12"
"1908.09066","Le Zhang Dr","Le Zhang, Zenglin Shi, Ming-Ming Cheng, Yun Liu, Jia-Wang Bian, Joey
  Tianyi Zhou, Guoyan Zheng and Zeng Zeng","Robust Regression via Deep Negative Correlation Learning",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Nonlinear regression has been extensively employed in many computer vision
problems (e.g., crowd counting, age estimation, affective computing). Under the
umbrella of deep learning, two common solutions exist i) transforming nonlinear
regression to a robust loss function which is jointly optimizable with the deep
convolutional network, and ii) utilizing ensemble of deep networks. Although
some improved performance is achieved, the former may be lacking due to the
intrinsic limitation of choosing a single hypothesis and the latter usually
suffers from much larger computational complexity. To cope with those issues,
we propose to regress via an efficient ""divide and conquer"" manner. The core of
our approach is the generalization of negative correlation learning that has
been shown, both theoretically and empirically, to work well for non-deep
regression problems. Without extra parameters, the proposed method controls the
bias-variance-covariance trade-off systematically and usually yields a deep
regression ensemble where each base model is both ""accurate"" and ""diversified"".
Moreover, we show that each sub-problem in the proposed method has less
Rademacher Complexity and thus is easier to optimize. Extensive experiments on
several diverse and challenging tasks including crowd counting, personality
analysis, age estimation, and image super-resolution demonstrate the
superiority over challenging baselines as well as the versatility of the
proposed method.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 01:26:03 GMT""}]","2019-08-27"
"1908.09067","Okyaz Eminaga","Okyaz Eminaga, Mahmoud Abbas, Christian Kunder, Andreas M. Loening,
  Jeanne Shen, James D. Brooks, Curtis P. Langlotz, and Daniel L. Rubin","Plexus Convolutional Neural Network (PlexusNet): A novel neural network
  architecture for histologic image analysis",,,,,"q-bio.QM cs.AI cs.CV eess.IV q-bio.TO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Different convolutional neural network (CNN) models have been tested for
their application in histological image analyses. However, these models are
prone to overfitting due to their large parameter capacity, requiring more data
or valuable computational resources for model training. Given these
limitations, we introduced a novel architecture (termed PlexusNet). We utilized
310 Hematoxylin and Eosin stained (H&E) annotated histological images of
prostate cancer cases from TCGA-PRAD and Stanford University and 398 H&E whole
slides images from the Camelyon 2016 challenge. PlexusNet-architecture -derived
models were compared to models derived from several existing ""state of the art""
architectures. We measured discrimination accuracy, calibration, and clinical
utility. An ablation study was conducted to study the effect of each component
of PlexusNet on model performance. A well-fitted PlexusNet-based model
delivered comparable classification performance (AUC: 0.963) in distinguishing
prostate cancer from healthy tissues, although it was at least 23 times
smaller, had a better model calibration and clinical utility than the
comparison models. A separate smaller PlexusNet model accurately detected
slides with breast cancer metastases (AUC: 0.978); it helped reduce the slide
number to examine by 43.8% without consequences, although its parameter
capacity was 200 times smaller than ResNet18. We found that the partitioning of
the development set influences the model calibration for all models. However,
with PlexusNet architecture, we could achieve comparable well-calibrated models
trained on different partitions. In conclusion, PlexusNet represents a novel
model architecture for histological image analysis that achieves classification
performance comparable to other models while providing orders-of-magnitude
parameter reduction.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 01:29:34 GMT""},{""version"":""v2"",""created"":""Wed, 3 Jun 2020 04:43:21 GMT""}]","2020-06-04"
"1908.09068","Alex Horn","Alex Horn and Ali Kheradmand and Mukul R. Prasad","A Precise and Expressive Lattice-theoretical Framework for Efficient
  Network Verification","ICNP'19",,,,"cs.NI cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network verification promises to detect errors, such as black holes and
forwarding loops, by logically analyzing the control or data plane. To do so
efficiently, the state-of-the-art (e.g., Veriflow) partitions packet headers
with identical forwarding behavior into the same packet equivalence class
(PEC).
  Recently, Yang and Lam showed how to construct the minimal set of PECs,
called atomic predicates. Their construction uses Binary Decision Diagrams
(BDDs). However, BDDs have been shown to incur significant overhead per packet
header bit, performing poorly when analyzing large-scale data centers. The
overhead of atomic predicates prompted ddNF to devise a specialized data
structure of Ternary Bit Vectors (TBV) instead.
  However, TBVs are strictly less expressive than BDDs. Moreover, unlike atomic
predicates, ddNF's set of PECs is not minimal. We show that ddNF's
non-minimality is due to empty PECs. In addition, empty PECs are shown to
trigger wrong analysis results. This reveals an inherent tension between
precision, expressiveness and performance in formal network verification.
  Our paper resolves this tension through a new lattice-theoretical
PEC-construction algorithm, #PEC, that advances the field as follows: (i) #PEC
can encode more kinds of forwarding rules (e.g., ip-tables) than ddNF and
Veriflow, (ii) #PEC verifies a wider class of errors (e.g., shadowed rules)
than ddNF, and (iii) on a broad range of real-world datasets, #PEC is 10X
faster than atomic predicates. By achieving precision, expressiveness and
performance, this paper answers a longstanding quest that has spanned three
generations of formal network analysis techniques.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 01:31:57 GMT""}]","2019-08-27"
"1908.09069","Marcelo Epstein","Marcelo Epstein","Hilbert bodies as quantum-classical continua",,,,,"quant-ph math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A hybrid quantum-classical model is proposed whereby a micro-structured
(Cosserat-type) continuum is construed as a principal Hilbert bundle
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 01:51:03 GMT""},{""version"":""v2"",""created"":""Wed, 30 Oct 2019 17:24:31 GMT""}]","2019-10-31"
"1908.09070","Max Noormohammadpour","Max Noormohammadpour, Ajitesh Srivastava, Cauligi S. Raghavendra","Optimizing Inter-Datacenter Tail Flow Completion Times using Best
  Worst-case Routing","Accepted for publication in the 2019 57th Annual Allerton Conference
  on Communication, Control, and Computing (Allerton)",,,,"cs.NI cs.PF cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Flow routing over inter-datacenter networks is a well-known problem where the
network assigns a path to a newly arriving flow potentially according to the
network conditions and the properties of the new flow. An essential system-wide
performance metric for a routing algorithm is the flow completion times, which
affect the performance of applications running across multiple datacenters.
Current static and dynamic routing approaches do not take advantage of flow
size information in routing, which is practical in a controlled environment
such as inter-datacenter networks that are managed by the datacenter operators.
In this paper, we discuss Best Worst-case Routing (BWR), which aims at
optimizing the tail completion times of long-running flows over
inter-datacenter networks with non-uniform link capacities. Since finding the
path with the best worst-case completion time for a new flow is NP-Hard, we
investigate two heuristics, BWRH and BWRHF, which use two different upper
bounds on the worst-case completion times for routing. We evaluate BWRH and
BWRHF against several real WAN topologies and multiple traffic patterns.
Although BWRH better models the BWR problem, BWRH and BWRHF show negligible
difference across various system-wide performance metrics, while BWRHF being
significantly faster. Furthermore, we show that compared to other popular
routing heuristics, BWRHF can reduce the mean and tail flow completion times by
over $1.5\times$ and $2\times$, respectively.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 02:04:37 GMT""}]","2019-08-27"
"1908.09071","Yishu Xue","Yishu Xue, Elizabeth D. Schifano, Guanyu Hu","Geographically Weighted Cox Regression for Prostate Cancer Survival Data
  in Louisiana",,,"10.1111/gean.12223",,"stat.AP","http://creativecommons.org/licenses/by-nc-sa/4.0/","  The Cox proportional hazard model is one of the most popular tools in
analyzing time-to-event data in public health studies. When outcomes observed
in clinical data from different regions yield a varying pattern correlated with
location, it is often of great interest to investigate spatially varying
effects of covariates. In this paper, we propose a geographically weighted Cox
regression model for sparse spatial survival data. In addition, a stochastic
neighborhood weighting scheme is introduced at the county level. Theoretical
properties of the proposed geographically weighted estimators are examined in
detail. A model selection scheme based on the Takeuchi's model robust
information criteria (TIC) is discussed. Extensive simulation studies are
carried out to examine the empirical performance of the proposed methods. We
further apply the proposed methodology to analyze real data on prostate cancer
from the Surveillance, Epidemiology, and End Results cancer registry for the
state of Louisiana.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 02:04:57 GMT""}]","2020-02-20"
"1908.09072","Zhaobing Kang","Zhaobing Kang, Wei Zou and Zheng Zhu","Camera Pose Correction in SLAM Based on Bias Values of Map Points",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Accurate camera pose estimation result is essential for visual SLAM (VSLAM).
This paper presents a novel pose correction method to improve the accuracy of
the VSLAM system. Firstly, the relationship between the camera pose estimation
error and bias values of map points is derived based on the optimized function
in VSLAM. Secondly, the bias value of the map point is calculated by a
statistical method. Finally, the camera pose estimation error is compensated
according to the first derived relationship. After the pose correction,
procedures of the original system, such as the bundle adjustment (BA)
optimization, can be executed as before. Compared with existing methods, our
algorithm is compact and effective and can be easily generalized to different
VSLAM systems. Additionally, the robustness to system noise of our method is
better than feature selection methods, due to all original system information
is preserved in our algorithm while only a subset is employed in the latter.
Experimental results on benchmark datasets show that our approach leads to
considerable improvements over state-of-the-art algorithms for absolute pose
estimation.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 02:07:51 GMT""}]","2019-08-27"
"1908.09073","Bokui Shen","Bokui Shen, Danfei Xu, Yuke Zhu, Leonidas J. Guibas, Li Fei-Fei,
  Silvio Savarese","Situational Fusion of Visual Representation for Visual Navigation",,,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A complex visual navigation task puts an agent in different situations which
call for a diverse range of visual perception abilities. For example, to ""go to
the nearest chair"", the agent might need to identify a chair in a living room
using semantics, follow along a hallway using vanishing point cues, and avoid
obstacles using depth. Therefore, utilizing the appropriate visual perception
abilities based on a situational understanding of the visual environment can
empower these navigation models in unseen visual environments. We propose to
train an agent to fuse a large set of visual representations that correspond to
diverse visual perception abilities. To fully utilize each representation, we
develop an action-level representation fusion scheme, which predicts an action
candidate from each representation and adaptively consolidate these action
candidates into the final action. Furthermore, we employ a data-driven
inter-task affinity regularization to reduce redundancies and improve
generalization. Our approach leads to a significantly improved performance in
novel environments over ImageNet-pretrained baseline and other fusion methods.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 02:20:43 GMT""},{""version"":""v2"",""created"":""Tue, 3 Aug 2021 18:49:31 GMT""}]","2021-08-05"
"1908.09074","Sumanta Chakraborty","T.R. Govindarajan and Sumanta Chakraborty","Embedding into flat spacetime and black hole thermodynamics","Published version, 16 pages, no figures","Mod. Phys. Lett. A 34, 2050013 (2019)","10.1142/S0217732320500133",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is known that static and spherically symmetric black hole solutions of
general relativity in different spacetimes can be embedded into higher
dimensional flat spacetime. Given this result, we have explored the
thermodynamic nature of black holes \'{a} la its embedding into flat spacetime.
In particular, we have explicitly demonstrated that black hole temperature can
indeed be determined starting from the embedding and hence mapping of the
static observers in black hole spacetime to Rindler observers in flat
spacetime. Furthermore, by considering the dynamics of a scalar field in the
flat spacetime it is indeed possible to arrive at the area scaling law for
black hole entropy. Thus using flat spacetime field theory, one can indeed
provide a thermodynamic description of black holes. Implications are also
discussed.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 02:24:15 GMT""},{""version"":""v2"",""created"":""Wed, 11 Sep 2019 04:11:49 GMT""},{""version"":""v3"",""created"":""Mon, 28 Oct 2019 08:35:37 GMT""}]","2019-10-29"
"1908.09075","Chen Joya","Joya Chen, Dong Liu, Bin Luo, Xuezheng Peng, Tong Xu, Enhong Chen","Residual Objectness for Imbalance Reduction","Tech report",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For a long time, object detectors have suffered from extreme imbalance
between foregrounds and backgrounds. While several sampling/reweighting schemes
have been explored to alleviate the imbalance, they are usually heuristic and
demand laborious hyper-parameters tuning, which is hard to achieve the
optimality. In this paper, we first reveal that such the imbalance could be
addressed in a learning-based manner. Guided by this illuminating observation,
we propose a novel Residual Objectness (ResObj) mechanism that addresses the
imbalance by end-to-end optimization, while no further hand-crafted
sampling/reweighting is required. Specifically, by applying multiple cascaded
objectness-related modules with residual connections, we formulate an elegant
consecutive refinement procedure for distinguishing the foregrounds from
backgrounds, thereby progressively addressing the imbalance. Extensive
experiments present the effectiveness of our method, as well as its
compatibility and adaptivity for both region-based and one-stage detectors,
namely, the RetinaNet-ResObj, YOLOv3-ResObj and FasterRCNN-ResObj achieve
relative 3.6%, 3.9%, 3.2% Average Precision (AP) improvements compared with
their vanilla models on COCO, respectively.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 02:24:25 GMT""}]","2019-08-27"
"1908.09076","Yohei Kono","Y. Kono, S. Kittaka, H. Yamaguchi, Y. Hosokoshi, and T. Sakakibara","Emergent critical phenomenon in spin-1/2 ferromagnetic-leg ladders:
  Quasi-one-dimensional Bose--Einstein condensate","8 pages, 10 figures, accepted for publication in Phys. Rev. B","Phys. Rev. B 100, 054442 (2019)","10.1103/PhysRevB.100.054442",,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We examine the magnetic-field-induced criticality of phase boundary near
saturation field $H_{\mathrm{c}}$ in the spin-1/2 ferromagnetic (FM)-leg ladder
3-Cl-4-F-V [=3-(3-chloro-4-fluorophenyl)-1,5-diphenylverdazyl], the predominant
interactions of which arise from FM chains (strong-leg type). Critical
temperatures were precisely determined through dc magnetization, specific heat,
and magnetocaloric effect measurements. The criticality of 3-Cl-4-F-V is
characterized by a linear phase boundary with respect to $H_{\mathrm{c}}-H$
near $H\,=\,H_{\mathrm{c}}$. This behavior is similar to that of another
strong-leg-type FM-leg ladder. The universal critical behavior in these
strong-leg-type FM-leg ladders is expected to demonstrate the theoretically
predicted quasi-one-dimensional Bose--Einstein condensation.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 02:32:25 GMT""}]","2019-08-29"
"1908.09077","Rachael C Aikens","Rachael C. Aikens (1 and 2), Dylan Greaves (2), Michael Baiocchi (3)
  ((1) Stanford University Department of Biomedical Informatics, (2) Stanford
  University Department of Statistics, (3) Stanford University Department of
  Epidemiology and Population Health)","A Pilot Design for Observational Studies: Using Abundant Data
  Thoughtfully","21 pages, 7 figures",,,,"stat.ME","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Observational studies often benefit from an abundance of observational units.
This can lead to studies that -- while challenged by issues of internal
validity -- have inferences derived from sample sizes substantially larger than
randomized controlled trials. But is the information provided by an
observational unit best used in the analysis phase? We propose the use of
`pilot design,' in which observations are expended in the design phase of the
study, and the post-treatment information from these observations is used to
improve study design. In modern observational studies, which are data rich but
control poor, pilot designs can be used to gain information about the structure
of post-treatment variation. This information can then be used to improve
instrumental variable designs, propensity score matching, doubly-robust
estimation, and other observational study designs.
  We illustrate one version of a pilot design, which aims to reduce within-set
heterogeneity and improve performance in sensitivity analyses. This version of
a pilot design expends observational units during the design phase to fit a
prognostic model, avoiding concerns of overfitting. Additionally, it enables
the construction of `Assignment-Control (AC) plots,' which visualize the
relationship between propensity and prognostic scores. We first show some
examples of these plots, then we demonstrate in a simulation setting how this
alternative use of the observations can lead to gains in terms of both
treatment effect estimation and sensitivity analyses of unobserved confounding.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 02:42:18 GMT""},{""version"":""v2"",""created"":""Thu, 23 Apr 2020 23:39:29 GMT""},{""version"":""v3"",""created"":""Fri, 21 Aug 2020 00:34:11 GMT""}]","2020-08-24"
"1908.09078","Shujun Bi","Shujun Bi, Ting Tao and Shaohua Pan","KL property of exponent $1/2$ of $\ell_{2,0}$-norm and DC regularized
  factorizations for low-rank matrix recovery","29 pages, 3 figures",,,,"math.OC cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper is concerned with the factorization form of the rank regularized
loss minimization problem. To cater for the scenario in which only a coarse
estimation is available for the rank of the true matrix, an $\ell_{2,0}$-norm
regularized term is added to the factored loss function to reduce the rank
adaptively; and account for the ambiguities in the factorization, a balanced
term is then introduced. For the least squares loss, under a restricted
condition number assumption on the sampling operator, we establish the KL
property of exponent $1/2$ of the nonsmooth factored composite function and its
equivalent DC reformulations in the set of their global minimizers. We also
confirm the theoretical findings by applying a proximal linearized alternating
minimization method to the regularized factorizations.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 02:56:17 GMT""}]","2019-08-27"
"1908.09079","Jana Rodriguez Hertz","Gabriel Nu\~nez and Jana Rodriguez Hertz","Stable minimality of expanding foliations","18 pages, 4 figures, edited version, one section with new examples
  added",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We prove that generically in $\text{Diff}^{1}_{m}(M)$, if an expanding
$f$-invariant foliation $W$ of dimension $u$ is minimal and there is a periodic
point of unstable index $u$, the foliation is stably minimal. By this we mean
there is a $C^{1}$-neighborhood $\mathcal{U}$ of $f$ such that for all
$C^{2}$-diffeomorphisms $g\in \mathcal{U}$, the $g$-invariant analytic
continuation of $W$ is minimal. In particular, all such $g$ are topologically
mixing. Moreover, all such $g$ have a hyperbolic ergodic component of the
volume measure $m$ which is essentially dense. This component is, in fact,
Bernoulli. We provide new examples of stably minimal diffeomorphisms which are
not partially hyperbolic.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:01:10 GMT""},{""version"":""v2"",""created"":""Wed, 23 Oct 2019 03:50:36 GMT""},{""version"":""v3"",""created"":""Wed, 13 May 2020 05:53:03 GMT""},{""version"":""v4"",""created"":""Thu, 14 May 2020 04:39:13 GMT""}]","2020-05-15"
"1908.09080","Mohammad Reza Besharati","MohammadReza Besharati, Mohammad Izadi","DAST Model: Deciding About Semantic Complexity of a Text",,,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Measuring text complexity is an essential task in several fields and
applications (such as NLP, semantic web, smart education, etc.). The semantic
layer of text is more tacit than its syntactic structure and, as a result,
calculation of semantic complexity is more difficult than syntactic complexity.
While there are famous and powerful academic and commercial syntactic
complexity measures, the problem of measuring semantic complexity is still a
challenging one. In this paper, we introduce the DAST model, which stands for
Deciding About Semantic Complexity of a Text. DAST proposes an intuitionistic
approach to semantics that lets us have a well-defined model for the semantics
of a text and its complexity: semantic is considered as a lattice of intuitions
and, as a result, semantic complexity is defined as the result of a calculation
on this lattice. A set theoretic formal definition of semantic complexity, as a
6-tuple formal system, is provided. By using this formal system, a method for
measuring semantic complexity is presented. The evaluation of the proposed
approach is done by a set of three human-judgment experiments. The results show
that DAST model is capable of deciding about semantic complexity of text.
Furthermore, the analysis of the results leads us to introduce a Markovian
model for the process of common-sense, multiple-steps and semantic-complexity
reasoning in people. The results of Experiments demonstrate that our method
outperforms the random baseline with improvement in better precision and
competes with other methods by less error percentage.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:10:38 GMT""},{""version"":""v2"",""created"":""Tue, 1 Oct 2019 08:10:24 GMT""},{""version"":""v3"",""created"":""Mon, 7 Oct 2019 21:09:09 GMT""},{""version"":""v4"",""created"":""Fri, 15 Nov 2019 21:16:18 GMT""},{""version"":""v5"",""created"":""Sat, 30 Nov 2019 23:23:09 GMT""}]","2019-12-03"
"1908.09081","Dhananjay Bhaskar","Dhananjay Bhaskar, Angelika Manhart, Jesse Milzman, John T. Nardini,
  Kathleen Storey, Chad M. Topaz, Lori Ziegelmeier","Analyzing Collective Motion with Machine Learning and Topology","Published in Chaos 29, 123125 (2019), DOI: 10.1063/1.5125493","Chaos 29, 123125 (2019)","10.1063/1.5125493",,"math.AT nlin.PS physics.bio-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We use topological data analysis and machine learning to study a seminal
model of collective motion in biology [D'Orsogna et al., Phys. Rev. Lett. 96
(2006)]. This model describes agents interacting nonlinearly via
attractive-repulsive social forces and gives rise to collective behaviors such
as flocking and milling. To classify the emergent collective motion in a large
library of numerical simulations and to recover model parameters from the
simulation data, we apply machine learning techniques to two different types of
input. First, we input time series of order parameters traditionally used in
studies of collective motion. Second, we input measures based in topology that
summarize the time-varying persistent homology of simulation data over multiple
scales. This topological approach does not require prior knowledge of the
expected patterns. For both unsupervised and supervised machine learning
methods, the topological approach outperforms the one that is based on
traditional order parameters.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:18:30 GMT""},{""version"":""v2"",""created"":""Mon, 3 Feb 2020 19:42:49 GMT""}]","2020-02-05"
"1908.09082","Felix Hamza-Lup","Felix Hamza-Lup","Kinesthetic Learning -- Haptic User Interfaces for Gyroscopic Precession
  Simulation",,"Journal of Human Computer Interaction (RO-CHI) Vol. 11(3) (2018)
  185-204",,,"cs.HC cs.MM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Some forces in nature are difficult to comprehend due to their non-intuitive
and abstract nature. Forces driving gyroscopic precession are invisible, yet
their effect is very important in a variety of applications, from space
navigation to motion tracking. Current technological advancements in haptic
interfaces, enables development of revolutionary user interfaces, combining
multiple modalities: tactile, visual and auditory. Tactile augmented user
interfaces have been deployed in a variety of areas, from surgical training to
elementary education. This research provides an overview of haptic user
interfaces in higher education, and presents the development and assessment of
a haptic-user interface that supports the learner's understanding of gyroscopic
precession forces. The visual-haptic simulator proposed, is one module from a
series of simulators targeted at complex concept representation, using
multi-modal user interfaces. Various higher education domains, from classical
physics to mechanical engineering, will benefit from the mainstream adoption of
multi-modal interfaces for hands-on training and content delivery. Experimental
results are promising, and underline the valuable impact that haptic user
interfaces have on enabling abstract concepts understanding, through
kinesthetic learning and hands-on practice.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:24:14 GMT""}]","2019-08-27"
"1908.09083","Sudipta Kar","Sudipta Kar and Gustavo Aguilar and Mirella Lapata and Thamar Solorio","Multi-view Story Characterization from Movie Plot Synopses and Reviews","EMNLP 2020",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper considers the problem of characterizing stories by inferring
properties such as theme and style using written synopses and reviews of
movies. We experiment with a multi-label dataset of movie synopses and a tagset
representing various attributes of stories (e.g., genre, type of events). Our
proposed multi-view model encodes the synopses and reviews using hierarchical
attention and shows improvement over methods that only use synopses. Finally,
we demonstrate how can we take advantage of such a model to extract a
complementary set of story-attributes from reviews without direct supervision.
We have made our dataset and source code publicly available at
https://ritual.uh.edu/ multiview-tag-2020.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:27:43 GMT""},{""version"":""v2"",""created"":""Thu, 8 Oct 2020 22:16:46 GMT""}]","2020-10-12"
"1908.09084","Will Farr","Will M. Farr, Maya Fishbach, Jiani Ye, Daniel Holz","A Future Percent-Level Measurement of the Hubble Expansion at Redshift
  0.8 With Advanced LIGO","as accepted by ApJL; 15 pages, 5 figures; code, data, and LaTeX
  source at https://github.com/farr/PISNLineCosmography","ApJL 883 L42 (2019)","10.3847/2041-8213/ab4284","LIGO P1900252","astro-ph.CO astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simultaneous measurements of distance and redshift can be used to constrain
the expansion history of the universe and associated cosmological parameters.
Merging binary black hole (BBH) systems are standard sirens---their
gravitational waveform provides direct information about the luminosity
distance to the source. Because gravity is scale-free, there is a perfect
degeneracy between the source masses and redshift; some non-gravitational
information is necessary to break the degeneracy and determine the redshift of
the source. Here we suggest that the pair instability supernova (PISN) process,
thought to be the source of the observed upper-limit on the black hole (BH)
mass in merging BBH systems at $\sim 45 \, M_\odot$, imprints a mass scale in
the population of BBH mergers and permits a measurement of the
redshift-luminosity-distance relation with these sources. We simulate five
years of BBH detections in the Advanced LIGO and Virgo detectors with realistic
assumptions about the BBH merger rate, a mass distribution incorporating a
smooth PISN cutoff, and measurement uncertainty. We show that after one year of
operation at design sensitivity (circa 2021) the BBH population can constrain
$H(z)$ to $6.1\%$ at a pivot redshift $z \simeq 0.8$. After five years (circa
2025) the constraint improves to $2.9\%$. This measurement relies only on
general relativity and the presence of a cutoff mass scale that is
approximately fixed or calibrated across cosmic time; it is independent of any
distance ladder or cosmological model. Observations by future
``third-generation'' gravitational wave detectors, which can see BBH mergers
throughout the universe, would permit sub-percent cosmographical measurements
to $z \gtrsim 4$ within one month of observation.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:28:35 GMT""},{""version"":""v2"",""created"":""Fri, 6 Sep 2019 23:06:27 GMT""}]","2019-10-02"
"1908.09085","Felix Hamza-Lup","Amar A. Rasheed, Rabi N. Mahapatra, and Felix G. Hamza-Lup","Adaptive Group-based Zero Knowledge Proof-Authentication Protocol
  (AGZKP-AP) in Vehicular Ad Hoc Networks",,"IEEE Intelligent Transportation Systems (2019)","10.1109/TITS.2019.2899321",,"cs.CR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Vehicular Ad Hoc Networks (VANETs) are a particular subclass of mobile ad hoc
networks that raise a number of security challenges, notably from the way users
authenticate the network. Authentication technologies based on existing
security policies and access control rules in such networks assume full trust
on Roadside Unit (RSU) and authentication servers. The disclosure of
authentication parameters enables user's trace-ability over the network.
VANETs' trusted entities (e.g. RSU) can utilize such information to track a
user traveling behavior, violating user privacy and anonymity. In this paper,
we proposed a novel, light-weight, Adaptive Group-based Zero Knowledge
Proof-Authentication Protocol (AGZKP-AP) for VANETs. The proposed
authentication protocol is capable of offering various levels of users' privacy
settings based on the type of services available on such networks. Our scheme
is based on the Zero-Knowledge-Proof (ZKP) crypto approach with the support of
trade-off options. Users have the option to make critical decisions on the
level of privacy and the amount of resources usage they prefer such as short
system response time versus the number of private information disclosures.
Furthermore, AGZKP-AP is incorporated with a distributed privilege control and
revoking mechanism that render user's private information to law enforcement in
case of a traffic violation.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:40:41 GMT""}]","2019-08-27"
"1908.09086","Yan Huang","Yan Huang, Qiang Wu, JingSong Xu, Yi Zhong","SBSGAN: Suppression of Inter-Domain Background Shift for Person
  Re-Identification","Accepted by ICCV2019",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cross-domain person re-identification (re-ID) is challenging due to the bias
between training and testing domains. We observe that if backgrounds in the
training and testing datasets are very different, it dramatically introduces
difficulties to extract robust pedestrian features, and thus compromises the
cross-domain person re-ID performance. In this paper, we formulate such
problems as a background shift problem. A Suppression of Background Shift
Generative Adversarial Network (SBSGAN) is proposed to generate images with
suppressed backgrounds. Unlike simply removing backgrounds using binary masks,
SBSGAN allows the generator to decide whether pixels should be preserved or
suppressed to reduce segmentation errors caused by noisy foreground masks.
Additionally, we take ID-related cues, such as vehicles and companions into
consideration. With high-quality generated images, a Densely Associated
2-Stream (DA-2S) network is introduced with Inter Stream Densely Connection
(ISDC) modules to strengthen the complementarity of the generated data and
ID-related cues. The experiments show that the proposed method achieves
competitive performance on three re-ID datasets, ie., Market-1501,
DukeMTMC-reID, and CUHK03, under the cross-domain person re-ID scenario.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:48:28 GMT""}]","2019-08-27"
"1908.09087","Hai Bi","Yu Zhang, Hai Bi, Yidu Yang","Lower bounds for eigenvalues of the Steklov eigenvalue problem with
  variable coefficients","16 pages,4 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, using new correction to the Crouzeix-Raviart finite element
eigenvalue approximations, we obtain lower eigenvalue bounds for the Steklov
eigenvalue problem with variable coefficients on d-dimensional domains (d =
2,3). In addition, we prove that the corrected eigenvalues asymptotically
converge to the exact ones from below whether the eigenfunctions are singular
or smooth and whether the eigenvalues are large enough or not. Further, we
prove that the corrected eigenvalues still maintain the same convergence order
as that of uncorrected eigenvalues. Finally, numerical experiments validate our
theoretical results.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:49:55 GMT""}]","2019-08-27"
"1908.09088","Felix Hamza-Lup","Paul N. Borza, Mihai Machedon-Pisu, Felix G. Hamza-Lup","Design of Wireless Sensors for IoT with Energy Storage and Communication
  Channel Heterogeneity",,"MDPI Journal (2019)","10.3390/s19153364",,"cs.NI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autonomous Wireless Sensors (AWSs) are at the core of every Wireless Sensor
Network (WSN). Current AWS technology allows the development of many IoT-based
applications, ranging from military to bioengineering and from industry to
education. The energy optimization of AWSs depends mainly on: Structural,
functional, and application specifications. The holistic design methodology
addresses all the factors mentioned above. In this sense, we propose an
original solution based on a novel architecture that duplicates the
transceivers and also the power source using a hybrid storage system. By
identifying the consumption needs of the transceivers, an appropriate
methodology for sizing and controlling the power flow for the power source is
proposed. The paper emphasizes the fusion between information, communication,
and energy consumption of the AWS in terms of spectrum information through a
set of transceiver testing scenarios, identifying the main factors that
influence the sensor node design and their inter-dependencies. Optimization of
the system considers all these factors obtaining an energy efficient AWS,
paving the way towards autonomous sensors by adding an energy harvesting
element to them.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 03:54:36 GMT""}]","2019-08-27"
"1908.09089","Felix Hamza-Lup","Felix G. Hamza-Lup, Ionut E. Iacob, Sushmita Khan","Web-enabled Intelligent System for Continuous Sensor Data Processing and
  Visualization",,"ACM (2019)","10.1145/3329714.3338127",,"eess.SP cs.HC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  A large number of sensors deployed in recent years in various setups and
their data is readily available in dedicated databases or in the cloud. Of
particular interest is real-time data processing and 3D visualization in
web-based user interfaces that facilitate spatial information understanding and
sharing, hence helping the decision making process for all the parties
involved. In this research, we provide a prototype system for near real-time,
continuous X3D-based visualization of processed sensor data for two significant
applications: thermal monitoring for residential/commercial buildings and
nitrogen cycle monitoring in water beds for aquaponics systems. As sensors are
sparsely placed, in each application, where they collect data for large periods
(of up to one year), we employ a Finite Differences Method and a Neural
Networks model to approximate data distribution in the entire volume.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 04:06:01 GMT""}]","2019-08-27"
"1908.09090","Yu Zhang","Yu Zhang, Yiming Huo, Jinlong Zhan, Dongming Wang, Xiaodai Dong,
  Xiaohu You","ADMM Enabled Hybrid Precoding in Wideband Distributed Phased Arrays
  Based MIMO Systems","5 pages, 5 figures, accepted for publication at the 90th IEEE
  Vehicular Technology Conference (IEEE VTC Fall 2019)",,,,"cs.IT eess.SP math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Distributed phased arrays based multiple-input multiple-output (DPA-MIMO) is
a recently proposed highly reconfigurable architecture enabling both spatial
multiplexing and beamforming in millimeter-wave (mmWave) systems. In this work,
we focus on coping with the hybrid precoding for the wideband DPA-MIMO system
with orthogonal frequency division multiplexing (OFDM) modulation. More
specifically, we propose an alternating direction method of multipliers (ADMM)
enabled hybrid precoding approach based on an alternating optimization
framework, abbreviated to ADMM-AltMin, for such cooperative array-of-subarrays
structures. Simulation results show that the proposed ADMM-AltMin method
achieves favourable performance with practical quantization of phase shifters
taken into account.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 04:21:08 GMT""}]","2019-08-27"
"1908.09091","Mandar Joshi","Mandar Joshi and Omer Levy and Daniel S. Weld and Luke Zettlemoyer","BERT for Coreference Resolution: Baselines and Analysis","Fix test set numbers for e2e-coref on GAP",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We apply BERT to coreference resolution, achieving strong improvements on the
OntoNotes (+3.9 F1) and GAP (+11.5 F1) benchmarks. A qualitative analysis of
model predictions indicates that, compared to ELMo and BERT-base, BERT-large is
particularly better at distinguishing between related but distinct entities
(e.g., President and CEO). However, there is still room for improvement in
modeling document-level context, conversations, and mention paraphrasing. Our
code and models are publicly available.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 05:07:36 GMT""},{""version"":""v2"",""created"":""Tue, 27 Aug 2019 01:42:51 GMT""},{""version"":""v3"",""created"":""Sun, 1 Sep 2019 07:58:39 GMT""},{""version"":""v4"",""created"":""Sun, 22 Dec 2019 23:58:16 GMT""}]","2019-12-24"
"1908.09092","Dylan Slack","Dylan Slack, Sorelle Friedler, Emile Givental","Fairness Warnings and Fair-MAML: Learning Fairly with Minimal Data",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Motivated by concerns surrounding the fairness effects of sharing and
transferring fair machine learning tools, we propose two algorithms: Fairness
Warnings and Fair-MAML. The first is a model-agnostic algorithm that provides
interpretable boundary conditions for when a fairly trained model may not
behave fairly on similar but slightly different tasks within a given domain.
The second is a fair meta-learning approach to train models that can be quickly
fine-tuned to specific tasks from only a few number of sample instances while
balancing fairness and accuracy. We demonstrate experimentally the individual
utility of each model using relevant baselines and provide the first experiment
to our knowledge of K-shot fairness, i.e. training a fair model on a new task
with only K data points. Then, we illustrate the usefulness of both algorithms
as a combined method for training models from a few data points on new tasks
while using Fairness Warnings as interpretable boundary conditions under which
the newly trained model may not be fair.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 05:15:41 GMT""},{""version"":""v2"",""created"":""Thu, 5 Dec 2019 05:51:42 GMT""}]","2019-12-06"
"1908.09093","Wenda Zhang","Wenda Zhang, Wenfei Yu, Vladim\'ir Karas, Michal Dov\v{c}iak","Probing the Bardeen-Petterson effect in tidal disruption events with
  spectral line reverberation mapping","Accepted for publication in ApJ",,"10.3847/1538-4357/ab3e3e",,"astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  For an inclined accretion flow around a rotating black hole, the combined
effect of the Lense-Thirring precession and viscous torque tends to align the
inner part of the flow with the black hole spin, leading to the formation of a
warped disc, known as the Bardeen-Petterson effect (Bardeen & Petterson 1975).
In tidal disruption events (TDEs) in which a super-massive black hole starts to
accrete the bound debris, if the black hole is spinning, in general the stellar
orbit is inclined with the black hole spin. So is the accretion disc formed
following circularization and radiative cooling of the debris. Xiang-Gruess et
al. (2016) studied in detail the stellar debris evolution and disc formation in
TDEs when the stellar orbit is inclined, and found that a warped disc would
form under certain conditions. In this work we investigate properties of
time-resolved fluorescent iron line originating from a warped disc that is
irradiated by the initial X-ray flare. We find that the time-resolved spectrum
shows distinct features before and after a critical time. This critical time
depends on the Bardeen-Petterson radius $r_{\rm BP}$, i.e., the outer boundary
of the inner aligned disc; while the line width during the later stage of the
X-ray flare is sensitive to the inclination of the outer disc flow. This
demonstrates that time-resolved X-ray spectroscopy can be a powerful tool to
probe the Bardeen-Petterson effect in TDE flares and can be used to measure the
Bardeen-Petterson radius as well as put constraint on the black hole mass and
spin.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 05:16:22 GMT""}]","2019-11-06"
"1908.09094","Sandeep Juneja","Shubhada Agrawal, Sandeep Juneja and Peter Glynn","Optimal $\delta$-Correct Best-Arm Selection for General Distributions","49 pages, 2 figures",,,,"cs.LG math.PR stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Given a finite set of unknown distributions, or arms, that can be sampled, we
consider the problem of identifying the one with the largest mean using a
delta-correct algorithm (an adaptive, sequential algorithm that restricts the
probability of error to a specified delta) that has minimum sample complexity.
Lower bounds for delta-correct algorithms are well known. Delta-correct
algorithms that match the lower bound asymptotically as delta reduces to zero
have been previously developed when arm distributions are restricted to a
single parameter exponential family. In this paper, we first observe a negative
result that some restrictions are essential, as otherwise under a delta-correct
algorithm, distributions with unbounded support would require an infinite
number of samples in expectation. We then propose a delta-correct algorithm
that matches the lower bound as delta reduces to zero under the mild
restriction that a known bound on the expectation of a non-negative,
continuous, increasing convex function (for example, the squared moment) of the
underlying random variables, exists. We also propose batch processing and
identify near-optimal batch sizes to substantially speed up the proposed
algorithm. The best-arm problem has many learning applications, including
recommendation systems and product selection. It is also a well studied classic
problem in the simulation community.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 05:31:49 GMT""},{""version"":""v2"",""created"":""Tue, 8 Oct 2019 07:13:06 GMT""}]","2019-10-09"
"1908.09095","Stephen Green","Stephen R. Green, Stefan Hollands, Peter Zimmerman","Teukolsky formalism for nonlinear Kerr perturbations","53 pages, 3 figures; v3: version accepted for publication in
  Classical and Quantum Gravity","Class. Quantum Grav. 37 (2020) 075001","10.1088/1361-6382/ab7075",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We develop a formalism to treat higher order (nonlinear) metric perturbations
of the Kerr spacetime in a Teukolsky framework. We first show that solutions to
the linearized Einstein equation with nonvanishing stress tensor can be
decomposed into a pure gauge part plus a zero mode (infinitesimal perturbation
of the mass and spin) plus a perturbation arising from a certain scalar
(""Debye-Hertz"") potential, plus a so-called ""corrector tensor."" The scalar
potential is a solution to the spin $-2$ Teukolsky equation with a source. This
source, as well as the tetrad components of the corrector tensor, are obtained
by solving certain decoupled ordinary differential equations involving the
stress tensor. As we show, solving these ordinary differential equations
reduces simply to integrations in the coordinate $r$ in outgoing Kerr-Newman
coordinates, so in this sense, the problem is reduced to the Teukolsky equation
with source, which can be treated by a separation of variables ansatz. Since
higher order perturbations are subject to a linearized Einstein equation with a
stress tensor obtained from the lower order perturbations, our method also
applies iteratively to the higher order metric perturbations, and could thus be
used to analyze the nonlinear coupling of perturbations in the near-extremal
Kerr spacetime, where weakly turbulent behavior has been conjectured to occur.
Our method could also be applied to the study of perturbations generated by a
pointlike body traveling on a timelike geodesic in Kerr, which is relevant to
the extreme mass ratio inspiral problem.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 05:39:23 GMT""},{""version"":""v2"",""created"":""Thu, 19 Sep 2019 09:08:23 GMT""},{""version"":""v3"",""created"":""Mon, 14 Sep 2020 16:04:53 GMT""}]","2020-09-15"
"1908.09096","Weizhu Bao","Weizhu Bao and Xinran Ruan","Computing ground states of Bose-Einstein Condensates with higher order
  interaction via a regularized density function formulation","26 pages, 5 figures",,,,"cond-mat.quant-gas cs.NA math.NA physics.comp-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We propose and analyze a new numerical method for computing the ground state
of the modified Gross-Pitaevskii equation for modeling the Bose-Einstein
condensate with a higher order interaction by adapting the density function
formulation and the accelerated projected gradient method. By reformulating the
energy functional $E(\phi)$ with $\phi$, the wave function, in terms of the
density $\rho=|\phi|^2$, the original non-convex minimization problem for
defining the ground state is then reformulated to a convex minimization
problem. In order to overcome the semi-smoothness of the function $\sqrt{\rho}$
in the kinetic energy part, a regularization is introduced with a small
parameter $0<\varepsilon\ll1$. Convergence of the regularization is established
when $\varepsilon\to0$. The regularized convex optimization problem is
discretized by the second order finite difference method. The convergence rates
in terms of the density and energy of the discretization are established. The
accelerated projected gradient method is adapted for solving the discretized
optimization problem. Numerical results are reported to demonstrate the
efficiency and accuracy of the proposed numerical method. Our results show that
the proposed method is much more efficient than the existing methods in the
literature, especially in the strong interaction regime.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 05:43:48 GMT""}]","2019-08-27"
"1908.09097","Toby Walsh","Toby Walsh","Experiments in Social Media","To appear in AI Magazine",,,,"cs.CY cs.SI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Social media platforms like Facebook and Twitter permit experiments to be
performed at minimal cost on populations of a size that scientists might
previously have dreamt about. For instance, one experiment on Facebook involved
over 60 million subjects. Such large scale experiments introduce new challenges
as even small effects when multiplied by a large population can have a
significant impact.
  Recent revelations about the use of social media to manipulate voting
behaviour compound such concerns. It is believed that the psychometric data
used by Cambridge Analytica to target US voters was collected by Dr Aleksandr
Kogan from Cambridge University using a personality quiz on Facebook. There is
a real risk that researchers wanting to collect data and run experiments on
social media platforms in the future will face a public backlash that hinders
such studies from being conducted. We suggest that stronger safe guards are put
in place to help prevent this, and ensure the public retain confidence in
scientists using social media for behavioural and other studies.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 06:01:13 GMT""}]","2019-08-27"
"1908.09098","Di Qiu","Di Qiu, Lok-Ming Lui","Inconsistent Surface Registration via Optimization of Mapping
  Distortions",,,,,"cs.CG cs.GR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We address the problem of registering two surfaces, of which a natural
bijection between them does not exist. More precisely, only a partial subset of
the source surface is assumed to be in correspondence with a subset of the
target surface. We call such a problem an {\it inconsistent surface
registration (ISR)} problem. This problem is challenging as the corresponding
regions on each surface and a meaningful bijection between them have to be
simultaneously determined. In this paper, we propose a variational model to
solve the ISR problem by minimizing mapping distortions. Mapping distortions
are described by the Beltrami coefficient as well as the differential of the
mapping. Registration is then guided by feature landmarks and/or intensities,
such as curvatures, defined on each surface. The key idea of the approach is to
control angle and scale distortions via quasiconformal theory as well as
minimizing landmark and/or intensity mismatch. A splitting method is proposed
to iteratively search for the optimal corresponding regions as well as the
optimal bijection between them. Bijectivity of the mapping is easily enforced
by a thresholding of the Beltrami coefficient. We test the proposed method on
both synthetic and real examples. Experimental results demonstrate the efficacy
of our proposed model.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 06:34:07 GMT""},{""version"":""v2"",""created"":""Thu, 9 Apr 2020 11:58:22 GMT""}]","2020-04-10"
"1908.09099","Zhonghuai Hou","Xinshuang Liu, Huijun Jiang and Zhonghuai Hou","Configuration Dynamics of a Flexible Polymer Chain in a Bath of Chiral
  Active Particles",,,"10.1063/1.5125607",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We investigate configuration dynamics of a flexible polymer chain in a bath
of active particles with dynamic chirality, i.e., particles rotate with a
deterministic angular velocity $\omega$ besides self-propulsion,by Langevin
dynamics simulations in two dimensional space. Particular attentions are paid
to how the gyration radius $R_{g}$ changes with the propulsion velocity
$v_{0}$,angular velocity $\omega$ and chain length. We find that in a chiral
bath with a typical nonzero $\omega$, the chain first collapses into a small
compact cluster and swells again with increasing $v_{0}$, in quite contrast to
the case for a normal achiral bath $(\omega=0)$ wherein a flexible chain swells
with increasing $v_{0}$. More interestingly, the polymer can even form a closed
ring if the chain length is large enough,which may oscillate with the cluster
if $v_{0}$ is large. Consequently, the gyration radius $R_{g}$ shows nontrivial
non-monotonic dependences on $v_{0}$, i.e., it undergoes a minimum for
relatively short chains, and two minima with a maximum in between for longer
chains. Our analysis shows that such interesting phenomena are mainly due to
the competition between two roles played by the chiral active bath: while the
persistence motion due to particle activity tends to stretch the chain, the
circular motion of the particle may lead to an effective osmotic pressure that
tends to collapse the chain. In addition, the size of the circular motion
$R_{0}=v_{0}/\omega$ shows an important role in that the compact clusters and
closed-rings are both observed at nearly the same values of $R_{0}$ for
different $\omega$.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 06:36:49 GMT""}]","2020-01-08"
"1908.09100","Manfred Kraus","Manfred Kraus, Till Martini, Sascha Peitzsch, Peter Uwer","Exploring BSM Higgs couplings in single top-quark production","6 pages, 6 figures",,,"HU-EP-19/21","hep-ph hep-ex","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this article we study a Standard Model extension modifying the top-quark
Yukawa coupling to the Higgs boson by allowing a mixture of CP-odd and -even
couplings. Single top-quark production in association with an additional Higgs
boson provides a natural laboratory to search for such extensions. However,
because of the small cross section the experimental analysis is challenging.
Already the measurement of the cross section for this process is highly
non-trivial. Furthermore, using only cross section measurements, a certain
parameter region would escape detection. Using an explicit BSM scenario we show
that employing the Matrix Element Method a precise measurement becomes
feasible. Ignoring signal detection efficiencies an integrated luminosity of
about 20 fb^-1 would allow a discovery. Assuming signal detection efficiencies
at the level of a few percent a potential signal could be established in the
high luminosity phase of the LHC.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 06:47:53 GMT""}]","2019-08-27"
"1908.09101","Haiyang Mei","Xin Yang, Haiyang Mei, Ke Xu, Xiaopeng Wei, Baocai Yin, Rynson W.H.
  Lau","Where Is My Mirror?","Accepted by ICCV 2019. Project homepage:
  https://mhaiyang.github.io/ICCV2019_MirrorNet/index.html",,,,"cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Mirrors are everywhere in our daily lives. Existing computer vision systems
do not consider mirrors, and hence may get confused by the reflected content
inside a mirror, resulting in a severe performance degradation. However,
separating the real content outside a mirror from the reflected content inside
it is non-trivial. The key challenge is that mirrors typically reflect contents
similar to their surroundings, making it very difficult to differentiate the
two. In this paper, we present a novel method to segment mirrors from an input
image. To the best of our knowledge, this is the first work to address the
mirror segmentation problem with a computational approach. We make the
following contributions. First, we construct a large-scale mirror dataset that
contains mirror images with corresponding manually annotated masks. This
dataset covers a variety of daily life scenes, and will be made publicly
available for future research. Second, we propose a novel network, called
MirrorNet, for mirror segmentation, by modeling both semantical and low-level
color/texture discontinuities between the contents inside and outside of the
mirrors. Third, we conduct extensive experiments to evaluate the proposed
method, and show that it outperforms the carefully chosen baselines from the
state-of-the-art detection and segmentation methods.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 06:57:04 GMT""},{""version"":""v2"",""created"":""Thu, 3 Oct 2019 10:44:28 GMT""}]","2019-10-04"
"1908.09102","Takuya Kanazawa","Takuya Kanazawa, Akinori Asahara, Hidekazu Morita","Accelerating small-angle scattering experiments with simulation-based
  machine learning","19 pages, 9 figures. Accepted for publication in Journal of Physics:
  Materials","J. Phys. Mater. 3 (2019) 015001","10.1088/2515-7639/ab3c45",,"cond-mat.mtrl-sci cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Making material experiments more efficient is a high priority for materials
scientists who seek to discover new materials with desirable properties. In
this paper, we investigate how to optimize the laborious sequential
measurements of materials properties with data-driven methods, taking the
small-angle neutron scattering (SANS) experiment as a test case. We propose two
methods for optimizing sequential data sampling. These methods iteratively
suggest the best target for the next measurement by performing a statistical
analysis of the already acquired data, so that maximal information is gained at
each step of an experiment. We conducted numerical simulations of SANS
experiments for virtual materials and confirmed that the proposed methods
significantly outperform baselines.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 07:21:36 GMT""}]","2019-10-24"
"1908.09103","J\""org Stoye","Hiroaki Kaido, Francesca Molinari, and J\""org Stoye","Constraint Qualifications in Partial Identification","Final version as accepted for publication in Econometric Theory",,"10.1017/S0266466621000207",,"econ.EM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The literature on stochastic programming typically restricts attention to
problems that fulfill constraint qualifications. The literature on estimation
and inference under partial identification frequently restricts the geometry of
identified sets with diverse high-level assumptions. These superficially appear
to be different approaches to closely related problems. We extensively analyze
their relation. Among other things, we show that for partial identification
through pure moment inequalities, numerous assumptions from the literature
essentially coincide with the Mangasarian-Fromowitz constraint qualification.
This clarifies the relation between well-known contributions, including within
econometrics, and elucidates stringency, as well as ease of verification, of
some high-level assumptions in seminal papers.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 07:34:43 GMT""},{""version"":""v2"",""created"":""Thu, 18 Jun 2020 15:13:03 GMT""},{""version"":""v3"",""created"":""Fri, 18 Dec 2020 18:11:53 GMT""},{""version"":""v4"",""created"":""Mon, 12 Apr 2021 01:32:03 GMT""}]","2021-07-01"
"1908.09104","Yujie Lin","Yujie Lin, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Jun Ma, Maarten de
  Rijke","Improving Outfit Recommendation with Co-supervision of Fashion
  Generation",,,"10.1145/3308558.3313614",,"cs.IR cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The task of fashion recommendation includes two main challenges: visual
understanding and visual matching. Visual understanding aims to extract
effective visual features. Visual matching aims to model a human notion of
compatibility to compute a match between fashion items. Most previous studies
rely on recommendation loss alone to guide visual understanding and matching.
Although the features captured by these methods describe basic characteristics
(e.g., color, texture, shape) of the input items, they are not directly related
to the visual signals of the output items (to be recommended). This is
problematic because the aesthetic characteristics (e.g., style, design), based
on which we can directly infer the output items, are lacking. Features are
learned under the recommendation loss alone, where the supervision signal is
simply whether the given two items are matched or not. To address this problem,
we propose a neural co-supervision learning framework, called the FAshion
Recommendation Machine (FARM). FARM improves visual understanding by
incorporating the supervision of generation loss, which we hypothesize to be
able to better encode aesthetic information. FARM enhances visual matching by
introducing a novel layer-to-layer matching mechanism to fuse aesthetic
information more effectively, and meanwhile avoiding paying too much attention
to the generation quality and ignoring the recommendation performance.
Extensive experiments on two publicly available datasets show that FARM
outperforms state-of-the-art models on outfit recommendation, in terms of AUC
and MRR. Detailed analyses of generated and recommended items demonstrate that
FARM can encode better features and generate high quality images as references
to improve recommendation performance.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 07:37:57 GMT""}]","2019-08-27"
"1908.09105","Hanshuang Chen","Huan Wang and Chuang Ma and Hanshuang Chen and Haifeng Zhang","Effect of overlap on spreading dynamics on multiplex networks","26 pages, 11 figures","Journal of Statistical Mechanics: Theory and Experiment (2020)
  043402","10.1088/1742-5468/ab780e",,"cond-mat.stat-mech physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In spite of the study of epidemic dynamics on single-layer networks has
received considerable attention, the epidemic dynamics on multiplex networks is
still limited and is facing many challenges. In this work, we consider the
susceptible-infected-susceptible-type (SIS) epidemic model on multiplex
networks and investigate the effect of overlap among layers on the spreading
dynamics. To do so, we assume that the prerequisite of one $S$-node to be
infected is that there is at least one infectious neighbor in each layer. A
remarkable result is that the overlap can alter the nature of the phase
transition for the onset of epidemic outbreak. Specifically speaking, the
system undergoes a usual continuous phase transition when two layers are
completely overlapped. Otherwise, a discontinuous phase transition is observed,
accompanied by the occurrence of a bistable region in which a disease-free
phase and an endemic phase are coexisting. As the degree of the overlap
decreases, the bistable region is enlarged. The results are validated by both
simulation and mean-field theory.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 07:58:09 GMT""},{""version"":""v2"",""created"":""Sat, 16 Nov 2019 02:13:20 GMT""},{""version"":""v3"",""created"":""Wed, 5 Feb 2020 07:15:13 GMT""}]","2021-11-03"
"1908.09106","Boris Kruglikov","Boris Kruglikov, Andrea Santi, Dennis The","G(3)-supergeometry and a supersymmetric extension of the Hilbert-Cartan
  equation","final version; the ancillary files can be accessed via version 1","Adv. Math. 376 (2021), 107420",,,"math.DG math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We realize the simple Lie superalgebra G(3) as supersymmetry of various
geometric structures, most importantly super-versions of the Hilbert-Cartan
equation (SHC) and Cartan's involutive PDE system that exhibit G(2) symmetry.
We provide the symmetries explicitly and compute, via the first Spencer
cohomology groups, the Tanaka-Weisfeiler prolongation of the negatively graded
Lie superalgebras associated with two particular choices of parabolics. We
discuss non-holonomic superdistributions with growth vector (2|4,1|2,2|0)
deforming the flat model SHC, and prove that the second Spencer cohomology
group gives a binary quadratic form, thereby providing a ""square-root"" of
Cartan's classical binary quartic invariant for generic rank 2 distributions in
a 5-dimensional space. Finally, we obtain super-extensions of Cartan's
classical submaximally symmetric models, compute their symmetries and observe a
supersymmetry dimension gap phenomenon.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 08:27:06 GMT""},{""version"":""v2"",""created"":""Fri, 25 Sep 2020 21:06:50 GMT""}]","2021-06-14"
"1908.09107","Stefano Marmi","Erwan Lanneau, Stefano Marmi and Alexandra Skripchenko","Cohomological equations for linear involutions","9 pages",,,,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the current note we extend results by Marmi, Moussa and Yoccoz about
cohomological equations for interval exchange transformations to irreducible
linear involutions.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 08:31:45 GMT""}]","2019-08-27"
"1908.09108","Sagi Eppel","Sagi Eppel, Alan Aspuru-Guzik","Generator evaluator-selector net for panoptic image segmentation and
  splitting unfamiliar objects into parts",,,,,"cs.CV cs.LG","http://creativecommons.org/licenses/by-nc-sa/4.0/","  In machine learning and other fields, suggesting a good solution to a problem
is usually a harder task than evaluating the quality of such a solution. This
asymmetry is the basis for a large number of selection oriented methods that
use a generator system to guess a set of solutions and an evaluator system to
rank and select the best solutions. This work examines the use of this approach
to the problem of panoptic image segmentation and class agnostic parts
segmentation. The generator/evaluator approach for this case consists of two
independent convolutional neural nets: a generator net that suggests variety
segments corresponding to objects, stuff and parts regions in the image, and an
evaluator net that chooses the best segments to be merged into the segmentation
map. The result is a trial and error evolutionary approach in which a generator
that guesses segments with low average accuracy, but with wide variability, can
still produce good results when coupled with an accurate evaluator. The
generator consists of a Pointer net that receives an image and a point in the
image, and predicts the region of the segment containing the point. Generating
and evaluating each segment separately is essential in this case since it
demands exponentially fewer guesses compared to a system that guesses and
evaluates the full segmentation map in each try. The classification of the
selected segments is done by an independent region-specific classification net.
This allows the segmentation to be class agnostic and hence, capable of
segmenting unfamiliar categories that were not part of the training set. The
method was examined on the COCO Panoptic segmentation benchmark and gave
results comparable to those of the basic semantic segmentation and Mask-RCNN
methods. In addition, the system was used for the task of splitting objects of
unseen classes (that did not appear in the training set) into parts.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:01:27 GMT""},{""version"":""v2"",""created"":""Tue, 27 Aug 2019 02:02:07 GMT""},{""version"":""v3"",""created"":""Wed, 8 Apr 2020 19:28:03 GMT""},{""version"":""v4"",""created"":""Mon, 13 Apr 2020 08:55:36 GMT""}]","2020-04-14"
"1908.09109","Pietro Tierno Dr","Pietro Tierno","Magnetic assembly and annealing of colloidal lattices and superlattices",,"Langmuir 30, 7670 (2014)","10.1021/la501273b",,"cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ability to assemble mesoscopic colloidal lattices above a surface is
important for fundamental studies related with nucleation and crystallization,
but also for a variety of technological applications in photonics and
micro-engineering. Current techniques based on particle sedimentation above a
lithographic template are limited by a slow deposition process and by the use
of static templates, which make difficult to implement fast annealing
procedures. Here it is demonstrated a method to realize and anneal a series of
colloidal lattices displaying triangular, honeycomb or kagome-like symmetry
above a structure magnetic substrate. By using a binary mixture of particles,
superlattices can be realized increasing further the variety and complexity of
the colloidal patterns which can be produced.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:02:27 GMT""}]","2019-08-27"
"1908.09110","Barnali Das","Barnali Das, Poonam Chandra, Matt. E. Shultz, Gregg A. Wade","The fifth main sequence magnetic B-type star showing coherent radio
  emission: is this really a rare phenomenon?","Accepted for publication in MNRAS Letters",,"10.1093/mnrasl/slz137",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report the discovery of intense, highly directional radio emission from
the Bp star HD 35298, which we interpret as the consequence of Electron
Cyclotron Maser Emission (ECME). The star was observed with the Giant Metrewave
Radio Telescope near the rotational phases of both magnetic nulls in band 4
(550-750 MHz) and one of the nulls in band 5 (1060-1460 MHz). In band 4, we
observed flux density enhancement in both circular polarizations near both
magnetic nulls. The sequences of arrival of the left and right circularly
polarized pulses are opposite near the two nulls. In band 5, we did not have
circular polarization information and hence measured only the total intensity
lightcurve, which also shows enhancement around the magnetic null. The observed
sequence of the circular polarization signs in band 4, compared with the
longitudinal magnetic field curve, is able to locate the hemisphere from which
ECME arises. This observational evidence supports the scenario of ECME in the
ordinary mode, arising in a magnetosphere shaped like an oblique dipole. HD
35298 is the most slowly rotating and most distant main sequence magnetic star
from which ECME has been observed.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:11:39 GMT""}]","2019-09-25"
"1908.09111","Jinsong Zeng","Yan Gao and Jinsong Zeng","The landing of parameter rays at non-recurrent critical portraits","16 pages","published in Sci China Math, December 2018, Vol.61 No.12:
  2267-2282","10.1007/s11425-017-9226-7",,"math.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Based on the distortion theory developed by Cui--Tan \cite{CT15}, we prove
the landing of every parameter ray at critical portraits coming from
non-recurrent polynomials, thereby generalizing a result of Kiwi
\cite[Corollary]{Ki05}
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:23:22 GMT""}]","2019-08-27"
"1908.09112","Daniel Andrade","Daniel Andrade and Kenji Fukumizu","Disjunct Support Spike and Slab Priors for Variable Selection in
  Regression under Quasi-sparseness",,,,,"stat.ME stat.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sparseness of the regression coefficient vector is often a desirable
property, since, among other benefits, sparseness improves interpretability. In
practice, many true regression coefficients might be negligibly small, but
non-zero, which we refer to as quasi-sparseness. Spike-and-slab priors as
introduced in (Chipman et al., 2001) can be tuned to ignore very small
regression coefficients, and, as a consequence provide a trade-off between
prediction accuracy and interpretability. However, spike-and-slab priors with
full support lead to inconsistent Bayes factors, in the sense that the Bayes
factors of any two models are bounded in probability. This is clearly an
undesirable property for Bayesian hypotheses testing, where we wish that
increasing sample sizes lead to increasing Bayes factors favoring the true
model. The moment matching priors as in (Johnson and Rossell, 2012) can resolve
this issue, but are unsuitable for the quasi-sparse setting due to their full
support outside the exact value 0. As a remedy, we suggest disjunct support
spike and slab priors, for which we prove consistent Bayes factors in the
quasi-sparse setting, and show experimentally fast growing Bayes factors
favoring the true model. Several experiments on simulated and real data confirm
the usefulness of our proposed method to identify models with high effect size,
while leading to better control over false positives than hard-thresholding.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:23:59 GMT""},{""version"":""v2"",""created"":""Sun, 29 Sep 2019 09:42:59 GMT""}]","2019-10-01"
"1908.09113","Wojciech G\'orny","Samer Dweik, Wojciech G\'orny","Least gradient problem on annuli","19 pages, 1 figure",,,,"math.AP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the two dimensional BV least gradient problem on an annulus with
given boundary data $g \in BV(\partial\Omega)$. Firstly, we prove that this
problem is equivalent to the optimal transport problem with source and target
measures located on the boundary of the domain. Then, under some admissibility
conditions on the trace, we show that there exists a unique solution for the BV
least gradient problem. Moreover, we prove some $L^p$ estimates on the
corresponding minimal flow of the Beckmann problem, which implies directly
$W^{1,p}$ regularity for the solution of the BV least gradient problem.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:25:46 GMT""}]","2019-08-27"
"1908.09114","Yoichi Miyata","Yoichi Miyata, Takayuki Shiohama and Toshihiro Abe","Identifiability of asymmetric circular and cylindrical distributions",,,,,"math.ST stat.TH","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Identifiability of statistical models is a fundamental and essential
condition that is required to prove the consistency of maximum likelihood
estimators. The identifiability of the skew families of distributions on the
circle and cylinder for estimating model parameters has not been fully
investigated in the literature. In this paper, a new method combining the
trigonometric moments and the simultaneous Diophantine approximation is
proposed to prove the identifiability of asymmetric circular and cylindrical
distributions. Using this method, we prove the identifiability of general
sine-skewed circular distributions, including the sine-skewed von Mises and
sine-skewed wrapped Cauchy distributions, and that of a M\""{o}bius transformed
cardioid distribution, which can be regarded as asymmetric distributions on the
unit circle. In addition, we prove the identifiability of two cylindrical
distributions wherein both marginal distributions of a circular random variable
are the sine-skewed wrapped Cauchy distribution, and conditional distributions
of a random variable on the non-negative real line given the circular random
variable are a Weibull distribution and a generalized Pareto-type distribution,
respectively.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:34:12 GMT""},{""version"":""v2"",""created"":""Sat, 26 Oct 2019 03:19:44 GMT""},{""version"":""v3"",""created"":""Sat, 2 Nov 2019 12:45:28 GMT""},{""version"":""v4"",""created"":""Sun, 16 Aug 2020 07:45:39 GMT""},{""version"":""v5"",""created"":""Mon, 4 Apr 2022 03:56:48 GMT""}]","2022-04-05"
"1908.09115","Taras Banakh","Taras Banakh","On topological classification of normed spaces endowed with the weak
  topology or the topology of compact convergence","7 pages","in: General Topology in Banach Spaces (T.Banakh ed.), Nova Sci.
  Publ., NY, (2001), 171--178",,,"math.GN math.FA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper the weak topology on a normed space is studied from the
viewpoint of infinite-dimensional topology. Besides the weak topology on a
normed space $X$ (coinciding with the topology of uniform convergence on finite
subsets of the dual space $X^*$), we consider the topology $c$ of uniform
convergence on compact subsets of $X^*$. It is known that this topology
coincides with the weak topology on bounded subsets of $X$, but unlike to the
latter has much better topological properties (e.g., is stratifiable).
  We prove that for normed spaces $X,Y$ with separable duals the spaces
$(X,weak)$, $(Y,weak)$ are sequentially homeomorphic if and only if $\mathcal
W(X)=\mathcal W(Y)$, where $\mathcal W(X)$ is the class of topological spaces
homeomorphic to closed bounded subsets of $(X,weak)$. Moreover, if $X,Y$ are
Banach spaces which are isomorphic to their hyperplanes and have separale
duals, then the spaces $(X,weak)$ and $(Y,weak)$ are sequentially homeomorphic
if and only of the spaces $(X,c)$ and $(Y,c)$ are homeomorphic. To prove this
result, we show that for a normed space $X$ which is isomorphic to its
hyperpane and has separable dual, the space $(X,c)$ (resp. $(X,weak)$) is
(sequentially) homeomorphic to the product $B\times\mathbb R^\infty$ of the
weak unit ball $B$ of $X$ and the linear space $\mathbb R^\infty$ with
countable Hamel basis and the strongest linear topology.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:41:33 GMT""}]","2019-08-27"
"1908.09116","Markus D Schirmer","Ai Wern Chung and Markus D. Schirmer","Network Dependency Index Stratified Subnetwork Analysis of Functional
  Connectomes: An application to autism",,,"10.1007/978-3-030-32391-2_13",,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autism spectrum disorder (ASD) is a neurodevelopmental condition impacting
high-level cognitive processing and social behavior. Recognizing the
distributed nature of brain function, neuroscientists are exploiting the
connectome to aid with the characterization of this complex disease. The human
connectome has demonstrated the brain to be a highly organized system with a
centralized core vital for effective function. As such, many have used this
topological principle to not only assess core regions, but have stratified the
remaining graph into subnetworks depending on their relation to the core.
Subnetworks are then utilized to further understand the supporting role of more
peripheral nodes with respects to the overall function in the network. A
recently proposed framework for subnetwork definition is based on the network
dependency index (NDI), a measure of a node's importance based on its
contribution to overall efficiency in the network, and the derived subnetworks,
or Tiers, have been shown to be largely stable across ages in structural
networks. Here, we extend the NDI framework to test its efficacy against a
number experimental conditions. We first not only demonstrated NDI's
feasibility on resting-state functional MRI data, but also its stability
irrespective of the group connectome on which NDI was determined for various
edge thresholds. Secondly, by comparing network theory measures of transitivity
and efficiency, significant group differences were identified in NDI Tiers of
greatest importance. This demonstrates the efficacy of utilizing NDI stratified
subnetworks, which can help to improve our understanding of diseases and how
they affect overall brain connectivity.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:44:39 GMT""},{""version"":""v2"",""created"":""Wed, 25 Sep 2019 09:06:06 GMT""}]","2019-09-26"
"1908.09117","Markus D Schirmer","Markus D. Schirmer and Ai Wern Chung","Heat kernels with functional connectomes reveal atypical energy
  transport in peripheral subnetworks in autism",,,"10.1007/978-3-030-32391-2_6",,"q-bio.NC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Autism is increasing in prevalence and is a neurodevelopmental disorder
characterised by impairments in communication skills and social behaviour.
Connectomes enable a systems-level representation of the brain with recent
interests in understanding the distributed nature of higher order cognitive
function using modules or subnetworks. By dividing the connectome according to
a central component of the brain critical for its function (it's hub), we
investigate network organisation in autism from hub through to peripheral
subnetworks. We complement this analysis by extracting features of energy
transport computed from heat kernels fitted with increasing time steps. This
heat kernel framework is advantageous as it can capture the energy transported
in all direct and indirect pathways between pair-wise regions over 'time', with
features that have correspondence to small-world properties. We apply our
framework to resting-state functional MRI connectomes from a large, publically
available autism dataset, ABIDE. We show that energy propagating through the
brain over time are different between subnetworks, and that heat kernel
features significantly differ between autism and controls. Furthermore, the hub
was functionally preserved and similar to controls, however, increasing
statistical significance between groups was found in increasingly peripheral
subnetworks. Our results support the increasing opinion of non-hub regions
playing an important role in functional organisation. This work shows that
analysing autism by subnetworks with the heat kernel reflects the atypical
activations in peripheral regions as alterations in energy dispersion and may
provide useful features towards understanding the distributed impact of this
disorder on the functional connectome.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:48:36 GMT""},{""version"":""v2"",""created"":""Wed, 25 Sep 2019 09:08:25 GMT""}]","2019-09-26"
"1908.09118","Alexander Andrianov A","A. A. Andrianov, V. A. Andrianov, D. Espriu","Chiral perturbation theory vs. Linear Sigma Model in a chiral imbalance
  medium","11 pages, coefficient corrections in eqs.(11) - (13),(21)","Particles 3 (2020) 1, 15-22",,,"hep-th hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We compare Chiral Perturbation Theory (ChPT) and the Linear Sigma Model (LSM)
as realizations of low energy QCD for light mesons in a chirally imbalanced
medium. The relations between the low-energy constants of the Chiral Lagrangian
and the corresponding constants of the Linear Sigma Model are established as
well as the expressions for the decay constant of the $\pi$-meson in the medium
and the mass of the $a_0$. In the large $N_c$ count taken from QCD the
correspondence of ChPT and LSM is remarkably good and give a solid ground for
search of chiral imbalance manifestation in pion physics. A possible
experimental detection of chiral imbalance tracks (and therefore a phase with
Local Parity Breaking) in the charged pion decays inside the fireball is
outlined.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 09:55:44 GMT""},{""version"":""v2"",""created"":""Sat, 19 Oct 2019 16:54:16 GMT""},{""version"":""v3"",""created"":""Sun, 17 May 2020 15:59:04 GMT""}]","2020-05-19"
"1908.09119","Varun Pandya","Varun Pandya","Automatic Text Summarization of Legal Cases: A Hybrid Approach","Part of 5th International Conference on Natural Language Processing
  (NATP 2019) Proceedings",,"10.5121/csit.2019.91004",,"cs.CL cs.IR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Manual Summarization of large bodies of text involves a lot of human effort
and time, especially in the legal domain. Lawyers spend a lot of time preparing
legal briefs of their clients' case files. Automatic Text summarization is a
constantly evolving field of Natural Language Processing(NLP), which is a
subdiscipline of the Artificial Intelligence Field. In this paper a hybrid
method for automatic text summarization of legal cases using k-means clustering
technique and tf-idf(term frequency-inverse document frequency) word vectorizer
is proposed. The summary generated by the proposed method is compared using
ROGUE evaluation parameters with the case summary as prepared by the lawyer for
appeal in court. Further, suggestions for improving the proposed method are
also presented.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 10:05:40 GMT""}]","2019-08-27"
"1908.09120","Alberto Baccini","Alberto Baccini, Lucio Barabesi, Mahdi Khelfaoui and Yves Gingras","Intellectual and social similarity among scholarly journals: an
  exploratory comparison of the networks of editors, authors and co-citations","21 pages, 9 Figures. Accepted for publication in Quantitative Science
  Studies. Fixed the spelling of the name of one of the authors","Quantitative Science Studies 2019","10.1162/qss_a_00006",,"cs.SI cs.DL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper explores, by using suitable quantitative techniques, to what
extent the intellectual proximity among scholarly journals is also a proximity
in terms of social communities gathered around the journals. Three fields are
considered: statistics, economics and information and library sciences.
Co-citation networks (CC) represent the intellectual proximity among journals.
The academic communities around the journals are represented by considering the
networks of journals generated by authors writing in more than one journal
(interlocking authorship: IA), and the networks generated by scholars sitting
in the editorial board of more than one journal (interlocking editorship: IE).
For comparing the whole structure of the networks, the dissimilarity matrices
are considered. The CC, IE and IA networks appear to be correlated for the
three fields. The strongest correlations is between CC and IA for the three
fields. Lower and similar correlations are obtained for CC and IE, and for IE
and IA. The CC, IE and IA networks are then partitioned in communities.
Information and library sciences is the field where communities are more easily
detectable, while the most difficult field is economics. The degrees of
association among the detected communities show that they are not independent.
For all the fields, the strongest association is between CC and IA networks;
the minimum level of association is between IE and CC. Overall, these results
indicate that the intellectual proximity is also a proximity among authors and
among editors of the journals. Thus, the three maps of editorial power,
intellectual proximity and authors communities tell similar stories.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 10:06:30 GMT""},{""version"":""v2"",""created"":""Tue, 27 Aug 2019 13:43:08 GMT""},{""version"":""v3"",""created"":""Mon, 2 Sep 2019 05:50:59 GMT""}]","2019-10-18"
"1908.09121","Luca Giorgetti","Luca Giorgetti","Minimal index and dimension for inclusions of von Neumann algebras with
  finite-dimensional centers","Invited contribution to the Proceedings of the 27th International
  Conference in Operator Theory (OT27), Timi\c{s}oara, 2018","Operator Theory 27, Theta Ser. Adv. Math. (2020) 183-191",,"Roma01.Math","math.OA math-ph math.CT math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The notion of index for inclusions of von Neumann algebras goes back to a
seminal work of Jones on subfactors of type ${I\!I}_1$. In the absence of a
trace, one can still define the index of a conditional expectation associated
to a subfactor and look for expectations that minimize the index. This value is
called the minimal index of the subfactor. We report on our analysis, contained
in [GL19], of the minimal index for inclusions of arbitrary von Neumann
algebras (not necessarily finite, nor factorial) with finite-dimensional
centers. Our results generalize some aspects of the Jones index for
multi-matrix inclusions (finite direct sums of matrix algebras), e.g., the
minimal index always equals the squared norm of a matrix, that we call
\emph{matrix dimension}, as it is the case for multi-matrices with respect to
the Bratteli inclusion matrix. We also mention how the theory of minimal index
can be formulated in the purely algebraic context of rigid 2-$C^*$-categories.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 10:07:40 GMT""}]","2022-05-04"
"1908.09122","Shiwan Zhao Mr","Mengting Hu, Yike Wu, Shiwan Zhao, Honglei Guo, Renhong Cheng, Zhong
  Su","Domain-Invariant Feature Distillation for Cross-Domain Sentiment
  Classification","Accepted by EMNLP 2019",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Cross-domain sentiment classification has drawn much attention in recent
years. Most existing approaches focus on learning domain-invariant
representations in both the source and target domains, while few of them pay
attention to the domain-specific information. Despite the non-transferability
of the domain-specific information, simultaneously learning domain-dependent
representations can facilitate the learning of domain-invariant
representations. In this paper, we focus on aspect-level cross-domain sentiment
classification, and propose to distill the domain-invariant sentiment features
with the help of an orthogonal domain-dependent task, i.e. aspect detection,
which is built on the aspects varying widely in different domains. We conduct
extensive experiments on three public datasets and the experimental results
demonstrate the effectiveness of our method.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 10:50:23 GMT""}]","2019-08-27"
"1908.09123","Gabriel Scherer","Pierre-\'Evariste Dagand, Lionel Rieg, Gabriel Scherer","Dependent Pearl: Normalization by realizability",,,,,"cs.PL cs.LO","http://creativecommons.org/licenses/by-sa/4.0/","  For those of us who generally live in the world of syntax, semantic proof
techniques such as reducibility, realizability or logical relations seem
somewhat magical despite -- or perhaps due to -- their seemingly unreasonable
effectiveness. Why do they work? At which point in the proof is ""the real work""
done?
  Hoping to build a programming intuition of these proofs, we implement a
normalization argument for the simply-typed lambda-calculus with sums: instead
of a proof, it is described as a program in a dependently-typed meta-language.
  The semantic technique we set out to study is Krivine's classical
realizability, which amounts to a proof-relevant presentation of reducibility
arguments -- unary logical relations. Reducibility assigns a predicate to each
type, realizability assigns a set of realizers, which are abstract machines
that extend lambda-terms with a first-class notion of contexts. Normalization
is a direct consequence of an adequacy theorem or ""fundamental lemma"", which
states that any well-typed term translates to a realizer of its type.
  We show that the adequacy theorem, when written as a dependent program,
corresponds to an evaluation procedure. In particular, a weak normalization
proof precisely computes a series of reduction from the input term to a normal
form. Interestingly, the choices that we make when we define the reducibility
predicates -- truth and falsity witnesses for each connective -- determine the
evaluation order of the proof, with each datatype constructor behaving in a
lazy or strict fashion.
  While most of the ideas in this presentation are folklore among specialists,
our dependently-typed functional program provides an accessible presentation to
a wider audience. In particular, our work provides a gentle introduction to
abstract machine calculi which have recently been used as an effective research
vehicle.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 10:53:27 GMT""},{""version"":""v2"",""created"":""Mon, 27 Jul 2020 12:56:02 GMT""}]","2020-07-28"
"1908.09124","Jintao Zhang","Jintao Zhang","SeesawFaceNets: sparse and robust face verification model for mobile
  platform","8 pages, 2 figures. All source code and proposed models will be
  released publicly later",,,,"cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep Convolutional Neural Network (DCNNs) come to be the most widely used
solution for most computer vision related tasks, and one of the most important
application scenes is face verification. Due to its high-accuracy performance,
deep face verification models of which the inference stage occurs on cloud
platform through internet plays the key role on most prectical scenes. However,
two critical issues exist: First, individual privacy may not be well protected
since they have to upload their personal photo and other private information to
the online cloud backend. Secondly, either training or inference stage is
time-comsuming and the latency may affect customer experience, especially when
the internet link speed is not so stable or in remote areas where mobile
reception is not so good, but also in cities where building and other
construction may block mobile signals. Therefore, designing lightweight
networks with low memory requirement and computational cost is one of the most
practical solutions for face verification on mobile platform. In this paper, a
novel mobile network named SeesawFaceNets, a simple but effective model, is
proposed for productively deploying face recognition for mobile devices. Dense
experimental results have shown that our proposed model SeesawFaceNets
outperforms the baseline MobilefaceNets, with only {\bf66\%}(146M VS 221M
MAdds) computational cost, smaller batch size and less training steps, and
SeesawFaceNets achieve comparable performance with other SOTA model e.g.
mobiface with only {\bf54.2\%}(1.3M VS 2.4M) parameters and {\bf31.6\%}(146M VS
462M MAdds) computational cost, It is also eventually competitive against
large-scale deep-networks face recognition on all 5 listed public validation
datasets, with {\bf6.5\%}(4.2M VS 65M) parameters and {\bf4.35\%}(526M VS 12G
MAdds) computational cost.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:21:38 GMT""},{""version"":""v2"",""created"":""Tue, 27 Aug 2019 17:54:54 GMT""},{""version"":""v3"",""created"":""Sun, 1 Dec 2019 12:52:26 GMT""}]","2019-12-03"
"1908.09125","Sara Giuliani","Sara Giuliani, Zsuzsanna Lipt\'ak, Francesco Masillo, Romeo Rizzi","When a Dollar Makes a BWT","This is the journal version of paper at ICTCS 2019 (20th Italian
  Conference on Theoretical Computer Science, 9-11 Sept. 2019, Como, Italy).
  Journal version appeared in TCS 2021","Theoretical Computer Science 857: 123-146 (2021)","10.1016/j.tcs.2021.01.008",,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The Burrows-Wheeler-Transform (BWT) is a reversible string transformation
which plays a central role in text compression and is fundamental in many
modern bioinformatics applications. The BWT is a permutation of the characters,
which is in general better compressible and allows to answer several different
query types more efficiently than the original string.
  It is easy to see that not every string is a BWT image, and exact
characterizations of BWT images are known. We investigate a related
combinatorial question. In many applications, a sentinel character dollar is
added to mark the end of the string, and thus the BWT of a string ending with
dollar contains exactly one dollar-character. Given a string w, we ask in which
positions, if any, the dollar-character can be inserted to turn w into the BWT
image of a word ending with dollar. We show that this depends only on the
standard permutation of w and present a O(n log n)-time algorithm for
identifying all such positions, improving on the naive quadratic time
algorithm. We also give a combinatorial characterization of such positions and
develop bounds on their number and value. This is an extended version of
[Giuliani et al. ICTCS 2019].
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:26:37 GMT""},{""version"":""v2"",""created"":""Wed, 4 Mar 2020 10:00:03 GMT""},{""version"":""v3"",""created"":""Fri, 12 Mar 2021 17:46:21 GMT""}]","2021-03-15"
"1908.09126","Kirill Bronnikov","K.A. Bronnikov, J.C. Fabris and Denis C. Rodrigues","On the instability of some k-essence space-times","7 pages, no figures","Int. J. Mod. Phys. D 2050016 (2020)","10.1142/S0218271820500169",,"gr-qc hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the stability properties of static, spherically symmetric
configurations in k-essence theories with the Lagrangians of the form $F(X)$,
$X \equiv \phi_{,\alpha} \phi^{,\alpha}$. The instability under spherically
symmetric perturbations is proved for two recently obtained exact solutions for
$F(X) =F_0 X^{1/3}$ and for $F(X) = F_0 X^{1/2} - 2 \Lambda$, where $F_0$ and
$\Lambda$ are constants. The first solution describes a black hole in an
asymptotically singular space-time, the second one contains two horizons of
infinite area connected by a wormhole. It is argued that spherically symmetric
k-essence configurations with $n < 1/2$ are generically unstable because the
perturbation equation is not of hyperbolic type.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:39:28 GMT""}]","2020-10-20"
"1908.09127","Ehsan Montahaei","Ehsan Montahaei, Danial Alihosseini, Mahdieh Soleymani Baghshah","DGSAN: Discrete Generative Self-Adversarial Network",,,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although GAN-based methods have received many achievements in the last few
years, they have not been entirelysuccessful in generating discrete data. The
most crucial challenge of these methods is the difficulty of passing the
gradientfrom the discriminator to the generator when the generator outputs are
discrete. Despite the fact that several attemptshave been made to alleviate
this problem, none of the existing GAN-based methods have improved the
performance oftext generation compared with the maximum likelihood approach in
terms of both the quality and the diversity. In thispaper, we proposed a new
framework for generating discrete data by an adversarial approach in which
there is no need topass the gradient to the generator. The proposed method has
an iterative manner in which each new generator is definedbased on the last
discriminator. It leverages the discreteness of data and the last discriminator
to model the real datadistribution implicitly. Moreover, the method is
supported with theoretical guarantees, and experimental results generallyshow
the superiority of the proposed DGSAN method compared to the other popular or
recent methods in generatingdiscrete sequential data.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:39:50 GMT""},{""version"":""v2"",""created"":""Thu, 15 Oct 2020 10:25:10 GMT""}]","2020-10-16"
"1908.09128","Wei Wei","Wei Wei, Zanbo Wang, Xianling Mao, Guangyou Zhou, Pan Zhou, Sheng
  Jiang","Position-Aware Self-Attention based Neural Sequence Labeling","12 pages, 6 figures","published by pattern recognition, 2021","10.1016/j.patcog.2020.107636",,"cs.CL cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Sequence labeling is a fundamental task in natural language processing and
has been widely studied. Recently, RNN-based sequence labeling models have
increasingly gained attentions. Despite superior performance achieved by
learning the long short-term (i.e., successive) dependencies, the way of
sequentially processing inputs might limit the ability to capture the
non-continuous relations over tokens within a sentence. To tackle the problem,
we focus on how to effectively model successive and discrete dependencies of
each token for enhancing the sequence labeling performance. Specifically, we
propose an innovative attention-based model (called position-aware
selfattention, i.e., PSA) as well as a well-designed self-attentional context
fusion layer within a neural network architecture, to explore the positional
information of an input sequence for capturing the latent relations among
tokens. Extensive experiments on three classical tasks in sequence labeling
domain, i.e., partof-speech (POS) tagging, named entity recognition (NER) and
phrase chunking, demonstrate our proposed model outperforms the
state-of-the-arts without any external knowledge, in terms of various metrics.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:40:08 GMT""},{""version"":""v2"",""created"":""Sat, 16 Oct 2021 13:11:22 GMT""}]","2021-10-19"
"1908.09129","Jaewoo Kim","Jaewoo Kim","On the existence of regular tetrahedral non-homothetic homographic
  solution","This paper has been presented in KSSS Spring meeting",,,,"physics.class-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  It is well known that the three-body problem has few analytical solutions in
certain symmetrical constraints; the Lagrangian triangular solution is one of
them. This triangular solution has been revisited by R.Broucke and H.Lass in
1971, concerning three relative position vectors pointing from one mass to
another. This paper proposes a significant advance to the method, extended to
four arbitrary masses on the vertices of a tetrahedron. The research provides a
geometrical proof that under such constraint, only homothetic solution is
possible which agrees with the conclusion brought by article 371 of Wintner
(1941).
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:51:58 GMT""}]","2019-08-27"
"1908.09130","Avinash Singh","Shubhajyoti Mohapatra and Avinash Singh","Magnetic order and anisotropic interactions induced by mixing between
  the $J=1/2$ and $3/2$ sectors in spin-orbit coupled honeycomb-lattice
  compounds","20 pages, 6 figures",,,,"cond-mat.str-el","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Novel magnetic ordering on the honeycomb lattice due to emergent weak
anisotropic interactions generated by the mixing between the $J=1/2$ sector and
the magnetically inactive 3/2 sector is investigated in a three-orbital
interacting electron model in the absence of Hund's coupling. Self-consistent
determination of magnetic order yields anisotropic N\'{e}el and zigzag orders
for different parameter regimes, highlighting the effect of the emergent
single-ion anisotropy. Study of magnon excitations shows extremely small magnon
energy scale compared to the hopping energy scale, and enhancement of
anisotropy effects for smaller spin-orbit coupling. These results account for
several features of the honeycomb lattice compounds such as $\rm Na_2 Ir O_3$
and $\rm Ru Cl_3$, where the leading order anisotropic interactions within the
magnetically active $J=1/2$ sector are completely quenched due to the
edge-sharing octahedra.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:53:05 GMT""}]","2019-08-27"
"1908.09131","Mohamed Abu-Shady","M. Abu-shady and H. M. Fath-Allah","The Effect of Extended Cornell Potential on Heavy and Heavy-Light Meson
  Masses Using Series Method","12 pages, 6 Tables",,,,"hep-ph","http://creativecommons.org/publicdomain/zero/1.0/","  The effect of an extended Cornell potential on mass spectra of heavy and
heavy-light mesons is studied. The Cornell potential is extended to include
quadratic potential and inverse quadratic potential. The N-radial Schrodinger
equation is solved by using series method. The results for charmonium and
bottomonium, and light-heavy meson masses are obtained. A comparison with other
recent works is discussed. The present results are improved in comparison with
other recent works and are in good agreement with experimental data.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:53:31 GMT""}]","2019-08-27"
"1908.09132","Thomas Thersleff Dr.","Thomas Thersleff, Linus Sch\""onstr\""om, Cheuk-Wai Tai, Roman Adam,
  Daniel E. B\""urgler, Claus M. Schneider, Shunsuke Muto, J\'an Rusz","Single-pass STEM-EMCD on a zone axis using a patterned aperture:
  progress in experimental and data treatment methods","17 pages, 9 figures. Data available at DOI: 10.5281/zenodo.3361582
  Code available at DOI: 10.5281/zenodo.3374648","Sci. Rep. 9, 18170 (2019)","10.1038/s41598-019-53373-1",,"cond-mat.mtrl-sci","http://creativecommons.org/licenses/by/4.0/","  Measuring magnetic moments in ferromagnetic materials with atomic column
resolution is theoretically possible using the electron magnetic circular
dichroism (EMCD) technique in a (scanning) transmission electron microscope
((S)TEM). However, experimental and data processing hurdles currently hamper
the realization of this goal. Experimentally, the sample must be tilted to a
zone-axis orientation, yielding a complex distribution of magnetic scattering
intensity, and the same sample region must be scanned multiple times with
sub-atomic spatial registration necessary at each pass. Furthermore, the weak
nature of the EMCD signal requires advanced data processing techniques to
reliably detect and quantify the result. In this manuscript, we detail our
experimental and data processing progress towards achieving single-pass
zone-axis EMCD using a patterned aperture. First, we provide a comprehensive
data acquisition and analysis strategy for this and other EMCD experiments that
should scale down to atomic resolution experiments. Second, we demonstrate
that, at low spatial resolution, promising EMCD candidate signals can be
extracted, and that these are sensitive to both crystallographic orientation
and momentum transfer.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 12:13:04 GMT""}]","2022-03-22"
"1908.09133","Hiroshi Fujiwara","Hiroshi Fujiwara, Kamran Sadiq, Alexandru Tamasan","Numerical reconstruction of radiative sources in an absorbing and
  non-diffusing scattering medium in two dimensions",,,"10.1137/19M1282921",,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We consider the two dimensional quantitative imaging problem of recovering a
radiative source inside an absorbing and scattering medium from knowledge of
the outgoing radiation measured at the boundary. The medium has an anisotropic
scattering property that is neither negligible nor large enough for the
diffusion approximation to hold. We present the numerical realization of the
authors' recently proposed reconstruction method. For scattering kernels of
finite Fourier content in the angular variable, the solution is exact. The
feasibility of the proposed algorithms is demonstrated in several numerical
experiments, including simulated scenarios for parameters meaningful in optical
molecular imaging.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 12:46:49 GMT""}]","2021-01-21"
"1908.09134","Kantepalli Sasikumar Raja","K. Sasikumar Raja, P. Janardhan, Susanta Kumar Bisoi, Madhusudan
  Ingale, Prasad Subramanian, K. Fujiki, Milan Maksimovic","Global Solar Magnetic-field and Interplanetary Scintillations During the
  Past Four Solar Cycles","Accepted for publication in Solar Physics, 16 pages, 5 Figures, 1
  Table",,"10.1007/s11207-019-1514-7",,"astro-ph.SR physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The extended minimum of Solar Cycle 23, the extremely quiet solar-wind
conditions prevailing, and the mini-maximum of Solar Cycle 24 drew global
attention and many authors have since attempted to predict the amplitude of the
upcoming Solar Cycle 25, which is predicted to be the third successive weak
cycle; it is a unique opportunity to probe the Sun during such quiet periods.
Earlier work has established a steady decline, over two decades, in solar
photospheric fields at latitudes above $45^{\circ}$ and a similar decline in
solar-wind micro-turbulence levels as measured by interplanetary scintillation
(IPS) observations. However, the relation between the photospheric magnetic
fields and those in the low corona/solar-wind are not straightforward.
Therefore, in the present article, we have used potential-field source-surface
(PFSS) extrapolations to deduce global magnetic-fields using synoptic
magnetograms observed with National Solar Observatory (NSO), Kitt Peak, USA
(NSO/KP) and Solar Optical Long-term Investigation of the Sun (NSO/SOLIS)
instruments during 1975-2018. Furthermore, we have measured the normalized
scintillation index [m] using the IPS observations carried out at the Institute
of Space Earth Environment Research (ISEE), Japan during 1983-2017. From these
observations, we have found that, since the mid-1990s, the magnetic-field over
different latitudes at 2.5 $\rm R_{\odot}$ and 10 $\rm R_{\odot}$(extrapolated
using PFSS method) has decreased by $\approx 11.3-22.2 \%$. In phase with the
declining magnetic-fields, the quantity m also declined by $\approx 23.6 \%$.
These observations emphasize the inter-relationship between the global
magnetic-field and various turbulence parameters in the solar corona and solar
wind.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 13:18:18 GMT""},{""version"":""v2"",""created"":""Thu, 3 Dec 2020 21:43:32 GMT""}]","2020-12-07"
"1908.09135","Kiyohito Nagano","Kiyohito Nagano, Akihiro Kishimoto","Subadditive Load Balancing","17 pages, 3 figures",,,,"cs.DS","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Set function optimization is essential in AI and machine learning. We focus
on a subadditive set function that generalizes submodularity, and examine the
subadditivity of non-submodular functions. We also deal with a minimax
subadditive load balancing problem, and present a modularization-minimization
algorithm that theoretically guarantees a worst-case approximation factor. In
addition, we give a lower bound computation technique for the problem. We apply
these methods to the multi-robot routing problem for an empirical performance
evaluation.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 13:27:38 GMT""}]","2019-08-27"
"1908.09136","Andreas Haungs","W. Painter, A. Haungs, T. Huber, M. Karus, A. Menshikov, M. Oehler, M.
  Renschler, JEM-EUSO Collaboration","Silicon Photomultipliers for Orbital Ultra High Energy Cosmic Ray
  Observation","presented at the 36th ICRC (Madison, WI; 2019)",,,"PoS(ICRC2019)285","astro-ph.IM astro-ph.HE physics.ins-det","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Development of the Silicon photomultiplier Elementary Cell Add-on camera
(SiECA) has provided extensive information regarding the use of SiPMs for
future cosmic ray detection systems. We present the technical aspects of sensor
readout development utilizing Citiroc ASIC chips from Weeroc controlled by a
Xilinx FPGA to process and package events from four 64 channel Hamamatsu MPPC
S13361 arrays generating 128 frame events with an integration time of 2.5ms
(parameters are based on JEM-EUSO geometry but can be easily adjusted). With
single photon counting capability, SiECA proves SiPM are viable sensors to
replace Multi-Anode PhotoMultiplier Tubes in future devices, especially when
high luminosity exposure is possible potentially damaging MAPMT based systems.
Complementary to the technical aspects, computational and analysis methods for
sensor array characterization and in depth device flat-fielding are presented.
Provided channel by channel biasing, in comparison to uniform biasing with
MAPMTs, fine tuning of operating parameters with MPPC arrays allows for
substantial improvements in detector and signal uniformity.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 13:29:03 GMT""}]","2019-08-27"
"1908.09137","Seunghyun Yoon","Seunghyun Yoon, Franck Dernoncourt, Doo Soon Kim, Trung Bui, Kyomin
  Jung","Propagate-Selector: Detecting Supporting Sentences for Question
  Answering via Graph Neural Networks","8 pages, Accepted as a conference paper at LREC 2020",,,,"cs.CL cs.AI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this study, we propose a novel graph neural network called
propagate-selector (PS), which propagates information over sentences to
understand information that cannot be inferred when considering sentences in
isolation. First, we design a graph structure in which each node represents an
individual sentence, and some pairs of nodes are selectively connected based on
the text structure. Then, we develop an iterative attentive aggregation and a
skip-combine method in which a node interacts with its neighborhood nodes to
accumulate the necessary information. To evaluate the performance of the
proposed approaches, we conduct experiments with the standard HotpotQA dataset.
The empirical results demonstrate the superiority of our proposed approach,
which obtains the best performances, compared to the widely used
answer-selection models that do not consider the intersentential relationship.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 13:37:35 GMT""},{""version"":""v2"",""created"":""Sun, 16 Feb 2020 13:25:41 GMT""}]","2020-02-18"
"1908.09138","Jiwei Li","Yuxian Meng, Xiaoya Li, Zijun Sun and Jiwei Li","Query-Based Named Entity Recognition","Please refer to the full version of this paper: A unified framework
  for named entity recognition arXiv:1910.11476",,,,"cs.CL","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a new strategy for the task of named entity
recognition (NER). We cast the task as a query-based machine reading
comprehension task: e.g., the task of extracting entities with PER is
formalized as answering the question of ""which person is mentioned in the text
?"". Such a strategy comes with the advantage that it solves the long-standing
issue of handling overlapping or nested entities (the same token that
participates in more than one entity categories) with sequence-labeling
techniques for NER. Additionally, since the query encodes informative prior
knowledge, this strategy facilitates the process of entity extraction, leading
to better performances. We experiment the proposed model on five widely used
NER datasets on English and Chinese, including MSRA, Resume, OntoNotes, ACE04
and ACE05. The proposed model sets new SOTA results on all of these datasets.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 13:42:57 GMT""},{""version"":""v2"",""created"":""Sat, 2 Nov 2019 15:12:22 GMT""}]","2019-11-05"
"1908.09139","W.J. Handley","Will Handley","Curvature tension: evidence for a closed universe","7 pages, 4 figures. Submitted to PRL","Phys. Rev. D 103, 041301 (2021)","10.1103/PhysRevD.103.L041301",,"astro-ph.CO gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The curvature parameter tension between Planck 2018, cosmic microwave
background lensing, and baryon acoustic oscillation data is measured using the
suspiciousness statistic to be 2.5 to 3$\sigma$. Conclusions regarding the
spatial curvature of the universe which stem from the combination of these data
should therefore be viewed with suspicion. Without CMB lensing or BAO, Planck
2018 has a moderate preference for closed universes, with Bayesian betting odds
of over 50:1 against a flat universe, and over 2000:1 against an open universe.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 13:56:59 GMT""}]","2021-02-10"
"1908.09140","Shanshan Wang","Shanshan Wang, Yanxia Chen, Taohui Xiao, Ziwen Ke, Qiegen Liu, Hairong
  Zheng","LANTERN: learn analysis transform network for dynamic magnetic resonance
  imaging with small dataset",,,,,"eess.IV cs.CV","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper proposes to learn analysis transform network for dynamic magnetic
resonance imaging (LANTERN) with small dataset. Integrating the strength of
CS-MRI and deep learning, the proposed framework is highlighted in three
components: (i) The spatial and temporal domains are sparsely constrained by
using adaptively trained CNN. (ii) We introduce an end-to-end framework to
learn the parameters in LANTERN to solve the difficulty of parameter selection
in traditional methods. (iii) Compared to existing deep learning reconstruction
methods, our reconstruction accuracy is better when the amount of data is
limited. Our model is able to fully exploit the redundancy in spatial and
temporal of dynamic MR images. We performed quantitative and qualitative
analysis of cardiac datasets at different acceleration factors (2x-11x) and
different undersampling modes. In comparison with state-of-the-art methods,
extensive experiments show that our method achieves consistent better
reconstruction performance on the MRI reconstruction in terms of three
quantitative metrics (PSNR, SSIM and HFEN) under different undersamling
patterns and acceleration factors.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 14:04:58 GMT""}]","2019-08-27"
"1908.09141","Tao Yu","Tao Yu, Yaroslav M. Blanter, and Gerrit E. W. Bauer","Chiral Pumping of Spin Waves","6+9 pages, 2+3 figures","Phys. Rev. Lett. 123, 247202 (2019)","10.1103/PhysRevLett.123.247202",,"cond-mat.mes-hall","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We report a theory for the coherent and incoherent chiral pumping of spin
waves into thin magnetic films through the dipolar coupling with a local
magnetic transducer, such as a nanowire. The ferromagnetic resonance of the
nanowire is broadened by the injection of unidirectional spin waves that
generate a non-equilibrium magnetization in only half of the film. A
temperature gradient between the local magnet and film leads to a
unidirectional flow of incoherent magnons, i.e., a chiral spin Seebeck effect.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 14:17:29 GMT""},{""version"":""v2"",""created"":""Sat, 7 Sep 2019 12:56:39 GMT""}]","2019-12-18"
"1908.09142","Jin-Chong Tan","Arun S. Babal, Lorenzo Don\`a, Matthew R. Ryder, Kirill Titov,
  Abhijeet K. Chaudhari, Zhixin Zeng, Chris S. Kelley, Mark D. Frogley,
  Gianfelice Cinque, Bartolomeo Civalleri, Jin-Chong Tan","Impact of pressure and temperature on the broadband dielectric response
  of the HKUST-1 metal-organic framework","20 pages, 6 figures, plus Supporting Information",,,,"cond-mat.mtrl-sci cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Herein we employed high-resolution spectroscopic techniques in combination
with periodic ab initio density functional theory (DFT) calculations to
establish the different polarization processes for a porous copper-based MOF,
termed HKUST-1. We used alternating current measurements to determine its
dielectric response between 4 Hz and 1.5 MHz where orientational polarization
is predominant, while synchrotron infrared (IR) reflectance was used to probe
the far-IR, mid-IR, and near-IR dielectric response across the 1.2 THz to 150
THz range (ca. 40 - 5000 cm^-1) where vibrational and optical polarizations are
principal contributors to its dielectric permittivity. We demonstrate the role
of pressure on the evolution of broadband dielectric response, where THz
vibrations reveal distinct blue and red shifts of phonon modes from structural
deformation of the copper paddle-wheel and the organic linker, respectively. We
also investigated the effect of temperature on dielectric constants in the MHz
region pertinent to microelectronics, to study temperature-dependent dielectric
losses via dissipation in an alternating electric field. The DFT calculations
offer insights into the physical mechanisms responsible for dielectric
transitions observed in the experiments and enable us to explain the frequency
shifts phenomenon detected under pressure. Together, the experiments and theory
have enabled us to glimpse into the complex dielectric response and mechanisms
underpinning a prototypical MOF subject to pressure, temperature, and vast
frequencies.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 14:18:36 GMT""}]","2019-08-27"
"1908.09143","Francisco de la Hoz","Jorge Cayama, Carlota M. Cuesta and Francisco de la Hoz","A Pseudospectral Method for the One-Dimensional Fractional Laplacian on
  $\mathbb R$","31 pages, 5 figures",,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we propose a novel pseudospectral method to approximate
accurately and efficiently the fractional Laplacian without using truncation.
More precisely, given a bounded regular function defined over $\mathbb R$, we
map the unbounded domain into a finite one, then we represent the function as a
trigonometrical series. Therefore, the central point of this paper is the
computation of the fractional Laplacian of an elementary trigonometric
function.
  As an application of the method, we also do the simulation of Fisher's
equation with fractional Laplacian in the monostable case.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 14:45:42 GMT""}]","2019-08-27"
"1908.09144","Jon Bohlin","Jon Bohlin, Brittany Rose, Ola Brynildsrud and Birgitte Freiesleben De
  Blasio","A simple stochastic model to describe the evolution over time of core
  genome SNP GC content in prokaryotes",,,,,"q-bio.PE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Genomes in living organisms consist of the nucleotides adenine (A), guanine
(G), cytosine (C) and thymine (T). All prokaryotes have genomes consisting of
double-stranded DNA, where the A's and G's (purines) of one strand bind
respectively to the T's and C's (pyrimidines) of the other. As such, the number
of A's on one strand nearly equals the number of T's on the other, and the same
is true of one strand's G's and the other's C's. Globally, this relationship is
formalized as Chargaff's first parity rule; its strandwise equivalent is
Chargaff's second parity rule. Therefore, the GC content of any double-stranded
DNA genome can be expressed as %GC=100%-%AT. Variation in prokaryotic GC
content can be substantial between taxa but is generally small within microbial
genomes. This variation has been found to correlate with both phylogeny and
environmental factors. Since novel single-nucleotide polymorphisms (SNPs)
within genomes are at least partially linked to the environment, SNP GC content
can be considered a compound measure of an organism's environmental influences,
lifestyle and phylogeny. We present a mathematical model that describes how SNP
GC content in microbial genomes evolves over time as a function of the AT->GC
and GC->AT mutation rates with Gaussian white noise disturbances. The model
suggests that, in non-recombining bacteria, mutations can first accumulate
unnoticeably and then abruptly fluctuate out of control. Thus, minuscule
variations in mutation rates can suddenly become unsustainable, ultimately
driving a species to extinction if not counteracted early enough. This model,
which is suited specifically to symbiotic prokaryotes, conforms to scenarios
predicted by Muller's ratchet and may suggest that this is not always a
gradual, degrading process.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 14:51:34 GMT""}]","2019-08-27"
"1908.09145","Tao Wang","Binjie Li, Tao Wang and Xiaoping Xie","Analysis of the L1 scheme for fractional wave equations with nonsmooth
  data",,,,,"math.NA cs.NA","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This paper analyzes the well-known L1 scheme for fractional wave equations
with nonsmooth data. A new stability estimate is obtained, and the temporal
accuracy $ \mathcal O(\tau^{3-\alpha}) $ is derived for the nonsmooth initial
data. In addition, a modified L1 scheme is proposed, and stability and temporal
accuracy $ \mathcal O(\tau^2) $ are derived for this scheme with nonsmooth
initial data. The convergence of the two schemes in the inhomogeneous case is
also established. Finally, numerical experiments are performed to verify the
theoretical results.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 14:57:53 GMT""},{""version"":""v2"",""created"":""Fri, 27 Dec 2019 11:31:56 GMT""}]","2019-12-30"
"1908.09146","Bin Chen","Bin Chen (1), Chengcai Shen (2), Katharine K. Reeves (2), Fan Guo (3
  and 4), Sijie Yu (1) ((1) Center for Solar-Terrestrial Research, New Jersey
  Institute of Technology, (2) Harvard-Smithsonian Center for Astrophysics, (3)
  Los Alamos National Laboratory, (4) New Mexico Consortium)","Radio Spectroscopic Imaging of a Solar Flare Termination Shock:
  Split-Band Feature as Evidence for Shock Compression","16 pages, 10 figures, accepted by The Astrophysical Journal. Version
  with minor (mostly typo) corrections",,"10.3847/1538-4357/ab3c58",,"astro-ph.SR astro-ph.HE","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Solar flare termination shocks have been suggested as one of the promising
drivers for particle acceleration in solar flares, yet observational evidence
remains rare. By utilizing radio dynamic spectroscopic imaging of decimetric
stochastic spike bursts in an eruptive flare, Chen et al. found that the bursts
form a dynamic surface-like feature located at the ending points of fast plasma
downflows above the looptop, interpreted as a flare termination shock. One
piece of observational evidence that strongly supports the termination shock
interpretation is the occasional split of the emission band into two finer
lanes in frequency, similar to the split-band feature seen in
fast-coronal-shock-driven type II radio bursts. Here we perform spatially,
spectrally, and temporally resolved analysis of the split-band feature of the
flare termination shock event. We find that the ensemble of the radio centroids
from the two split-band lanes each outlines a nearly co-spatial surface. The
high-frequency lane is located slightly below its low frequency counterpart by
~0.8 Mm, which strongly supports the shock upstream-downstream interpretation.
Under this scenario, the density compression ratio across the shock front can
be inferred from the frequency split, which implies a shock with a Mach number
of up to 2.0. Further, the spatiotemporal evolution of the density compression
along the shock front agrees favorably with results from magnetohydrodynamics
simulations. We conclude that the detailed variations of the shock compression
ratio may be due to the impact of dynamic plasma structures in the reconnection
outflows, which results in distortion of the shock front.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:04:40 GMT""},{""version"":""v2"",""created"":""Thu, 26 Sep 2019 23:00:01 GMT""}]","2019-10-16"
"1908.09147","Florence Raynal","Florence Raynal and Romain Volk","Diffusiophoresis, Batchelor scale and effective P\'eclet numbers",,"J. Fluid Mech. 876 (2019) 818-829","10.1017/jfm.2019.589",,"physics.flu-dyn cond-mat.soft","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  We study the joint mixing of colloids and salt released together in a
stagnation point or in a globally chaotic flow. In the presence of salt
inhomogeneities, the mixing time is strongly modified depending on the sign of
the diffusiophoretic coefficient $D_\mathrm{dp}$. Mixing is delayed when
$D_\mathrm{dp}>0$ (salt-attracting configuration), or faster when
$D_\mathrm{dp}<0$ (salt-repelling configuration). In both configurations, as
for molecular diffusion alone, large scales are barely affected in the dilating
direction while the Batchelor scale for the colloids, $\ell_{c,\mathrm{diff}}$,
is strongly modified by diffusiophoresis. We propose here to measure a global
effect of diffusiophoresis in the mixing process through an effective P\'eclet
number built on this modified Batchelor scale. Whilst this small scale is
obtained analytically for the stagnation point, in the case of chaotic
advection, we derive it using the equation of gradients of concentration,
following Raynal \& Gence (\textit{Intl J. Heat Mass Transfer}, vol. 40 (14),
1997, pp. 3267--3273). Comparing to numerical simulations, we show that the
mixing time can be predicted by using the same function as in absence of salt,
but as a function of the effective P\'eclet numbers computed for each
configuration. The approach is shown to be valid when the ratio
$D_\mathrm{dp}^2/D_s D_c \gg 1$, where $D_c$ and $D_s$ are the diffusivities of
the colloids and salt.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:10:23 GMT""}]","2019-09-04"
"1908.09148","Szymon P{\l}otka","Tomasz W{\l}odarczyk, Szymon P{\l}otka, Tomasz Trzci\'nski,
  Przemys{\l}aw Rokita, Nicole Sochacki-W\'ojcicka, Micha{\l} Lipa, Jakub
  W\'ojcicki","Estimation of preterm birth markers with U-Net segmentation network","Accepted at MICCAI Workshop on Perinatal, Preterm and Paediatric
  Image analysis (PIPPI) 2019",,,,"eess.IV cs.CV cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Preterm birth is the most common cause of neonatal death. Current diagnostic
methods that assess the risk of preterm birth involve the collection of
maternal characteristics and transvaginal ultrasound imaging conducted in the
first and second trimester of pregnancy. Analysis of the ultrasound data is
based on visual inspection of images by gynaecologist, sometimes supported by
hand-designed image features such as cervical length. Due to the complexity of
this process and its subjective component, approximately 30% of spontaneous
preterm deliveries are not correctly predicted. Moreover, 10% of the predicted
preterm deliveries are false-positives. In this paper, we address the problem
of predicting spontaneous preterm delivery using machine learning. To achieve
this goal, we propose to first use a deep neural network architecture for
segmenting prenatal ultrasound images and then automatically extract two
biophysical ultrasound markers, cervical length (CL) and anterior cervical
angle (ACA), from the resulting images. Our method allows to estimate
ultrasound markers without human oversight. Furthermore, we show that CL and
ACA markers, when combined, allow us to decrease false-negative ratio from 30%
to 18%. Finally, contrary to the current approaches to diagnostics methods that
rely only on gynaecologist's expertise, our method introduce objectively
obtained results.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:14:11 GMT""}]","2019-08-27"
"1908.09149","Orlando Silva","Orlando Silva","Model for heterogeneous reaction-diffusion systems with application to
  one epidemic","19 pages, 7 figures",,,,"physics.soc-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The dynamics of ecological as well as chemical systems may depend on
heterogeneous configurations. Heterogeneity in reaction-diffusion systems often
increase modelling and simulating difficulties when non-linear effects are
present. One synthetic epidemic system with short range heterogeneous
composition is modelled and its space-time evolution studied using maximum
heterogeneity details. Two other modelling alternatives are applied, one of
them using elementary mean-field variables, one other using non-localized
geometrical parameters, so avoiding the limitations of the used mean-field
model, while keeping significant features of more detailed models. Both the
detailed and the mean-field models are solved by means of the standard finite
volume method. The model with less defined geometry is solved by means of one
modified version of the finite volume method. Simulation results of the three
models are compared. At the high diffusion range all models behave similarly.
At moderate diffusion fluxes, the numerical results of the model with reduced
geometric details are in excellent agreement with the results of the detailed
model. The simple mean-field model presents limited accuracy at low and
moderate values of the diffusion coefficient.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:14:51 GMT""}]","2019-08-27"
"1908.09150","Patrick Concha","Ricardo Caroca, Patrick Concha, Octavio Fierro, Evelyn Rodr\'iguez","On the supersymmetric extension of asymptotic symmetries in three
  spacetime dimensions","V2, 40 pages, Accepted version in European Physical Journal C","European Physical Journal C 80 (2020) 29","10.1140/epjc/s10052-019-7595-5",,"hep-th math-ph math.MP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work we obtain known and new supersymmetric extensions of diverse
asymptotic symmetries defined in three spacetime dimensions by considering the
semigroup expansion method. The super-$BMS_3$, the superconformal algebra and
new infinite-dimensional superalgebras are obtained by expanding the
super-Virasoro algebra. The new superalgebras obtained are supersymmetric
extensions of the asymptotic algebras of the Maxwell and the
$\mathfrak{so}(2,2)\oplus\mathfrak{so}(2,1)$ gravity theories. We extend our
results to the $\mathcal{N}=2$ and $\mathcal{N}=4$ cases and find that
R-symmetry generators are required. We also show that the new
infinite-dimensional structures are related through a flat limit $\ell
\rightarrow \infty$.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:15:14 GMT""},{""version"":""v2"",""created"":""Fri, 27 Dec 2019 14:59:02 GMT""}]","2020-01-14"
"1908.09151","Peter Zeman","V\'it Kalisz, Pavel Klav\'ik, Peter Zeman","Circle Graph Isomorphism in Almost Linear Time",,,,,"cs.DS cs.DM math.CO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Circle graphs are intersection graphs of chords of a circle. In this paper,
we present a new algorithm for the circle graph isomorphism problem running in
time $O((n+m)\alpha(n+m))$ where $n$ is the number of vertices, $m$ is the
number of edges and $\alpha$ is the inverse Ackermann function. Our algorithm
is based on the minimal split decomposition [Cunnigham, 1982] and uses the
state-of-art circle graph recognition algorithm [Gioan, Paul, Tedder, Corneil,
2014] in the same running time. It improves the running time $O(nm)$ of the
previous algorithm [Hsu, 1995] based on a similar approach.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:17:27 GMT""}]","2019-08-27"
"1908.09152","Jie Huang","Jie Huang, Xin Liu, Yangqiu Song","Hyper-Path-Based Representation Learning for Hyper-Networks","Accepted by CIKM 2019",,"10.1145/3357384.3357871",,"cs.SI cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Network representation learning has aroused widespread interests in recent
years. While most of the existing methods deal with edges as pairwise
relationships, only a few studies have been proposed for hyper-networks to
capture more complicated tuplewise relationships among multiple nodes. A
hyper-network is a network where each edge, called hyperedge, connects an
arbitrary number of nodes. Different from conventional networks, hyper-networks
have certain degrees of indecomposability such that the nodes in a subset of a
hyperedge may not possess a strong relationship. That is the main reason why
traditional algorithms fail in learning representations in hyper-networks by
simply decomposing hyperedges into pairwise relationships. In this paper, we
firstly define a metric to depict the degrees of indecomposability for
hyper-networks. Then we propose a new concept called hyper-path and design
hyper-path-based random walks to preserve the structural information of
hyper-networks according to the analysis of the indecomposability. Then a
carefully designed algorithm, Hyper-gram, utilizes these random walks to
capture both pairwise relationships and tuplewise relationships in the whole
hyper-networks. Finally, we conduct extensive experiments on several real-world
datasets covering the tasks of link prediction and hyper-network
reconstruction, and results demonstrate the rationality, validity, and
effectiveness of our methods compared with those existing state-of-the-art
models designed for conventional networks or hyper-networks.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:19:29 GMT""},{""version"":""v2"",""created"":""Mon, 21 Oct 2019 19:08:21 GMT""}]","2019-10-23"
"1908.09153","Chao Ji","Claudianor O. Alves and Chao Ji","Multi-bump positive solutions for a logarithmic Schr\""{o}dinger equation
  with deepening potential well","Accepted for Publication in SCIENCE CHINA Mathematics",,,,"math.AP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article concerns the existence of multi-bump positive solutions for the
following logarithmic Schr\""{o}dinger equation $$ \left\{ \begin{array}{lc}
-\Delta u+ \lambda V(x)u=u \log u^2, & \mbox{in} \quad \mathbb{R}^{N}, \\ u \in
H^1(\mathbb{R}^{N}), \\ \end{array} \right. $$ where $N \geq 1$, $\lambda>0$ is
a parameter and the nonnegative continuous function $V:
\mathbb{R}^{N}\rightarrow \mathbb{R}$ has a potential well $\Omega:
=\text{int}\, V^{-1}(0)$ which possesses $k$ disjoint bounded components
$\Omega=\bigcup_{j=1}^{k}\Omega_{j}$. Using the variational methods, we prove
that if the parameter $\lambda>0$ is large enough, then the equation has at
least $2^{k}-1$ multi-bump positive solutions.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:35:57 GMT""},{""version"":""v2"",""created"":""Tue, 15 Dec 2020 01:32:57 GMT""}]","2020-12-16"
"1908.09154","Andrea Mehner","A. Mehner, W.-J. de Wit, D. Asmus, P.W. Morris, C. Agliozzo, M.J.
  Barlow, T.R. Gull, D.J. Hillier, G. Weigelt","Mid-infrared evolution of eta Car from 1968 to 2018","5 pages, 4 Figures, accepted for publication in A&A","A&A 630, L6 (2019)","10.1051/0004-6361/201936277",,"astro-ph.SR","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Eta Car is one of the most luminous and massive stars in our Galaxy and is
the brightest mid-infrared (mid-IR) source in the sky, outside our solar
system. Since the late 1990s the central source has dramatically brightened at
ultraviolet and optical wavelengths. This might be explained by a decrease in
circumstellar dust extinction. We aim to establish the mid-IR flux evolution
and further our understanding of the star's ultraviolet and optical
brightening. Mid-IR images from $8-20~\mu$m were obtained in 2018 with VISIR at
the Very Large Telescope. Archival data from 2003 and 2005 are retrieved from
the ESO Science Archive Facility and historical records are collected from
publications. We present the highest angular resolution mid-IR images of $\eta$
Car to date at the corresponding wavelengths ($\geq 0.22''$). We reconstruct
the mid-IR evolution of the spectral energy distribution of the spatially
integrated Homunculus nebula from 1968 to 2018 and find no long-term changes.
Eta Car's bolometric luminosity has been stable over the past five decades. We
do not observe a long-term decrease in the mid-IR flux densities that could be
associated with the brightening at ultraviolet and optical wavelengths, but
circumstellar dust must be declining in our line-of-sight only. Short-term flux
variations within about 25% of the mean levels could be present.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:38:04 GMT""}]","2019-10-02"
"1908.09155","Haihong Che","H. Che and G. P. Zank","A Brief Review on Particle Acceleration in Multi-island Magnetic
  Reconnection","in publication",,"10.1088/1742-6596/1332/1/012003",,"astro-ph.SR astro-ph.HE physics.geo-ph physics.plasm-ph physics.space-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The basic physics and recent progresses in theoretical and particle-in-cell
(PIC) simulation studies of particle acceleration in multi-island magnetic
reconnection are briefly reviewed. Particle acceleration in multi-island
magnetic reconnection is considered a plausible mechanism for the acceleration
of energetic particles in solar flares and the solar wind. Theoretical studies
have demonstrated that such a mechanism can produce the observed power-law
energy distribution of energetic particles if the particle motion is
sufficiently randomized in the reconnection event. However, PIC simulations
seem to suggest that the first-order Fermi acceleration mechanism is unable to
produce a power-law particle energy distribution function in mildly
relativistic multi-island magnetic reconnections. On the other hand, while
simulations of highly relativistic reconnections appear to be able to produce a
power-law energy spectrum, the spectral indices obtained are generally harder
than the soft power-law spectra with indices $\sim -5$ commonly observed in the
solar wind and solar flare events. In addition, the plasma heating due to
kinetic instabilities in 3D magnetic reconnection may ""thermalize"" the
power-law particles, making it even more difficult for multi-island
reconnections to generate a power-law spectrum. We discuss the possible reasons
that may lead to these problems.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:38:41 GMT""}]","2020-01-08"
"1908.09156","Armineh Nourbakhsh","Armineh Nourbakhsh, Grace Bang","A framework for anomaly detection using language modeling, and its
  applications to finance","5 pages, 2 figures, presented at the 2nd KDD Workshop on Anomaly
  Detection in Finance, 2019",,,,"cs.CL cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In the finance sector, studies focused on anomaly detection are often
associated with time-series and transactional data analytics. In this paper, we
lay out the opportunities for applying anomaly and deviation detection methods
to text corpora and challenges associated with them. We argue that language
models that use distributional semantics can play a significant role in
advancing these studies in novel directions, with new applications in risk
identification, predictive modeling, and trend analysis.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:52:57 GMT""}]","2019-08-27"
"1908.09157","Pawe{\l} Czy\.z","Albert Ziegler and Pawe{\l} Czy\.z","Unsupervised Recalibration","26 pages, added comparison with standard quantification algorithms",,,,"stat.ML cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Unsupervised recalibration (URC) is a general way to improve the accuracy of
an already trained probabilistic classification or regression model upon
encountering new data while deployed in the field. URC does not require any
ground truth associated with the new field data. URC merely observes the
model's predictions and recognizes when the training set is not representative
of field data, and then corrects to remove any introduced bias.
  URC can be particularly useful when applied separately to different
subpopulations observed in the field that were not considered as features when
training the machine learning model. This makes it possible to exploit
subpopulation information without retraining the model or even having ground
truth for some or all subpopulations available.
  Additionally, if these subpopulations are the object of study, URC serves to
determine the correct ground truth distributions for them, where naive
aggregation methods, like averaging the model's predictions, systematically
underestimate their differences.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:54:00 GMT""},{""version"":""v2"",""created"":""Thu, 12 Sep 2019 11:31:32 GMT""},{""version"":""v3"",""created"":""Sat, 17 Oct 2020 13:01:13 GMT""}]","2020-10-20"
"1908.09158","Atsuyuki Yamada","Junji Hisano, Yutaro Shoji, Atsuyuki Yamada","To be, or not to be finite? The Higgs potential in Gauge-Higgs
  Unification","23 pages. Accepted for publication in JHEP","JHEP 02 (2020) 193","10.1007/JHEP02(2020)193","IPMU19-0104","hep-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we investigate the finiteness of the Higgs effective potential
in an ${\rm SU}(\mathcal N)$ Gauge-Higgs Unification (GHU) model defined on
${\bf M}^4\times S^1$. We obtain the Higgs effective potential at the two-loop
level and find that it is finite. We also discuss that the Higgs effective
potential is generically divergent for three- or higher-loop levels. As an
example, we consider an ${\rm SU}(\mathcal N)$ gauge theory on ${\bf M}^5\times
S^1$, where the one-loop corrections to the four-Fermi operators are divergent.
We find that the Higgs effective potential depends on their counter terms at
the three-loop level.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:56:51 GMT""},{""version"":""v2"",""created"":""Mon, 2 Mar 2020 00:23:56 GMT""}]","2020-03-03"
"1908.09642","David Galas PhD","David J. Galas","The Group Theoretic Roots of Information: permutations, symmetry, and
  entropy","This revised manuscript has 37 pages, a few small corrections and
  clarifications, an added section and an added appendix",,,,"cs.IT math.IT","http://creativecommons.org/licenses/by-sa/4.0/","  We propose a new interpretation of measures of information and disorder by
connecting these concepts to group theory in a new way. Entropy and group
theory are connected here by their common relation to sets of permutations. A
combinatorial measure of information and disorder is proposed, in terms of
integers and discrete functions, that we call the integer entropy. The Shannon
measure of information is the limiting case of a richer, more general
conceptual structure that reveals relations among finite groups, information,
and symmetries. It is shown that the integer entropy converges uniformly to the
Shannon entropy when the group includes all permutations, the Symmetric group,
and the number of objects increases without bound. The harmonic numbers have a
well-known combinatorial meaning as the expected number of disjoint, non-empty
cycles in permutations of n objects, and since integer entropy is defined in
terms of the expected value of the number of cycles over the set of
permutations, it also has a clear combinatorial meaning. Since all finite
groups are isomorphic to subgroups of the Symmetric group, every finite group
has a corresponding information functional, analogous to the Shannon entropy
and a number series analogous to the harmonic numbers. The Cameron-Semeraro
cycle polynomial is used to analyze the integer entropy for finite groups, and
to characterize the series analogous to the Harmonic numbers. We introduce and
use a reciprocal polynomial, the transposition polynomial that provides an
additional tool and new insights. Broken symmetries and conserved quantities
are linked through the cycle and transposition properties of the groups, and
can be used to generalize the analysis of stochastic processes.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:05:49 GMT""},{""version"":""v2"",""created"":""Thu, 21 Nov 2019 23:14:27 GMT""}]","2019-11-25"
"1908.09651","Christopher Blake","Christopher G. Blake and Giuseppe Castiglione and Christopher
  Srinivasa and Marcus Brubaker","Parity Partition Coding for Sharp Multi-Label Classification","13 pages",,,,"cs.LG cs.IT math.IT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The problem of efficiently training and evaluating image classifiers that can
distinguish between a large number of object categories is considered. A novel
metric, sharpness, is proposed which is defined as the fraction of object
categories that are above a threshold accuracy. To estimate sharpness (along
with a confidence value), a technique called fraction-accurate estimation is
introduced which samples categories and samples instances from these
categories. In addition, a technique called parity partition coding, a special
type of error correcting output code, is introduced, increasing sharpness,
while reducing the multi-class problem to a multi-label one with exponentially
fewer outputs. We demonstrate that this approach outperforms the baseline model
for both MultiMNIST and CelebA, while requiring fewer parameters and exceeding
state of the art accuracy on individual labels.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:23:17 GMT""}]","2019-08-27"
"1908.09652","Thiago Miranda","Thiago Zafalon Miranda, Diorge Brognara Sardinha, Ricardo Cerri","Preventing the Generation of Inconsistent Sets of Classification Rules",,,,,"cs.LG cs.AI","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In recent years, the interest in interpretable classification models has
grown. One of the proposed ways to improve the interpretability of a rule-based
classification model is to use sets (unordered collections) of rules, instead
of lists (ordered collections) of rules. One of the problems associated with
sets is that multiple rules may cover a single instance, but predict different
classes for it, thus requiring a conflict resolution strategy. In this work, we
propose two algorithms capable of finding feature-space regions inside which
any created rule would be consistent with the already existing rules,
preventing inconsistencies from arising. Our algorithms do not generate
classification models, but are instead meant to enhance algorithms that do so,
such as Learning Classifier Systems. Both algorithms are described and analyzed
exclusively from a theoretical perspective, since we have not modified a
model-generating algorithm to incorporate our proposed solutions yet. This work
presents the novelty of using conflict avoidance strategies instead of conflict
resolution strategies.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:26:35 GMT""},{""version"":""v2"",""created"":""Mon, 30 Mar 2020 13:04:17 GMT""}]","2020-03-31"
"1908.09827","Xiang-Qian Li","Xiang-Qian Li, Bo Chen, Li-li Xing","5D black holes in Einstein-Gauss-Bonnet gravity with a background of
  modified Chaplygin gas","18 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:1611.02936 by other authors",,,,"gr-qc","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Supposing the existence of modified Chaplygin gas with the equation of state
$p=A\rho-B/\rho^\beta$ as a cosmic background, we obtain a static
spherically-symmetric black hole solution to the Einstein-Gauss-Bonnet
gravitational equations in 5D spacetime. The spacetime structure of the
obtained black hole solution is analyzed, also the related black hole
properties are studied by calculating the thermodynamical quantities. During
this process, effects of the Gauss-Bonnet coupling constant and the modified
Chaplygin gas parameters on black hole solution, as well as on its
thermodynamical properties are discussed. At the end, we study the quantum
tunneling of scalar particles and the propagating of scalar waves within the
background of modified Chaplygin gas. The study shows that the system is stable
under scalar perturbations and the Hawking radiation could stop at some point,
leaving an extremal black hole as remnant for evaporation.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:54:05 GMT""}]","2019-08-27"
"1908.09828","Xianan Huang","Xianan Huang, Boqi Li, Huei Peng, Joshua A. Auld, Vadim O. Sokolov","Eco-Mobility-on-Demand Fleet Control with Ride-Sharing","arXiv admin note: text overlap with arXiv:1801.08602",,"10.1109/TITS.2020.3032473",,"stat.AP cs.RO eess.SP math.OC","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Shared Mobility-on-Demand using automated vehicles can reduce energy
consumption and cost for future mobility. However, its full potential in energy
saving has not been fully explored. An algorithm to minimize fleet fuel
consumption while satisfying customers travel time constraints is developed in
this paper. Numerical simulations with realistic travel demand and route choice
are performed, showing that if fuel consumption is not considered, the MOD
service can increase fleet fuel consumption due to increased empty vehicle
mileage. With fuel consumption as part of the cost function, we can reduce
total fuel consumption by 7 percent while maintaining a high level of mobility
service.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:45:42 GMT""},{""version"":""v2"",""created"":""Sat, 17 Oct 2020 19:32:04 GMT""}]","2020-10-20"
"1908.09829","Zhuofa Chen","Zhuofa Chen, Dedong Han, Xing Zhang and Yi Wang","Improving Performance of Tin-Doped-Zinc-Oxide Thin-Film Transistors by
  Optimized Multi-Stacked Active-Layer Structures","14 pages, 7 figures",,,,"physics.app-ph cond-mat.mes-hall","http://creativecommons.org/licenses/by/4.0/","  In this paper, we investigated the performance of thin-film transistors
(TFTs) with different channel configurations including single-active-layer
(SAL) Sn-Zn-O (TZO), dual-active-layers (DAL) In-Sn-O (ITO)/TZO, and
triple-active-layers (TAL) TZO/ITO/TZO. The TAL TFTs were found to combine the
advantages of SAL TFTs (a low off-state current) and DAL TFTs (a high mobility
and a low threshold voltage). The proposed TAL TFTs exhibit superior electrical
performance, e.g. a high on-off state current ratio of 2*10^8, a low threshold
voltage of 0.52 V, a high saturation mobility of 145.2 cm2/Vs, and a low
off-state current of 3.3 pA. The surface morphology and characteristics of the
ITO and TZO films were investigated and the TZO film was found to be
C-axis-aligned crystalline (CAAC). A simplified resistance model was deduced to
explain the high channel resistance of TAL TFTs. At last, TAL TFTs with
different channel lengths were also discussed to show the stability and the
uniformity of our fabrication process. Owing to its low-processing temperature,
superior electrical performance, and low cost, TFTs with the proposed TAL
channel configuration are highly promising for flexible displays where the use
of heat-sensitive polymeric substrates is desirable.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:05:55 GMT""}]","2019-08-28"
"1908.10195","Jothi Prasanna Shanmuga Sundaram","Jothi Prasanna Shanmuga Sundaram, Wan Du, Zhiwei Zhao","A Survey on LoRa Networking: Research Problems, Current Solutions and
  Open Issues",,,,,"eess.SP cs.SY eess.SY","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Wireless networks have been widely deployed for many Internet-of-Things (IoT)
applications, like smart cities and precision agriculture. Low Power Wide Area
Networking (LPWAN) is an emerging IoT networking paradigm to meet three key
requirements of IoT applications, i.e., low cost, large scale deployment and
high energy efficiency. Among all available LPWAN technologies, LoRa networking
has attracted much attention from both academia and industry, since it
specifies an open standard and allows us to build autonomous LPWAN networks
without any third-party infrastructure. Many LoRa networks have been developed
recently, e.g., managing solar plants in Carson City, Nevada, USA and power
monitoring in Lyon and Grenoble, France. However, there are still many research
challenges to develop practical LoRa networks, e.g., link coordination,
resource allocation, reliable transmissions and security. This article provides
a comprehensive survey on LoRa networks, including the technical challenges of
deploying LoRa networks and recent solutions. Based on our detailed analysis of
current solutions, some open issues of LoRa networking are discussed. The goal
of this survey paper is to inspire more works on improving the performance of
LoRa networks and enabling more practical deployments.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 00:39:08 GMT""}]","2019-08-30"
"1908.10197","Jian-Xun Wang","Han Gao, Xueyu Zhu, Jian-Xun Wang","A Bi-fidelity Surrogate Modeling Approach for Uncertainty Propagation in
  Three-Dimensional Hemodynamic Simulations","44 pages, 15 figures","Computer Methods in Applied Mechanics and Engineering, 366,
  113047, 2020","10.1016/j.cma.2020.113047",,"physics.flu-dyn eess.IV physics.med-ph","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image-based computational fluid dynamics (CFD) modeling enables derivation of
hemodynamic information, which has become a paradigm in cardiovascular research
and healthcare. Nonetheless, the predictive accuracy largely depends on
precisely specified boundary conditions and model parameters, which, however,
are usually uncertain in most patient-specific cases. Quantifying the
uncertainties in model predictions due to input randomness can provide
predictive confidence and is critical to promote the transition of CFD modeling
in clinical applications. In the meantime, forward propagation of input
uncertainties often involves numerous expensive CFD simulations, which is
computationally prohibitive in most practical scenarios. This paper presents an
efficient bi-fidelity surrogate modeling framework for uncertainty
quantification (UQ) in cardiovascular simulations, by leveraging the accuracy
of high-fidelity models and efficiency of low-fidelity models. Contrary to most
data-fit surrogate models with several scalar quantities of interest, this work
aims to provide high-resolution, full-field predictions. Moreover, a novel
empirical error bound estimation approach is introduced to evaluate the
performance of the surrogate a priori. The proposed framework is tested on a
number of vascular flows with both standardized and patient-specific vessel
geometries, and different combinations of high- and low-fidelity models are
investigated. The results show that the bi-fidelity approach can achieve high
predictive accuracy with a significant reduction of computational cost,
exhibiting its merit and effectiveness. Particularly, the uncertainties from a
high-dimensional input space can be accurately propagated to clinically
relevant quantities of interest in the patient-specific case using only a
limited number of high-fidelity simulations, suggesting a good potential in
practical clinical applications.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 16:18:27 GMT""}]","2021-07-20"
"1908.10209","Sameera Ramasinghe Mr.","Sameera Ramasinghe, Salman Khan, Nick Barnes, Stephen Gould","Blended Convolution and Synthesis for Efficient Discrimination of 3D
  Shapes","10 pages: corrected typos and added affiliations. The IEEE Winter
  Conference on Applications of Computer Vision. 2020",,,,"cs.LG stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Existing networks directly learn feature representations on 3D point clouds
for shape analysis. We argue that 3D point clouds are highly redundant and hold
irregular (permutation-invariant) structure, which makes it difficult to
achieve inter-class discrimination efficiently. In this paper, we propose a
two-faceted solution to this problem that is seamlessly integrated in a single
`Blended Convolution and Synthesis' layer. This fully differentiable layer
performs two critical tasks in succession. In the first step, it projects the
input 3D point clouds into a latent 3D space to synthesize a highly compact and
more inter-class discriminative point cloud representation. Since, 3D point
clouds do not follow a Euclidean topology, standard 2/3D Convolutional Neural
Networks offer limited representation capability. Therefore, in the second
step, it uses a novel 3D convolution operator functioning inside the unit ball
($\mathbb{B}^3$) to extract useful volumetric features. We extensively derive
formulae to achieve both translation and rotation of our novel convolution
kernels. Finally, using the proposed techniques we present an extremely
light-weight, end-to-end architecture that achieves compelling results on 3D
shape recognition and retrieval.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 08:18:33 GMT""},{""version"":""v2"",""created"":""Sun, 19 Jul 2020 09:29:28 GMT""}]","2020-07-21"
"1908.10291","Mohammad Mohammadi","M. Mohammadi, R. Gheisari","Relativistic k-fields with Massless Soliton Solutions in 3+1 Dimensions",,,,,"nlin.PS hep-th","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this work, the relativistic non-standard Lagrangian densities (k-fields)
with massless solutions are generally introduced. Such solutions are not
necessarily energetically stable. However, in 3+1 dimensions, we introduce a
new k-field model that results in a single non-topological massless solitary
wave solution. This special solution is energetically stable; that is, any
arbitrary deformation above its background leads to an increase in the total
energy. In other words, its energy is zero which is the least energy in all
solutions. Hence, it can be called a massless soliton solution.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:39:27 GMT""},{""version"":""v2"",""created"":""Wed, 28 Aug 2019 02:37:16 GMT""},{""version"":""v3"",""created"":""Mon, 14 Oct 2019 17:43:45 GMT""},{""version"":""v4"",""created"":""Tue, 19 May 2020 00:34:20 GMT""},{""version"":""v5"",""created"":""Thu, 25 Feb 2021 14:21:55 GMT""},{""version"":""v6"",""created"":""Tue, 12 Jul 2022 14:30:02 GMT""}]","2022-07-13"
"1908.10312","Kun Qian","Kun Qian, Abduallah Mohamed and Christian Claudel","Physics Informed Data Driven model for Flood Prediction: Application of
  Deep Learning in prediction of urban flood development",,,,,"eess.SP cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Flash floods in urban areas occur with increasing frequency. Detecting these
floods would greatlyhelp alleviate human and economic losses. However, current
flood prediction methods are eithertoo slow or too simplified to capture the
flood development in details. Using Deep Neural Networks,this work aims at
boosting the computational speed of a physics-based 2-D urban flood
predictionmethod, governed by the Shallow Water Equation (SWE). Convolutional
Neural Networks(CNN)and conditional Generative Adversarial Neural
Networks(cGANs) are applied to extract the dy-namics of flood from the data
simulated by a Partial Differential Equation(PDE) solver. Theperformance of the
data-driven model is evaluated in terms of Mean Squared Error(MSE) andPeak
Signal to Noise Ratio(PSNR). The deep learning-based, data-driven flood
prediction modelis shown to be able to provide precise real-time predictions of
flood development
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 20:50:14 GMT""}]","2019-08-28"
"1908.10349","Jiunn-Kai Huang","Jiunn-Kai Huang, Shoutian Wang, Maani Ghaffari, and Jessy W. Grizzle","LiDARTag: A Real-Time Fiducial Tag System for Point Clouds",,"IEEE Robotics and Automation Letters, 31 March 2021","10.1109/LRA.2021.3070302",,"cs.RO cs.CV cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Image-based fiducial markers are useful in problems such as object tracking
in cluttered or textureless environments, camera (and multi-sensor) calibration
tasks, and vision-based simultaneous localization and mapping (SLAM). The
state-of-the-art fiducial marker detection algorithms rely on the consistency
of the ambient lighting. This paper introduces LiDARTag, a novel fiducial tag
design and detection algorithm suitable for light detection and ranging (LiDAR)
point clouds. The proposed method runs in real-time and can process data at 100
Hz, which is faster than the currently available LiDAR sensor frequencies.
Because of the LiDAR sensors' nature, rapidly changing ambient lighting will
not affect the detection of a LiDARTag; hence, the proposed fiducial marker can
operate in a completely dark environment. In addition, the LiDARTag nicely
complements and is compatible with existing visual fiducial markers, such as
AprilTags, allowing for efficient multi-sensor fusion and calibration tasks. We
further propose a concept of minimizing a fitting error between a point cloud
and the marker's template to estimate the marker's pose. The proposed method
achieves millimeter error in translation and a few degrees in rotation. Due to
LiDAR returns' sparsity, the point cloud is lifted to a continuous function in
a reproducing kernel Hilbert space where the inner product can be used to
determine a marker's ID. The experimental results, verified by a motion capture
system, confirm that the proposed method can reliably provide a tag's pose and
unique ID code. The rejection of false positives is validated on the Google
Cartographer indoor dataset and the Honda H3D outdoor dataset. All
implementations are coded in C++ and are available at:
https://github.com/UMich-BipedLab/LiDARTag.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 22:10:39 GMT""},{""version"":""v2"",""created"":""Tue, 3 Nov 2020 20:07:16 GMT""},{""version"":""v3"",""created"":""Sat, 13 Feb 2021 22:33:19 GMT""}]","2021-04-05"
"1908.10674","Joydeep Basu","Joydeep Basu","From design to tape-out in SCL 180nm CMOS integrated circuit fabrication
  technology","This is preprint of article accepted for publication in IETE Journal
  of Education, published by Taylor & Francis. Available online at:
  https://doi.org/10.1080/09747338.2019.1657787",,"10.1080/09747338.2019.1657787",,"eess.SP","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Although India has achieved considerable capability in electronic chip
design, but developing the infrastructure for capital-intensive semiconductor
fabrication remains a challenge. The rising domestic and global demand for
electronics products, the need of enhancing the country's high-technology
talent pool, employment generation, and national security concerns dictates the
Indian Government's heightened efforts in promoting electronics hardware
manufacturing in the country. A recent milestone in this regard is the setting
up of 180nm CMOS fabrication facility at SCL, Chandigarh. The Multi Project
Wafer runs of this indigenous foundry promises to be a relatively
cost-effective option for Indian academic and R&D institutions in realizing
their designed VLSI circuits. Written from the perspective of an Analog VLSI
designer, this tutorial paper strives to provide all the requisite information
and guidance that might be required in order to prepare chip designs for
submission to SCL for fabrication.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 12:54:37 GMT""}]","2019-08-29"
"1908.10834","Ang Li","Tong Geng, Ang Li, Runbin Shi, Chunshu Wu, Tianqi Wang, Yanfei Li,
  Pouya Haghi, Antonino Tumeo, Shuai Che, Steve Reinhardt, Martin Herbordt","AWB-GCN: A Graph Convolutional Network Accelerator with Runtime Workload
  Rebalancing",,,,,"cs.DC cs.LG","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Deep learning systems have been successfully applied to Euclidean data such
as images, video, and audio. In many applications, however, information and
their relationships are better expressed with graphs. Graph Convolutional
Networks (GCNs) appear to be a promising approach to efficiently learn from
graph data structures, having shown advantages in many critical applications.
As with other deep learning modalities, hardware acceleration is critical. The
challenge is that real-world graphs are often extremely large and unbalanced;
this poses significant performance demands and design challenges.
  In this paper, we propose Autotuning-Workload-Balancing GCN (AWB-GCN) to
accelerate GCN inference. To address the issue of workload imbalance in
processing real-world graphs, three hardware-based autotuning techniques are
proposed: dynamic distribution smoothing, remote switching, and row remapping.
In particular, AWB-GCN continuously monitors the sparse graph pattern,
dynamically adjusts the workload distribution among a large number of
processing elements (up to 4K PEs), and, after converging, reuses the ideal
configuration. Evaluation is performed using an Intel D5005 FPGA with five
commonly-used datasets. Results show that 4K-PE AWB-GCN can significantly
elevate PE utilization by 7.7x on average and demonstrate considerable
performance speedups over CPUs (3255x), GPUs (80.3x), and a prior GCN
accelerator (5.1x).
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 17:18:49 GMT""},{""version"":""v10"",""created"":""Fri, 11 Sep 2020 01:50:22 GMT""},{""version"":""v2"",""created"":""Wed, 27 Nov 2019 00:55:01 GMT""},{""version"":""v3"",""created"":""Fri, 21 Feb 2020 04:14:59 GMT""},{""version"":""v4"",""created"":""Sat, 29 Feb 2020 01:27:39 GMT""},{""version"":""v5"",""created"":""Thu, 30 Apr 2020 04:58:53 GMT""},{""version"":""v6"",""created"":""Thu, 30 Jul 2020 21:41:06 GMT""},{""version"":""v7"",""created"":""Fri, 14 Aug 2020 02:01:00 GMT""},{""version"":""v8"",""created"":""Sun, 6 Sep 2020 16:17:54 GMT""},{""version"":""v9"",""created"":""Thu, 10 Sep 2020 15:52:32 GMT""}]","2020-09-14"
"1908.11342","Alex Shkotin","Alex Shkotin","Quantifiers metamorphoses. Generalizations, variations, algorithmic
  semantics","6 pages",,,,"cs.LO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  This article contains ideas and their elaboration for quantifiers, which
appeared after checking in practice the experimental language of the formal
knowledge representation YAFOLL [1]: - looking at for_all and exists
quantifiers as operators clarifying two trivial properties of a function: the
constancy of result value and presence of a value in the result; -It turned out
that the quantifier term can be written in the lambda calculus technique, i.e.
as definition; -quantifier of quantity # is introduced into the language, as
needed in practice and does not cause logical and algorithmic problems on
finite structures; - the quantifier of the sum is mentioned because it is a
quantifier of the language; -algorithmic semantics is written for for_all and
exists quantifiers as an introduction to the topic.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 10:24:16 GMT""}]","2019-08-30"
"1908.11450","Siqi Wang","Siqi Wang, Anuj Pathania, Tulika Mitra","Neural Network Inference on Mobile SoCs","Accepted to IEEE Design & Test","in IEEE Design & Test, vol. 37, no. 5, pp. 50-57, Oct. 2020","10.1109/MDAT.2020.2968258",,"cs.LG cs.DC stat.ML","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  The ever-increasing demand from mobile Machine Learning (ML) applications
calls for evermore powerful on-chip computing resources. Mobile devices are
empowered with heterogeneous multi-processor Systems-on-Chips (SoCs) to process
ML workloads such as Convolutional Neural Network (CNN) inference. Mobile SoCs
house several different types of ML capable components on-die, such as CPU,
GPU, and accelerators. These different components are capable of independently
performing inference but with very different power-performance characteristics.
In this article, we provide a quantitative evaluation of the inference
capabilities of the different components on mobile SoCs. We also present
insights behind their respective power-performance behavior. Finally, we
explore the performance limit of the mobile SoCs by synergistically engaging
all the components concurrently. We observe that a mobile SoC provides up to 2x
improvement with parallel inference when all its components are engaged, as
opposed to engaging only one component.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 07:13:57 GMT""},{""version"":""v2"",""created"":""Wed, 22 Jan 2020 16:03:15 GMT""}]","2021-02-03"
"1908.11852","Endre Kov\'acs Dr","Endre Kov\'acs, Andr\'as Gilicz","New stable method to solve heat conduction problems in extremely large
  systems","9 pages","Design of Machines and Structures, Vol. 8, No. 2, 2018",,,"cs.CE cs.NA math.NA physics.comp-ph physics.data-an physics.flu-dyn","http://creativecommons.org/publicdomain/zero/1.0/","  We present a new explicit and stable numerical algorithm to solve the
homogeneous heat equation. We illustrate the performance of the new method in
the cases of two 2D systems with highly inhomogeneous random parameters.
Spatial discretization of these problems results in huge and stiff ordinary
differential equation systems, which can be solved by our novel method faster
than by explicit or the commonly used implicit methods.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 08:08:22 GMT""}]","2019-09-02"
"1909.01735","Mohammad Akbari","Mohammad Akbari and Rumi Chunara","Using Contextual Information to Improve Blood Glucose Prediction","17 pages, 3 figures",,,,"stat.ML cs.LG q-bio.QM","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Blood glucose value prediction is an important task in diabetes management.
While it is reported that glucose concentration is sensitive to social context
such as mood, physical activity, stress, diet, alongside the influence of
diabetes pathologies, we need more research on data and methodologies to
incorporate and evaluate signals about such temporal context into prediction
models. Person-generated data sources, such as actively contributed surveys as
well as passively mined data from social media offer opportunity to capture
such context, however the self-reported nature and sparsity of such data mean
that such data are noisier and less specific than physiological measures such
as blood glucose values themselves. Therefore, here we propose a Gaussian
Process model to both address these data challenges and combine blood glucose
and latent feature representations of contextual data for a novel multi-signal
blood glucose prediction task. We find this approach outperforms common methods
for multi-variate data, as well as using the blood glucose values in isolation.
Given a robust evaluation across two blood glucose datasets with different
forms of contextual information, we conclude that multi-signal Gaussian
Processes can improve blood glucose prediction by using contextual information
and may provide a significant shift in blood glucose prediction research and
practice.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:02:52 GMT""}]","2019-09-05"
"1909.02943","Ce Xu","Weiping Wang, Ce Xu","Alternating multiple zeta values, and explicit formulas of some
  Euler-Apery-type series",,,,,"math.NT","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  In this paper, we study some Euler-Ap\'ery-type series which involve central
binomial coefficients and (generalized) harmonic numbers. In particular, we
establish elegant explicit formulas of some series by iterated integrals and
alternating multiple zeta values. Based on these formulas, we further show that
some other series are reducible to ln(2), zeta values, and alternating multiple
zeta values by considering the contour integrals related to gamma functions,
polygamma functions and trigonometric functions. The evaluations of a large
number of special Euler-Ap\'ery-type series are presented as examples.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 15:59:10 GMT""},{""version"":""v2"",""created"":""Wed, 11 Sep 2019 05:32:50 GMT""},{""version"":""v3"",""created"":""Mon, 21 Oct 2019 00:13:52 GMT""}]","2019-10-22"
"1909.05214","Baichuan Huang","Baichuan Huang, Jun Zhao, Jingbin Liu","A Survey of Simultaneous Localization and Mapping with an Envision in 6G
  Wireless Networks","Comments are welcome and can be sent to email addresses in the paper",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Simultaneous Localization and Mapping (SLAM) achieves the purpose of
simultaneous positioning and map construction based on self-perception. The
paper makes an overview in SLAM including Lidar SLAM, visual SLAM, and their
fusion. For Lidar or visual SLAM, the survey illustrates the basic type and
product of sensors, open source system in sort and history, deep learning
embedded, the challenge and future. Additionally, visual inertial odometry is
supplemented. For Lidar and visual fused SLAM, the paper highlights the
multi-sensors calibration, the fusion in hardware, data, task layer. The open
question and forward thinking with an envision in 6G wireless networks end the
paper. The contributions of this paper can be summarized as follows: the paper
provides a high quality and full-scale overview in SLAM. It's very friendly for
new researchers to hold the development of SLAM and learn it very obviously.
Also, the paper can be considered as a dictionary for experienced researchers
to search and find new interesting orientation.
","[{""version"":""v1"",""created"":""Sat, 24 Aug 2019 11:41:05 GMT""},{""version"":""v2"",""created"":""Sat, 12 Oct 2019 12:03:06 GMT""},{""version"":""v3"",""created"":""Wed, 1 Jan 2020 01:12:38 GMT""},{""version"":""v4"",""created"":""Fri, 14 Feb 2020 08:07:24 GMT""}]","2020-02-17"
"1911.06632","Hossein Sharifi","Hossein Sharifi, William C. Black","Identification Algorithm to Determine the Trajectory of Robots with
  Singularities","4 pages, 30 equations, accepted in the international robotics
  conference USA",,,,"cs.RO","http://arxiv.org/licenses/nonexclusive-distrib/1.0/","  Singularity in robot controls is an important problem. By identifying an
appropriate trajectory for the robots, the singular situations can be avoided.
In this paper an identification algorithm is proposed to control the robot such
that it can change its direction to avoid the singularity situation. Base on
the singular value decomposition, the proposed algorithm is developed for the
non-redundant, single-rank robots. The proposed method is employed on a robot
with six degrees of freedom, in order to identify its feasible trajectory.
  Keywords: Singularity; Trajectory identification; Robot control;
Identification algorithm; Singular value decomposition.
","[{""version"":""v1"",""created"":""Fri, 23 Aug 2019 18:34:25 GMT""}]","2019-11-18"
